<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>📝 Paper Notes on SwimmingLiu&#39;s Blog</title>
    <link>https://swimmingliu.github.io/categories/paper-notes/</link>
    <description>Recent content in 📝 Paper Notes on SwimmingLiu&#39;s Blog</description>
    <image>
      <title>SwimmingLiu&#39;s Blog</title>
      <url>https://swimmingliu.github.io/papermod-cover.png</url>
      <link>https://swimmingliu.github.io/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 12 Nov 2023 16:32:06 +0800</lastBuildDate><atom:link href="https://swimmingliu.github.io/categories/paper-notes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ACC-UNet: A Completely Convolutional UNet model for the 2020s (MICCAI2023)</title>
      <link>https://swimmingliu.github.io/posts/papernotes/2023-acc-unet/</link>
      <pubDate>Sun, 12 Nov 2023 16:32:06 +0800</pubDate>
      
      <guid>https://swimmingliu.github.io/posts/papernotes/2023-acc-unet/</guid>
      <description>ACC-UNet: A Completely Convolutional UNet model for the 2020s (MICCAI2023) 1. Abstract 由于ViT （Vision Transformer）的引入，UNet和Transformer融合已成为大趋势。最近，又有很多研究人员开始重新思考卷积模型，比如将ConvNext嵌入到ResNet，能够达到Swin Transformer的水平。受此启发，作者提出了一个纯粹的卷积UNET模型 （ACC-UNet），并且超越基于Transfomer的模型(如Swin-UNET或UCTransNet)。 作者研究了基于Transfomer的UNET模型优点：长范围依赖关系和跨级别跳过连接。 ACC-UNet结合了卷积神经网络（ConvNets）的内在归纳偏差和Transformer的设计决策 卷积神经网络（ConvNets）的内在归纳偏差：卷积神经网络具有天生的归纳偏差，这意味着它们在处理图像等数据时具有一些固有的假设和特点。例如，卷积神经网络擅长处理局部特征、平移不变性等，这些特点使它们在图像处理任务中表现出色。 Transformer的设计决策：Transformer是一种不同的神经网络架构，它采用了一些独特的设计决策，例如自注意力机制和位置编码等。这些设计决策使得Transformer在处理长距离依赖性、全局关系等方面表现出色，适合处理序列数据和具有远程依赖的任务。 ACC-UNet 在 5 个不同的医学图像分割基准上进行了评估，并且始终优于卷积网络、Transfomer及其混合网络。
2.Introduction 语义分割是计算机辅助医学图像分析的重要组成部分，可识别并突出显示各种诊断任务中感兴趣的区域。然而，由于涉及图像模态和采集以及病理和生物变化的各种因素，这通常变得复杂[18]。深度学习在这一领域的应用无疑在这方面受益匪浅。最值得注意的是，自推出以来，UNet 模型 [19] 在医学图像分割方面表现出了惊人的功效。结果，UNet 及其衍生品已成为事实上的标准[25]。
学习一下这里的背景描述
原始的 UNet 模型包含对称的编码器-解码器架构（图 1a）并采用跳跃连接，这为解码器提供了在编码器的池化操作期间可能丢失的空间信息。尽管通过简单串联的信息传播提高了性能，但编码器-解码器特征图之间可能存在语义差距。这导致了第二类 UNet 的发展（图 1b）。 U-Net++ [26] 利用密集连接，而 MultiResUNet [11] 在跳过连接上添加了额外的卷积块作为潜在的补救措施。到目前为止，UNet 的历史上所有创新都是使用 CNN 进行的。然而，2020 年的十年给计算机视觉领域带来了根本性的变化。 CNN 在视觉领域的长期主导地位被视觉转换器打破了 [7]。 Swin Transformers [15] 进一步针对一般视觉应用调整了变压器。因此，UNet 模型开始采用 Transformer [5]。 Swin-Unet [9] 用 Swin Transformer 块取代了卷积块，从而开创了一类新的模型（图 1c）。尽管如此，CNN 在图像分割方面仍然具有各种优点，导致了融合这两者的发展[2]。这种混合类 UNet 模型（图 1d）在编码器-解码器中采用卷积块，并沿跳跃连接使用变换器层。 UCTransNet [22]和MCTrans[24]是此类的两个代表性模型。最后，还尝试开发全变压器 UNet 架构（图 1e），例如，SMESwin Unet [27] 在编码器-解码器块和跳跃连接中都使用变压器。</description>
    </item>
    
    <item>
      <title>M2SNet: Multi-scale in Multi-scale Subtraction Network for Medical Image Segmentation</title>
      <link>https://swimmingliu.github.io/posts/papernotes/2023-m2snet/</link>
      <pubDate>Sun, 12 Nov 2023 16:25:03 +0800</pubDate>
      
      <guid>https://swimmingliu.github.io/posts/papernotes/2023-m2snet/</guid>
      <description>(2023) M2SNet: 新颖多尺度模块 + 智能损失函数 = 通用图像分割SOTA网络 Abstract 准确的医学图像分割对于早期医学诊断至关重要。大多数现有方法基于U形结构，并使用逐元素加法或串联在解码器中逐步融合不同级别的特征。然而，这两种操作都容易产生大量冗余信息，从而削弱不同级别特征之间的互补性，导致病灶定位不准确和边缘模糊。为了应对这一挑战，我们提出了一种通用的多尺度减法网络（M2SNet）来完成医学图像的多样化分割。具体来说，我们首先设计一个基本减法单元（SU）来产生编码器中相邻级别之间的差异特征。接下来，我们将单尺度 SU 扩展到层内多尺度 SU，它可以为解码器提供像素级和结构级差异信息。
然后，我们金字塔式地为不同层次的多尺度SU配备不同的感受野，从而实现层间多尺度特征聚合并获得丰富的多尺度差异信息。此外，我们构建了一个免训练网络“LossNet”来全面监督从底层到顶层的任务感知特征，这驱动我们的多尺度减法网络同时捕获细节和结构线索。
没有花里胡哨的东西，我们的方法在不同的评估指标下，在不同图像模态的四种不同医学图像分割任务的 11 个数据集上表现优于大多数最先进的方法，包括彩色结肠镜成像、超声成像、计算机断层扫描 (CT) ）和光学相干断层扫描（OCT）。
两个主要创新点：多尺度金字塔减法单元 （确实牛逼）+ LossNet（为了创新而创新的损失函数）
Introduction 作为计算机辅助诊断系统中的重要作用，精确的医学图像分割技术可以为医生做出临床决策提供重要指导。精确分割存在三个普遍的挑战：首先，U形结构[1]、[2]由于其利用多级信息重建高分辨率特征图的能力而受到了相当多的关注。在UNet [2]中，上采样的特征图与从编码器跳过的特征图连接在一起，并在上采样步骤之间添加卷积和非线性，如图1（a）所示。后续基于UNet的方法通过注意力机制[3]、[4]、门机制[5]、[6]、变压器技术[7]、[8]设计不同的特征增强模块，如图1（b）所示。 UNet++[9]使用嵌套和密集的跳跃连接来减少编码器和解码器的特征图之间的语义差距，如图1（c）所示。
先说医学分割在医学领域重要&amp;hellip;(balabala) 然后当前领域存在xxx挑战&amp;hellip;(balabala)
这里是以医学图像分割挑战的视角，介绍UNet发展的情况。然后在描述不同UNet变体发展过程中解决的不同问题（感觉可以借鉴）
一般来说，编码器中不同级别的特征有不同的特征。高级别具有更多的语义信息，有助于定位对象，而低级别具有更详细的信息，可以捕捉对象的微妙边界。解码器利用特定级别和跨级别特征来生成最终的高分辨率预测。然而，上述方法直接使用逐元素加法或串联来融合来自编码器的任意两级特征并将它们传输到解码器。这些简单的操作并没有更多地关注不同层次之间的差异信息。这一缺点不仅会产生冗余信息来稀释真正有用的特征，还会削弱特定于级别的特征的特性，从而导致网络无法平衡精确定位和微妙的边界细化。其次，由于感受野有限，单尺度卷积核很难捕获大小变化物体的上下文信息。一些方法[1]、[2]、[9]-[11]依赖于层间多尺度特征，并逐步整合来自不同尺度表示的语义上下文和纹理细节。其他人[6]、[12]-[15]专注于基于网络中的空洞空间金字塔池化模块[16]（ASPP）或DenseASPP [17]提取层内多尺度信息。然而，类似ASPP的多尺度卷积模块会产生许多额外的参数和计算。许多方法[5]、[18]-[21]通常将多个ASPP模块安装到不同级别的编码器/解码器块中，而有些方法[13]、[14]、[22]、[23]将其安装在不同级别的编码器/解码器块中。最高级别的编码器块。第三，损失函数的形式直接为网络的梯度优化提供了方向。在分割领域，提出了许多损失函数来监督不同级别的预测，例如像素级别的L1损失、交叉熵损失和加权交叉熵损失[24]，SSIM[25]损失区域层面的不确定性损失[26]，全局层面的IoU损失、Dice损失和一致性增强损失[11]。尽管这些基本损失函数及其变体具有不同的优化特性，但复杂的手动数学形式的设计对于许多研究来说确实非常耗时。为了获得综合性能，模型通常会集成多种损失函数，这对研究人员的训练技能提出了很高的要求。因此，我们认为有必要引入一种无需复杂人工设计的智能损失函数来全面监督分割预测。
在本文中，我们提出了一种用于一般医学图像分割的新型多尺度减法网络（M2SNet）。首先，我们设计一个减法单元（SU）并将其应用于每对相邻的级别特征。 SU突出了特征之间有用的差异信息，并消除了冗余部分的干扰。其次，我们借助所提出的多尺度减法模块收集极端多尺度信息。
对于层间多尺度信息，我们以金字塔方式连接多个减法单元来捕获大跨度的跨层信息。然后，我们聚合特定于级别的特征和多路径跨级别差分特征，然后在解码器中生成最终预测。对于层内多尺度信息，我们通过一组不同内核大小的full one滤波器将单尺度减法单元改进为多尺度减法单元，可以自然地实现多尺度减法聚合，而无需引入额外的参数。如图1所示，MSNet配备了层间多尺度减法模块，M2SNet同时具有层间和层内多尺度减法结构。第三，我们提出了一个LossNet来自动监督从底层到顶层提取的特征图，它可以通过简单的L2损失函数优化从细节到结构的分割。
多尺度减法单元可以去特征之间的差异信息，消除冗余干扰。
（也就是说可以用这种办法替换注意力机制）
RELATED WORK Medical Image Segmentation Network 根据不同器官或病变的特点，我们将现有的医学图像分割方法分为两类：医学通用的和医学专用的。随着U-Net[2]在医学图像分割领域取得稳定的性能，带有编码器-解码器的U形结构已成为基本的分割基线。 U-Net++[9]集成了长连接和短连接，可以减少编码器和解码器子网络的特征图之间的语义差距。对于注意力 U-Net [28]，注意力门嵌入在编码器和解码器块之间的每个过渡层中，它可以自动学习关注不同形状和大小的目标结构。最近，Transformer [29]架构在许多自然语言处理任务中取得了成功。一些作品[7]、[8]探讨了其对医学视觉任务的有效性。 UTNet [7] 是一种简单但功能强大的混合变压器架构，它在编码器和解码器中应用自注意力模块，以最小的开销捕获不同规模的远程依赖关系。另一个具有代表性的基于 Transformer 的模型是 TransUNet [8]，它通过将图像特征视为序列来编码强全局上下文，并通过 U 形混合架构设计利用低级 CNN 特征。
医学特定方法。在息肉分割任务中，SFA [30]和PraNet [4]专注于恢复息肉与其周围粘膜之间的清晰边界。前者提出了共享编码器和两个相互约束的解码器下的选择性特征聚合结构和边界敏感损失函数。后者利用反向注意模块来建立区域和边界线索之间的关系。此外，Ji等人[31]利用时空信息构建视频息肉分割模型。在COVID-19肺部感染任务中，Paluru等人[32]提出了一种基于变形深度嵌入的轻量级CNN来分割COVID-19胸部CT图像中的异常。 Inf-Net [33] 构建隐式反向注意力和显式边缘注意力来对边界进行建模。 BCS-Net [34]具有三个渐进边界上下文语义重建块，可以帮助解码器捕获肺部感染的零散区域。在乳腺分割任务中，Byra等人[35]通过注意力机制开发了选择性核来调整U-Net的感受野，可以进一步提高乳腺肿瘤的分割精度。 Chen 等人 [36] 提出了一种嵌套 U 网，通过利用不同的深度和共享权重来实现乳腺肿瘤的稳健表示。</description>
    </item>
    
    <item>
      <title>EGE-UNet: an Efficient Group Enhanced UNet for skin lesion segmentation</title>
      <link>https://swimmingliu.github.io/posts/papernotes/2023-ege-unet%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Sat, 11 Nov 2023 19:51:21 +0800</pubDate>
      
      <guid>https://swimmingliu.github.io/posts/papernotes/2023-ege-unet%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</guid>
      <description>EGE-UNet: an Efficient Group Enhanced UNet for skin lesion segmentation 1. Abstract 目前的医学图像分割模型大多是 Transformer + Unet，这些模型的大量参数和计算负载使得它们不适合移动健康应用。
作者提出的EGE-UNet 模型轻量、高效。（与 TransFuse 相比，参数和计算成本分别降低了 494 倍和 160 倍，模型参数量只有50KB）
创新点：组多轴哈达玛产品注意力模块（GHPA）和组聚合桥模块（GAB）。
1.GHPA 对输入特征进行分组，并在不同轴上执行哈达玛产品注意力机制（HPA），以从不同角度提取病理信息。
2.GAB 通过对低级特征、高级特征以及解码器在每个阶段生成的掩码进行分组，有效地融合了多尺度信息。
2. Introduction 背景: 恶性黑色素瘤是世界上增长最快的癌症之一。据美国癌症协会估计，2020 年约有 100,350 例新发病例，超过 6,500 例死亡。因此，自动化皮肤病变分割系统势在必行，因为它可以帮助医疗专业人员快速识别病变区域并促进后续治疗过程。
相同方式可引入脑瘤、肺癌。
为了提高分割性能，最近的研究倾向于采用具有更大参数和计算复杂度的模块，例如结合视觉变换器（ViT）的自注意力机制[7]。例如，Swin-UNet [4]，基于Swin Transformer [11]，利用自注意力机制的特征提取能力来提高分割性能。 TransUNet [5] 开创了用于医学图像分割的 CNN 和 ViT 的串行融合。 TransFuse [26]采用双路径结构，利用 CNN 和 ViT 分别捕获局部和全局信息。UTNetV2[8]利用混合分层架构、高效的双向注意力和语义图来实现全局多尺度特征融合，结合了CNN和ViT的优点。 TransBTS [23] 将自注意力引入脑肿瘤分割任务中，并用它来聚合高级信息。
Abstract提到当前医学分割模型大部分是Transformer + Unet，这里做出具体阐述。
先前的工作通过引入复杂的模块来提高性能，但忽略了实际医疗环境中计算资源的限制。因此，迫切需要为移动医疗中的分割任务设计一种低参数、低计算负载的模型。最近，UNeXt [22] 结合了 UNet [18] 和 MLP [21] 开发了一种轻量级模型，该模型可以获得优异的性能，同时减少参数和计算量。此外，MALUNet [19]通过减少模型通道数并引入多个注意力模块来减小模型大小，从而比 UNeXt 具有更好的皮肤病变分割性能。然而，尽管MALUNet大大减少了参数数量和计算量，但其分割性能仍然低于一些大型模型，例如TransFuse。因此，在本研究中，我们提出了 EGE-UNet，这是一种轻量级皮肤病变分割模型，可实现最先进的效果，同时显着降低参数和计算成本。此外，据我们所知，这是第一个将参数减少到大约 50KB 的工作。</description>
    </item>
    
  </channel>
</rss>
