[{"content":"链表 1. 两数相加 题目链接：两数相加\n【思路】\n引入一个临时变量 carry 记录进位的值，默认是0。开一个新的链表 l ，同时遍历两个链表的值。l1.val + l2.val + carry = l.val。注意，最后有多余的进位时，要新增一个节点。\n整个过程可以用递归来实现，递归的边界条件是当 l1 、l2 为 null 且 carry 为 0 的时候 。然后，返回值是 new ListNode(carry % 10, addTwo(l1, l2, carry / 10)) 。其中, carry % 10 表示当前值， carry / 10 表示进位值。计算过程是l1 和 l2 都获取 val 和 carry 相加，并且向前遍历。\n【伪代码】\n// l1 和 l2 为当前遍历的节点，carry 为进位， 默认为0 private ListNode addTwo(ListNode l1, ListNode l2, int carry) { if (l1 == null \u0026amp;\u0026amp; l2 == null \u0026amp;\u0026amp; carry == 0) { // 递归边界 return null; } int s = carry; if (l1 != null) { s += l1.val; // 累加进位与节点值 l1 = l1.next; } if (l2 != null) { s += l2.val; l2 = l2.next; } // s 除以 10 的余数为当前节点值，商为进位 return new ListNode(s % 10, addTwo(l1, l2, s / 10)); } 2. 删除链表的倒数第 N 个结点 题目链接：删除链表的倒数第 N 个结点\n【思路】\n链表类型找倒数第 x 个节点，可以肌肉反应想到是用左右指针。右指针先走 x 步，然后左右指针一起向前遍历，直到右指针为 null ，则左指针位置就为倒数第 x 个节点。题目要删除倒数第 n 个节点，可以转换为找倒数第 n + 1 个节点。为了防止链表长度刚好为 n + 1， 可以让左右指针和额外的 dummy 指针指向头节点。然后用左指针找到倒数第 n + 1 个节点，删除后一个节点，最后返回 dummy 的下一个节点，就是头节点。\n【伪代码】\npublic ListNode removeNthFromEnd(ListNode head, int n) { // 由于可能会删除链表头部，用哨兵节点简化代码 ListNode dummy = new ListNode(0, head); ListNode left = dummy; ListNode right = dummy; while (n-- \u0026gt; 0) { right = right.next; // 右指针先向右走 n 步 } while (right.next != null) { left = left.next; right = right.next; // 左右指针一起走 } left.next = left.next.next; // 左指针的下一个节点就是倒数第 n 个节点 return dummy.next; } 3. 合并两个有序链表 题目链接：合并两个有序链表\n【思路】创建一个哨兵节点 dummy 和 新链表指针 cur，指向 dummy 对应的头 节点 。同时遍历两个有序链表，比较值的大小。将值小的节点作为 cur 的 next , 然后让 cur 和 值小的链表同时向前遍历一个。 最后，判断哪一个链表不会空，将其接到 cur 后面，再返回 dummy.next 即可。\n【伪代码】\npublic ListNode mergeTwoLists(ListNode list1, ListNode list2) { ListNode dummy = new ListNode(); // 用哨兵节点简化代码逻辑 ListNode cur = dummy; // cur 指向新链表的末尾 while (list1 != null \u0026amp;\u0026amp; list2 != null) { if (list1.val \u0026lt; list2.val) { cur.next = list1; // 把 list1 加到新链表中 list1 = list1.next; } else { // 注：相等的情况加哪个节点都是可以的 cur.next = list2; // 把 list2 加到新链表中 list2 = list2.next; } cur = cur.next; } cur.next = list1 != null ? list1 : list2; // 拼接剩余链表 return dummy.next; } 4. 合并K个升序链表 题目链接：合并K个升序链表\n【思路】\n要将K个升序链表合成一个升序链表，合成的顺序肯定是，依次找最小的节点。第一个最小的节点，肯定是在某个升序链表的表头。但是，第二个最小的节点，可能是在升序链表的表头，也可能是第一个最小节点的后一个节点。\n所以合并顺序就是从 K 数中找出最小的值加入新链表，然后插入最小节点的后一个节点，反复执行这个步骤。其实就是一个最小堆的概念。所以，我们只需要维护一个最小堆，先将 K 个链表的表头节点插入最小堆。然后选出最小节点加入新链表，再将最小节点的后一个节点加入最小堆里面。反复执行上面的操作，直到最小堆中所有值被取出来，就组成了新的链表。\n【伪代码】\n【注】new PriorityQueue\u0026lt;\u0026gt;((a, b) -\u0026gt; a.val - b.val) 中，PriorityQueue 的优先级取决于 lambda 表达式的正负。如果 lambda 表达式为负数，则优先级高，反之亦然。\npublic ListNode mergeKLists(ListNode[] lists) { // 用PriorityQueue优先队列构建最小堆 PriorityQueue\u0026lt;ListNode\u0026gt; pq = new PriorityQueue\u0026lt;\u0026gt;((a, b) -\u0026gt; a.val - b.val); for (ListNode head : lists) { if (head != null) { pq.offer(head); // 把所有非空链表的头节点入堆 } } ListNode dummy = new ListNode(); // 哨兵节点，作为合并后链表头节点的前一个节点 ListNode cur = dummy; while (!pq.isEmpty()) { // 循环直到堆为空 ListNode node = pq.poll(); // 剩余节点中的最小节点 if (node.next != null) { // 下一个节点不为空 pq.offer(node.next); // 下一个节点有可能是最小节点，入堆 } cur.next = node; // 把 node 添加到新链表的末尾 cur = cur.next; // 准备合并下一个节点 } return dummy.next; // 哨兵节点的下一个节点就是新链表的头节点 } 5. 环形链表 题目链接：环形链表\n【思路】\n判断是否有链表是否有环形可以采用快慢指针，可以参考龟兔赛跑。如果乌龟和兔子同时出发，跑道是环形的，那么兔子一定会追上乌龟。同样，一个有环形的链表，快指针一定可以追上慢指针。\n【伪代码】\npublic boolean hasCycle(ListNode head) { ListNode slow = head, fast = head; // 乌龟和兔子同时从起点出发 while (fast != null \u0026amp;\u0026amp; fast.next != null) { slow = slow.next; // 乌龟走一步 fast = fast.next.next; // 兔子走两步 if (fast == slow) { // 兔子追上乌龟（套圈），说明有环 return true; } } return false; // 访问到了链表末尾，无环 } 6. 环形链表 II 题目链接：环形链表 II\n【口诀记忆】快慢相遇，头慢同步。 再会之处，便是环口。\n【思路】\n二级结论：环形链表的入环位置就是快慢指针相遇后，慢指针和头指针相遇的位置。\n分析：假设快慢指针相遇的时候，慢指针走了 b 步，快指针走了 2b 步，再设入环的位置需要走 a 步，环的长度为 c 。 因为快指针和慢指针都会走入环的这段距离 ( a 步)，剩下的路程都是在环内绕圈。则他们相差的距离 2b - b = kc （龟兔赛跑中，兔子一定比乌龟多跑 k 圈，才会相遇）-\u0026gt; b = kc。又因为 b - a = kc - a -\u0026gt; (b - a) + a = (kc - a) + a = kc，其中 b - a 是快慢指针第一次相遇，慢指针在环中走的步数。走 kc步，刚好回到起点。 说明从相遇位置再走 a 步就是入环的位置。\n注 1：因为 (kc − a) + a = kc，从 kc − a 开始，再走 a 步，就可以走满 k 圈。想象你在操场上跑步，从入环口开始跑，跑满 k 圈，你现在人在哪？刚好在入环口。\n注 2：慢指针从相遇点开始，移动 a 步后恰好走到入环口，但在这个过程中，可能会多次经过入环口。\n【伪代码】\npublic ListNode detectCycle(ListNode head) { ListNode slow = head, fast = head; while (fast != null \u0026amp;\u0026amp; fast.next != null) { slow = slow.next; fast = fast.next.next; if (fast == slow) { // 相遇 while (slow != head) { // 再走 a 步 (头指针走a步 = 慢指针从相遇位置走a步) slow = slow.next; head = head.next; } return slow; } } return null; } 7. 排序链表 题目链接：排序链表\n【思路】\n按照分而治之的思想，将链表从中间分为两段，确保左右两段都有序。再合并两个有序链表即可。对于两段链表进行排序，可以再采取这个思路，将链表分为两段有序链表，再进行合并。一直划分到只有一个节点或者链表没有节点（奇数个）为止 链表找中点：快慢指针一起走，快指针结束，慢指针刚好在中点 合并两个有序链表：双指针比较大小 【复杂度分析】\n时间复杂度：O(nlogn)，其中 n 是链表长度。递归式 T(n) = 2T(n/2) + O(n)，由主定理可得时间复杂度为 O(nlogn)。 空间复杂度：O(logn)。递归需要 O(logn) 的栈开销。 【伪代码】\npublic ListNode sortList(ListNode head) { // 如果链表为空或者只有一个节点，无需排序 if (head == null || head.next == null) { return head; } // 找到中间节点 head2，并断开 head2 与其前一个节点的连接 // 比如 head=[4,2,1,3]，那么 middleNode 调用结束后 head=[4,2] head2=[1,3] ListNode head2 = middleNode(head); // 分别排序左边和右边 head = sortList(head); head2 = sortList(head2); // 合并 -\u0026gt; 双指针 + 比较大小 return mergeTwoLists(head, head2); } 8. 相交链表 题目链接：相交链表\n【思路】\n简单总结：两个人从不同的地方来，同时走过一段旅程之后，从另外一个人的源头再走一遍，一定会重逢。如果没有重逢说明，他们没有一起走过的旅程。\n【伪代码】\npublic ListNode getIntersectionNode(ListNode headA, ListNode headB) { ListNode p = headA; ListNode q = headB; while (p != q) { p = p != null ? p.next : headB; q = q != null ? q.next : headA; } return p; } 9. 反转链表 题目链接：反转链表\n【思路】\n使用头节点的头插法，创建一个新的 dummy 节点，然后采用头插法将元素插入dummy 后面，最后dummpy.next 就是逆序后的头节点\n【伪代码】\npublic ListNode reverseList(ListNode head) { ListNode dummy = new ListNode(); ListNode cur = head; while (cur != null) { ListNode nxt = cur.next; cur.next = dummy.next; dummy.next = cur; cur = nxt; } return dummy.next; } 【第二种思路】\n直接使用头插法，将后面一个节点放到当前节点的前面，同时将当前节点的下一个节点替换为上一个节点。\n【为代码】\npublic ListNode reverseList(ListNode head) { ListNode pre = null; ListNode cur = head; while (cur != null) { ListNode nxt = cur.next; cur.next = pre; pre = cur; cur = nxt; } return pre; } 10. 回文链表 题目链接：回文链表\n【思路】\n这道题应该拆分为两道题来做，一个是找中间节点（快慢指针） + 后半部分链表反转。然后从中间节点开始比较，如果有某一处不相同就返回 false， 否则最后返回 true\n【伪代码】\npublic boolean isPalindrome(ListNode head) { ListNode mid = middleNode(head); // 寻找中间节点 ListNode head2 = reverseList(mid); // 反转链表 while (head2 != null) { if (head.val != head2.val) { // 不是回文链表 return false; } head = head.next; head2 = head2.next; } return true; } 二叉树 1. 二叉树的中序遍历 题目链接：二叉树的中序遍历\n【思路】\n中序遍历：左根右，遍历过程：上下递归，中间输出，边界条件是空\n【伪代码】\nvoid dfs(List\u0026lt;Integer\u0026gt; res, TreeNode root) { if(root==null) { return; } //按照 左-打印-右的方式遍历 dfs(res,root.left); res.add(root.val); dfs(res,root.right); } 2. 验证二叉搜索树 题目链接：验证二叉搜索树\n【思路】\n二叉搜索树就是根比左边大，比右边小。所以可以采用先序遍历的方式，传入左边合右边的值。递归遍历当前节点和左边节点、右边节点是否都符合规则。如果不符合，则输出 fasle。\n【伪代码】\npublic boolean isValidBST(TreeNode root) { return isValidBST(root, Long.MIN_VALUE, Long.MAX_VALUE); } private boolean isValidBST(TreeNode node, long left, long right) { if (node == null) { return true; } long x = node.val; return left \u0026lt; x \u0026amp;\u0026amp; x \u0026lt; right \u0026amp;\u0026amp; isValidBST(node.left, left, x) \u0026amp;\u0026amp; isValidBST(node.right, x, right); } 3. 对称二叉树 题目链接：对称二叉树\n【思路】\n对称二叉树：二叉树相对轴是对称的\n判断方法是递归判断当前节点的左右节点是否满足轴对称条件。两个节点左右对称的条件是 l.left = r.right \u0026amp;\u0026amp; l.right == r.left 。边界判断条件为左右节点是否均为空，如果为空说明父节点是叶子节点，表明 满足轴对称。如果只有一个节点为空，或者两个节点的值不同，则说明他们不是轴堆成的。如果左右节点都有值且相同，则继续往下递归。\n【伪代码】\npublic boolean isSymmetric(TreeNode root) { return root == null || recur(root.left, root.right); } boolean recur(TreeNode L, TreeNode R) { if (L == null \u0026amp;\u0026amp; R == null) return true; if (L == null || R == null || L.val != R.val) return false; return recur(L.left, R.right) \u0026amp;\u0026amp; recur(L.right, R.left); } 4. 二叉树的层序遍历 题目链接：二叉树的层序遍历\n【思路】\n二叉树的层序遍历就是用队列的方式实现，具体可以使用 ArrayDeque 来存储节点。每次循环都统计队列的大小 (表示有多少个同级的节点)，然后将这些节点放入数组中，并且将他们的左右子节点放入队列中，循环直到队列为空才结束。\n【伪代码】\npublic List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; levelOrder(TreeNode root) { if (root == null) { return List.of(); } List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; ans = new ArrayList\u0026lt;\u0026gt;(); Queue\u0026lt;TreeNode\u0026gt; q = new ArrayDeque\u0026lt;\u0026gt;(); q.add(root); while (!q.isEmpty()) { int n = q.size(); List\u0026lt;Integer\u0026gt; vals = new ArrayList\u0026lt;\u0026gt;(n); // 预分配空间 while (n-- \u0026gt; 0) { TreeNode node = q.poll(); vals.add(node.val); if (node.left != null) q.add(node.left); if (node.right != null) q.add(node.right); } ans.add(vals); } return ans; } 5. 二叉树的最大深度 题目链接：二叉树的最大深度\n【思路】\n最大深度可以采用后序遍历、先序遍历或者层序遍历，不过一般都使用后序遍历或者先序遍历来做。可以按照先序遍历和后序遍历分为两种方案，一种是自顶向下，一种是自底向上的方式。\n自顶向下 (先序遍历)：先设置 depth 为 0，用一个全局的 answer 来记录答案。按照后序遍历的顺序，一定能遍历到最下面的一层，每次讲 answer 更新为最大深度即可。 自底向上 (后序遍历)：采用后序遍历递归获取左右节点的最长深度，加上当前层的深度就是二叉树的最大深度 【伪代码】\n// 自顶向下：先序遍历，ans是全局变量 public int maxDepth(TreeNode root) { dfs(root, 0); return ans; } private void dfs(TreeNode node, int depth) { if (node == null) { return; } depth++; ans = Math.max(ans, depth); dfs(node.left, depth); dfs(node.right, depth); } // 自底向上：后序遍历 public int maxDepth(TreeNode root) { if (root == null) { return 0; } int lDepth = maxDepth(root.left); int rDepth = maxDepth(root.right); return Math.max(lDepth, rDepth) + 1; } 6. 从前序与中序遍历序列构造二叉树 题目链接：从前序与中序遍历序列构造二叉树\n【思路】\n手推：先按照手推的方式思考，用先序和中序构成二叉树的方法：先序列表用于确定根节点，中序列表用于确定左右子树。然后逐个确定每一层的根节点，及其左右子树。\n程序：分析手推的方式可以发现确定每一层根节点及其左右子树的方法是重复的，可以采用递归的方式完成。所以我们可以先通过先序找到根节点的位置，再按照根节点的位置将先序列表和中序列表一分为二。然后分别将先序和中序的两个左子树数组进行递归构建，再将两个右子树数组进行递归构建。\n【伪代码】\npublic TreeNode buildTree(int[] preorder, int[] inorder) { int n = preorder.length; if (n == 0) { // 空节点 return null; } int leftSize = indexOf(inorder, preorder[0]); // 左子树的大小 int[] pre1 = Arrays.copyOfRange(preorder, 1, 1 + leftSize); // 先序左子树 int[] pre2 = Arrays.copyOfRange(preorder, 1 + leftSize, n); // 先序右子树 int[] in1 = Arrays.copyOfRange(inorder, 0, leftSize); // 中序左子树 int[] in2 = Arrays.copyOfRange(inorder, 1 + leftSize, n); // 中序右子树 TreeNode left = buildTree(pre1, in1); TreeNode right = buildTree(pre2, in2); return new TreeNode(preorder[0], left, right); } // 获取左子树大小：返回 x 在 a 中的下标，保证 x 一定在 a 中 private int indexOf(int[] a, int x) { for (int i = 0; ; i++) { if (a[i] == x) { return i; } } } 7. 将有序数组转换为二叉搜索树 题目链接：将有序数组转换为二叉搜索树\n【思路】\n有序数组其实是二叉搜索树的中序遍历，则说明中间的位置就是根节点，左右两边的区间分别为左子树和右子树。从根节点开始，循环递归的构建左子树和右子树，就可以的到二叉搜索树。 【注】当数组长度 n 为偶数的时候，可以去中间左边的节点，也可以取中间右边的结果，所以答案不唯一。下面的伪代码是取得中间右边的节点。\n【伪代码】\npublic TreeNode sortedArrayToBST(int[] nums) { return dfs(nums, 0, nums.length); } // 把 nums[left] 到 nums[right-1] 转成平衡二叉搜索树 private TreeNode dfs(int[] nums, int left, int right) { if (left == right) { return null; } int m = (left + right) \u0026gt;\u0026gt;\u0026gt; 1; return new TreeNode(nums[m], dfs(nums, left, m), dfs(nums, m + 1, right)); } 8. 二叉树展开为链表 题目链接：二叉树展开为链表\n【思路】\n将二叉树展开为链表（还是二叉树结构），其实是按照二叉树的先序遍历顺序进行展开(根-左-右)。如果要构建这个展开后的链表，可以按照相反的方向(右-左-根)的方向进行构建。\n只需要采用头插法，从相反方向(右-左-根)的第一个元素开始，用 pre 记录上一个节点，递归构建展开后的链表即可。\n【伪代码】\npublic void flatten(TreeNode root) { if (root == null) { return; } flatten(root.right); // 右节点 flatten(root.left); // 左节点 root.left = null; // 左子树置空 root.right = pre; // 头插法，相当于链表的 root.next = head pre = root; // 现在链表头节点是 root } 9. 翻转二叉树 题目链接：翻转二叉树\n【思路】\n翻转二叉树：翻转每个节点的左子树和右子树。所以，可以从根节点开始，递归翻转左子树和右子树，直到子树为空为止。\n【伪代码】\npublic TreeNode invertTree(TreeNode root) { if (root == null){ return null; } TreeNode left = invertTree(root.left); TreeNode right = invertTree(root.right); root.left = right; // 交换左右子树的值 root.right = left; return root; } 10. 二叉树的最近公共祖先 题目链接：二叉树的最近公共祖先\n对于有根树 T 的两个节点 p、q，最近公共祖先表示为一个节点 x，满足 x 是 p、q 的祖先且 x 的深度尽可能大（一个节点也可以是它自己的祖先）。\n【思路】\n分析：该题目需要找到两个节点的公共祖先，应该是一个从下往上找的过程，所以应该选择后序遍历的方式。\n首先基于某个节点，分析二叉树最近公共祖先可能出现的位置：\n当 p 和 q 位于当前节点的左右子树，则说明最近公共祖先就是当前节点 当 p 和 q 均位于当前节点的某一个子树，则说明最近公共祖先就在这个子树中 如果当前节点是 p 和 q 中的某一个，并且另外一个节点在当前子树中，则说明当前节点是最近公共祖先节点。 解决方案：对于从底向上的某一个节点，应该判断下面的几个条件：\n如果当前节点为 null 或者为 p 和 q 中的某一个，则可以直接返回节点。 因为是自底向上的，如果子树存在另外一个节点，说明当前节点是最近公共祖先。如果不存在，则也没有必要去探寻一遍。 如果当前节点的左右子树分别包含 p 和 q ，则说明当前节点就是最近公共祖先，直接返回当前节点。 如果当前节点的左右子树中，某一个子树包含 p 和 q ，则说明当前节点不是最近公共祖先，返回该子树中的结果值。因为可能他的子树中，同时包含 p 和 q ，则向上传递的节点就是最新公共祖先。如果不是，则还需要向上继续判断。 【伪代码】\npublic TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) { // 基本情况处理： // 1.如果当前节点为空，返回null // 2.如果当前节点是p或q中的任一个，直接返回该节点 if (root == null || root == p || root == q) { return root; } // 递归搜索左子树 TreeNode findInLeftTree = lowestCommonAncestor(root.left, p, q); // 递归搜索右子树 TreeNode findInRightTree = lowestCommonAncestor(root.right, p, q); // 情况1: p和q分别位于当前节点的左右子树 // 此时当前节点就是最近公共祖先 if (findInLeftTree != null \u0026amp;\u0026amp; findInRightTree != null) { return root; } // 情况2: p和q都在左子树中 if (findInLeftTree != null) { return findInLeftTree; } // 情况3: p和q都在右子树中 // 情况4: p和q都不在当前子树中(此时right为null) return findInRightTree; } 11. 把二叉搜索树转换为累加树 题目链接：把二叉搜索树转换为累加树\n【思路】\n题目的意思是在每个节点上计算累加和，从最大的节点开始进行递归计算。因为原来的树为二叉搜索树，所以最大的节点在最右下方。二叉搜索树中，右子树节点 \u0026gt; 根节点 \u0026gt; 左子树节点。所以可以按照 右-根-左 的遍历方式进行遍历，用一个全局变量来记录累加值。\n【伪代码】\nprivate int s = 0; // 全局变量记录累加值 public TreeNode convertBST(TreeNode root) { dfs(root); return root; } private void dfs(TreeNode node) { if (node == null) { return; } dfs(node.right); // 递归右子树 s += node.val; node.val = s; // 此时 s 就是 \u0026gt;= node.val 的所有数之和 dfs(node.left); // 递归左子树 } 12. 二叉树的直径 题目链接：二叉树的直径\n【思路】\n链长：定义从最底的叶子节点到当前节点的距离为链长，则空节点的链长为 -1，因为它还在叶子节点下面。\n当前节点的直径：当前节点的左子树链长+当前节点的右子树链长\n所以，只需要设置一个全局的变量 ans ，然后从根节点递归计算每一个节点的左右子树链长，然后获取 ans 和当前节点直径的最大值，每次返回左右子树的最大链长即可。边界条件是当节点为空的时候，返回的链长为 -1。\n【伪代码】\nprivate int ans; // 全局变量记录结果 public int diameterOfBinaryTree(TreeNode root) { dfs(root); return ans; } private int dfs(TreeNode node) { if (node == null) { return -1; // 对于叶子来说，链长就是 -1+1=0 } int lLen = dfs(node.left) + 1; // 左子树最大链长+1 int rLen = dfs(node.right) + 1; // 右子树最大链长+1 ans = Math.max(ans, lLen + rLen); // 两条链拼成路径 return Math.max(lLen, rLen); // 当前子树最大链长 } 13. 合并二叉树 题目链接：合并二叉树\n【思路】\n如果 root1 为空，则直接返回 root2 。如果 root2 为空，则直接返回 root1。如果都不为空，则返回一个新的节点，并递归合并他的左右子树。\n【伪代码】\npublic TreeNode mergeTrees(TreeNode root1, TreeNode root2) { if (root1 == null) return root2; if (root2 == null) return root1; return new TreeNode(root1.val + root2.val, mergeTrees(root1.left, root2.left), // 合并左子树 mergeTrees(root1.right, root2.right)); // 合并右子树 } DFS/BFS 1. 单词搜索 题目链接：单词搜索\n【思路】\n遍历 board 网格中的所有字符，对每个字符进行递归遍历 dfs(i, j, k) ，其中 i 和 j 分别表示 board 网格中的位置，k 表示当前需要验证的 word[k] 。判断 board[i][j] == word[k]， 如果不相等，则直接返回 false。如果相等，则查询四周是否存在 word [k + 1]，即遍历 dfs (x, y, k + 1) 。遍历 dfs(x, y, k + 1) 前，将 board[i][j] 标记为 -1， 遍历后再恢复现场，用于表示标识 board[i][j] 是否被使用。最后返回当 k == word.size() - 1 ，则返回 true。\n优化点1: 可以先统计 word 中所有字符出现的次数，以及 board 网格所有字符出现的次数。如果 word 中某个字符出现的次数大于 board 网格中出现的次数，则直接返回 false\n优化点2: 判断 word 中首尾单词出现的次数，从次数较少的一头开始比较，可以减少比较次数。注意，如果要用末尾的开始，需要将 word 数组进行逆序。\n【伪代码】\nprivate static final int[][] DIRS = {{0, -1}, {0, 1}, {-1, 0}, {1, 0}}; // 四个方向 public boolean exist(char[][] board, String word) { // 为了方便，直接用数组代替哈希表 int[] cnt = new int[128]; for (char[] row : board) { for (char c : row) { cnt[c]++; } } // 优化一 char[] w = word.toCharArray(); int[] wordCnt = new int[128]; for (char c : w) { if (++wordCnt[c] \u0026gt; cnt[c]) { return false; } } // 优化二 if (cnt[w[w.length - 1]] \u0026lt; cnt[w[0]]) { w = new StringBuilder(word).reverse().toString().toCharArray(); } for (int i = 0; i \u0026lt; board.length; i++) { for (int j = 0; j \u0026lt; board[i].length; j++) { if (dfs(i, j, 0, board, w)) { return true; // 搜到了！ } } } return false; // 没搜到 } private boolean dfs(int i, int j, int k, char[][] board, char[] word) { if (board[i][j] != word[k]) { // 匹配失败 return false; } if (k == word.length - 1) { // 匹配成功！ return true; } board[i][j] = 0; // 标记访问过 for (int[] d : DIRS) { int x = i + d[0]; int y = j + d[1]; // 相邻格子 if (0 \u0026lt;= x \u0026amp;\u0026amp; x \u0026lt; board.length \u0026amp;\u0026amp; 0 \u0026lt;= y \u0026amp;\u0026amp; y \u0026lt; board[x].length \u0026amp;\u0026amp; dfs(x, y, k + 1, board, word)) { return true; // 搜到了！ } } board[i][j] = word[k]; // 恢复现场 return false; // 没搜到 } 2. 岛屿数量 题目链接：岛屿数量\n【思路】\n遍历网格中所有为 1 的位置，递归判断上、下、左、右是否有为 1 的格子。如果没有，则直接返回。如果有，则标记当前的格子，并且继续往后递归判断。每遍历完一次，说明发现了一个完整的岛屿，则答案加 1。然后继续找下一个为 1 的位置，继续递归判断。 【注】 递归有回退的操作，案例1里面是会回退回来遍历所有部分的，不是最后一个不满足条件就直接结束了。\n【伪代码】\npublic int numIslands(char[][] grid) { int ans = 0; for (int i = 0; i \u0026lt; grid.length; i++) { for (int j = 0; j \u0026lt; grid[i].length; j++) { if (grid[i][j] == \u0026#39;1\u0026#39;) { // 找到了一个新的岛 dfs(grid, i, j); // 把这个岛插满旗子，这样后面遍历到的 \u0026#39;1\u0026#39; 一定是新的岛 ans++; } } } return ans; } private void dfs(char[][] grid, int i, int j) { // 出界，或者不是 \u0026#39;1\u0026#39;，就不再往下递归 if (i \u0026lt; 0 || i \u0026gt;= grid.length || j \u0026lt; 0 || j \u0026gt;= grid[0].length || grid[i][j] != \u0026#39;1\u0026#39;) { return; } grid[i][j] = \u0026#39;2\u0026#39;; // 插旗！避免来回横跳无限递归 dfs(grid, i, j - 1); // 往左走 dfs(grid, i, j + 1); // 往右走 dfs(grid, i - 1, j); // 往上走 dfs(grid, i + 1, j); // 往下走 } 3. 路径总和 III 题目链接：路径总和 III\n【思路】\n首先，要找到一条路径的总合为 targetNum， 可以利用前缀和的特性。例如，当 targetNum = 8， 三个节点的前缀和数组为 10, 15, 18 ，因为 18 - 10 = 8 = targetNum， 说明后面两个节点可以组成一条路径和为 targetNum。其次，判断的时候，以第三个节点为终点，判断存在多少条路径的前缀和为 18 - targetNum = 10，就说明有多少条路径和为 targetNum 。所以，按照先序遍历的顺序，用 cnt 的 Map对象记录前缀和的个数。遍历的过程中，将当前前缀和的值放入 cnt 中。\n注意，为了防止出现 targetNum = 8， 第一个节点刚好为 8，导致漏算的情况。可以初始化 cnt(0, 1)，也就是 8 - targeNum = 0，本身也是一条路径。\n【伪代码】\nprivate int ans; // 全局记录答案 public int pathSum(TreeNode root, int targetSum) { Map\u0026lt;Long, Integer\u0026gt; cnt = new HashMap\u0026lt;\u0026gt;(); cnt.put(0L, 1); dfs(root, 0, targetSum, cnt); return ans; } private void dfs(TreeNode node, long s, int targetSum, Map\u0026lt;Long, Integer\u0026gt; cnt) { if (node == null) { return; } s += node.val; // 把 node 当作路径的终点，统计有多少个起点 ans += cnt.getOrDefault(s - targetSum, 0); cnt.merge(s, 1, Integer::sum); // cnt[s]++ dfs(node.left, s, targetSum, cnt); dfs(node.right, s, targetSum, cnt); cnt.merge(s, -1, Integer::sum); // cnt[s]-- 恢复现场，防止遍历完左子树，遍历右子树的时候出现前缀合多加上左子树值的情况。 } ","permalink":"https://swimmingliu.cn/posts/job/leetcode-hot100-notes/","summary":"\u003ch2 id=\"链表\"\u003e链表\u003c/h2\u003e\n\u003ch3 id=\"1-两数相加\"\u003e1. 两数相加\u003c/h3\u003e\n\u003cp\u003e题目链接：\u003ca href=\"https://leetcode.cn/problems/add-two-numbers/description/\"\u003e两数相加\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e【思路】\u003c/p\u003e\n\u003cp\u003e引入一个临时变量 \u003ccode\u003ecarry\u003c/code\u003e 记录进位的值，默认是0。开一个新的链表 \u003ccode\u003el\u003c/code\u003e ，同时遍历两个链表的值。\u003ccode\u003el1.val\u003c/code\u003e + \u003ccode\u003el2.val\u003c/code\u003e +  \u003ccode\u003ecarry\u003c/code\u003e = \u003ccode\u003el.val\u003c/code\u003e。注意，最后有多余的进位时，要新增一个节点。\u003c/p\u003e\n\u003cp\u003e整个过程可以用递归来实现，递归的边界条件是当 \u003ccode\u003el1\u003c/code\u003e 、\u003ccode\u003el2\u003c/code\u003e 为 \u003ccode\u003enull\u003c/code\u003e 且 \u003ccode\u003ecarry\u003c/code\u003e 为 \u003ccode\u003e0\u003c/code\u003e 的时候 。然后，返回值是 \u003ccode\u003enew ListNode(carry % 10, addTwo(l1, l2, carry / 10))\u003c/code\u003e 。其中, \u003ccode\u003ecarry % 10\u003c/code\u003e 表示当前值， \u003ccode\u003ecarry / 10\u003c/code\u003e 表示进位值。计算过程是\u003ccode\u003el1\u003c/code\u003e 和 \u003ccode\u003el2\u003c/code\u003e 都获取 \u003ccode\u003eval\u003c/code\u003e 和 \u003ccode\u003ecarry\u003c/code\u003e 相加，并且向前遍历。\u003c/p\u003e\n\u003cp\u003e【伪代码】\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-java\" data-lang=\"java\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// l1 和 l2 为当前遍历的节点，carry 为进位， 默认为0\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"kd\"\u003eprivate\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eListNode\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003eaddTwo\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eListNode\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003el1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eListNode\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003el2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ecarry\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003el1\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kc\"\u003enull\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003el2\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kc\"\u003enull\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ecarry\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"c1\"\u003e// 递归边界\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kc\"\u003enull\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003es\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ecarry\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003el1\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e!=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kc\"\u003enull\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"n\"\u003es\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e+=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003el1\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eval\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"c1\"\u003e// 累加进位与节点值\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"n\"\u003el1\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003el1\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003enext\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003el2\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e!=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kc\"\u003enull\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"n\"\u003es\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e+=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003el2\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eval\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"n\"\u003el2\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003el2\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003enext\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"c1\"\u003e// s 除以 10 的余数为当前节点值，商为进位\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003enew\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eListNode\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003es\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e%\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eaddTwo\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003el1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003el2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003es\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e));\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"2-删除链表的倒数第-n-个结点\"\u003e2. 删除链表的倒数第 N 个结点\u003c/h3\u003e\n\u003cp\u003e题目链接：\u003ca href=\"https://leetcode.cn/problems/remove-nth-node-from-end-of-list/description/\"\u003e删除链表的倒数第 N 个结点\u003c/a\u003e\u003c/p\u003e","title":"Leetcode Hot100 刷题笔记"},{"content":"并发与性能优化 1. 大文件上传如何处理？分片上传 相关代码：https://github.com/SwimmingLiu/JavaSceneQuiz100/tree/main/lesson001\n1.1 为什么需要分片上传? 大文件在上传的过程中，耗费的时间比较长。如果网络不稳定，很可能导致上传失败，需要重新上传。分片上传，就可以解决这个问题。\n分片上传定义：将大文件拆分为不同的文件块，逐块进行上传\n1.2 如何实现分片上传？ 1.2.1 如何存储分片信息 分片上传需要记录文件的属性 (md5、大小、名称)、分片数量、文件存储的完整路径 (本地路径)，还需要记录每个分块的上传情况 (分块大小、分块顺序、分块任务id)。可以用 分块上传任务表 和 分块文件表 来记录。\n分块任务表 (t_shard_upload)\ncreate table if not exists t_shard_upload( id varchar(32) primary key, file_name varchar(256) not null comment \u0026#39;文件名称\u0026#39;, part_num int not null comment \u0026#39;分片数量\u0026#39;, md5 varchar(128) comment \u0026#39;文件md5值\u0026#39;, file_full_path varchar(512) comment \u0026#39;文件完整路径\u0026#39; ) comment = \u0026#39;分片上传任务表\u0026#39;; 分块文件表 (t_shard_upload_part）\ncreate table if not exists t_shard_upload_part( id varchar(32) primary key, shard_upload_id varchar(32) not null comment \u0026#39;分片任务id（t_shard_upload.id）\u0026#39;, part_order int not null comment \u0026#39;第几个分片，从1开始\u0026#39;, file_full_path varchar(512) comment \u0026#39;文件完整路径\u0026#39;, UNIQUE KEY `uq_part_order` (`shard_upload_id`,`part_order`) ) comment = \u0026#39;分片文件表，每个分片文件对应一条记录\u0026#39;; 分块文件表和分块上传表是 1 to M 的关系，假如当前文件分为10块。则会出现1个分片上传任务，和10个分片文件记录。\n1.2.2 如何定义分块上传接口 分块上传可以分为下面 5 个接口\n**创建分片上传任务接口 ** (/shardUpload/init) 入参：文件名称、文件大小、文件md5 出参：任务id、分片数量 实现：计算分片数量，创建分片任务 上传分片文件 (/shardUpload/uploadPart) 入参：MultiPartFile 文件 出参 ：分片文件记录id、任务id 实现：存入文件到磁盘自动位置，创建分片文件记录 合并分片、完成上传 (/shardUpload/complete) 入参：任务id 出参：布尔值 实现：按照顺序合并所有二进制文件 获取分片任务详细信息(/shardUpload/detail) 入参：任务id 、文件md5 (二选一) 出参：任务进度、文件名称、文件md5 实现：读取分片文件表查看上传情况 功能：获取分片任务的状态信息，如分片任务是否上传完毕，哪些分片已上传等信息，网络出现故障，可以借助此接口恢复上传 1.3 如果上传过程中，出现故障如何处理？ 情况1：浏览器无法读取刚才用户选择的文件了 此时需要用户重新选择文件，重新上传。这个地方也可以给大家提供另外一种思路，第1个接口创建分片任务的时候传入了文件的md5，按说这个值是具有唯一性的，那么就可以通过这个值找到刚才的任务，按照这种思路，就需要后端提供一个新的接口：通过文件的md5值找到刚才失败的那个任务，然后继续上传未上传的分片。\n情况2：浏览器可以继续读取刚才用户选择的文件 这种情况，可以先调用第4个接口，通过此接口可以知道那些分片还未上传，然后继续上传这些分片就可以了。\n2. 多线程任务批处理通用工具类 相关代码：https://github.com/SwimmingLiu/JavaSceneQuiz100/tree/main/lesson002\n使用线程池批量发送短信，当短信发送完毕之后，记录耗时情况 【主要知识点】\nCountDownLatch：如果想要等异步线程执行之后，再继续回到原方法中，可以使用CountDownLatch Executors：用于创建线程池，重写 executor.execute 中的 Runnable 方法，可实现异步执行线程 public class TaskDisposeUtils { /** * 使用线程池批处理文件，当所有任务处理完毕后才会返回 * * @param taskList 任务列表 * @param consumer 处理任务的方法 * @param executor 线程池 * @param \u0026lt;T\u0026gt; * @throws InterruptedException */ public static \u0026lt;T\u0026gt; void dispose(List\u0026lt;T\u0026gt; taskList, Consumer\u0026lt;? super T\u0026gt; consumer, Executor executor) throws InterruptedException { if (taskList == null || taskList.isEmpty() || consumer == null) return; CountDownLatch latch = new CountDownLatch(taskList.size()); for (T item : taskList) { executor.execute(() -\u0026gt; { try { consumer.accept(item); } finally { latch.countDown(); } }); } latch.await(); } public static void main(String[] args) throws InterruptedException { long startTime = System.currentTimeMillis(); List\u0026lt;String\u0026gt; taskList = List.of(\u0026#34;短信-1\u0026#34;, \u0026#34;短信-2\u0026#34;, \u0026#34;短信-3\u0026#34;); ExecutorService executor = Executors.newFixedThreadPool(10); dispose(taskList, TaskDisposeUtils::doTask, executor); System.out.println(\u0026#34;任务处理完毕,耗时(ms):\u0026#34; + (System.currentTimeMillis() - startTime)); executor.shutdown(); } public static void doTask(String task) { System.out.println(task + \u0026#34;发送成功\u0026#34;); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { Thread.currentThread().interrupt(); } } } 3. 接口性能压力测试工具 相关代码：https://github.com/SwimmingLiu/JavaSceneQuiz100/tree/main/lesson003\n3.1 常用压测工具类 Jemeter 、LoadRunner、ApiFox - 自动化测试\n【注意】LoadRunner 只有window可以用\n3.2 手写压测工具类 【主要知识点】\n为什么 updateFastestTime 方法需要使用循环而不是直接 compareAndSet ：因为直接使用 compareAndSet 会出现线程不安全的情况，比如下面的情况\n// 错误的做法（非线程安全） int current = fastestCostTime.get(); // 线程A读取到值100 if (current \u0026gt; costTime) { // 线程A判断100 \u0026gt; 30，准备更新 // 此时线程B也读取到100，也判断100 \u0026gt; 50，也准备更新 fastestCostTime.set(costTime); // 线程A设置为30 // 线程B设置为50，覆盖了线程A的结果 (最小时间应该是30s) } // 使用while循环保证线程安全 （其实就是CAS） while (true){ int fsCostTime = fastestCostTime.get(); // 线程A读取到100 // 线程B此时将值改为90 if (fastestCostTime.compareAndSet(fsCostTime, costTime)) { // 线程A尝试将100改为50 // 失败！因为当前值已经是90，不等于预期的100 break; } // 继续循环，重新获取最新值90，再次尝试 } 线程池参数：数依次为 coolPoolSize 、maxPoolSize、keepAliveTime、TimeUnit、waitQueue 等待队列\n为什么线程需要预热：预热是为了避免线程创建时带来的额外开销，如果不预热，很可能前 100 个核心线程需要多消耗 10~50 ms 来创建线程\nAtomicInteger：防止多线程修改同一数据时，出现线程不安全的情况\n// 普通Integer的问题 int value = counter; // 1. 读取 value = value + 1; // 2. 修改 counter = value; // 3. 写入 // 这三步不是原子的，可能被其他线程中断 // AtomicInteger采用CAS + volatile 保证原子性 atomicCounter.incrementAndGet(); // 原子操作 volatile 关键字在AtomicInteger作用：volatile 就像是给变量贴了个\u0026quot;实时更新\u0026quot;的标签。通过内存可见性和禁止指令重排序来保证实时更新\n// 没有volatile的情况 int count = 0; // 线程A修改了count = 100 // 线程B可能还是看到count = 0（因为每个线程都有自己的缓存） 所以，如果 没有volatile 关键字， 没有线程都有自己的\u0026quot;小本本\u0026quot;（CPU缓存，线程私有），可能记录的数据不是最新的。\npublic class LoadRunnerUtils { public static class LoadRunnerResult { private int requests; // 请求总数 private int concurrency; // 并发量 private int successRequests; // 成功请求数 private int failRequests; // 失败请求数 private int timeTakenForTests; // 请求总耗时(ms) private float requestsPerSecond; // 每秒请求数（吞吐量） private float timePerRequest; // 每个请求平均耗时(ms) private float fastestCostTime; // 最快的请求耗时(ms) private float slowestCostTime; // 最慢的请求耗时(ms) } /** * 执行并发压力测试 * @param requests 总请求数 * @param concurrency 并发数量 * @param command 被测试的代码 * @return 压测结果 */ public static LoadRunnerResult run(int requests, int concurrency, Runnable command) throws InterruptedException { log.info(\u0026#34;压测开始......\u0026#34;); // 创建固定大小的线程池，预热所有核心线程 ThreadPoolExecutor executor = createThreadPool(concurrency); // 用于等待所有请求完成的同步器 CountDownLatch latch = new CountDownLatch(requests); // 统计数据（使用原子类保证线程安全） AtomicInteger successCount = new AtomicInteger(0); AtomicInteger fastestTime = new AtomicInteger(Integer.MAX_VALUE); AtomicInteger slowestTime = new AtomicInteger(Integer.MIN_VALUE); long startTime = System.currentTimeMillis(); // 提交所有压测任务 for (int i = 0; i \u0026lt; requests; i++) { executor.execute(() -\u0026gt; executeRequest(command, successCount, fastestTime, slowestTime, latch)); } // 等待所有请求完成 latch.await(); executor.shutdown(); long endTime = System.currentTimeMillis(); log.info(\u0026#34;压测结束，总耗时(ms):{}\u0026#34;, (endTime - startTime)); // 返回压测结果 } /** * 创建线程池并预热核心线程 */ private static ThreadPoolExecutor createThreadPool(int concurrency) { // 参数依次为 coolPoolSize、maxPoolSize、keepAliveTime、TimeUnit、等待队列 ThreadPoolExecutor executor = new ThreadPoolExecutor(concurrency, concurrency, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;\u0026gt;()); executor.prestartAllCoreThreads(); return executor; } /** * 执行单个请求并统计结果 */ private static void executeRequest(Runnable command, AtomicInteger successCount, AtomicInteger fastestTime, AtomicInteger slowestTime, CountDownLatch latch) { try { long requestStart = System.currentTimeMillis(); command.run(); // 执行被测试的方法 int costTime = (int)(System.currentTimeMillis() - requestStart); // 更新统计数据 updateFastestTime(fastestTime, costTime); updateSlowestTime(slowestTime, costTime); successCount.incrementAndGet(); } catch (Exception e) { log.error(\u0026#34;请求执行失败: {}\u0026#34;, e.getMessage()); } finally { latch.countDown(); // 标记当前请求完成 } } /** * 原子更新最快耗时 */ private static void updateFastestTime(AtomicInteger fastestTime, int costTime) { while (true) { int current = fastestTime.get(); if (current \u0026lt;= costTime || fastestTime.compareAndSet(current, costTime)) { break; } } } } 4. Semaphore实现接口限流 如果后端服务是单体服务，且只部署在一台服务器上，可以采用 Semaphore 信号量的方式实现简单的接口限流机制\n相关代码：https://github.com/SwimmingLiu/JavaSceneQuiz100/tree/main/lesson005\nSemaphore : JUC当中对信号量的实现，用于控制同时访问共享资源的线程数量。\npublic class TestController { /** * Juc中的Semaphore可以实现限流功能，可以将 Semaphore 想象成停车场入口的大爷， * 大爷手里面拥有一定数量的停车卡（也可以说是令牌），卡的数量是多少呢？就是Semaphore构造方法中指定的，如下就是50个卡， * 车主想进去停车，先要从大爷手中拿到一张卡，出来的时候，需要还给大爷，如果拿不到卡，就不能进去停车。 * semaphore 内部提供了获取令牌，和还令牌的一些方法 */ private Semaphore semaphore = new Semaphore(50); /** * 来个案例，下面是一个下单的方法，这个方法最多只允许 50 个并发，若超过50个并发，则进来的请求，最多等待1秒，如果无法获取到令牌，则快速返回失败，请重试 * @return */ @GetMapping(\u0026#34;/placeOrder\u0026#34;) public String placeOrder() throws InterruptedException { /** * semaphore 在上面定义的，里面有50个令牌，也就是同时可以支持50个并发请求 * 下面的代码，尝试最多等待1秒去获取令牌，获取成功，则进入下单逻辑，获取失败，则返回系统繁忙，请稍后重试 */ boolean flag = this.semaphore.tryAcquire(1, 1L, TimeUnit.SECONDS); // 获取到令牌，则进入下单逻辑 if (flag) { try { //这里休眠2秒，模拟下单的操作 TimeUnit.SECONDS.sleep(2); return \u0026#34;下单成功\u0026#34;; } finally { //这里一定不要漏掉了，令牌用完了，要还回去 this.semaphore.release(); } } else { return \u0026#34;系统繁忙，请稍后重试\u0026#34;; } } } 5. 并行查询 - 提交接口响应速度 需求分析：当前接口需要实现下面的功能\n接收一个商品id，需要返回商品下面这些信息，这些信息都在不同的表中，通过商品id就可以查到\n商品基本信息（如商品名称、价格等基本信息) 商品描述信息（可能是富文本，放在单独的表中） 商品收藏量 商品评论量 相关代码：https://github.com/SwimmingLiu/JavaSceneQuiz100/tree/main/lesson006\n5.1 常规做法 按照商品 id 分别查询不同的数据库，在JVM内存中对结果进行组装。\npublic class GoodsController { /** * 根据商品id获取商品信息(基本信息、描述信息、评论量，收藏量) * * @param goodsId 商品id * @return * @throws InterruptedException */ @GetMapping(\u0026#34;/getGoodsDetail\u0026#34;) public GoodsDetailResponse getGoodsDetail(@RequestParam(\u0026#34;goodsId\u0026#34;) String goodsId) { long st = System.currentTimeMillis(); GoodsDetailResponse goodsDetailResponse = new GoodsDetailResponse(); // 1、获取商品基本信息，耗时100ms goodsDetailResponse.setGoodsInfo(this.getGoodsInfo(goodsId)); //2、获取商品描述信息，耗时100ms goodsDetailResponse.setGoodsDescription(this.getGoodsDescription(goodsId)); //3、获取商品评论量，耗时100ms goodsDetailResponse.setCommentCount(this.getGoodsCommentCount(goodsId)); //4、获取商品收藏量，耗时100ms goodsDetailResponse.setFavoriteCount(this.getGoodsFavoriteCount(goodsId)); // 总耗时为500ms左右 LOGGER.info(\u0026#34;获取商品信息，普通版耗时：{} ms\u0026#34;, (System.currentTimeMillis() - st)); } // 使用sleep模拟数据库查询的延迟 private int getGoodsFavoriteCount(String goodsId) { try { log.info(\u0026#34;获取商品收藏量\u0026#34;); TimeUnit.MILLISECONDS.sleep(100); } catch (InterruptedException e) { Thread.currentThread().interrupt(); throw new RuntimeException(e); } return 10000; } 5.2 使用线程池并行查询商品信息 分析：上方的4个商品信息查询之间并没有任何依赖，这些没有依赖的查询其实是可以并行查询的。所以可以使用线程池同时去拿这4个结果，然后在JVM内存中进行组装\n【主要知识点】\nCompletableFuture (CF)：主要用于异步执行多个相互独立的任务 （适合异步任务编排，可以方便地组合和转换任务结果）\nCountDownLatch (CDL): 主要用于线程协调，等待一组线程完成 （一般就是用来等待一批线程执行完）\nCF 和 CDL 区别\nCountDownLatch 👉 运动会起跑 裁判（主线程）等待所有运动员（子线程）就位（countDown），枪响（计数器归零）后统一开跑。 CompletableFuture 👉 外卖订单流程 下单（异步任务）→ 制作（thenApply 加工）→ 配送（thenAccept 交付），每个环节自动触发下一步，无需阻塞 对比维度 CountDownLatch CompletableFuture 核心用途 线程等待机制（阻塞线程直到任务完成） 异步编程模型（非阻塞链式任务处理） 工作方式 通过计数器递减（countDown()）触发释放 通过回调链（thenApply()/thenAccept()）传递结果 线程阻塞 调用线程主动阻塞（await()） 调用线程不阻塞，通过回调处理结果 结果传递 ❌ 不支持任务结果传递 ✅ 支持任务结果传递和转换 异常处理 ❌ 需手动捕获异常 ✅ 内置异常处理（exceptionally()/handle()） 任务组合 ❌ 仅支持单次计数 ✅ 支持多任务组合（allOf()/anyOf()） 复用性 ❌ 计数器归零后不可重用 ✅ 可重复组合新任务 典型场景 启动前等待资源初始化、批量任务并行执行 异步API调用、流水线式数据处理、微服务编排 下面看一组CF和CDL的代码对比：\npublic class AsyncDemo { // 模拟线程池 private static final ExecutorService executor = Executors.newFixedThreadPool(3); /** * CompletableFuture方式 - 支持任务编排和结果处理 */ public GoodsInfo getGoodsInfoWithCF(String goodsId) { GoodsInfo result = new GoodsInfo(); // 1. 创建多个异步任务 CompletableFuture\u0026lt;String\u0026gt; basicInfoFuture = CompletableFuture .supplyAsync(() -\u0026gt; queryBasicInfo(goodsId), executor); CompletableFuture\u0026lt;Integer\u0026gt; priceFuture = CompletableFuture .supplyAsync(() -\u0026gt; queryPrice(goodsId), executor); // 2. 对结果进行处理转换 CompletableFuture\u0026lt;String\u0026gt; processedInfo = basicInfoFuture .thenApply(info -\u0026gt; \u0026#34;处理后的商品信息: \u0026#34; + info) .exceptionally(ex -\u0026gt; \u0026#34;获取商品信息失败\u0026#34;); // 3. 等待所有任务完成并组装结果 CompletableFuture.allOf(processedInfo, priceFuture).join(); result.setInfo(processedInfo.join()); result.setPrice(priceFuture.join()); return result; } /** * CountDownLatch方式 - 仅支持等待多个线程完成 */ public GoodsInfo getGoodsInfoWithCDL(String goodsId) throws InterruptedException { GoodsInfo result = new GoodsInfo(); CountDownLatch latch = new CountDownLatch(2); // 1. 需要手动创建线程执行任务 executor.submit(() -\u0026gt; { try { result.setInfo(queryBasicInfo(goodsId)); } finally { latch.countDown(); } }); executor.submit(() -\u0026gt; { try { result.setPrice(queryPrice(goodsId)); } finally { latch.countDown(); } }); // 2. 等待所有任务完成 latch.await(); return result; } 如果需要异步并行 + 任务编排，就用 CompletableFuture ；如果只是用于等待一批异步任务执行完，就用 CountDownLaunch\npublic class GoodsController { /** * 优化后的方法，根据商品id获取商品信息(基本信息、描述信息、评论量，收藏量) * * @param goodsId 商品id * @return * @throws InterruptedException */ @GetMapping(\u0026#34;/getGoodsDetailNew\u0026#34;) public GoodsDetailResponse getGoodsDetailNew(@RequestParam(\u0026#34;goodsId\u0026#34;) String goodsId) { long st = System.currentTimeMillis(); GoodsDetailResponse goodsDetailResponse = new GoodsDetailResponse(); // 1、获取商品基本信息，耗时100ms CompletableFuture\u0026lt;Void\u0026gt; goodsInfoCf = CompletableFuture.runAsync(() -\u0026gt; goodsDetailResponse.setGoodsInfo(this.getGoodsInfo(goodsId)), this.goodsThreadPool); //2、获取商品描述信息，耗时100ms CompletableFuture\u0026lt;Void\u0026gt; goodsDescriptionCf = CompletableFuture.runAsync(() -\u0026gt; goodsDetailResponse.setGoodsDescription(this.getGoodsDescription(goodsId)), this.goodsThreadPool); //3、获取商品评论量，耗时100ms CompletableFuture\u0026lt;Void\u0026gt; goodsCommentCountCf = CompletableFuture.runAsync(() -\u0026gt; goodsDetailResponse.setCommentCount(this.getGoodsCommentCount(goodsId)), this.goodsThreadPool); //4、获取商品收藏量，耗时100ms CompletableFuture\u0026lt;Void\u0026gt; goodsFavoriteCountCf = CompletableFuture.runAsync(() -\u0026gt; goodsDetailResponse.setFavoriteCount(this.getGoodsFavoriteCount(goodsId)), this.goodsThreadPool); //等待上面执行结束 CompletableFuture.allOf(goodsInfoCf, goodsDescriptionCf, goodsCommentCountCf, goodsFavoriteCountCf).join(); // 总耗时大约在100ms左右 LOGGER.info(\u0026#34;获取商品信息，使用线程池并行查询耗时：{} ms\u0026#34;, (System.currentTimeMillis() - st)); return goodsDetailResponse; } } 6. 并行查询可能存在的问题？如何解决？ 相关代码：https://github.com/SwimmingLiu/JavaSceneQuiz100/tree/main/lesson006\n6.1 并行查询中存在的问题 并行查询所用到的线程池配置是非常关键且重要的配置，如果设置不当可能出现严重的性能问题。\n比如将核心线程数设置为了 1 ，而队列大小没有限制，那么所有的请求都变成串行了，会导致请求响应非常慢。另外，核心线程池和队列大小的上限也应该匹配。如果核心线程池设置为 10 ，而队列大小没有设置上限。该线程池同时只可支持 10 个任务并行，其他的请求都会变成串行执行了，进入队列排队，从而导致接口响应特别慢。\n6.2 如何解决并行查询的问题 解决并行查询问题的核心：不要让任务排队或者排队时间不要太长\n下面从线程池的执行流程入手，优化并行查询问题\n【解决方案】\n增大线程数：可以将核心线程数、最大线程数调大，但不能调到超过CPU的最大负载，不然可能会降低系统性能分。该参数应该根据业务的指标进行压测得到一个合理的值\n减少队列数：\n将队列大小设置的比较小，这样排队的时间大概率会比较短，或者排队失败，直接后面的流程\n⚠️ 之前理解存在误区：应该是核心线程检查完了，就检查能否放入队列，再检查最大线程数。而不是核心线程检查完，就去检查最大线程数。\n减少队列数至 0：这样任务就不会进入队列，而直接创建新的线程去执行，或者走拒绝策略\nLinkedBlockingQueue、ArrayBlockingQueue 容量是不允许为0的，如果需要用到容量为0的队列，则需要使用同步阻塞队列 SynchronousQueue\n拒绝策略：可以使用 CallerRunsPolicy，这个策略是直接在调用线程的当前线程中执行。该策略可以保证任务能快速被处理，不会一直处于阻塞态\n策略名称 行为描述 适用场景 生活实例类比 AbortPolicy 直接抛出 RejectedExecutionException 异常 需要严格保证任务不丢失的场景 餐厅满员时直接拒绝新顾客 CallerRunsPolicy 让提交任务的线程自己执行该任务 需要降低任务提交速度的场景 经理亲自处理无法分配的任务 DiscardPolicy 静默丢弃新任务，不抛异常也不执行 允许丢弃非关键任务的场景 快递爆仓时直接丢弃新包裹 DiscardOldestPolicy 丢弃队列中最老的任务，然后尝试重新提交当前任务 优先处理新任务的场景 超市排队时让等待最久的顾客离开 线程池隔离：不同的业务最好使用不同的线程池，互不影响，强烈建议核心业务一定要使用单独的线程池。\n【优化后的线程池配置】\n@Bean public ThreadPoolTaskExecutor goodsThreadPool() { ThreadPoolTaskExecutor threadPoolTaskExecutor = new ThreadPoolTaskExecutor(); threadPoolTaskExecutor.setThreadNamePrefix(\u0026#34;ThreadPool-Goods-\u0026#34;); // 核心线程数为cpu核数 * 4，最大线程数据为cpu核数 * 8 threadPoolTaskExecutor.setCorePoolSize(Runtime.getRuntime().availableProcessors() * 4); threadPoolTaskExecutor.setMaxPoolSize(Runtime.getRuntime().availableProcessors() * 8); // 队列容量为0，则任务就不会进入队列 threadPoolTaskExecutor.setQueueCapacity(0); // 拒绝策略使用CallerRunsPolicy，让当前线程去兜底去执行任务 threadPoolTaskExecutor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); return threadPoolTaskExecutor; } 7. 接口性能调优之大 (长) 事务优化 日常编程中，容易遇到事务执行时间较长的情况。如果该事务的对应的接口，请求量暴增，由于数据库连接池的限制，大部分请求可能会失败。\n相关代码：https://github.com/SwimmingLiu/JavaSceneQuiz100/tree/main/lesson009\n7.1 大(长)事务所带来的问题 下面的代码带有 @Transcational 注解， 说明该方法会交给 Spring 来管理该方法的事务。具体执行逻辑如下：\n1、Spring去数据库连接池拿到一个数据库连接 2、开启事务 3、执行bigTransaction()中的代码 4、提交事务 5、将数据库连接还给数据库连接池中 在这个过程中，数据库连接会一直被占用。因为数据库连接时有限的，并且是非常稀缺的资。如果长时间被占用，并且数据库连接池中的可用连接都被占用了，则其他请求无法连接数据库。它会导致连接超时，执行方法失败。例如，下面方法中 this.getData() 方法会占用 5s 的时间。如果 5s 内有 100 条请求并发执行，且数据库连接池最大连接数为 20，超时时间为3s。 则剩余的 80 条请求，都会出现连接失败的现象。\n@Transactional public void bigTransaction() throws InterruptedException { // 1、getData()方法模拟一个比较耗时的获取数据的操作，这个方法内部会休眠5秒 String data = this.getData(); //2、将上面获取到的数据写入到db中 Lesson007PO po = new Lesson007PO(); po.setId(UUID.randomUUID().toString()); po.setData(data); this.lesson007Mapper.insert(po); } public String getData() throws InterruptedException { //休眠5秒 TimeUnit.SECONDS.sleep(5); return UUID.randomUUID().toString(); } 7.2 如何解决大 (长) 事务的问题 (拆分为小事务) 优化方法：将大(长)事务进行拆分，将无需数据库连接的部分拆出来，将事务最小化。 例如，上方的代码中，this.getData() 方法是不需要操作数据库的，只有最后的 insert 方法才需要连接数据库。所以，可以将事务的粒度控制在 insert 方法中。\nTranscationTemplate：Spring中的 TranscationTemplate 工具类能够采用编程式的方案，灵活控制事务的粒度。\n/** * 使用 TransactionTemplate 编程式事务，可以灵活的控制事务的范围 * * @throws InterruptedException */ public void smallTransaction() throws InterruptedException { // 1、调用getData()方法，讲获取的数据写到db中，假设 getData方法比较耗时，比如耗时 5秒 String data = this.getData(); //2、将上面获取到的数据写入到db中 Lesson007PO po = new Lesson007PO(); po.setId(UUID.randomUUID().toString()); po.setData(data); // this.transactionTemplate.executeWithoutResult可以传入一个Consumer，这个Consumer表述需要在事务中执行的业务操作 this.transactionTemplate.executeWithoutResult(action -\u0026gt; { this.lesson007Mapper.insert(po); }); } 【总结】\n控制事务粒度 ：使用 TransactionTemplate 编程式事务，精准控制事务的粒度，尽量让事务小型化 非数据库相关代码，避免出现在事务中：尽量避免将没有事务的耗时操作放到事务代码中；避免在事务中执行远程操作，远程操作是不需要用到本地事务的，所以没有必要放在事务中 事务集中化：尽量让事务的操作集中在一起执行，比如都放到方法最后，使用 TransactionTemplate 执行，这样可使事务最小化 8. 动态线程池 相关代码：https://github.com/SwimmingLiu/JavaSceneQuiz100/tree/main/lesson009\n8.1 为什么需要动态线程池 平时我们在开发中，创建了不少线程池，这些线程池都处于游离状态，不方便管理和监控。无法知道目前系统中有哪些线程池、以及每个线程池当前的一个状态，负载情况等，所以我们可以开发一个线程池管理器来解决这个问题。\n8.2 线程池管理器 统管系统中所有线程池，负责所有线程池的创建、监控等操作。\npublic class ThreadPoolManager { /** 线程池Map */ private static Map\u0026lt;String, ThreadPoolTaskExecutor\u0026gt; threadPoolMap = new ConcurrentHashMap\u0026lt;String, ThreadPoolTaskExecutor\u0026gt;(16); /** * 创建新的线程池，如果线程池已经创建，返回已经创建的线程池 * * @param name 线程池名称 * @param corePoolSize 核心线程数 * @param maxPoolSize 最大线程数 * @param queueCapacity 队列大小 * @param keepAliveSeconds 线程池存活时间（秒） * @param threadFactory 线程工厂 * @param rejectedExecutionHandler 拒绝策略 * @return */ public static ThreadPoolTaskExecutor newThreadPool(String name, int corePoolSize, int maxPoolSize, int queueCapacity, int keepAliveSeconds, ThreadFactory threadFactory, RejectedExecutionHandler rejectedExecutionHandler) { return threadPoolMap.computeIfAbsent(name, threadGroupName -\u0026gt; { ThreadPoolTaskExecutor threadPoolExecutor = new ThreadPoolTaskExecutor() { private boolean initialized = false; // 初始化标记 @Override protected BlockingQueue\u0026lt;Runnable\u0026gt; createQueue(int queueCapacity) { if (queueCapacity \u0026gt; 0) { // 使用自定义的 ResizeLinkedBlockingQueue 替代默认队列，保证能够在运行时动态调整队列大小 return new ResizeLinkedBlockingQueue\u0026lt;\u0026gt;(queueCapacity); } else { // 当队列容量设置为0时，使用 SynchronousQueue。表示任务必须立即被线程处理，否则就会被拒绝 return new SynchronousQueue\u0026lt;\u0026gt;(); } } @Override public void setQueueCapacity(int queueCapacity) { // 确保线程池已初始化且队列类型正确时才调整容量 if (this.initialized \u0026amp;\u0026amp; this.getThreadPoolExecutor() != null \u0026amp;\u0026amp; this.getThreadPoolExecutor().getQueue() != null \u0026amp;\u0026amp; this.getThreadPoolExecutor().getQueue() instanceof ResizeLinkedBlockingQueue) { ((ResizeLinkedBlockingQueue) this.getThreadPoolExecutor().getQueue()).setCapacity(queueCapacity); } super.setQueueCapacity(queueCapacity); } @Override public void afterPropertiesSet() { // 使用 initialized 标记确保线程池只被初始化一次 if (initialized) { return; } super.afterPropertiesSet(); this.initialized = true; } }; // 设置参数 threadPoolExecutor.setCorePoolSize(corePoolSize); ... if (threadFactory != null) { // ThreadFactory相当于线程池的一些规定 (招聘标准) threadPoolExecutor.setThreadFactory(threadFactory); } if (rejectedExecutionHandler != null) { // 拒绝执行的策略，上方提到的四种拒绝策略 threadPoolExecutor.setRejectedExecutionHandler(rejectedExecutionHandler); } threadPoolExecutor.afterPropertiesSet(); return threadPoolExecutor; }); } /** 获取所有线程池信息 */ public static List\u0026lt;ThreadPoolInfo\u0026gt; threadPoolInfoList() { return threadPoolMap .entrySet() .stream() .map(entry -\u0026gt; threadPoolInfo(entry.getKey(), entry.getValue())) .collect(Collectors.toList()); } } 8.3 动态线程池 动态线程池：无需重启的情况下，可以对线程池进行扩缩容，比如改变线程池的核心线程数量、最大线程数量、队列容量等。\n8.3.1 常用动态线程池 dynamic-tp：https://github.com/dromara/dynamic-tp\n8.3.2 手动实现动态线程池 线程池中会用到Java中的阻塞队列 java.util.concurrent.BlockingQueue，目前 jdk中自带几个阻塞队列都不支持动态扩容。 比如 java.util.concurrent.LinkedBlockingQueue，它的 capacity 是 final 修饰的，不支持修改。\n动态调整大小的前提：动态调整线程池大小需要队列容量能够支持调整，我们需要创建可扩容的阻塞队列 ResizeLinkedBlockingQueue。代码是从LinkedBlockingQueue 中拷贝过来的，增加可修改容量 的setCapacity 方法。然后创建线程池的时，使用自定义的阻塞队列便可以实现线程池的动态扩容。\n/** * 设置容量 * @param capacity */ public void setCapacity(int capacity) { if (capacity \u0026lt;= 0) throw new IllegalArgumentException(); final ReentrantLock putLock = this.putLock; putLock.lock(); try { if (count.get() \u0026gt; capacity) { throw new IllegalArgumentException(); } this.capacity = capacity; } finally { putLock.unlock(); } } 动态更改线程池大小的方法如下所示：\npublic class ThreadPoolManager { /** * 动态变更线程池（如：扩缩容、扩缩队列大小） * @param threadPoolChange 变更线程池信息 */ public static void changeThreadPool(ThreadPoolChange threadPoolChange) { ThreadPoolTaskExecutor threadPoolTaskExecutor = threadPoolMap.get(threadPoolChange.getName()); if (threadPoolTaskExecutor == null) { throw new IllegalArgumentException(); } if (threadPoolChange.getCorePoolSize() \u0026gt; threadPoolChange.getMaxPoolSize()) { throw new IllegalArgumentException(); } synchronized (ThreadPoolManager.class) { // 增加线程情况：需要修改的最大线程大于当前核心线程，则设置当前核心线程为修改后的最大线程 if (threadPoolChange.getMaxPoolSize() \u0026gt; threadPoolTaskExecutor.getCorePoolSize()) { // 先调整最大线程数，再调整核心数 （先扩大总量，再扩大局部） threadPoolTaskExecutor.setMaxPoolSize(threadPoolChange.getMaxPoolSize()); threadPoolTaskExecutor.setCorePoolSize(threadPoolChange.getCorePoolSize()); threadPoolTaskExecutor.setQueueCapacity(threadPoolChange.getQueueCapacity()); } else { // 先减少局部，再减少总量 threadPoolTaskExecutor.setCorePoolSize(threadPoolChange.getCorePoolSize()); threadPoolTaskExecutor.setMaxPoolSize(threadPoolChange.getMaxPoolSize()); threadPoolTaskExecutor.setQueueCapacity(threadPoolChange.getQueueCapacity()); } } } } 分布式与微服务 1. SpringBoot实现动态Job的实战 相关代码：https://github.com/SwimmingLiu/JavaSceneQuiz100/tree/main/lesson011\n1.1 Job表 - 表结构 字段名 类型 可空 默认 备注 id varchar(50) 否 - id，主键 name varchar(100) 否 - job名称，可以定义一个有意义的名称 cron varchar(50) 否 - job的执行周期，cron表达式 bean_name varchar(100) 否 - job需要执行那个bean，对应spring中bean的名称 bean_method varchar(100) 否 - job执行的bean的方法 status smallint 否 0 job的状态,0：停止，1：执行中 1.2 Job执行管理器 @Component public class SpringJobRunManager implements CommandLineRunner { // applicationContext 主要用于在任务执行时动态获取和调用指定的 Bean 和方法，实现灵活的任务调度。 // 可以把它理解为“Spring 管理的对象工厂和服务总线” @Autowired private ApplicationContext applicationContext; // threadPoolTaskScheduler 是 Spring 提供的线程池定时任务调度器，主要用于在应用中以多线程方式执行定时任务（如定时执行、Cron表达式调度等） @Autowired private ThreadPoolTaskScheduler threadPoolTaskScheduler; // job表相关服务 @Autowired private JobService jobService; /** * 系统重正在运行中的job列表 */ private Map\u0026lt;String, SpringJobTask\u0026gt; runningJobMap = new ConcurrentHashMap\u0026lt;\u0026gt;(); /** * springboot应用启动后会回调 * * @param args incoming main method arguments * @throws Exception */ @Override public void run(String... args) throws Exception { //1、启动job this.startAllJob(); //2、监控db中job的变化（job增、删、改），然后同步给job执行器去执行 this.monitorDbJobChange(); } } Springboot应用启动之后会回调 CommandLineRunner 中的 run 方法，依次启动job，并监控job中的变化。\n1.2.1 启动job 启动job的方式比较简单，就是从数据库中找出所有需要启动的job（状态为start），然后循环启动。\n启动job具体方式如下：\nprivate void startAllJob() { List\u0026lt;Job\u0026gt; jobList = this.jobService.getStartJobList(); for (Job job : jobList) { this.startJob(job); } } /** * 启动一个定时任务（job） * * @param job 需要启动的任务对象 */ private void startJob(Job job) { // 1. 创建任务执行体，注入Spring上下文，便于任务内获取Bean对象 SpringJobTask springJobTask = new SpringJobTask(job, this.applicationContext); // 2. 根据job的cron表达式创建调度触发器 CronTrigger trigger = new CronTrigger(job.getCron()); // 3. 使用线程池调度器注册任务，返回调度句柄 ScheduledFuture\u0026lt;?\u0026gt; scheduledFuture = this.threadPoolTaskScheduler.schedule(springJobTask, trigger); // 4. 记录调度句柄到任务对象，便于后续取消 -\u0026gt; springJobTask.setScheduledFuture(scheduledFuture); // 5. 将任务放入运行中的任务Map，方便管理和查找 runningJobMap.put(job.getId(), springJobTask); // 6. 记录日志，方便追踪 logger.info(\u0026#34;启动 job 成功:{}\u0026#34;, JSONUtil.toJsonStr(job)); } /** * 删除（停止）一个定时任务 * @param job 需要删除的任务对象 */ private void deleteJob(Job job) { if (job == null) { return; } // 1. 从运行中的任务Map获取任务 SpringJobTask springJobTask = this.runningJobMap.get(job.getId()); if (springJobTask == null) { return;} // 2. 取消任务调度（停止定时执行） springJobTask.getScheduledFuture().cancel(false); // 3. 从Map中移除该任务 runningJobMap.remove(job.getId()); // 4. 记录日志 logger.info(\u0026#34;移除 job 成功:{}\u0026#34;, JSONUtil.toJsonStr(job)); } /** * 更新一个定时任务（先删除再启动） * @param job 需要更新的任务对象 */ public void updateJob(Job job) { // 1. 先删除旧的任务 this.deleteJob(job); // 2. 再启动新的任务 this.startJob(job); // 3. 记录日志 logger.info(\u0026#34;更新 job 成功:{}\u0026#34;, JSONUtil.toJsonStr(job)); } 1.2.2 动态监控DB中job的变化 /** * 监控db中job的变化，每5秒监控一次，这个频率大家使用的时候可以稍微调大点 */ private void monitorDbJobChange() { this.threadPoolTaskScheduler.scheduleWithFixedDelay(this::jobChangeDispose, Duration.ofSeconds(5)); } // 任务变化处理 private void jobChangeDispose() { //1、从db中拿到所有job，和目前内存中正在运行的所有job对比，可得到本次新增的job、删除的job、更新的job JobChange jobChange = this.getJobChange(); //2、处理新增的job for (Job job : jobChange.getAddJobList()) { this.startJob(job);} //3、处理删除的job for (Job job : jobChange.getDeleteJobList()) { this.deleteJob(job);} //4、处理变化的job for (Job job : jobChange.getUpdateJobList()) { this.updateJob(job);} } private JobChange getJobChange() { //新增的job List\u0026lt;Job\u0026gt; addJobList = new ArrayList\u0026lt;\u0026gt;(); //删除的job List\u0026lt;Job\u0026gt; deleteJobList = new ArrayList\u0026lt;\u0026gt;(); //更新的job List\u0026lt;Job\u0026gt; updateJobList = new ArrayList\u0026lt;\u0026gt;(); //从db中拿到所有job，和目前内存中正在运行的所有job对比，可得到本次新增的job、删除的job、更新的job List\u0026lt;Job\u0026gt; startJobList = this.jobService.getStartJobList(); for (Job job : startJobList) { SpringJobTask springJobTask = runningJobMap.get(job.getId()); if (springJobTask == null) { addJobList.add(job); } else { //job的执行规则变了 if (jobIsChange(job, springJobTask.getJob())) { updateJobList.add(job); } } } //获取被删除的job，springJobTaskMap中存在的，而startJobList不存在的，则是需要从当前运行列表中停止移除的 Set\u0026lt;String\u0026gt; startJobIdList = CollUtils.convertSet(startJobList, Job::getId); for (Map.Entry\u0026lt;String, SpringJobTask\u0026gt; springJobTaskEntry : runningJobMap.entrySet()) { if (!startJobIdList.contains(springJobTaskEntry.getKey())) { deleteJobList.add(springJobTaskEntry.getValue().getJob()); } } //返回job变更结果 return new JobChange(addJobList, updateJobList, deleteJobList); } /** * 检测两个job是否发生了变化，（cron、beanName、beanMethod）中有任意一项变动了，则返回true * * @param job1 * @param job2 * @return */ private boolean jobIsChange(Job job1, Job job2) { return !(Objects.equals(job1.getCron(), job2.getCron()) \u0026amp;\u0026amp; Objects.equals(job1.getBeanName(), job2.getBeanName()) \u0026amp;\u0026amp; Objects.equals(job1.getBeanMethod(), job2.getBeanMethod())); } ","permalink":"https://swimmingliu.cn/posts/job/java-scene-quiz-100/","summary":"\u003ch1 id=\"并发与性能优化\"\u003e并发与性能优化\u003c/h1\u003e\n\u003ch2 id=\"1-大文件上传如何处理分片上传\"\u003e1. 大文件上传如何处理？分片上传\u003c/h2\u003e\n\u003cp\u003e相关代码：\u003ca href=\"https://github.com/SwimmingLiu/JavaSceneQuiz100/tree/main/lesson001\"\u003ehttps://github.com/SwimmingLiu/JavaSceneQuiz100/tree/main/lesson001\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"11-为什么需要分片上传\"\u003e1.1 为什么需要分片上传?\u003c/h3\u003e\n\u003cp\u003e大文件在上传的过程中，耗费的时间比较长。如果网络不稳定，很可能导致上传失败，需要重新上传。分片上传，就可以解决这个问题。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e分片上传定义\u003c/strong\u003e：将大文件拆分为不同的文件块，逐块进行上传\u003c/p\u003e\n\u003ch3 id=\"12-如何实现分片上传\"\u003e1.2 如何实现分片上传？\u003c/h3\u003e\n\u003ch4 id=\"121-如何存储分片信息\"\u003e1.2.1 如何存储分片信息\u003c/h4\u003e\n\u003cp\u003e分片上传需要记录文件的属性 (md5、大小、名称)、分片数量、文件存储的完整路径 (本地路径)，还需要记录每个分块的上传情况 (分块大小、分块顺序、分块任务id)。可以用 \u003cstrong\u003e分块上传任务表\u003c/strong\u003e 和 \u003cstrong\u003e分块文件表\u003c/strong\u003e 来记录。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e分块任务表 (t_shard_upload)\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sql\" data-lang=\"sql\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003ecreate\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003etable\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003enot\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eexists\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003et_shard_upload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nb\"\u003evarchar\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eprimary\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003ekey\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"n\"\u003efile_name\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nb\"\u003evarchar\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e256\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003enot\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003enull\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003ecomment\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;文件名称\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"n\"\u003epart_num\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003enot\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003enull\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003ecomment\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;分片数量\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"n\"\u003emd5\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nb\"\u003evarchar\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e128\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003ecomment\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;文件md5值\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"n\"\u003efile_full_path\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nb\"\u003evarchar\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e512\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003ecomment\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;文件完整路径\u0026#39;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003ecomment\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;分片上传任务表\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e分块文件表 (t_shard_upload_part）\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sql\" data-lang=\"sql\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003ecreate\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003etable\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003enot\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eexists\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"n\"\u003et_shard_upload_part\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nb\"\u003evarchar\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eprimary\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003ekey\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"n\"\u003eshard_upload_id\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nb\"\u003evarchar\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003enot\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003enull\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003ecomment\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;分片任务id（t_shard_upload.id）\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"n\"\u003epart_order\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003enot\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003enull\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003ecomment\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;第几个分片，从1开始\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"n\"\u003efile_full_path\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nb\"\u003evarchar\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e512\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003ecomment\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;文件完整路径\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"k\"\u003eUNIQUE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eKEY\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003euq_part_order\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003eshard_upload_id\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003epart_order\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003ecomment\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;分片文件表，每个分片文件对应一条记录\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e分块文件表和分块上传表是 \u003cstrong\u003e1 to M\u003c/strong\u003e 的关系，假如当前文件分为\u003cstrong\u003e10\u003c/strong\u003e块。则会出现\u003cstrong\u003e1\u003c/strong\u003e个分片上传任务，和\u003cstrong\u003e10\u003c/strong\u003e个分片文件记录。\u003c/p\u003e","title":"Java场景100题"},{"content":"八股题 Java 基础 + 集合 面向对象和面向过程的区别？ 面向对象：将数据和方法封装成对象，作为程序的基本单元来组织代码，包含封装、继承、多态三大特性，方便代码复用和灵活性。\n面向过程：以过程做为基本单元来组织代码，过程对应到代码中就是函数，将函数和数据分离，比较关注步骤和流程。其实就是一条路走到底的思想，关注如何设计一系列顺序执行的过程实现。\n封装、继承、多态? 封装（Encapsulation）：通过将对象的属性和方法结合为独立单元，并利用访问修饰符（如private）隐藏内部细节，仅通过公共接口（如getter/setter）控制访问，从而提升安全性和可维护性\n继承（Inheritance）：允许子类基于父类的属性和方法进行扩展，实现代码复用，Java采用单继承机制（仅支持一个直接父类），但可通过接口实现多重继承的效果\n多态（Polymorphism）：同一方法调用因对象实际类型不同而产生不同行为，通常通过父类引用指向子类对象及方法重写实现，依赖运行时动态绑定机制决定具体执行逻辑。（重写和重载）\n常见排序算法？时间复杂度？ 直接插入排序：o(n^2)\n冒泡排序：o(n^2)\n快速排序: o(nlogn)\n堆排序：o(nlogn)\n归并排序：o(nlogn)\n算法 平均时间复杂度 最坏时间复杂度 空间复杂度 稳定性 适用场景 插入排序 O(n²) O(n²) O(1) 稳定 部分有序数据 冒泡排序 O(n²) O(n²) O(1) 稳定 教学示例、小数据 快速排序 O(n log n) O(n²) O(log n) 不稳定 大规模随机数据 归并排序 O(n log n) O(n log n) O(n) 稳定 大数据、外部排序 堆排序 O(n log n) O(n log n) O(1) 不稳定 实时系统、内存受限场景 ArrayList 和 LinkedList 的区别？ ArrayList：底层是动态数组，有扩容机制，内存连续，查询快，增删慢。 LinkedList：底层是双向链表，内存不连续，查询慢，增删快。 【注意】 实际过程中，ArrayList 的增删操作比 LinkedList 快了进百倍。\n随着集合容量的增加，LinkedList add累计耗时直线上升，ArrayList add累计耗时上升很慢；LinkedList 慢的原因应该是每次add一个值都需要封装成Node然后追加到链表尾部，每次封装Node（实例化Node对象）的耗时不容小觑；ArrayList add 不需要封装，影响耗时的只有扩容，而每次扩容都是调用底层System.arraycopy 数组拷贝，这个拷贝函数内存复制执行很快，而且每次扩容int newCapacity = oldCapacity + (oldCapacity \u0026gt;\u0026gt; 1); 为原容量的1.5倍，所以随着容量增加其实扩容不了几次，这也是ArrayList add速度快的原因。\nJava的基本数据类型？ String创建对象时如何创建，创建几个对象，用new和不用的区别？ String创建对象的时候，可能会创建1个或者2个对象。\n如果不使用 new\n第一次需要创建字符串字面量存入字符串常量池中，String s1 = \u0026quot;SwimmingLiu\u0026quot;，引用该字符串字面量 第二次如果需要相同的字符串，String s2 = \u0026quot;SwimmingLiu\u0026quot;，引用该字符串字面量且不会创建任何对象 如果使用new ：每次创建字符串对象都会在堆内存中存放一个新的对象\n如果字符串字面量不在字符串常量池中，会创建两个对象（堆内存对象 + 字符串常量池中的对象），String s3 = new String(\u0026quot;SwimmingLiu\u0026quot;) 如果字符串字面量已经在字符串常量池中，只会创建一个对象（堆内存对象），String s4 = new String(\u0026quot;SwimmingLiu\u0026quot;) 字符串操作有哪些类？有什么区别？ String、StringBuilder、StringBuffer\n线程安全：String 、StringBuffer String：String 是不可变量，底层用 final 修饰，每次对String修改都会产生新的副本，从而占用更多的资源，频繁大量的修改会造成资源的浪费 StringBuffer：StringBuffer 是为了解决String 可能造成资源浪费的问题，底层用 char[] 数组，所有修改方法采用 synchronized 锁， 所以线程安全 线程不安全：StringBuilder StringBuilder：StringBuilder 在 StringBuffer 的基础上把 synchronized 锁去掉了，舍弃了线程安全单性能更高 如何通过Stream流进行过滤、集合和映射的操作？ JUC 并发 Java的锁有哪些？ 内置锁（synchronized）：Java语言层面提供的关键字，隐式加锁，使用简单。 显示锁（Lock接口及其实现）：比如 ReentrantLock、ReentrantReadWriteLock（读写锁）、StampedLock 等，提供更灵活的锁操作，如可中断、公平性等。 【不同锁的区别】\nsynchronized：内置锁（Monitor Lock），可以用于方法或代码块，提供互斥访问。当一个线程进入 synchronized 方法或块时，它会自动获取对象的锁，其他线程则需等待锁释放后才能进入。 synchronized 是一种非公平，悲观，独享，互斥，可重入的重量级锁。\nReentrantLock：是一个重入锁，是 java.util.concurrent.locks 包中的接口 Lock 的实现，提供了比 synchronized 更灵活的锁操作，如尝试获取锁、可中断的获取锁、超时获取锁等。它也支持公平锁和非公平锁策略。 ReentrantLock 是一种默认非公平但可实现公平的，悲观，独享，互斥，可重入，重量级锁。\nReentrantReadWriteLock（读写锁）：也是 java.util.concurrent.locks 包中的一部分，允许同时有多个读取者，但只允许一个写入者。它分为读锁和写锁，读锁之间不互斥，读锁与写锁互斥，写锁之间也互斥，适用于读多写少的场景。\nReentrantReadWriteLock 是一种 默认非公平但可实现公平的，悲观，写独享，读共享，读写，可重入，重量级锁。\nStampedLock（Java 8 引入）：提供了三种锁模式：读锁、写锁和乐观读锁。相较于 ReentrantReadWriteLock ，StampedLock 提供了更细粒度的控制，支持乐观读取操作，可以提高并发性能。\n可以给我简述一下你都有什么并发经验吗 （JUC当中用到了哪些功能）？平时项目中有哪些地方用到了锁？项目中哪些部分考虑了线程安全？怎么用的？ 面试官您好，我平时在项目中大部分用到的都是分布式锁，主要是为了避免项目服务宕机和锁带来的内存压力。不过，我之前在学习的过程中，是整个方法区/代码块这种粒度比较大的地方，涉及到多个线程功能访问操作。我可能会选用 sychronized 。如果需要更细粒度的显示控制，或者需要让所有线程按顺序执行，我会采用ReentantLock 。\nSynchronized可以用在哪里？Synchronized锁升级的机制？ sychronized 一般用于需要存在线程安全问题的代码块/方法区，上锁需要一个锁对象。\nsychronized 锁升级机制主要是三种状态，从偏向锁(一个线程) -\u0026gt; 轻量级锁 (多个线程) -\u0026gt; 重量级锁 (多个线程竞争激烈)\n偏向锁：最开始有一个线程第一次获取锁的时候，JVM 会记录修改锁对象的对象头，标记为偏向状态。对象头里面会记录线程 id 和 对应的 epoch 偏向锁版本。后续该线程再获取这个锁，基本没啥开销。 轻量级锁：当有另外的线程尝试去获取已经被偏向的锁时，锁会升级为轻量级锁。上锁的过程中，JVM 会在当前线程的栈帧中，创建一个锁记录 LockRecord ，当锁记录指向锁对象。然后用 CAS 替换锁对象的标记字 Mark Word， 并将 Mark Word 的值存入锁记录。如果替换成功，锁对象的 Mark Word 就变成当前线程的所锁记录。使用 CAS 操作的目的是减少锁竞争的开销。 重量级锁：当 CAS 失败无法获取锁的时候，JVM判定其为多个线程竞争锁激烈，锁会升级成为重量锁。会使用操作系统的互斥量 Mutex 来实现线程的阻塞和唤醒。如果获取锁成功，线程会被放入Monitor的 owner 当中 Java内存模型（JMM), jdk8中有什么变化？ JMM 是用来解决由硬件速度差异引起的并发编程问题。CPU、内存、I/O设备之间的速度差异回影响程序性能。为了提高效率，采用了缓存、多任务处理和指令重排序等技术，但是这也导致了并发程序当中的可见性、有序性、原子性问题。JMM 就定义了一系列关键字 volatile 、synchronized 、final 确保程序能正确执行，还定义了Happens-Before 规则来明确操作之间的顺序关系。 【JDK8 变化】\nJDK 8通过元空间替代永久代、锁机制优化及内存屏障指令增强，JDK 8通过元空间替代永久代、锁机制优化及内存屏障指令增强\nJVM 虚拟机 JVM的垃圾回收机制和JVM性能调优了解？ 垃圾回收一般都是发生在堆内存里面，所以下面所有垃圾回收操作的对象基本都是在堆内存里面\n【JVM垃圾回收机制】\nJVM垃圾回收机制有三种，标记-清除 (CMS) 、**标记-整理 (G1) **、标记-复制\n标记-清除：主要分为两个阶段，标记 和 清除 标记：从 GC Roots 开始，通过 DFS 或者 BFS 遍历所有被引用的对象，并且在对象的头部 Header 标记为存活 （标记的都是不需要回收的对象-存活对象）。GC Roots 的对象包括 JVM 中引用的对象（如局部变量、方法参数）、方法区中类静态属性引用的对象（全局变量）、方法区中常量引用的对象、本地方法栈中 JNI 引用的对象 清除：遍历堆中的对象，将所有没有被标记的对象进行垃圾回收。垃圾回收的过程，不会移动和整理内存空间。一般都是通过空闲链表（双向链表）来标记被垃圾回收的区域，内存是空闲可用的。所以这种算法会导致内存空间碎片的产生 标记-复制：主要分为两个阶段，标记 和 复制，标记部分和上面一样 复制：该算法会把堆分成两块 (From 区和 To 区)，所有对象创建的时候都在 From 区里面（标记的对象也都在 From 区）。发生 GC 垃圾回收的时候，会将标记的对象（存活对象）从 From 区 复制到 To 区，然后整体回收 From 区。然后再从 To 区中，将存活对象复制回 From 区 标记-整理：主要分为两个阶段，标记 和 整理，标记部分和上面一样 整理：将被标记的对象（存活对象）往边界上整理，对其他的部分进行垃圾回收。它的优点是不会出现内存碎片，也不需要像复制算法那样腾出一半的空间，所以内存利用率也挺高的。它的缺点是需要对堆内存进行多次搜索，因为需要在同一个空间里面，完成标记和整理（移动）的操作。 【JVM性能调优】\nGC 垃圾回收器调优的核心原理就是尽可能在年轻代 Young GC 回收对象 （年轻代包含 Eden 区 和 两个 Survivor 区）。\n具体实现步骤如下：\n选择合适的GC：CMS (实时Web服务、电商秒杀等对响应时间敏感的场景)、G1 (平衡吞吐与延迟，如微服务集群、分布式缓存) 调整堆和新生代大小：内存设置合理可以减少 GC 频率，通过设置 -Xms 和 -Xmx 调整堆内存初始/最大值，结合 -Xmn 或 -XX:NewRatio 控制新生代占比，并通过 -XX:SurvivorRatio 调节 Eden 与 Survivor 区比例，根据应用对象生命周期和 GC 监控动态优化。 启用GC日志检测：监控和分析GC的行为，找出性能瓶颈 调整GC线程：提高并行GC性能 【CMS 和 G1对比】\n维度 CMS G1 算法 标记-清除（内存碎片） 标记-整理（减少碎片） 停顿时间 短（但可能因碎片触发Full GC） 可预测（默认200ms，可调） 堆内存范围 中小堆（\u0026lt;32GB） 大堆（4GB~32GB+） CPU占用 高（并发阶段占用25% CPU） 较低（并发线程自适应） JVM 运行时内存情况，每个地方存储的是什么？（JVM内存区域如何划分？） 堆内存、方法区（元空间）、直接内存、虚拟机栈、本地方法栈、程序计数器\n线程的共享区域以及非共享？ 共享区域：堆内存、直接内存、方法区（元空间） 私有区域：虚拟机栈、本地方法栈、程序计数器 MySQL 一条SQL语句的执行过程？ 检查连接： 校验账号密码，确定用户的连接权限 缓存查询：如果存在缓存，直接返回查询结果。(MySQL 8.0之后废弃) 语法分析：通过语法树分析SQL语句的语法是否正确 查询条件优化：优化 where 语句中的查询条件，比如联合索引拼接等等 执行SQL语句：执行器执行SQL语句，并返回执行结果 说一下MySQL索引？有什么优点？ 划分方向 索引类型 数据结构 B+树索引、Hash索引、倒排索引 (全文索引)、R-树索引 (多维空间树)、位图索引(Bitmap) 物理存储 聚簇索引、非聚簇索引 字段特性 主键索引、唯一索引、普通索引(二级索引、辅助索引)、前缀索引 字段个数 单列索引、联合索引 优点：索引可以加速SQL语句条件查询的检索过程，快速定位到关键行\n为什么我们不每一列数据都创建一个索引？索引过多的缺点是什么？ 索引不是越多越好，如果创建的索引过多，因为每次修改都需要维护索引数据，会消耗资源和导致查询时间增长。\n**【时间开销】**进行增删改操作的时候，索引也必须更新。索引越多，需要修改的地方就越多，时间开销大。B+树可能会出现页分裂、合并等操作，时间开销更大。\n【空间开销】 建立二级索引，都需要新建一个B+树，每个数据页面都是16KB。如果数据大，索引又多，占用的空间不小。\n什么情况会出先索引失效？简单说三种让索引失效的情况？ 联合索引不满足最左前缀匹配原则 联合索引的首列使用 \u0026gt; 或者 \u0026lt; (单列索引不会失效) 对索引列使用运算 where id + 8 = 16、函数 count()、distinct() 、like '%xx%' 等操作 对索引列使用不同的数据类型进行条件筛选 （强制转换 -\u0026gt; 函数） 对索引列和非索引列使用 or 操作 (where name = \u0026quot;swimmingliu\u0026quot; or age = 34) 怎么判断查询是走索引还是走全表 ？ 使用 EXPLAIN 对指定的SQL语句进行分析，EXPLAIN 分析结果 的 type 表示查询的访问类型，影响查询的效率。常见的值：\nref: 使用索引，查找匹配某个单一列的值（比如通过外键查找）。比 range 更高效。 range: 使用索引扫描某个范围内的值，适用于 BETWEEN、\u0026gt; \u0026lt; 等条件。 index: 全索引扫描，扫描整个索引结构，不读表数据，通常效率比全表扫描好。 all: 全表扫描，没有使用索引 总结：ref \u0026gt; range \u0026gt; index \u0026gt; all。\n了解分页查询吗？第一页查询和最后一页查询哪一个快？ 第一页查询通常比最后一页快。 使用 LIMIT 和 OFFSET 进行分页时，数据库必须跳过前面的记录。例如，LIMIT 10 OFFSET 0（第一页）只需读取前10条记录，而 LIMIT 10 OFFSET 99990（最后一页）则需要跳过99990条记录后再读取10条，导致性能下降。\n为提高性能，建议使用 “键集分页”（Keyset Pagination），即基于唯一字段（如自增ID）进行分页：\nSELECT * FROM table WHERE id \u0026gt; ? ORDER BY id ASC LIMIT 10; MySQL索引怎么实现 （原理）? MySQL 索引主要通过 B+ 树实现，其原理是将所有数据存储在叶子节点，非叶子节点仅存储索引键。这种结构使得树的高度较低，减少磁盘 I/O 次数，提高查询效率。此外，叶子节点之间通过链表连接，支持高效的范围查询和顺序访问。由于非叶子节点不存储实际数据，每个节点可以容纳更多的索引键，从而进一步降低树的高度。这种设计充分利用磁盘预读特性，适合存储在磁盘上的大规模数据，提高了查询性能。\n怎么优化SQL语句查询效率？ 可以分为预防和解决慢查询两种方案。\n【预防】\n创建合适的索引：对需要频繁查询、数据分布一致性低、 group by 分组、order by 排序的列建立单列索引或者联合索引。 避免索引失效：联合索引最左前缀匹配原则、单列索引避免使用函数、计算、like %xx% 等 减少回表和I/O次数：避免 select * 操作。因为正常情况下，部分字段是没有二次索引的，它会用主键id或者rowid 进行回表查询，会增加系统的I/O。 【解决慢查询】\n开启慢SQL日志记录功能：使用set global slow_query_log = \u0026quot;ON\u0026quot;， 默认是关闭的。设置一个查询延迟的阈值，把超过规定时间的SQL查询找出来。 分析慢SQL：利用explain关键字分析慢SQL的原因，比如看看是否有索引失效、select *等情况 MySQL用了哪些优化方式？ 存储引擎优化：默认使用 InnoDB，支持事务、行级锁和崩溃恢复。 索引优化：使用 B+ 树索引，支持复合索引和覆盖索引，提升查询效率。 查询优化：利用查询优化器选择最佳执行计划，避免全表扫描。 缓存机制：通过调整 innodb_buffer_pool_size 等参数，提高数据和索引的缓存命中率。 连接管理：使用连接池减少连接开销，提升并发处理能力。 配置调整：根据负载调整参数，如 max_connections、query_cache_size 等，优化资源使用。 分库分表：对大数据量进行水平或垂直拆分，减小单表压力。 读写分离：主从复制架构中，主库负责写操作，从库负责读操作，提升整体性能。 MySQL是左优先还是右优先？ MySQL 使用 “最左前缀匹配原则”，即索引匹配从最左列开始，必须连续匹配。例如，联合索引 (a, b, c) 中，查询条件必须包含 a，才能利用索引。如果查询条件是 b=1 或 c=1，索引将不会被使用。此外，遇到范围查询（如 \u0026gt;、\u0026lt;、BETWEEN、LIKE）时，匹配会停止，后续列无法利用索引。查询优化器会尝试重排条件顺序，但必须包含最左列才能命中索引。\n聊一下MySQL隔离级别 ？ MySQL的隔离级别有四种：读未提交 RU、读已提交 RC、可重复读 RR、串行化 MySQL的默认隔离级别为 可重复度 RR\n隔离性 读未提交 RU 读已提交 RC 可重复读 RR 串行读 脏读 ❌ ✅ ✅ ✅ 不可重复读 ❌ ❌ ✅ ✅ 幻读 ❌ ❌ ❌ ✅ 脏读：事务A开启事务准备查询 name = SwimmingLiu 的学生信息 (数据库当中 age = 23 )，网络延迟还没开始执行。此时，事务B修改 name = SwimmingLiu 的 age = 99， 然后区执行其他的操作，还没提交事务。事务A读取到的数据为 age = 99， 但是此时数据库中的数据为 age = 23，出现数据不一致的情况。 不可重复读：事务A开启事务准备查询 name = SwimmingLiu 的学生信息 age = 23 ，然后去执行其他的事务。此时，事务B修改 name = SwimmingLiu 的 age = 99，提交事务。事务A 第二次重新去读取 name = SwimmingLiu 的学生信息 (age = 99)， 第二次读取的数据和第一次读取的数据出现数据不一致的情况。 幻读：事务A最开始查询 age = 23 的学生人数，发现有 10 个人，然后去执行其他的操作。事务B 新增了一条age = 23 的学生信息数据，提交事务。事务A第二次去查询 age = 23 的学生人数的时候，发现学生人数变成了 11 个人，和第一次读取的数据总量相比不一样。 MySQL的乐观锁，悲观锁 ？ 悲观锁：假设会发生并发冲突，操作前加锁。\n-- 悲观锁，使用SELECT ... FOR UPDATE START TRANSACTION; -- 开启事务 SELECT * FROM products WHERE id = 1 FOR UPDATE; -- 上锁（排他锁） UPDATE products SET stock = stock - 1 WHERE id = 1; COMMIT; 乐观锁：假设不会发生冲突，更新时校验版本号。\n-- 表结构添加version字段 ALTER TABLE products ADD COLUMN version INT DEFAULT 0; -- 查询当前版本 SELECT id, stock, version FROM products WHERE id = 1; -- 乐观锁更新，条件中包含版本号 UPDATE products SET stock = stock - 1, version = version + 1 WHERE id = 1 AND version = 当前版本号; Redis 聊一下Redis的应用场景 ？ 数据缓存：消息缓存、商品缓存预览 分布式锁：操作临界资源的时候，使用分布式锁进行上锁。 计数器（Counter）：适用于实现访问量统计、点赞数等功能，支持高并发下的原子自增操作。 排行榜（Leaderboard）：通过有序集合（Sorted Set）实现实时排名功能，如游戏积分榜等。 位图（Bitmap）：用于实现签到、活跃用户统计等功能，节省存储空间。 全局唯一 ID 生成（Unique ID Generation）：通过自增键生成全局唯一的标识符，适用于订单号等场景。 缓存三件套和对应的解决方案？ 穿透：客户端查询的数据在数据库中不存在，所有的请求都打到数据库上，导致数据库压力过大。解决方法有两种，一种是对数据库查询不到的数据，同样存入Redis当中，值设置为 null。另外一种方案是采用布隆过滤器的策略，过滤掉部分数据不存在的请求。 雪崩：Redis当中大量的key同时过期，导致大部分请求都打到数据库上。解决方法是设置随机的过期时间 TTL ，防止大量key同时过期。 击穿：Redis当中某个热点Key突然过期，大量的流量同一时间全部打到数据库上。可以采用互斥锁、逻辑过期两种方案。如果对数据一致性要求高，可以采用互斥锁。如果要求不高，可以采用逻辑过期的方案，可能返回的缓存数据和数据库不一致。 另外，雪崩和击穿都可以采用限流+熔断的机制，暂停服务对于缓存服务的访问，直接返回错误。或者启用限流规则，只允许商家或指定类型的用户请求发送数据库进行处理，过多的请求就会拒接。一般会使用 Hystrix 或者 Sentinel 实现熔断或者限流。\n为什么要用Redis进行缓存？ 因为Redis是基于内存的，查询速度比MySQL数据库的速度要快很多倍。用Redis进行缓存，可以加速查询操作。\nRedis持久化机制有哪些？各自的优缺点？ Redis的持久化机制主要有两种：RDB 和 AOF\nRDB: Redis在指定的时间间隔内，生成数据库的快照并将其保存为二进制文件（dump.rdb）。\n优点：\n性能高：RDB是通过生成快照的方式进行持久化，不会阻塞客户端操作。 备份方便：可以通过RDB文件进行数据备份，且RDB文件较小。 恢复速度快：Redis重启时，加载RDB文件比AOF恢复速度要快。 缺点：\n数据丢失：如果Redis在快照保存期间宕机，会丢失未持久化的数据。 持久化频率不灵活：需要根据业务需求手动设置持久化的间隔。 **AOF: **Redis将每次写操作追加到AOF日志文件中，保存所有写命令。\n优点：\n数据持久性高：AOF保证了所有写操作都会被记录，可以做到较高的数据可靠性。 灵活的持久化频率：AOF有三种同步策略： 每次写入后同步：最安全，但性能最差。 每秒同步：安全与性能的折衷。 从不同步：性能最佳，但最容易丢失数据。 缺点：\n性能开销大：频繁的文件追加和同步可能会影响性能。 恢复速度慢：AOF文件较大，恢复时需要重新执行所有写命令。 文件大小：AOF文件相较于RDB文件要大，且随着操作增多，AOF文件会变得越来越大。 你刚刚说到的RDB和AOF，是怎么开启的呢？你有修改过Redis的配置文件吗？开启的参数是什么？ RDB：\nredis.conf保留/添加 save 900 1, save 300 10, save 60 10000 等行即可（默认已启用 RDB）。\nsave 900 1 # 15分钟至少1次修改触发 save 60 10000 # 1分钟至少10000次修改触发 rdbcompression yes # 启用压缩减少磁盘占用 在线开启：CONFIG SET save \u0026quot;900 1 300 10 60 10000\u0026quot;，随后 CONFIG REWRITE 写回文件。\nAOF\nredis.conf 设置 appendonly yes，通常配置 appendfsync everysec。 在线开启：CONFIG SET appendonly yes，Redis 会自动触发 AOF 重写；完成后执行 CONFIG REWRITE 。 AOF 文件名默认 appendonly.aof，可用 appendfilename 自定义。 聊一下Redis集群 ？ Redis集群有两种模式：一种是主从节点+ 哨兵机制 Sential 模式，另外一种是 Redis Cluster 模式 Cluster 集群当中包含多个 哨兵机制 Sential 模式的主从节点\nCluster集群模式：集群模式用于对数据进行分片，主要用于解决大数据、高吞吐量的场景。将数据自动分不到多个Redis实例上，支持自动故障转移（如果某个实例失效，集群会自动重写配置和平衡，不需要手动进行调整，因为内置了哨兵逻辑）\nSentinel哨兵模式: 哨兵模式用于保证主从节点的高可用，读写分离场景。如果主节点宕机，哨兵会将从节点升为主节点。\n如果集群的Redis中一台突然挂了，此时有请求未处理怎么办？ 选取新的主节点：从有效的从节点中选取一个从节点做为新的主节点（选取条件：优先级 \u0026gt; 复制进度 offset \u0026gt; 从节点 id 大小）\n客户端重试与重定向：Redis集群的Smart客户端（如JedisCluster）内置路由表，当请求发送至故障节点时，客户端会收到 MOVED 或 ASK 重定向指令，自动将请求转发至新主节点。\nRedis如何设置均衡负载的？ Redis 缓存是如何更新的 （数据一致性问题）？ 先写数据库，再删缓存：除了删除缓存操作失败以外，能确保数据一致性问题 延迟双删 (先删缓存，再写数据库，再延迟删除缓存)：除了删除缓存操作失败以外，能确保数据一致性问题，另外也不好确定延迟的时间（一般是手动设置的） 【强一致性】\nbinlog + Canal：通过 binlog 检测数据库是否发生改动，如果出现改动，就触发删除缓存的机制。删除缓存操作使用消息队列的方式实现，之后当Redis消息被成功删除，才消费这条消息。 为什么Redis是单线程的 ？ 基于内存操作，Redis的瓶颈主要是内存，多数操作的性能瓶颈不是CPU带来的 (增加多线程也没啥用) 单线程模型的代码简单，可以减少线程上下文切换的性能开销。 单线程结合I/O多路复用模型，能提高I/O利用率 【注意】 Redis的单线程是指网络请求模块和数据操作模块是单线程的, 但是持久化存储模块和集群支撑模块是多线程的。\nSpring Spring的两大特性？IOC和AOP? IoC（控制反转）：将对象的创建和依赖关系交由 Spring 容器管理，实现解耦和灵活配置。\nAOP（面向切面编程）：将横切关注点（如日志、事务）从业务逻辑中抽离，集中管理，提高代码的模块化和可维护性。\nSpring 的 bean 生命周期？ Spring 的 Bean 生命周期从容器启动开始，首先加载 Bean 定义并实例化 Bean。然后 Spring 容器注入依赖，并调用初始化方法，如 @PostConstruct 注解的方法或配置文件中指定的 init-method 方法。Bean 完成初始化后，准备好供应用程序使用。当容器关闭时，Spring 会调用销毁方法，如 @PreDestroy 注解的方法或配置文件中指定的 destroy-method 方法，最后销毁 Bean 实例。\nSpringMVC 中的Bean作用域 ? singleton（默认）：整个 Spring 容器中仅有一个实例，适用于无状态的共享组件。 prototype：每次请求都会创建一个新的实例，适用于有状态的组件。 request：每个 HTTP 请求创建一个新的实例，适用于每次请求需要独立状态的组件。 session：每个 HTTP 会话创建一个新的实例，适用于需要在用户会话中共享状态的组件。 application：整个 ServletContext 共享一个实例，适用于需要在整个应用中共享状态的组件。 Springboot如何加载配置文件 ? Spring Boot通过多源层级化的配置加载机制，支持从多种来源（如属性文件、YAML文件、环境变量、命令行参数等）动态加载配置，并按优先级从高到低覆盖同名属性。默认情况下，它会优先加载命令行参数（如 --server.port=8080），其次是环境变量（如SPRING_DATASOURCE_URL）和外部配置文件（application.yml 或 application.properties），最后是项目内部资源目录下的默认配置文件。另外，可以通过spring.profiles.active 激活特定环境配置，比如dev 、test 、prod 环境\n【注意】application.properties 的优先级高于 application.yml\nSpringMVC的启动流程 ? 首先，启动时加载 DispatcherServlet，它是 SpringMVC 的核心控制器；\n其次，DispatcherServlet 通过 web.xml 配置文件读取相关配置，初始化Spring容器；\n然后，DispatcherServlet 根据 URL请求 通过 HandlerMapping 查找对应的处理器（Controller）；\n最后，执行处理器方法后，通过 ViewResolver 解析视图并返回给客户端。\n整个过程实现了请求的分发、处理和响应。\n其他 你自己在部署项目的时候有排查过问题没有？简单描述一下查询日志的linux命令 排查过问题, 我使用的是 tail -n 20 -f xxx.log\nLinux中pwd命令，以及如何查找指定文件命令 pwd 命令：这个命令是用来显示当前路径的绝对路径的 查找指定文件命令：find /home -name xxx.txt AI嵌入进IDEA中的底层原理是什么？什么算法？ copilot : 大语言模型接口 + 当前文件 / 指定文件做为上下文\n设计模式了解哪些，设计模式有哪些原则 【设计模式】\n设计模式是对软件设计中常见问题的通用可复用解决方案，分为三大类：\n创建型模式：解决对象创建的复杂性，如 Singleton（单例）、Factory Method（工厂方法）、Abstract Factory（抽象工厂）、Builder（建造者）、Prototype（原型）。 结构型模式：处理类和对象的组合，简化结构，如 Adapter（适配器）、Bridge（桥接）、Composite（组合）、Decorator（装饰器）、Facade（外观）、Flyweight（享元）、Proxy（代理）。 行为型模式：关注对象之间的通信和职责分配，如 Chain of Responsibility（责任链）、Command（命令）、Iterator（迭代器）、Observer（观察者）、Strategy（策略）、Template Method（模板方法）、Visitor（访问者）。 【设计原则】\n设计原则则是指导软件开发的高层次准则，帮助构建可维护、可扩展的系统。其中，SOLID 是五个核心面向对象设计原则的首字母缩写：\n单一职责原则（SRP）：一个类应仅有一个引起其变化的原因，即只承担一个职责。 开闭原则（OCP）：软件实体应对扩展开放，对修改关闭，即可以在不修改现有代码的情况下扩展功能。 里氏替换原则（LSP）：子类型对象应能够替换任何父类型对象，并且程序行为不受影响。 接口隔离原则（ISP）：不应强迫客户依赖它们不使用的方法，建议为不同的客户提供专门的接口。 依赖倒置原则（DIP）：高层模块不应依赖低层模块，二者都应依赖于抽象；抽象不应依赖细节，细节应依赖抽象。 请求转发和重定向区别 ? 特性 请求转发（Forward） 请求重定向（Redirect） 跳转方式 服务器端内部跳转 浏览器发起新请求 请求次数 一次请求 至少两次请求 URL 地址栏 不变 更新为新 URL 数据共享 同一请求对象，共享数据 不共享数据，需通过 session 或 URL 参数传递 性能 较快 较慢 使用场景 同一 Web 应用内部跳转 跨域、跨站点跳转，或避免重复提交等场景 TCP三次握手，4次挥手 简历相关八股 为什么要设置一人一单？如何解决超卖问题和一人一单问题？ 设置一人一单：防止顾客反复刷单 超卖问题：MySQL 乐观锁检测 stock \u0026gt; 0 / Redis用 lua 脚本 一人一单问题：MySQL 统计是否存在该用户的订单 / Redis 用 lua 脚本 消息队列怎么保证数据可靠性 ? 消息队列（MQ）通过多种机制确保数据的可靠性，主要包括：\n消息持久化：将消息存储到磁盘，确保在系统崩溃或重启后消息不会丢失。 消息确认机制：生产者在发送消息后，等待消息被消费者确认处理成功，未确认的消息会被重试发送。 重试机制：在消息发送或消费失败时，系统会按照预定策略进行重试，直至消息成功处理或达到最大重试次数。 幂等性处理：消费者在处理消息时，确保同一消息多次消费不会导致数据不一致。 死信队列：将无法成功消费的消息转移到专门的队列中，供后续人工或系统处理。 事务机制：在生产者和消费者之间实现事务，确保消息的发送和消费操作要么都成功，要么都失败。 Websocket，websocket 与 http 区别？ Websocket 相当于全双工通信，例如直播聊天就是采用 Websocket 全双工通信，客户端和服务端可以双向发送消息\n【websocket 和 http 区别】\nHTTP 是基于请求-响应模式的无状态短连接协议，客户端每次需主动发起请求，服务器返回响应后连接立即断开，适用于传统网页加载等低频交互场景；WebSocket 则通过一次 HTTP 握手升级为全双工长连接协议，支持客户端与服务器实时双向通信，数据以二进制帧高效传输，减少了头部冗余开销，适用于在线聊天、实时游戏等高频低延迟场景。此外，HTTP 默认无加密（HTTPS 需额外配置），而 WebSocket 天然支持 WSS 加密，安全性更优。\n场景题 我现在有两千万的客户数据，但是我的Redis中只能存储20万的高净值用户数据，那么我该怎么确保每次拿出来的都是高净值的用户呢？ 筛选的步骤如图所示：\n高净值用户定义与数据建模： 根据业务特征定义多维度评估模型，构建指标体系。例如，金融资产总额 (40%)、年消费频次 (30%)、最近活跃时间 (20%)、风险等级 (10%)\n@Data public class Customer { private String id; // 用户ID（唯一标识） private BigDecimal assets; // 金融资产（精确计算） private int annualPurchases; // 年消费次数 private LocalDateTime lastActive; // 最近活跃时间 private int riskLevel; // 风险等级（1-5级） // 计算综合得分（需缓存避免重复计算） private transient BigDecimal score; } 高效筛选2000万中的20万优质数据：\n方案1：Stream API + 并行计算（适合全量筛选） List\u0026lt;Customer\u0026gt; allCustomers = loadFromDatabase(); // 从数据库加载2000万数据 Predicate\u0026lt;Customer\u0026gt; highValueFilter = customer -\u0026gt; customer.getRiskLevel() \u0026lt;= 3 \u0026amp;\u0026amp; // 风险等级≤3 customer.getLastActive().isAfter(LocalDateTime.now().minusMonths(3)); // 近3个月活跃 List\u0026lt;Customer\u0026gt; topCustomers = allCustomers.parallelStream() // 启用并行流 .filter(highValueFilter) .sorted(Comparator.comparing(Customer::getScore).reversed()) // 按得分降序 .limit(200_000) // 取前20万 .collect(Collectors.toList()); 方案2：数据库分页+实时计算（适合增量更新） // 使用JPA/Hibernate分页查询（避免内存溢出） int pageSize = 5000; int page = 0; List\u0026lt;Customer\u0026gt; batchList; do { batchList = customerRepository.findHighValueCustomers( PageRequest.of(page, pageSize, Sort.by(\u0026#34;score\u0026#34;).descending()) ); redisClient.batchInsert(batchList); // 批量写入Redis page++; } while (!batchList.isEmpty()); Redis 存储数据 (对应上面的批量写入Redis)：\n存储客户排名数据：采用 Sorted Set（ZSET) 以用户ID为 member，综合得分为score，自动按 score 排序，天然支持 TOP N查询。\nJedis jedis = RedisPool.getResource(); Pipeline pipeline = jedis.pipelined(); topCustomers.forEach(c -\u0026gt; pipeline.zadd(\u0026#34;high_value_users\u0026#34;, c.getScore().doubleValue(), c.getId()) ); pipeline.sync(); 存储客户信息数据：用Hash存储用户详细信息\ntopCustomers.forEach(c -\u0026gt; { pipeline.hset(\u0026#34;user:\u0026#34; + c.getId(), \u0026#34;assets\u0026#34;, c.getAssets().toString(), \u0026#34;lastActive\u0026#34;, c.getLastActive().toString() ); }); 容量控制 (只保留20万数据)：\n// 保留前20万，自动淘汰低分用户 jedis.zremrangeByRank(\u0026#34;high_value_users\u0026#34;, 200_000, -1); // 设置TTL避免数据过期（数据不一致） jedis.expire(\u0026#34;high_value_users\u0026#34;, 86400); 动态更新机制 (定时更新)\n@Scheduled(cron = \u0026#34;0 0 3 * * ?\u0026#34;) // 每天凌晨3点执行 public void refreshHighValueUsers() { List\u0026lt;Customer\u0026gt; newHighValue = customerRepository.findNewHighValueUsers(); // 使用Lua脚本保证原子性（网页6[6](@ref)） String luaScript = \u0026#34;redis.call(\u0026#39;ZADD\u0026#39;, KEYS[1], ARGV[1], ARGV[2]) \u0026#34; + \u0026#34;redis.call(\u0026#39;ZREMRANGEBYRANK\u0026#39;, KEYS[1], 200000, -1)\u0026#34;; jedis.eval(luaScript, 1, \u0026#34;high_value_users\u0026#34;, newHighValue.getScore(), newHighValue.getId()); } 我们在实际部署过程中，经常会遇到节点挂掉或者是整个Redis挂掉的情况，那么怎么才能保证Redis挂掉之后能够让数据进行恢复呢? 打开 AOF (everysec) + RDB 双持久化；重启时先加载 RDB 再回放 AOF，几乎零丢数据。 部署主从复制＋ 大于等于3 个 的哨兵Sentinel 或直接用 Redis Cluster，节点宕机秒级自动选主并切换客户端。 定时把 AOF/RDB 备份到外部存储；灾难时拉回文件启动或 RESTORE 即可，注意多 TB 备份的加载时间并定期演练。 【AOF 和 RDB 如何打开？】\nRDB：\nredis.conf保留/添加 save 900 1, save 300 10, save 60 10000 等行即可（默认已启用 RDB）。\nsave 900 1 # 15分钟至少1次修改触发 save 60 10000 # 1分钟至少10000次修改触发 rdbcompression yes # 启用压缩减少磁盘占用 在线开启：CONFIG SET save \u0026quot;900 1 300 10 60 10000\u0026quot;，随后 CONFIG REWRITE 写回文件。\nAOF\nredis.conf 设置 appendonly yes，通常配置 appendfsync everysec。 在线开启：CONFIG SET appendonly yes，Redis 会自动触发 AOF 重写；完成后执行 CONFIG REWRITE 。 AOF 文件名默认 appendonly.aof，可用 appendfilename 自定义。 我现在Redis是个单机，但是我现在有很多个系统，同时对一个类进行操作，那么我的一个key肯定会导致被多并发的去竞争？怎么解决这样的竞争问题？ 分布式锁（SETNX）：使用Redis的 SETNX 命令或者Redisson实现分布式锁，确保同一时间只有一个系统实例操作该key。\n消息队列串行化：将对同一 key 的操作放入消息队列，确保操作按顺序执行，避免并发冲突。例如，使用RabbitMQ或Kafka等消息中间件，将操作封装为消息，按顺序处理。\n时间戳控制：在写入key时，携带时间戳，只有当新操作的时间戳晚于当前存储的时间戳时，才执行写入，确保数据的时序性。\nHSET your_key value new_value timestamp new_timestamp 高并发主要要考虑哪些问题？ 线程/连接池容量：Tomcat workThreads、HikariCP max‑pool‑size 必须按 CPU×2+I/O 负载估算，防止池耗尽和排队 熔断‑限流‑隔离：用 Hystrix/Sentinel/Gateway 做线程池隔离、熔断与基于 Redis 的限流，阻断级联雪崩 缓存策略：热点预加载、互斥锁、布隆过滤器，分散过期时间，解决穿透/击穿/雪崩 数据一致性：幂等键＋TCC/SAGA 分布式事务，避免重复写与脏数据 JVM GC停顿：G1/ZGC + -XX:MaxGCPauseMillis=*，持续压测、监控 超时/重试/背压：超时 \u0026gt; 重试总时长；Reactive 流背压守护线程池 可观测性：指标、日志、分布式 Tracing 持续审计性能瓶颈。 对一个字符串进行排序然后转换为大写怎么实现？ 将字符串专程数组，然后调用 Arrays.sort() 函数，然后调用 new String(chars).toUpperCase() 将字符数组转成字符串，然后将所有的字母都转换成大小。\nString originalStr = \u0026#34;helloWorld\u0026#34;; // 1. 转换为字符数组并排序 char[] chars = originalStr.toCharArray(); Arrays.sort(chars); // 2. 生成排序后的字符串并转大写 String sortedUpperStr = new String(chars).toUpperCase(); System.out.println(sortedUpperStr); // 输出: DEHLLLOORW 综合题 \u0026amp; 智力题 高考完学生投档到各个学校，应该怎样设计算法？ 求两支股票在一段时间内的最长同步上升时间 ","permalink":"https://swimmingliu.cn/posts/job/hensheng-interview-questions/","summary":"\u003ch2 id=\"八股题\"\u003e八股题\u003c/h2\u003e\n\u003ch3 id=\"java-基础--集合\"\u003eJava 基础 + 集合\u003c/h3\u003e\n\u003ch4 id=\"面向对象和面向过程的区别\"\u003e面向对象和面向过程的区别？\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e面向对象\u003c/strong\u003e：将数据和方法封装成对象，作为程序的基本单元来组织代码，包含封装、继承、多态三大特性，方便代码复用和灵活性。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e面向过程\u003c/strong\u003e：以过程做为基本单元来组织代码，过程对应到代码中就是函数，将函数和数据分离，比较关注步骤和流程。其实就是一条路走到底的思想，关注如何设计一系列顺序执行的过程实现。\u003c/p\u003e\n\u003ch4 id=\"封装继承多态\"\u003e封装、继承、多态?\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e封装\u003c/strong\u003e（Encapsulation）：通过将\u003cstrong\u003e对象的属性和方法结合为独立单元\u003c/strong\u003e，并利用访问修饰符（如\u003ccode\u003eprivate\u003c/code\u003e）隐藏内部细节，仅通过\u003cstrong\u003e公共接口（如\u003ccode\u003egetter/setter\u003c/code\u003e）控制访问\u003c/strong\u003e，从而提升安全性和可维护性\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e继承\u003c/strong\u003e（Inheritance）：允许\u003cstrong\u003e子类基于父类的属性和方法进行扩展\u003c/strong\u003e，实现代码复用，Java采用单继承机制（仅支持一个直接父类），但可通过接口实现多重继承的效果\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e多态\u003c/strong\u003e（Polymorphism）：同一方法调用因对象实际类型不同而产生不同行为，通常通过\u003cstrong\u003e父类引用指向子类对象及方法重写实现\u003c/strong\u003e，依赖运行时动态绑定机制决定具体执行逻辑。（重写和重载）\u003c/p\u003e\n\u003ch4 id=\"常见排序算法时间复杂度\"\u003e常见排序算法？时间复杂度？\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e直接插入排序：o(n^2)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e冒泡排序：o(n^2)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e快速排序: o(nlogn)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e堆排序：o(nlogn)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e归并排序：o(nlogn)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: center\"\u003e\u003cstrong\u003e算法\u003c/strong\u003e\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003e平均时间复杂度\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003e最坏时间复杂度\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003e空间复杂度\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003e稳定性\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003e适用场景\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e插入排序\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eO(n²)\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eO(n²)\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eO(1)\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e稳定\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e部分有序数据\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e冒泡排序\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eO(n²)\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eO(n²)\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eO(1)\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e稳定\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e教学示例、小数据\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e快速排序\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eO(n log n)\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eO(n²)\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eO(log n)\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e不稳定\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e大规模随机数据\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e归并排序\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eO(n log n)\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eO(n log n)\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eO(n)\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e稳定\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e大数据、外部排序\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e堆排序\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eO(n log n)\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eO(n log n)\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eO(1)\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e不稳定\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e实时系统、内存受限场景\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch4 id=\"arraylist-和-linkedlist-的区别\"\u003eArrayList 和 LinkedList 的区别？\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eArrayList\u003c/strong\u003e：底层是动态数组，有扩容机制，内存连续，查询快，增删慢。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLinkedList\u003c/strong\u003e：底层是双向链表，内存不连续，查询慢，增删快。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e【注意】\u003c/strong\u003e 实际过程中，\u003ccode\u003eArrayList\u003c/code\u003e 的增删操作比 \u003ccode\u003eLinkedList\u003c/code\u003e 快了进百倍。\u003c/p\u003e","title":"恒生聚源面经记录"},{"content":"JVM 全局构架图如下，包含 JVM 的全部内容\n1. JVM 的内存区域是如何划分的？ JVM 内存当中，运行时数据的区域包含堆、方法区（元空间）、虚拟机栈、本地方法栈、程序计数器。另外，其他的内存区域属于本地内存，本地内存就包括直接内存，直接内存是非运行时数据区的一部分。 其中，堆和方法区（元空间） 是线程共享的，虚拟机栈、本地方法栈、程序计数器都是线程私有的。\n【注意】 JVM 规范对于运行时数据区域的规定是很宽松的。就拿堆来说，堆可以是连续空间，也可以是不连续空间。堆的大小可以固定，也可以再运行时按照需求进行扩展。虚拟机实现者可以使用任何垃圾回收算法管理堆，甚至完全不进行垃圾回收也是可以的。\n下面逐一介绍不同部分的功能和作用\n首先是线程私有的部分，程序计数器、虚拟机栈、本地方法栈。\n【程序计数器】\n定义：程序计数器就是记录当前所执行的字节码的行号。字节码解释器通过改变程序计数器的值，来选取下一条需要执行的字节码指令。它的生命周期随着线程的创建而创建，随着线程的结束而死亡。 作用：分支、循环、跳转、异常处理、线程恢复这些功能都需要依赖程序计数器完成。比如线程切换上下文中，从 A线程 先切换到 B线程，然后从 B线程 恢复到 A线程 的过程当中，为了 A线程 能够恢复到正确的执行位置，就需要读取 A线程 程序计数器的值，来确认切换线程前执行的位置在哪里。 为什么是线程私有：因为线程切换的过程当中，每个线程都需要一个程序计数器来记录自己的程序执行位置。 【注意】 程序计数器是唯一一个不会出现 OOM 内存不足的内存区域，因为他就只是存储一个值。\n【虚拟机栈】\n定义：虚拟机栈按照先进后出的方案存储的是非本地方法的调用对应的栈帧。每一次方法调用的时候会被压入栈中，方法结束的时候会被弹出栈中。栈帧中包含局部变量表、操作次数栈（存储操作数和临时计算结果）、动态链接、方法的返回地址。虚拟机的生命周期随着线程的创建而创建，随着线程的结束而死亡。 作用：存储非本地方法的栈帧，支持方法的调用和返回。当栈深度超过虚拟机允许的最大深度，会抛出 StackOverflowError 栈溢出异常。如果虚拟机栈无法动态扩展或申请到足够的内存，会抛出 OutOfMemoryError 内存不足异常。 栈帧中包含局部变量表、操作次数栈（存储操作数和临时变量）、动态链接、方法的返回地址。其中，局部变量表存放的是所有的局部变量，或者其出对应的地址（数组）。动态链接就是当前类常量池的引用。\n局部变量表：存放方法参数传入的形参值，方法内的局部变量、方法的 this 引用。内部结构主要存放了编译期可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针） 操作数栈：主要作为方法调用的中转站使用，用于存放方法执行过程中产生的中间计算结果。另外，计算过程中产生的临时变量也会放在操作数栈中。 动态链接：主要作用是实现在当前方法中调用其他方法。 Class 文件的常量池里面保存有大量的符号引用，比如方法的符号引用。 当一个方法需要调用其他方法，需要将常量池中只想方法的符号引用转换为在内存地址当中的直接引用。动态链接的作用就是把常量池的符号引用转换为内存当中的直接引用。 【本地方法栈】\n定义：本地方法栈和虚拟栈的结构是一样的。不同的是，本地方法栈是 JVM 调用 Native 方法的时候才会用到的，虚拟机栈是执行 Java 自身的方法 (也就是字节码) 会用到的。 作用：存储本地方法 (Native) 栈帧，支持方法的调用和返回。 【注意】 在 HotSpot 虚拟机当中，将本地方法栈和虚拟机栈合二为一了。\n其次，我们将介绍线程共享的部分，堆 和 方法区 （JDK 1.8叫元空间）\n【堆】\n定义：堆当中存储了所有的对象实例、数组。堆是 JVM 内存区域当中最大的一块，所有线程均可共享。另外，JVM 的堆是垃圾收集器管理的主要区域，因此也被称作 GC 堆（Garbage Collected Heap） 堆结构：从垃圾回收的角度，堆可以分为新生代、老年代、永久代。其中，新生代当中还包括了一个 Eden 伊甸园区 和 两个 Survivor 存活区 (S0 和 S1) 。在 JDK 1.8 当中，永久代已经被元空间取代了，而且元空间用得是本地内存。 不同代的区别：大部分情况下，对象会分先分到新生代的 Eden 区域，在一次新生代垃圾回收之后，如果对象还存货，则进入 Survivor 区中的 s0 或者 s1。同时，对象的年龄还会增加 1 (从 Eden 区到 Survior 区后，对象的初始年龄变为 1)。当它的年龄达到一定阈值 (默认为 15 岁)，就会从新生代晋升到老年代。年龄的阈值可以通过 XX:MaxTenuringThreshold 来设置，但是设置的值必须在 0 ~ 15 之间，不然会报错。 为什么年龄只能是 0-15?: 因为记录对象年龄的区域在对象头中，这个区域的大小通常是 4 位。这 4 位可以表示的最大二进制数字是 1111 ，即十进制的 15 。因此，对象的年龄被限制为 0 ~ 15。 在Hotspot 虚拟机中，遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了 Survivor 区的一半时，取这个年龄和 MaxTenuringThreshold 中更小的一个值，作为新的晋升年龄阈值 【注意】 JVM 的堆 最容易出现的就是 OutOfMemoryError 内存不足错误，并且出现这种错误之后的表现形式还会有好几种。比如 java.lang.OutOfMemoryError: GC Overhead Limit Exceeded 说明 JVM 花太多时间 ( 98% 的时间) 进行垃圾回收并且只回收了很少的垃圾 (2% 的垃圾); java.lang.OutOfMemoryError: Java heap space 是在创建新对象的时候，堆内存中空间不足，不能再存放新创建的对象了。\n【方法区】\n定义：当虚拟机要使用一个类的时候，它需要读取并解析 Class 文件并获取相关信息，再将信息存入方法区。方法区存储被 JVM 加载的 类信息、字段信息、方法信息、常量、静态变量、JIT 即时编译器编译后的代码缓存等数据\n方法区和永久代以及元空间是什么关系？：方法区和永久代以及元空间的关系，特别像 Java 当中的接口和类的关系，类实现了接口。类就相当于永久代或者元空间，接口就是方法区。也就是说永久代或者元空间是 HotSpot 虚拟机对方法区的两种实现方式。 JDK 1.7 是 永久代， JDK 1.8 之后是方法区。\n为什么JDK 1.8 采用元空间替换永久代？\n无法动态调整大小，容易内存溢出：整个永久代的大小受 JVM 内存大小的限制，而元空间用的是本地内存，元空间的大小和本机可用内存大小相关。虽然元空间还是可能出现内存溢出，但是比原来的几率更小。\n可以使用 -XX：MaxMetaspaceSize 标志设置最大元空间大小，默认值为 unlimited，这意味着它只受系统内存的限制。-XX：MetaspaceSize 调整标志定义元空间的初始大小如果未指定此标志，则元空间将根据运行时的应用程序需求动态地重新调整大小。\n元空间加载的类更多：元空间存放的是类的元数据，所以加载类的元数据不再受 MaxPermSize 控制 (永久代的最大阈值) ，而是由系统的实际可用空间来进行控制的，这样加载的类就更多了。\n永久代 GC 复杂度更高：永久代会为 GC 带来不必要的复杂度，并且回收效率偏低。\n方法区常用参数有哪些？： 可以分为 JDK 1.7 和 JDK 1.8 来看\nJDK 1.7: 采用永久代，常用下面的参数\n-XX:PermSize=N //方法区 (永久代) 初始大小 -XX:MaxPermSize=N //方法区 (永久代) 最大大小,超过这个值将会抛出 OutOfMemoryError 异常:java.lang.OutOfMemoryError: PermGen JDK 1.8：采用元空间，常用下面的参数\n-XX:MetaspaceSize=N //设置 Metaspace 的初始（和最小大小） -XX:MaxMetaspaceSize=N //设置 Metaspace 的最大大小, 默认值为 unlimited 下面将对运行时常量池 （方法区）、字符串常量池 （堆）、直接内存进行介绍\n【运行时常量池】\n运行时常量池是用来存放编译期间生成的各种字面量和符号引用的常量池表。这个常量池表会在类加载之后，存放到方法区的运行时常量池当中。\n字面量：顾名思义，包括整数、浮点数、字符串等字面量 符号引用：类符号引用、字段符号引用、方法符号引用、接口方法符号 【字符串常量池】\n字符串常量池是 JVM 为了提升性能和减少内存消耗专门针对字符串 String 类开辟的一块区域，主要是用来避免字符串的重复创建。\n// 在字符串常量池中创建字符串对象 \u0026#34;ab\u0026#34; // 将字符串对象 \u0026#34;ab\u0026#34; 的引用赋值给给 aa String aa = \u0026#34;ab\u0026#34;; // 直接返回字符串常量池中字符串对象\u0026#34;ab\u0026#34;，赋值给引用 bb String bb = \u0026#34;ab\u0026#34;; System.out.println(aa==bb); // true, aa和bb都是用的字符串常量池中的\u0026#34;ab\u0026#34; JDK 1.6 和 JDK 1.7 中，字符串常量池的存放位置不一致。在 JDK 1.6 中和 运行时常量池一样，存放在方法区里面。在 JDK 1.7 中，存放在堆里面。那么 JDK 1.7 为什么要将字符串常量池移动到堆中呢？ 主要是因为永久代 (方法区) 的 GC 回收效率太低， 只有在整堆收集 Full GC 的时候，才会被执行 GC。 Java 程序中通常会有大量的被创建的字符串等待回收，将这些字符串常量池存放在堆中，能够更高效及时地回收字符串内存。\n【直接内存】\n直接内存是一种特殊的内存缓冲区，并不属于 JVM 当中的堆或者方法区，而是通过 JNI （Java Native Interface）Java 本地方法接口的方式在本地内存上直接分配的一块区域。直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 错误出现。\nJDK1.4 中新加入的 NIO（Non-Blocking I/O，也被称为 New I/O），引入了一种基于通道（Channel）与缓存区（Buffer）的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。\n2. HotSpot 对象的创建过程 在 HotSpot 虚拟机当中，对象的创建过程如下：\n类加载检查：虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。\n分配内存：在类加载检查通过后，接下来 JVM 将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。\n指针碰撞：\n适用场合：**堆内存规整（即没有内存碎片）**的情况下。 原理：用过的内存全部整合到一边，没有用过的内存放在另一边，中间有一个分界指针，只需要向着没用过的内存方向将该指针移动对象内存大小位置即可。 使用该分配方式的 GC 收集器：Serial, ParNew 空闲列表：\n适用场合：堆内存不规整的情况下。 原理：虚拟机会维护一个列表，该列表中会记录哪些内存块是可用的，在分配的时候，找一块儿足够大的内存块儿来划分给对象实例，最后更新列表记录。 使用该分配方式的 GC 收集器：CMS 初始化零值：内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。\n设置对象头：初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希值、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。\n执行 init 方法：在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，\u0026lt;init\u0026gt; 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 \u0026lt;init\u0026gt; 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。\n【对象的内存布局】\n在 Hotspot 虚拟机中，对象在内存中的布局可以分为 3 块区域：对象头（Header）、**实例数据（Instance Data）**和 对齐填充（Padding）。\n对象头： 对象头主要包含标记字段和类型指针两个部分\n标记字段（Mark Word）：用于存储对象自身的运行时数据， 如哈希码（HashCode）、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳等等。 类型指针（Klass pointer）：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 实例数据：实例数据部分是对象真正存储的有效信息，也是在程序中所定义的各种类型的字段内容。\n对齐填充：对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。因为 Hotspot 虚拟机的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，换句话说就是对象的大小必须是 8 字节的整数倍。而对象头部分正好是 8 字节的倍数（1 倍或 2 倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全.\n【对象的访问方式】\n对象的访问方式主要有两种：使用句柄 或者 直接指针\n句柄：如果使用句柄的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与对象类型数据各自的具体地址信息。 直接指针：如果使用直接指针访问，reference 中存储的直接就是对象的地址。 3. 说说 Java 的执行流程? Java 程序的执行流程，可以分成三步。首先，从编译到字节码的生成。其次，再到类加载和 JIT 即时编译器的编译过程。最终，在 JVM 当中执行。 程序在运行的过程中，JVM 负责内存管理、垃圾回收和线程调度等工作。\n具体的执行流程如下：\n编写源代码：程序员编写 .java 源代码文件 编译器编译源代码：javac 编译器编译 .java 源代码，生成 .class 字节码文件 类加载：JVM 的类加载器加载 .class 文件到内存里面 解释执行：JVM 将加载后的 .class 文件的字节码转换为及其码执行 JIT 即时编译器编译：在解释执行过程中，JVM 会通过 热点探测技术（如方法调用计数器、回边计数器）识别频繁执行的代码（热点代码）。当某段代码的调用次数超过阈值（例如 Server 模式下的 10000 次），JIT 编译器会将其编译为本地机器码，并缓存到方法区的 Code Cache 中。其他代码仍由解释器执行。 运行程序：执行 main 方法中的逻辑 垃圾回收：JVM 管理内存，回收不再使用的对象 程序执行结束： main 方法结束，JVM 清理资源，退出程序 4. Java中常见的垃圾收集器有哪些？ Java 当中常见的垃圾收集器可以分为两种，新生代垃圾收集器和老年代垃圾收集器\n新生代垃圾收集器：新生代垃圾收集器都采用 “标记-复制” 的垃圾回收算法\nSerial 收集器：Serial 收集器是一种串行的单线程收集器，适合小型应用和单处理器的环境。收集的过程中，会触发 Stop-The-World (STW) 操作，所有应用线程在 GC 垃圾收集的时候会被暂停。\nParNew Parallel New 收集器：ParNew 收集器就是 Serial 收集器的并行多线程版本，能够并行地进行垃圾收集。和 CMS 收集器进行配合使用 (CMS 收集器用来收集老年代的垃圾，ParNew 收集新生代的垃圾)。一般适用于多处理器的环境。\nParallel Scavenge 并行清除垃圾收集器：Parallel Scavenge 也被称为 吞吐量收集器, 基于标记-复制垃圾回收算法实现的，主要侧重于最大化 CPU 时间的利用率。并行处理新生代垃圾回收，适合大规模运算密集型的后台任务，以及对吞吐量要求较高的场景。\n-XX:+UseParallelGC //使用 Parallel 收集器+ 老年代串行 -XX:+UseParallelOldGC //使用 Parallel 收集器+ 老年代并行 【注意】 ParNew 和 Parallel Scavenge 垃圾收集器的区别在于 ParNew 垃圾收集器通常配合 CMS 收集器进行使用，主要侧重于控制 GC 所导致的 STOP-THE-WORLD (STW) 操作的暂停时间，但是可能 GC 的次数更加频繁。Parallel Scavenge 收集器主要侧重吞吐量的大小，支持自适应调节(比如最大的 GC 暂停时间 MaxGCPauseMillis 和 GC 时间比例 GCTimeRatio)，但是可能牺牲部分响应时间 (STW过程) 。\n老年代垃圾收集器：大部分老年代垃圾收集器采用的**\u0026ldquo;标记-整理\u0026rdquo;** 垃圾回收算法，部分收集器 (比如 CMS 收集器) 采用的**\u0026ldquo;标记-清除\u0026rdquo;**\nSerial Old 收集器：Serial Old 其实就是 Serial 收集器的老年代版本，采用标记-整理 算法进行垃圾回收。适合单线程环境和低内存使用场景 Parallel Old 收集器：Parallel Old 收集器是 Parallel Scavenge 收集器的老年代版本，使用多线程并行标记-整理算法。适合大规模并行计算的场景，适用于高吞吐量要求的任务。 CMS Concurrent Mark-Sweep 收集器：CMS 收集器采用的并发标记-清除垃圾收集算法，追求低延迟，减少 GC 停顿时间 (STW 过程)。但是这个垃圾收集的过程中，可能会产生内存脆片，并且在并发阶段可能会出现 Concurrent Mode Failure， 导致 Full GC。适用于对响应时间要求高的应用，比如 Web 服务和电商平台 G1 Garbage First 收集器：主要用来取代 CMS 的地延迟垃圾收集器，能够提供可预测的停顿时间， 采用并发的标记-整理算法。通过分区来管理内存，并在垃圾收集的时候，优先处理最有价值的区域，避免了 CMS 内存碎片问题。适用于大内存、多 CPU 服务器，后期是在延迟和响应时间铭感的场景。 ZGC Z Garbage Collector 收集器：ZGC 是一种低停顿 (STW操作)、高吞吐量的垃圾收集器，停顿时间一般不会超过 10 ms。适用于需要管理大堆内存且对低延迟要求极高的应用。 【详解 CMS、G1 垃圾收集器】\nCMS Concurrent Mark Sweep垃圾收集器：CMS 是一种以获取最短回收停顿时间 (SWT操作) 为目标的收集器，基于 标记-清除 算法实现，整个收集过程分为下面四个阶段：\n初始标记：标记 GC Roots 能直接关联到的对象 （可达性分析），耗时短但需要暂停用户线程。 并发标记：从 GC Roots 能直接关联到的对象开始遍历整个对象图 （就是从所有可达的对象开始，遍历所有的对象），耗时长但是不需要暂停用户线程。 重新标记：采用增量更新算法 （就是不从头开始标记），对并发标记阶段因为用户线程运行而产生变动的那部分对象进行重新标记，耗时比初始标记会稍微长一点，需要暂停线程。（相当于对并发标记做一次兜底操作） 并发清除：并发清除掉已经死亡的对象，耗时长但不需要暂停用户线程。 CMS 的优点在于耗时长的并发标记和并发清除 阶段都不需要暂停用户县城，因此SWT操作的时间就比较短。但是它的缺点也很明显：\n内存碎片：由于 CMS 收集器采用 标记-清除 算法实现，因此会产生大量空间碎片。\n吞吐量下降：由于 CMS 收集器在并发的阶段会占用部分 CPU 资源，导致用户线程的可用 CPU 资源变少（计算能力减少），整体引用程序的吞吐量就降低了。\n吞吐量 = 运行用户代码时间 \\ (运行用户代码时间 + 运行垃圾收集时间) 无法一次性处理浮动垃圾：由于并发清除的时候，用户线程还是在继续，所以此时仍然会产生垃圾 （浮动垃圾）。只能等到下一次出发垃圾回收的时候，再做清理。\nG1 收集器：G1 收集器是一种面向服务器的垃圾收集器，主要应用就是在多核 CPU 和大内存的服务器环境当中。 G1 同样遵循分代收集理论，但是不再以固定大小和固定数量来划分分代区域，而是把连续的 Java 堆 划分为多个大小相等的独立区域 (Region)。每一个独立区域都可以根据不同的需求来扮演新生代的 Eden 空间 (E) 、Survivor 空间 (S) 或者老年代空间 (O)，收集器会根据独立区域扮演的不同角色，采用不同的收集策略。除了上述的空间之外，还有一部分独立区域使用 H 进行标注，表示 Humongous 巨大的，说明这部分独立区域用来存储大对象，一般是大对象是指对象大小 \u0026gt;= 独立区域一半空间的对象。\nG1 收集器的实现流程大致也可以分为四个步骤，如下所示：\n初始标记：标记 GC Roots 能直接关联到的对象，并且修改 TAMS (Top at Mark Start) 指针的值，让下一个阶段用户线程并发运行时，能够正确的在独立区域中分配新对象。G1 为每个独立区域都设置了两个 TAMS 指针，新分配的对象必须位于这两个指针位置上，位于这两个指针位置上的对象默认被隐式标记为存活的，不会纳入回收范围。 并发标记: 从GC Roots 能直接关联到的对象开始变量整个对象图。遍历完成之后，还需要处理 SATB 记录当中变动的对象。 SATB (snapshot-at-the-beginning，开始阶段快照) 能够有效的解决并发标记阶段因为用户线程允许而导致的独享变动，其效率比 CMS 重新标记使用的增量更新算法效率更高。 最终标记：堆用户线程做一个短暂的暂停，用于处理并发阶段结束后的少量 STAB 记录。虽然并发标记阶段会处理 SATB 记录，但由于处理的时候，用户线程依然是运行中的，因此依然会有少量的变动，所以需要最终标记来做兜底。 筛选回收：负责更新独立区域 Region 统计数据，按照各个 Region 的回收价值和成本进行排序，在根据用户期望的停顿时间进行来指定回收计划，可以选择任意多个独立区域构成回收集。然后将回收集中独立区域的存活对象复制到空的独立区域里面，再亲历掉整个旧的独立区域。此时，因为涉及到存活对象的移动，所以需要暂停用户线程，并且由多个收集线程并发执行。 5. Java 中有哪些垃圾回收算法？ Java 中的垃圾算法主要包括三种，标记-清除、标记-整理、标记-复制 【注意】 三种算法都是标记存活的对象，也就是不需要进行垃圾回收的对象\n特性 标记-清除 标记-整理 标记-复制 工作原理 首先遍历堆中的对象，标记出所有存活的对象，然后直接清除未标记的对象 首先标记出堆中存活的对象，然后将存活的对象单独整理在一个区域，最后清除为标记的对象 将内存分两部分，每次只用其中的一半。标记堆中存活的对象，将其复制到未使用的那一半区域，然后清除另外一半区域。（实际上会用到 eden 和 两个 survivor 区） 优点 实现简单，能够清除堆中所有需要回收的对象 解决了内存碎片问题 无序处理内存碎片，并且分配效率高 缺点 标记和清除的过程中会产生内存碎片，影响后续内存分配的效率 整理阶段需要移动对象，会导致额开销 需要双倍的内存空间，浪费了一半的空间 【标记-清除】\n标记-清除 主要分为两个阶段：标记和清除\n标记阶段 (tracing)：从GC Roots 根出发，通过 DFS 或者 BFS 遍历所有被引用的对象，并且在对象的头部 Header 标记为存活。如果没有标记到的对象，说明他们是不可达的，不进行标记方便后期进行回收。 【注意】 GC Roots 的对象包括：栈、寄存器、全局变量等。具体来说，虚拟机中引用的对象（如局部变量、方法参数）、方法区中类静态属性引用的对象（全局变量）、方法区中常量引用的对象、本地方法栈中 JNI 引用的对象\n清除阶段：遍历堆中的独享，将未被标记的对象 (不可达) 进行垃圾回收。清除的过程不会移动和整理内存空间，一般都是通过空闲链表（双向链表）来标记被垃圾回收的区域，内存是空闲可用的。所以这种算法会导致内存空间碎片的产生\n内存碎片 (清除过程)：程序在申请使用内存的时候，明明剩余内存空间是够的，但就是申请不到内存，这种现象就是存在内存碎片。另外，内存碎片会导致在申请内存的时候比较麻烦，需要遍历链表查找合适的内存块，会比较耗时。所以，一般会采用多个空闲链表来根据内存分块大小来组成不同的链表。比如分为大分块链表和小分块链表，根据申请的内存分块大小遍历不同的链表，加快内存的申请效率。\n位图标记法 (标记过程)：标记的过程中，一般是标记在对象头里面，但这可能会导致写时复制不兼容。因为标记的过程需要修改对象头，即便没有修改对象的值，也可能被误判为写操作。所以可以采用位图标记法，将堆内存的某个块用一个位来标记，把堆内存分为一块一块的。对象就是存储在一块或者多块内存上。根据对象所在的地址和堆的其实地址，就可以算出对象是在第几块上。然后用位图（数组）将对应的对象第一块的对位置为1，表明该对象被标记了。这样就可以兼容写时复制的算法了。另外，如果标注在对象头上，则清除的过程需要遍历整个堆来扫描对象。而如果采用位图标记法，则可以直接快速遍历位图，清除对应的对象 （位图的数组和堆内存块位置对应）。但是，无论是采用标记对象头还是位图标记法，都会存在内存碎片 【注意】写时复制操作就是多个进程或线程共享同一份数据，直到某个进程/线程尝试修改数据时，才复制并生成该数据的独立副本\n【标记-复制】\n标记-复制算法会把堆分为两块，一块是 From 区，一块是 To 区 。所有的对象在创建的时候，都会放在 From 区域。发生 GC 垃圾回收的时候，会标记所有存活的对象，然后将标记的对象从 From 区 复制到 To 区，然后整体回收 From 区。回收完 From 区之后，将 To 区和 From 区的进行置换，让原来的 From 区 变成 To 区，原来的 To 区 变成 From 区。 该过程当中，因为是整体From 区进行回收，不会出现内存碎片。同时，也不需要空闲链表来记录内存空闲的区域，直接移动指针分配内存。该方法对 CPU 缓存非常友好，因为从 GC Roots 开始采用DFS遍历一个节点，把关联的对象都找到，然后对象和关联对象的内存位置分配的很近。根据局部性原理，访问到一个对象的时候，关联对象也可能被同时访问，访问缓存可以直接命中。 该方法的缺点是，有一半的堆内存是不能使用的，内存的利用率很低。另外，如果存活的对象很多，复制的过程是很慢的。\n【标记-整理】\n标记-整理和标记-复制的原理其实差不多，区别在于复制算法需要分为两个区来回复制，而整理部分需，直接整理。标记整理的过程是，将存活的对象往边界上整理，然后对其他的部分进行垃圾回收。它的优点是不会出现内存碎片，也不需要像复制算法那样腾出一半的空间，所以内存利用率也挺高的。它的缺点是需要对堆内存进行多次搜索，因为需要在同一个空间里面，完成标记和整理（移动）的操作。所以完成该过程需要花费很多的时间。\n6. Java 中的强引用、软引用、弱引用和虚引用分别是什么？ 强引用：强引用实际上就是程序代码中普遍存在的引用赋值，这是使用最普遍的引用，其代码如下\nString strongReference = new String(\u0026#34;abc\u0026#34;); 如果一个对象具有强引用，那就类似于必不可少的生活用品，垃圾回收器绝不会回收它。当内存空间不足，Java 虚拟机宁愿抛出 OutOfMemoryError 错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。\n软引用：如果一个对象只具有软引用，那就类似于可有可无的生活用品。软引用代码如下\nString str = new String(\u0026#34;abc\u0026#34;); SoftReference\u0026lt;String\u0026gt; softReference = new SoftReference\u0026lt;String\u0026gt;(str); 如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。软引用可以和一个引用队列 ReferenceQueue 联合使用，如果软引用所引用的对象被垃圾回收，JVM 就会把这个软引用加入到与之关联的引用队列中。\n弱引用：如果一个对象只具有弱引用，那就类似于可有可无的生活用品。弱引用代码如下：\nString str = new String(\u0026#34;abc\u0026#34;); WeakReference\u0026lt;String\u0026gt; weakReference = new WeakReference\u0026lt;\u0026gt;(str); str = null; //str变成软引用，可以被收集 弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。弱引用也可以和一个引用队列 ReferenceQueue 联合使用，如果弱引用所引用的对象被垃圾回收，JVM 就会把这个弱引用加入到与之关联的引用队列中。\n虚引用：顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。虚引用代码如下\nString str = new String(\u0026#34;abc\u0026#34;); ReferenceQueue queue = new ReferenceQueue(); // 创建虚引用，要求必须与一个引用队列关联 PhantomReference pr = new PhantomReference(str, queue); 虚引用主要用来跟踪对象被垃圾回收的活动。虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列ReferenceQueue 联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。特别注意，在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为软引用可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出 OutOfMemory 等问题的产生。\n","permalink":"https://swimmingliu.cn/posts/job/java-jvm-interview-questions/","summary":"\u003cp\u003e\u003ccode\u003eJVM\u003c/code\u003e 全局构架图如下，包含 \u003ccode\u003eJVM\u003c/code\u003e 的全部内容\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"JVM-全局结构图\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/695c3cf0-098e-11f0-a8ba-c858c0c1deba\"\u003e\u003c/p\u003e\n\u003ch2 id=\"1-jvm-的内存区域是如何划分的\"\u003e1. JVM 的内存区域是如何划分的？\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eJVM\u003c/code\u003e 内存当中，运行时数据的区域包含堆、方法区（元空间）、虚拟机栈、本地方法栈、程序计数器。另外，其他的内存区域属于本地内存，本地内存就包括直接内存，直接内存是非运行时数据区的一部分。\n其中，堆和方法区（元空间） 是线程共享的，虚拟机栈、本地方法栈、程序计数器都是线程私有的。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【注意】\u003c/strong\u003e \u003ccode\u003eJVM\u003c/code\u003e 规范对于运行时数据区域的规定是很宽松的。就拿堆来说，堆可以是连续空间，也可以是不连续空间。堆的大小可以固定，也可以再运行时按照需求进行扩展。虚拟机实现者可以使用任何\u003cstrong\u003e垃圾回收算法\u003c/strong\u003e管理堆，甚至完全不进行垃圾回收也是可以的。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"JVM内存区域\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/6ebff0fa-07e8-11f0-86bd-c858c0c1debd\"\u003e\u003c/p\u003e\n\u003cp\u003e下面逐一介绍不同部分的功能和作用\u003c/p\u003e\n\u003cp\u003e首先是线程私有的部分，\u003cstrong\u003e程序计数器\u003c/strong\u003e、\u003cstrong\u003e虚拟机栈\u003c/strong\u003e、\u003cstrong\u003e本地方法栈\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【程序计数器】\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e定义\u003c/strong\u003e：程序计数器就是记录当前所执行的字节码的行号。字节码解释器通过改变程序计数器的值，来选取下一条需要执行的字节码指令。它的生命周期随着线程的创建而创建，随着线程的结束而死亡。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e作用\u003c/strong\u003e：分支、循环、跳转、异常处理、线程恢复这些功能都需要依赖程序计数器完成。比如线程切换上下文中，从 \u003ccode\u003eA线程\u003c/code\u003e 先切换到 \u003ccode\u003eB线程\u003c/code\u003e，然后从 \u003ccode\u003eB线程\u003c/code\u003e 恢复到 \u003ccode\u003eA线程\u003c/code\u003e 的过程当中，为了 \u003ccode\u003eA线程\u003c/code\u003e 能够恢复到正确的执行位置，就需要读取 \u003ccode\u003eA线程\u003c/code\u003e 程序计数器的值，来确认切换线程前执行的位置在哪里。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e为什么是线程私有\u003c/strong\u003e：因为线程切换的过程当中，每个线程都需要一个程序计数器来记录自己的程序执行位置。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e【注意】\u003c/strong\u003e 程序计数器是唯一一个不会出现 \u003ccode\u003eOOM\u003c/code\u003e 内存不足的内存区域，因为他就只是存储一个值。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【虚拟机栈】\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e定义\u003c/strong\u003e：虚拟机栈按照先进后出的方案存储的是非本地方法的调用对应的\u003cstrong\u003e栈帧\u003c/strong\u003e。每一次方法调用的时候会被压入栈中，方法结束的时候会被弹出栈中。栈帧中包含\u003cstrong\u003e局部变量表\u003c/strong\u003e、\u003cstrong\u003e操作次数栈\u003c/strong\u003e（存储操作数和临时计算结果）、\u003cstrong\u003e动态链接\u003c/strong\u003e、\u003cstrong\u003e方法的返回地址\u003c/strong\u003e。虚拟机的生命周期随着线程的创建而创建，随着线程的结束而死亡。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e作用\u003c/strong\u003e：存储非本地方法的栈帧，支持方法的调用和返回。当栈深度超过虚拟机允许的最大深度，会抛出 \u003ccode\u003eStackOverflowError\u003c/code\u003e 栈溢出异常。如果虚拟机栈无法动态扩展或申请到足够的内存，会抛出 \u003ccode\u003eOutOfMemoryError\u003c/code\u003e 内存不足异常。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"JVM-虚拟机栈-完整结构\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/6f22fcdc-07e8-11f0-92ef-c858c0c1debd\"\u003e\u003c/p\u003e\n\u003cp\u003e栈帧中包含\u003cstrong\u003e局部变量表\u003c/strong\u003e、\u003cstrong\u003e操作次数栈\u003c/strong\u003e（存储操作数和临时变量）、\u003cstrong\u003e动态链接\u003c/strong\u003e、\u003cstrong\u003e方法的返回地址\u003c/strong\u003e。其中，局部变量表存放的是所有的局部变量，或者其出对应的地址（数组）。动态链接就是当前类常量池的引用。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e局部变量表\u003c/strong\u003e：存放\u003cstrong\u003e方法参数传入的形参值\u003c/strong\u003e，\u003cstrong\u003e方法内的局部变量\u003c/strong\u003e、\u003cstrong\u003e方法的 \u003ccode\u003ethis\u003c/code\u003e 引用\u003c/strong\u003e。内部结构主要存放了编译期可知的各种数据类型（\u003ccode\u003eboolean\u003c/code\u003e、\u003ccode\u003ebyte\u003c/code\u003e、\u003ccode\u003echar\u003c/code\u003e、\u003ccode\u003eshort\u003c/code\u003e、\u003ccode\u003eint\u003c/code\u003e、\u003ccode\u003efloat\u003c/code\u003e、\u003ccode\u003elong\u003c/code\u003e、\u003ccode\u003edouble\u003c/code\u003e）、对象引用（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e操作数栈\u003c/strong\u003e：主要作为\u003cstrong\u003e方法调用的中转站\u003c/strong\u003e使用，用于存放\u003cstrong\u003e方法执行过程中\u003c/strong\u003e产生的\u003cstrong\u003e中间计算结果\u003c/strong\u003e。另外，\u003cstrong\u003e计算过程中产生的临时变量\u003c/strong\u003e也会放在操作数栈中。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e动态链接\u003c/strong\u003e：主要作用是实现在\u003cstrong\u003e当前方法中调用其他方法\u003c/strong\u003e。 \u003ccode\u003eClass\u003c/code\u003e 文件的常量池里面保存有大量的符号引用，比如方法的符号引用。 当一个方法需要调用其他方法，需要将常量池中只想方法的符号引用转换为在内存地址当中的直接引用。动态链接的作用就是\u003cstrong\u003e把常量池的符号引用转换为内存当中的直接引用\u003c/strong\u003e。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e【本地方法栈】\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e定义\u003c/strong\u003e：本地方法栈和虚拟栈的结构是一样的。不同的是，本地方法栈是 \u003ccode\u003eJVM\u003c/code\u003e 调用 \u003ccode\u003eNative\u003c/code\u003e 方法的时候才会用到的，虚拟机栈是执行 \u003ccode\u003eJava\u003c/code\u003e 自身的方法 (也就是字节码) 会用到的。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e作用\u003c/strong\u003e：存储本地方法 (\u003ccode\u003eNative\u003c/code\u003e) 栈帧，支持方法的调用和返回。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e【注意】\u003c/strong\u003e 在 \u003ccode\u003eHotSpot\u003c/code\u003e 虚拟机当中，将本地方法栈和虚拟机栈合二为一了。\u003c/p\u003e","title":"JVM 面试题笔记"},{"content":"1. TCP 和 UDP 有什么区别？ TCP 是一种可靠的、面向连接、基于字节流传输的传输协议，能够保证数据的顺序，但是其延迟比较大。一般适用于需要数据完整性和顺序的场景，比如文件传输、邮件、Web 网站。 UDP 是一种不可靠的、无连接、基于数据报传输的传输协议，不能保证数据的顺序，但是延迟比较小。一般适用于需要高性能要求和快速传输数据的应用，比如实时通讯、语音、视频、游戏等。\n【注意】TCP 和 UDP 都属于传输层\n特性 TCP UDP 连接方式 面向连接 (三次握手) 无连接 可靠性和顺序保证 可靠，保证数据按顺序送达 不可靠，不能保证数据的顺序，而不能保证安全送达 流量控制/拥塞控制 提供流量控制和拥塞控制 没有流量控制和拥塞控制 头部大小 头部较大 (20 ~ 80 字节) 较小 (只有 8 字节) 性能 较低，延迟大 较高，延迟小 是否支持广播 不支持广播 支持广播 数据传输模式 通过字节流传输 通过数据报传输 适用场景 文件传输、Web、邮件等需要可靠性的传输 实时通讯、语音、视频、游戏等高性能要求应用 基于两者的协议 1. HTTP协议：超文本和多媒体内容的协议\n2. HTTPS协议：基于HTTP协议上加了一层SSL / TSL 外壳，保证了数据传输的安全性\n3. FTP协议： 文件传输协议，用来传文件到服务器的\n4. SMTP协议：简单邮件协议，用于发送邮件的协议 (POP3 协议： 负责邮件接受的协议) 1. HTTP 3.0 协议: 基于 UDP 的QUIC 协议\n2. DHCP 协议： 动态主机配置协议，动态配置 IP 地址\n3. DNS ：域名解析系统，将域名转变为机器刻度的 IP 地址 【ISO 和 TCP/IP 模型】\n**ISO (7层) **： “物联网淑慧适用” : 物理层—数据链路层—网络层—传输层—会话层—表示层—应用层 TCP/IP (4层)：链路层—网络层—传输层—应用层 【TCP 详解】\nTCP包没有IP地址，网络层已经处理过了。但是有源端口和目标端口\n序列号 (Sequence Number)：在建立连接的时候，主机生成随机数作为初始值， 经过 SYN 包 (第一次握手)传给接收端主机。每发送一次数据，累加数据字节数大小，用来确保传输是按照顺序接受的。 确认应答号 (Acknowledgement Number) ：用来表示下一次希望受到的数据序列号，发送端受到确认应答后可认为此序列号前数据已经被正常接受，防止出现丢包的情况。 控制位 (TCP Flags): 下面的字段都是二进制来表示是否有效，0 和 1 分别表示无效和有效 ACK : 表示确认应答字段是否有效, TCP 规定除了第一次握手的 SYN 包以外，该位置必须为 1，也就是必须有效 **RST (Reset) **: 表示 TCP连接当中出现异常，是否需要强制断开连接，进行重置 SYN：表示是否用来建立连接 (第一次握手)， 并设置其序列号的字段的初始值 FIN：表示是否结束 TCP 连接，如果为1， 后面不会再传输数据，断开连接。 窗口大小 (Window / Advertise-Window)：用于实现滑动窗口，进行流量控制，确保发送方不会超出接收方的处理能力，防止缓冲区溢出。滑动窗口机制是用来允许发送方在未收到接收方确认的情况下，连续发送多个数据包，提高传输效率。实现方式是，接收方在报文当中通知其剩余的缓冲区大小，发送方根据该信息调整发送窗口，动态控制数据流量。 【TCP 面试题拓展】\n有一个IP的服务端监听了一个端口，它的TCP最大连接数目是多少？\n最大TCP连接数 = 客户端IP数 * 客户端的端口数 在 IPv4 当中，客户端的IP数目最多为 2^32, 客户端的端口数最多为 2^16，所以单机的TCP最大连接数为2^48。但是由于文件描述符和内存限制，一般没法儿达到理论上限。\n【UDP 的首部结构】\nUDP 对应用层传下来的保温，既不合并也不拆分，保留这些报文的边界, 只是加一个 UDP 头部。\n目标、源端口：表示 UDP 将数据发送到哪个进程 包长度：表示 UDP 首部和数据的总长度 校验和：用于确保 UDP 首部和数据在传输过程中未受损 【TCP 和 UDP 能否使用同一个端口】\nTCP 和 UDP 可以使用同一个端口，因为这两个传输协议是完全独立的软件模块。数据包通过 IP包头中的协议号字段判断是 TCP 还是 UDP，并转发给相应的模块处理。然后, TCP 或 UDP 模块根据端口号将报文转发给对应的应用程序。\n2. 说说TCP的三次握手过程 ? TCP 三次握手的过程如下：\n客户端发送 SYN 给服务端，建立连接 服务端收到 SYN 消息之后，回复一个 SYN-ACK 确认消息，表示接收到了客服端的连接请求 客服端收到SYN-ACK 消息之后，再发一个 ACK 确认消息，表示收到服务器的SYN-ACK 消息，成功建立连接。 【TCP 三次握手的实现细节】\n最开始的时候，客户端和服务端都处于 CLOSE 状态，表示双方没有建立连接。服务端主动监听某个端口，处于LISTEN 状态。\n【第一次握手】\n客户端随机初始化 client_isn 值，将其设置为TCP 头部的序列号字段。 将标志位的 SYN 设置为 1，表示该报文为 SYN 报文。 客服端将该报文发送给服务端，之后客户端处于 SYN-SENT 状态。表示向服务端发起 TCP 连接，该报文不包含应用层的任何数据，只用于建立连接。 【第二次握手】\n服务端收到客户端 SYN 报文知乎，随机初始化序号server_isn , 并把它填入 TCP 头部的序列号字段。 将确认应答好修改为 SYN 报文中的序列号 + 1，也就是client_isn + 1。并把SYN 和 ACK 的标记位都改为1，该报文为 SYN-ACK 报文 发送 SYN-ACK 报文给客户端，不包含任何应用层数据，只用于确认收到客户端的 SYN 报文，服务端进入 SYN-RCVD 状态 【第三次握手】\n客户端收到服务端的 SYN-ACK 报文，准备回应最后的应答报文 把报文的 TCP 头部的确认应答号修改为 SYN-ACK 报文的序列号 + 1，也就是server_isn + 1。 ACK 标志修改为 1, SYN 不做任何修改，依然为 0，该报文表示 ACK报文。 把报文发送给服务端，可以携带应用层的数据，之后客户端处于ESTABLISHED 状态，表示成功建立连接。 **【注意】**第三次握手是可以携带数据的，但是前两次握手都不能携带数据。并且就算第三次握手丢失，服务端依然可以根据数据包来得到第三次握手的信息 (用序列号进行判断，找client_isn + 1 的数据包)。如果第三次握手 ACK 确认包丢失了，但是收到了客服端发的携带数据的包，并且包含 ACK 标记， 服务端默认表示第三次握手有效，成功建立连接。然后处理该数据包并继续正常传输数据。\n【TCP 三次握手中每次握手的意义】\n客户端和服务端需要通过三次握手来确认双方的发送和接受都是正常的\n第一次握手：服务端确认客户端发送正常，自己接受正常。客户端无法确认。 第二次握手：客户端确认自己发送和接受正常，服务端接受正常。服务端确认自己接受正常，客服端发送正常。 第三次握手：客户端和服务端都确认自己和对方，彼此发送和接受都是正常的 【为什么是三次握手，不是两次或者四次呢？】\n避免浪费资源：如果只有两次握手，无法阻止历史连接。服务端在向客户端发送数据之前，没有阻止掉历史连接 (第一次 SYN 请求到达就会建立连接)，从而导致服务端建立了一个历史连接。如果客户端发送了 多个SYN 报文，就会不断重复建立连接，浪费资源。如果采用四次握手，就需要多一次不必要的操作，也会浪费资源。\n【为什么每次建立TCP连接的时候，初始化的序列号要求不一致？】\n防止历史报文被下一个相同的四元组连接接受 防止黑客伪造相同序列号的 TCP 报文被对方接受 【什么是半连接队列和全连接队列？】\nTCP 三次握手的过程当中， Linux内核会维护两个队列来管理连接。\n半连接队列 (SYN Queue)： 服务端收到客户端的 SYN 请求后，双方未完全建立连接，会将半连接状态的连接放入半连接队列 全连接队列 (Accept Queue)：服务端收到客户端对 ACK 响应的时候，意味着三次握手完成，服务端将该连接从半连接队列移动到全连接队列。 3. TCP 用来解决什么问题的？ TCP 协议主要是通过可靠传输、流量控制、拥塞控制和连接管理，解决数据在不可靠的IP网络上传输的问题。\n可靠性：TCP 确保数据包在网络传输的过程当中不丢失、不重复，并且按顺序到达。通过确认-重传机制和序列号，保证数据在IP网络上的可靠传输。 流量控制：TCP 通过滑动窗口机制调节发送方(客户端)的发送速率，防止接收方因为处理能力或者缓存有限，而导致数据流被淹没或者丢失。 拥塞控制：TCP 通过拥塞避免算法 (比如慢启动、拥塞避免、快速重传和快速恢复) 来防止网络过载，确保网络资源的公平使用和稳定性。 连接管理： TCP 是面向连接的协议，采用三次握手建立连接，四次挥手断开连接，来管理连接会话，确保通信的可靠性和状态的同步。 4. 说说 TCP 的四次挥手？ TCP 的四次挥手是用来安全关闭已经建立的连接的过程，它可以确保双方都能完成数据传输并且安全释放连接资源。四次挥手的过程如下所示：\n第一次挥手：客户端发 FIN (seq_num = x) 数据包到客户端，表示其申请关闭服务端的数据传送，随后进入FIN_WAIT_1 状态，等待服务端进行确认。 第二次挥手：服务端收到客户端的 FIN (seq_num = x) 数据包之后，发送 ACK (ack_num = x + 1, seq_num = y) 给客户端，表示确认收到 FIN 数据包，随后进入 CLOSE_WAIT 状态。客户端接收到 ACK 包之后，进入FIN_WAIT_2 状态。同时，服务端会将没有传送完的数据传给客户端。 第三次挥手：服务端发送 FIN (seq_num = w) 的数据包给客服端，请求关闭连接，进入 LAST-ACK 状态。 第四次挥手：客户端收到 FIN 数据包之后，发送 ACK (ack_num = w + 1)数据包，随后进入 TIME-WAIT 状态。服务端收到此数据包之后，进入 CLOSE 状态。如果客户端等待 2MSL 没有收到回复的话，证明服务端已经正常关闭，此时客户端也进入 CLOSE 状态。 【注意】\n四次挥手过程中，服务端 (被动关闭的一方) 在 CLOSE_WAIT 的状态下，仍然可以发送数据，直到它主动发送FIN 请求关闭连接。 客户端(主动关闭连接的一方) 发出 FIN 后，无法再传输数据，只能接受数据 只有客户端 (主动关闭的一方) 会进入TIME_WAIT 状态，用于等待潜在的重传 FIN 【为什么需要四次挥手】\n为了确保数据的完整性，服务器需要把没有发送完的数据全部传输完之后，再关闭连接。所以，服务端的 ACK 确认包 和 FIN 请求关闭包，一般都会分开发送，所以需要四次挥手。TCP 为全双工通信，可以双向传输数据。任意一方数据传输结束都可以发送连接释放通知，对方确认后进入半关闭状态。另一方无数据再发送的时候，也发连接释放通知，双方确认则完全关闭TCP连接 (客户端和服务端都需要一来一回，请求释放和确认一次)\n【什么情况下会出现三次挥手】\n如果服务端没有数据需要发送了，并且开启了 TCP 延迟确认机制 (默认开启)，第二次和第三次挥手就会合并传输 (ACK 和 FIN)，就会出现三次挥手。\n5. TCP 的粘包和拆包能说说吗？ 【定义】\n拆包 / 半包：客服端 (发送方) 要发送的包太大了，必须拆分成多个包进行发送。导致一条完整的消息要被拆分为多个部分，服务端 (接收方) 无法一次性接受完整的数据。 粘包：客户端 (发送方)要发送的包太小了，会将多个包放在数据缓存区，合并成一个包发送出去。服务端(接收方)在读取的时候，可能将多个消息拼接在一起。导致多条消息数据粘在一起，服务端 (接受方) 无法区分这些消息的边界。 【原因】\n拆包 / 半包：由于网络传输中的 MTU 最大传输单元限制或者发送缓冲区的大小的限制，一个大包必须被拆分为多个小包。 粘包：由于 TCP 是基于字节流传输的协议，不关心数据的边界。数据在发送方可能被一次性发送，接收方读取的时候可能会将多个消息拼接在一起。 【注意】 只有 TCP 协议才会出现粘包和拆包的现象，UDP 协议不会出现这种情况。因为 TCP 协议的包没有报文长度，而 UDP 的包有报文长度。 所以TCP 是流式的，数据之间没有界限，而 UDP 是有界限的。\n【解决方案】\n固定数据包的长度：客户端每次发送数据包的时候，统一数据包的长度。比如采用 1024 字节，如果数据不足，就采用空格进行填充。\n添加分隔符：客户端在每个数据包的末尾用固定的分隔符 （比如 \\r\\n 或 ;）。服务端收到数据包之后，根据分隔符进行合并或拆分头部与前包剩余的部分，获取完整数据包。\n固定消息头部和消息体：采用固定长度的头部记录整个消息的长度，读取到足够长度数据，才视为完整消息。\n禁用Nagle协议：为了减少网络中的小包数量，TCP 采用了 Nagle 算法，将小数据块缓冲起来，直到缓冲区满了或者收到接受方的确认之后，再发送数据包。该算法可能会导致粘包现象，所以在需要实时传输小数据包的场景，可以设置 TCP_NODELAY 禁用 Nagle 算法，减少粘包的可能性。\n6. 说说 TCP 阻塞控制步骤 ? 阻塞控制机制：就像高速公路上的交通管理，目的是防止数据流量过大导致网络“拥堵”。当网络开始“拥塞”时，TCP会自动减慢数据发送速度，以确保网络保持畅通。\n滑动窗口机制：这是一种流量控制方法，确保发送方不会发送超过接收方处理能力的数据量。可以类比为水管中的水流，滑动窗口就像一个阀门，调节水流量，防止水管溢出。\n【注意】 假设拥塞窗口 为 cwnd 和 流量控制的滑动窗口 为rwnd，当前窗口的右边界受这两个值共同影响，应该取它们之间的最小值。\n窗口大小 = min(cwnd, rwnd) 【阻塞控制步骤】 阻塞控制可以分为两种情况来看，分别是超时重传 (基于超时的拥塞控制) 和快速重传 (基于重复 ACK 的拥塞控制)\n超时重传：当客户端检测到数据包传输超时 (未收到 ACK 确认)，会认为网络出现严重阻塞。此时，TCP会采取最保守的策略：将拥塞窗口cwnd 重置为 1，并重新进入慢启动阶段， 同时将慢启动阈值ssthresh 设置未当前拥塞窗口的一半 快速重传：当客户端连续收到3个重复的 ACK (比如服务端检测到报文段失序的时候，会触发该机制)，表明网络中可能只发生了单个数据包丢失而非全局阻塞。此时，TCP会出发快速重传 (立即重传丢失的数据包) 和 快速恢复 (调整拥塞窗口 cwnd 为 慢启动阈值 + 3 ssthred + 3，避免完全退回到慢启动)。 TCP 协议的拥塞控制主要通过五个算法来实现：慢启动、拥塞避免、超时重传、快速重传和快速恢复。\n慢启动：发送方开始设置一个较小的拥塞窗口大小，在每收到一个新的报文段的 ACK 确认之后，每当成功发送跟拥塞窗口大小等量的数据后，拥塞窗口大小就会翻倍。拥塞窗口按照指数方式增长，直到拥塞窗口 cwnd 达到 慢启动门限 ssthresh 拥塞避免：当拥塞窗口大小 cwnd 达到 慢启动门限 ssthresh 之后，就进入拥塞避免阶段。每当成功发送跟拥塞窗口大小等量的数据之后，拥塞窗口大小就会增加一个报文段的大小，以线性的方式增长。 拥塞发生：随着发送速率慢慢加快，可能会出现网络阻塞现象，发生数据包丢失。此时，就需要重传数据。重传的机制有两种，超时重传和快速重传。 超时重传：当发生超时重传的时候，慢启动门限ssthresh会设置为拥塞窗口的一半，并且将拥塞窗口恢复为初始值。随后重新开始慢启动，发送速率就瞬间下降了。 快速重传和快速恢复：当客户端连续收到3个重复的 ACK (比如服务端检测到报文段失序的时候，会触发该机制)，就认为发送了丢包。此时，拥塞窗口会 cwnd 减少到原来的一半，然后慢启动门限 ssthresh 设置为减少后的拥塞窗口的大小 cwnd，然后进入快速恢复阶段。此时，会把拥塞控制窗口+3 (cwnd + 3)， 3 的意思是确认有 3 个数据包收到了。然后重传丢失的报文，如果收到重传丢失报文的ACK 之后，将拥塞窗口设置为慢启动门限，直接进入拥塞避免，继续增大发送速率。 7. 常见的 HTTP 状态码有哪些？ 常见的 HTTP 状态分为五大类，有三位数字，一般用第一位数字来区分类别。\n1xx 信息状态码 : 协议处理中的中间状态，还有后续操作 100 Continue：服务器接收到请求的初步部分，客户端需要继续请求 101 Switching Protocols：服务器同意切换协议，比如：从 HTTP 协议切换到 WebSocket 协议 2xx 成功状态码：服务器成功处理客户端请求 ⭐ 200 OK: 请求成功，服务器返回所请求的资源或数据 201 Created: 请求成功并创建新的资源，一般用于 POST 请求 202 Accepted：服务端收到请求，但是还未处理 ⭐ 204 Not Content：请求成功但是服务器不返回任何内容，常用于删除 ⭐ 206 Partial Content：请求成功但服务器返回部分资源，一般用于HTTP分块下载或者断点续传 3xx 重定向状态码：客户端用新的 URL 重新发送请求获取资源 ⭐ 301 Moved Permanently：永久重定向，资源已经移动到新的 URL，通知客户端用新的 URL 访问 ⭐ 302 Found：资源临时移动到新的 URL， 客户端应该继续使用原来的 URL。允许浏览器将 POST 请求转换为 GET 303 See Other：和 302 有相同的功能，但是 303 明确要求客户端采用 GET 方法获取资源 304 No Modified：缓存重定向，资源没有被修改。客户端可以继续使用缓存资源，减少带宽消耗 307 Temporary Redirect：临时重定向，和 302 的含义几乎差不多。但是 307 需要保证重定向时请求方法和主体不变。 4xx 客户端请求错误状态码：客户端发送的报文有误，服务器无法处理 ⭐ 400 Bad Request：客户端请求报文无效或者语法错误 401 Unauthorized: 请求需要身份验证，客户端未提供有效的凭证 ⭐ 403 Forbidden：服务器理解该请求，但是拒绝执行，一般是客户端没有权限访问 ⭐ 404 Not Found： 请求的资源在服务器上找不到，比如 URL 的一部分写错了 409 Conflict： 请求的资源和服务器的当前状态存在冲突 5xx 服务端错误状态码：客户端请求的报文正确，但是服务器处理的时候内部发送错误。 ⭐ 500 Internal Server Error：服务器内部错误，无法完成请求，而且不知道是什么错误 501 Not Implemented：还不支持客户端请求，类似于“即将开业，敬请期待”的意思 502 Bad Gateway：服务器作为网关或者代理，从上游服务器收到无效响应。比如调用其他网站的API 发生错误的时候 503 Service Unavailable：服务器暂时无法处理请求，一般是因为处理维护中，或者服务过载 8. HTTP 请求包含哪些内容，请求头和请求体有哪些类型？ 【请求报文】 请求报文主要包括四个部分，请求行，请求头，空行(分割请求头和请求体)，请求体。\n请求行：包含请求方法 (GET / POST) 、请求路径 /doc/test.html) 和 HTTP 版本 (HTTP/1.1) 请求头：包含各种键值对，客户端环境(User-Agent)、请求内容 和认证信息 (Token) 等等 空行：用于分割请求头和请求体 请求体：只在 POST 和 PUT 方法中存在，包含需要发送到服务器的信息 【响应报文】 响应报文主要包含四个部分，状态行，响应头，空行，响应体\n状态行：包含 HTTP 的版本 (HTTP/1.1)、状态码 (200) 和状态描述 (OK) 响应头：包含服务器返回的各种键值对，用于描述响应的元信息，常见的响应头如下 Content-Type：响应额呢绒的类型, 一般为 text/html / application/json Content-Length： 响应内容的字节长度 空行：用于风格响应头和响应体 响应体：包含服务器返回的实际内容，比如 HTML文档、图片、JSON数据等 【HTTP 常见请求方法】\nGET：获取指定的资源 POST: 传输实体数据，POST 一般用来传数据，GET 一般用来获取数据 PUT: 上传文件，由于自身没有验证机制，任何人都可以上传文件 DELETE: 删除文件，和 PUT 功能正好相反，同样没有验证机制 9. HTTP 中 GET 和 POST 的区别是什么？ 特性 GET POST 主要用途 获取服务端的资源 向服务器提交数据，一般用于创建或者修改 参数传递 参数都在 URL 中 参数都在请求体当中，URL 也可以放参数 安全性 参数可见，数据容易暴露在浏览器的历史记录、日志和缓存里面，不适合传递敏感信息，不安全 数据放在请求体中，相对安全，但是需要HTTPS才能保证数据加密传输 (不然会被抓包) 幂等性 只读操作，多次请求不会改变服务器状态 修改操作，多次请求可能会导致重复创建资源，或者执行多次相同操作 长度限制 请求参数在 URL 中，浏览器对 URL 有长度限制 请求参数放在请求体中，理论上来说没有任何限制。但一般服务器对请求体长度有配置限制，比如 Nginx 默认限制为 1MB 缓存机制 浏览器和CDN都会缓存 GET 请求的数据，用于减少服务器的负载，比如图片、静态页面等不会频繁改动的静态资源 一般不会缓存 POST 请求，因为它通常对服务器数据会产生影响 【注意】 幂等意味着相同的请求重复多次，服务器的状态只会改变一次，不会累计多次副作用，而非幂等请求每次调用可能引起状态的多次改变\n【GET 请求一定是幂等的吗？】\n不一定，因为如果有开发者不遵循规范去处理请求，采用 GET 方式来新增数据，这时候 GET 请求就不是幂等的了。曾经有个笑话，有人写了个博客，删除博客用的是 GET 请求，他觉得没人访问就连鉴权都没做。然后 Google 服务器爬虫爬了一遍，他所有博文就没了\u0026hellip;\n10. HTTP 1.0、HTTP 1.1、HTTP 2.0、HTTP 3.0 区别？ 【区别】\n特性 HTTP 1.0 HTTP 1.1 HTTP 2.0 HTTP 3.0 连接方式 短连接 持久连接 持久连接 QUIC 连接 (基于UDP) 传输方式 文本 文本 二进制 二进制 多路复用 不支持 不支持 支持 支持 服务器推送 不支持 不支持 支持（主动推送资源） 支持（增强资源推送效率） 头部压缩 不支持 不支持 支持 (HPACK) 支持 (QPACK) 安全性 明文传输（需 HTTPS 加密） 明文传输（需 HTTPS 加密） 强制建议 HTTPS 默认集成 TLS 1.3， 支持HTTPS 是否解决队头阻塞问题 存在（单请求阻塞） 部分缓解（管道化请求，但响应仍需顺序接收） 基本解决（TCP 连接内多路复用） 彻底解决（QUIC 协议是基于UDP协议，没有阻塞队列） 典型改进 定义了基础 HTTP 协议 长连接、断点续传、Host 头域 二进制协议、头部压缩、多路复用 基于 UDP 的 QUIC 协议、零 RTT 连接、抗网络切换 适用场景 静态网页、简单文件下载 中小型网站、内部管理系统 (非高并发网站) 高并发网站(淘宝/微博)、动态加载的单页应用、视频流媒体 实时通信(视频会议/在线游戏)、移动端应用(5G/弱网环境)、物联网设备通信 【HTTP/1.0】\n无状态、短连接：每次请求都需要建立新的TCP连接，处理完之后立即关闭，导致开销比较大 队头阻塞：每个请求必须按照顺序依次处理，前面的请求还没完成，后面的请求只能等待，并发效率不高 【HTTP/1.1】\n持久连接：引入了连接复用（Keep-Alive)，只要任意一端没有明确提出断开连接，就保持TCP连接状态。减少TCP握手开销 管道传输：在一个TCP链接里面，客户端发送多个请求，只要一个请求发出了，不用等待响应，直接发送第二个请求。该策略可以减少整体的响应时间。 队头阻塞：当顺序发送的请求序列中的一个请求，可能因为某种原因被阻塞的时候，后面排队的所有请求也一同被阻塞了，会导致客户端一致请求不到数据。 HOST字段：可以在同一个IP地址上运行多个虚拟主机 断点续传：支持文件传输中断后，从断点出继续传输。 【HTTP/1.0 和 HTTP/1.1 缓存机制区别】\nHTTP/1.0 缓存机制：基于时间的缓存机制，用请求头中的 If-Modified-Since 和响应头中的 Last-Modified 字段实现\n响应头中的 Last-Modified ：表示响应资源的最后修改时间\n请求头中的 If-Modified-Since ：请求的时候修改为响应头的 Last-Modified 时间。当服务器受到该请求之后，会对比请求资源最后修改的时间Last-Modified。 如果从 If-Modified-Since 没有修改，直接响应 304 Not Modified 走缓存。如果已经被修改过，返回最新资源, 响应 200 OK。\nHTTP/1.1 缓存机制：基于唯一标识的缓存机制，用请求头中的 If-None-Match 字段和响应头中的 ETag 字段实现\n响应头中的 ETag：表示响应资源的唯一标识，可以看成是一个id 请求头中的 If-None-Match ：当资源过期的时候，浏览器发现响应头里面有 ETag，再次想服务器发起请求的时候，将If-None-Match 设为 Etag 的值。服务器受到请求后进行对比，资源没变化，返回304。资源有变化，返回信的资源，响应200 【HTTP/2.0】\n多路复用：支持一个TCP连接中，传输多个请求和响应，解决了 HTTP/1.x 中的串行问题\n二进制帧：使用二进制桢格式，头信息帧和数据帧分离，提高传输效率。其中桢数据(Data Frame)，会被头部压缩\n头部压缩 (HPACK): 通过静态表和动态表对HTTP头部进行压缩，减少带宽占用。客户端和服务端维护同一张头信息表，所有字段都会存储这个表，生成一个索引号，以后发送后借助索引号提升速度。\n服务器推送：服务器可以主动向客户端推送资源，减少请求延迟。HTTP/1.1 需要从服务器获取HTML文件，如果还需要获取 CSS渲染页面，需要再次发起获取 CSS文件的请求，就需要两次消息往返。HTTP/2.0 服务器可以主动向客户端发送HTML和CSS文件信息，双方建立 Stream。\n【注意】 客户端的 Stream 必须是奇数号、服务器建立的 Stream 必须是偶数号\n【HTTP/3.0】\nRTT: Round Trip Time 往返时间 RTO: Retransmission Timeout 超时重传时间 QUIC 协议：基于UDP协议，QUIC 通过自身实现可靠传输，减少了 RTT。参考材料：QUIC如何实现可靠传输\n多路复用：在一个 QUIC 协议上，可以同时传输多个请求和响应，并支持流优先级。QUIC 当中每个 stream 之间是相互独立的，假如单个 stream 丢失了，不会影响其他的stream，彻底解决了队头阻塞问题。但是，因为UDP是无序交付的，数据不一定按照发送时的顺序到达。\n更快的连接建立：模拟TCP的三次握手操作，但是握手过程只需要一个往返时间RTT ，用于确认双方的连接ID。QUIC 内部包含了 TLS/1.3 ，其帧携带了 TLS 记录, 所以不需要 TLS 握手。\n11. TCP/IP 四层模型是什么？ TCP/IP 四层模型是一个分层网络通信模型，这四层从底向上分别是：网络接口层 (物理层+数据链路层)、网络层、传输层、应用层 (会话层+表示层+应用层)\n网络接口层：负责数据桢的封装和物理传输 (比如以太网、WIFI、PPP拨号协议等) 网络层：负责数据包的路由和寻址 (比如 IP、ARP、NAT等协议) 传输层：负责端到端的通信 (比如TCP、UDP) 应用层：负责为用户提供应用服务 (比如 HTTP、域名服务器 DNS、邮件 SMTP和POP3、FTP、SSH、动态IP地址分配 DHCP) 【应用层】 提供两个终端设备上的应用程序之间信息交换的服务 (比如两个QQ发消息)，定义了信息交换的格式，消息会交给下一个传输层来传输\n【传输层】 负责将两台设备进程之间的通信提供通用的数据传输服务，应用进程利用该服务传送应用层的报文。\n【网络层】 分组交换网上的不同主机提供通信服务，选择合适的路由，让源主机传输层传下来的分组，可以通过网络层中的路由器找到目的主机。路由器寻址工作中，要找到目标地址的子网，找到后进而把数据包转发给对应的网络内。\n网络层常见的协议如下：\nIP ：用于对数据包进行路由和寻址 ARP：用于将IP地址和MAC地址进行相互转换 NAT：用于将内部IP和外部IP进行相互转换 ICMP：用于传输网络状态和错误消息的状态，一般用来网络诊断和故障排除 【网络接口层】 将网络层的IP数据报组装成帧，在相邻节点之间的链路传送。每一帧含数据和必要的控制信息 (比如同步、地址、差错控制等信息)。实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异\n12. Cookie、Session、Token 之间有什么区别？ 特性 Cookie Session Token 用途 用于跟踪和保护用户状态信息的小型数据文件 用于保存用户状态的机制，每个会话都有一个唯一的Session ID 一串加密字符串，用于身份校验 存储位置 客户端 (浏览器) 服务器 客户端 (浏览器、移动设备) 是否有状态 没有 有状态 没有 适用场景 轻量级状态存储 (用户偏好、个性化设置) 用户身份认证、临时会话数据存储 分布式认证、移动端和单页应用 (SPA) 适用协议 HTTP/HTTPS HTTP/HTTPS HTTP、HTTPS、WebSocket 安全性 较低：容易被篡改或者伪造 较高：数据存储在服务端 较高：Token通常加密且支持签名和过期机制 【Cookies 详解】\n服务器通过 HTTP 响应头 (Set-Cookie) 返回Cookie给客户端 客户端保存 Cookie，后续所有同源的请求，都会携带该 Cookie 服务器根据 Cookie 的值 (比如 SessionID) 识别用户状态 【注意】 Cookie是HTTP协议簇的一部分，HTTP协议没有状态，每个请求都是独立的。所以Cookie是无状态协议下在客户端存储状态信息的补充机制\n【Session 详解】\n用户登录的时候提交包含用户名和密码的表单的HTTP请求报文，服务器验证该用户和密码 如果正确，则把用户信息存储到 Redis / ConcurrentHashMap 里面, key 为 Session ID， value 包含用户的信息 服务器返回的响应报文中，头部的 Set-Cookie 字段包含该Session ID，客户端收到响应报文后存储Cookie值 客户端后续请求同一服务器会包含Cookie值，服务器会提取当中的 Session ID，从Redis里面提取用户信息，继续业务操作。 【Cookie 和 Session 的关系】\nSession 的主要作用就是通过服务端记录用户的状态， Cookie就是在客户端保存对应的Session ID。典型的场景就是购物车，服务端给指定用户创建 Session 之后，就可以标识这个用户并且跟踪这个用户。\n【分布式 Session共享问题】\n假如在一个秒杀场景下, 每个用户只能进入一次秒杀页面。但是，用户在请求的过程当中，Nginx可能会将其负载均衡到不同的 Tomcat。比如第一次请求到 Tomcat A 记录 Session, 然后购买了商品。但是，第二次请求到 Tomcat B 就会出问题，因为 Tomcat B 认为用户第一次来而允许购买请求，造成重复购买。因为每台 Tomcat 当中，只能看到自己存储的Session\n【Token 详解】\n客户端用用户名和密码登录服务器 服务端验证身份之后生成Token并返回给客户端 客户端将Token存到本地浏览器 (一般存到Cookie里面) 客户端发起请求的时候携带Token，服务端收到请求后，先验证Token再返回数据 Token一般都采用 JWT 算法进行颁发令牌，其主要构成如下：\nHeader：描述JWT元数据，定义生成签名的算法和 Token 类型 Payload：用来存放实际需要传递的数据集 Signature：服务器利用Payload、Header 和密钥 (Secret)，采用Header指定的签名算法 (默认为HS256) 生成 【注意】 JWT一般存在 LocalStorage 本地存储当中，放在Cookie 会有跨站请求伪装CSRF 风险，一般请求服务端携带JWT的长火箭做法是使用 HTTP Header 中的 Authorization 字段\n13. 从网络角度来看，用户从输入网址到网页显示，期间发生了什么？ 用户在浏览器输入指定网页的URL，浏览器解析URL路径 浏览器通过DNS协议，获取域名对应的IP地址 (先找本地缓存，找不到就找配置的DNS服务器) 浏览器根据IP地址和端口号，向目标服务器发起一个TCP连接请求 （三次握手） 浏览器在TCP连接上，向服务器发送一个HTTP请求报文，封装成IP数据包，请求获取网页内容 操作系统在IP数据包的基础上加上MAC头部，加上发送方MAC地址和接受方目标MAC地址 (ARP协议) 数据包还是存储在内存中的二进制数据，网卡将二进制数据转为电信号，通过网线进行传输 交换机收到数据包之后，会根据数据包中的MAC头找到另外一个设备连接在交换机的哪个端口，然后传输。（如果找不到，就对所有的端口进行广播） 路由器收到数据包之后根据IP地址，在不同的网络节点之间转发，最后到达服务器。（如果超过TTL，还没找到服务器，则说明服务器不可达） 服务器收到HTTP请求报文之后进行处理，重复上面的过程，返回HTTP响应报文给浏览器 浏览器收到HTTP响应报文之后，解析HTML代码渲染网页结构和央视。同时根据HTML中的资源URL再次发起请求，获取资源内容 （比如一些图片资源），直到网页完全加载 浏览器再不需要和服务器进行通信的时候，主动关闭TCP连接或等待服务器关闭请求，进行四次挥手。 【URL 结构】\nSchema 协议类型：一般为HTTP/HTTPS协议，也可能是文件传输协议 FTP, 邮件协议 SMTP 域名 + 端口：域名是网址的通用名或者IP地址的可读版本，端口就在域名后面，用冒号隔开 资源路径：指明要访问哪一个网页/资源 参数：参数用键值对的形式 key = value，用 \u0026amp; 进行隔开 锚点：锚点以#开头，是页面上的锚，用于定位，不发送给服务端 【域名解析】\n查询本地的Host文件/列表：浏览器回去查询本地是否有对应域名的记录， 如果有，直接提取对应的IP地址\n查询本地DNS缓存： 查询浏览器缓存/操作系统缓存/路由器缓存，如果存在记录，直接提取对应的IP地址\n查询DNS服务器： 如果缓存没有命中，浏览器会向配置的DNS服务器发送查询请求 (通常由运营商 ISP 提供)，DNS服务器会通过递归查询的方式解析域名\n根DNS服务器：返回顶级域名的服务器地址 (.com) 顶级域名(TLD)服务器：返回权威DNS服务器的地址 权威DNS服务器： 返回具体域名的具体IP地址 14. HTTP 和 HTTPS 的区别？ 先说区别，上表！！！\n特性 HTTP HTTPS 安全性 明文传输，不安全 采用TLS / SSL 安全协议，让报文加密传输 连接过程 基于 TCP 协议，三次握手之后，即可发送报文信息 基于 TCP + SSL / TLS 协议，在 TCP 的三次握手之后，还会进行 SSL / TLS 的握手过程，才能进行加密报文传输 默认端口 80 443 数字证书 不需要数字证书 需要向 CA （Certificate Authority) 证书权威机构申请数字证书，确保服务器的身份是可信的 【为什么需要 HTTPS协议】\n传统的 HTTP 协议存在下面的三种安全风险隐患：\n窃听风险：通信链路上可以获取通信内容，用户信息容易被盗窃 （抓包） 篡改风险：比如在服务器返回的报文里面，强行植入垃圾广告，用户容易误触进入垃圾网站 冒充风险：伪装成天猫、京东等官方网站，用户容易被骗钱。 HTTPS 就可以很好的解决上面的三种风险，具体方案如下：\n信息加密 （解决窃听）：网络报文传输的过程中，报文时加密的，抓包拿到报文也没用 校验机制 （解决篡改）：无法篡改通信内容，篡改之后就不能正常显示。HTTPS 会通过消息认证码 (MAC) 或者数字签名确保数据完整。 MAC机制：发送方用密钥生成数据的哈希值 (HMAC)， 接收方重新计算并进行对比额如果哈希值不匹配，则说明数据被篡改。 数字签名：CA 对证书内容哈希值加密生成签名，客户端验证签名一致性，防止证书内容被篡改 身份证书：通过 CA 颁发的证书，验证当前网站是否为真实的网站。 【HTTPS详解】\n下面围绕 HTTPS 解决三大风险（窃听、篡改、冒充）的方案进行展开\n【窃听风险 (混合加密)】\n为了解决窃听风险，HTTPS对报文采用了混合加密的方式 。HTTPS 采用的是对称加密 + 非对称加密的方式来实现混合加密的。具体方式如下：\n在通信建立前，采用非对称加密的方式交换会话密钥，后续不再使用非对称加密 在通信过程中，全部使用对称加密的会话密钥加密明文数据 为什么会采用混合加密呢？主要是单个加密方式都有其对应的缺点，具体加密特点如下：\n对称加密：只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换 非对称加密：需要使用两个密钥，公钥和私钥，公钥可以任意分发而私钥需要保密，解决了密钥交换问题，但是速度慢 为了均衡速度和安全的性能，HTTPS 采用混合加密方式进行加密 【篡改风险 (摘要算法 + 数字签名)】\n为了解决篡改风险，HTTPS对报文采用了摘要算法 + 数字签名的方式 。为了保证传输的内容不被篡改，需要对发送方的报文内容进行哈希计算，计算出其哈希值，然后放在报文内容当中一起传输给客户端。如果对方收到报文内容之后，同样会先计算报文的哈希值。如果计算出来的哈希值和报文本身携带的哈希值不一样，就说明报文被篡改了，会丢弃这条数据。\nHTTPS 协议采用摘要算法 (哈希函数) 来计算报文内容的哈希值，哈希值是唯一的，并且没法儿通过哈希值反推内容，可以防止报文在传输的过程当中被篡改。但是，如果有中间人将内容和哈希值同时进行篡改，接收方是没法儿判断报文是否是源于发送方发出的还是中间人发出的。为此，HTTPS 协议采用了非对称加密算法，利用私钥将哈希值生成数字签名来解决这个问题。 发送方会把内容和数字签名(私钥加密之后的哈希值)一起发送出去。接收方收到之后，采用公钥对数字签名进行解密。并且同时对内容进行哈希运算，如果内容计算的哈希值和数字签名解密的哈希值相同，则说明消息没有被篡改。否则，说明消息被篡改了，直接丢弃。 【公钥和私钥关系】 公钥和私钥是可以双向加解密的，也就是说可以用公钥加密，私钥解密，或者用私钥加密，公钥解密。\n公钥加密，私钥解密：一般用于防止传输的内容被窃取，其他人是截取到报文，也是没法儿解密的。只有持有私钥的人，才能够解密。 私钥加密，公钥解密：一般用于防止传输的内容被冒充，因为私钥是不可泄露的，如果公钥能够解密出私钥的内容，证明这条消息是私钥身份的人发送的。 【冒充风险 (数字证书)】\n虽然前面通过哈希算法能够保证消息不被篡改，且通过数字签名保证数据的来源可靠性（确保是持有私钥的一方发送的）。但是，如果中间人伪造一堆公钥和私钥，将接收方原来的公钥替换为伪造的公钥。那么中间人就可以构造假报文，接收方通过被替换的假公钥正常解密，得到的却是伪造的假报文。HTTPS 协议为了解决中间人冒充发送方的问题，采用了数字证书的方式。CA 数字证书认证机构可以利用私钥 (CA自己的私钥)制作数字证书（公钥 + CA的数字签名），所有 CA 的公钥都已经置入浏览器或者操作系统里面了。发送方将公钥交给 CA 数字证书认证机构生成数字证书，然后接收方收到消息之后，用浏览器/操作系统自带的 CA 公钥进行解密，确认服务器数字证书的真实性。如果解密成功且哈希值匹配，则从数字证书中提取发送方颁发的公钥，然后用公钥将报文加密进行传输。\n【HTTPS 建立连接过程】\nHTTPS 相较于 HTTP 来说， 除了 TCP 三次握手之外，还多了 SSL/TLS 协议的握手阶段。TLS 握手阶段涉及四次通信，使用不同的密钥交换算法，一般常用 RSA 算法 和 ECDHE 算法。下面具体介绍基于 RSA 算法的 TLS 握手过程。TLS 协议建立的具体流程如下：\nClientHello：首先，客户端向服务器发起加密通信请求 ClientHello。客户端会在这一步向服务器发送一下信息：\n客户端支持的 TLS 版本，比如 TLS 1.2 客户端产生的随机数 C，后面用于生成会话密钥的条件之一 客户端支持的密码套件列表，比如 RSA 加密算法 ServerHello：服务器收到客户端请求之后，想客户端发出响应 ServerHello。服务器回应的内容如下：\n确认 TLS 协议版本，如果浏览器不支持，则关闭加密通信 服务器产生的随机数 S, 也是后面用于生成会话密钥的条件之一 确认密码套件列表，比如 RSA 加密算法 服务器的数字证书 (服务器向CA申请的) 客户端回应：客户端收到服务端的回之后，首先通过浏览器/操作系统中的 CA 公钥，对服务器的数字证书进行校验。如果证书没有问题，则取出数字证书中的服务器公钥，然后使用服务器的公钥加密报文，向服务器发送下面的信息：\n一个随机数 (pre-master key)，该随机数会被客户端用服务器的公钥加密 加密通信算法改变通知，表示随后的信息都将用会话密钥进行加密通信 客户端握手结束通知，通知服务器表明客户端握手的阶段已经结束了 【注意】 服务器和客户端都有了三个随机数 (客户端随机数 C、服务器随机数 S、pre-master key)之后，通过协商的加密算法，计算出本次的通信的会话密钥。\n服务器的最后回应：服务器计算出会话密钥之后，向客户端发送最后的消息：\n加密通信算法改变通知，表示随后的消息都将用会话密钥加密通信 服务器握手结束通知，通知客户端表明服务器握手的阶段结束了 ","permalink":"https://swimmingliu.cn/posts/job/computer-networks-interview-questions/","summary":"\u003ch2 id=\"1-tcp-和-udp-有什么区别\"\u003e1. TCP 和 UDP 有什么区别？\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eTCP\u003c/code\u003e 是一种可靠的、面向连接、基于字节流传输的传输协议，能够保证数据的顺序，但是其延迟比较大。一般适用于需要数据完整性和顺序的场景，比如文件传输、邮件、\u003ccode\u003eWeb\u003c/code\u003e 网站。\n\u003ccode\u003eUDP\u003c/code\u003e 是一种不可靠的、无连接、基于数据报传输的传输协议，不能保证数据的顺序，但是延迟比较小。一般适用于需要高性能要求和快速传输数据的应用，比如实时通讯、语音、视频、游戏等。\u003c/p\u003e\n\u003cp\u003e【注意】\u003ccode\u003eTCP\u003c/code\u003e 和 \u003ccode\u003eUDP\u003c/code\u003e 都属于传输层\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e特性\u003c/th\u003e\n          \u003cth\u003eTCP\u003c/th\u003e\n          \u003cth\u003eUDP\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e连接方式\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e面向连接 (三次握手)\u003c/td\u003e\n          \u003ctd\u003e无连接\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e可靠性和顺序保证\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e可靠，保证数据按顺序送达\u003c/td\u003e\n          \u003ctd\u003e不可靠，不能保证数据的顺序，而不能保证安全送达\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e流量控制/拥塞控制\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e提供流量控制和拥塞控制\u003c/td\u003e\n          \u003ctd\u003e没有流量控制和拥塞控制\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e头部大小\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e头部较大 (\u003ccode\u003e20\u003c/code\u003e ~ \u003ccode\u003e80\u003c/code\u003e 字节)\u003c/td\u003e\n          \u003ctd\u003e较小 (只有 \u003ccode\u003e8\u003c/code\u003e 字节)\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e性能\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e较低，延迟大\u003c/td\u003e\n          \u003ctd\u003e较高，延迟小\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e是否支持广播\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e不支持广播\u003c/td\u003e\n          \u003ctd\u003e支持广播\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e数据传输模式\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e通过字节流传输\u003c/td\u003e\n          \u003ctd\u003e通过数据报传输\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e适用场景\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e文件传输、Web、邮件等需要可靠性的传输\u003c/td\u003e\n          \u003ctd\u003e实时通讯、语音、视频、游戏等高性能要求应用\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e基于两者的协议\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e1. \u003cstrong\u003eHTTP协议\u003c/strong\u003e：超文本和多媒体内容的协议\u003cbr /\u003e2. \u003cstrong\u003eHTTPS协议\u003c/strong\u003e：基于HTTP协议上加了一层\u003ccode\u003eSSL\u003c/code\u003e / \u003ccode\u003eTSL\u003c/code\u003e 外壳，保证了数据传输的安全性\u003cbr /\u003e3. \u003cstrong\u003eFTP协议\u003c/strong\u003e： 文件传输协议，用来传文件到服务器的\u003cbr /\u003e4. \u003cstrong\u003eSMTP协议\u003c/strong\u003e：简单邮件协议，用于发送邮件的协议 (\u003ccode\u003ePOP3\u003c/code\u003e 协议： 负责邮件接受的协议)\u003c/td\u003e\n          \u003ctd\u003e1. \u003cstrong\u003eHTTP 3.0 协议\u003c/strong\u003e: 基于 \u003ccode\u003eUDP\u003c/code\u003e 的\u003ccode\u003eQUIC\u003c/code\u003e 协议\u003cbr /\u003e2. \u003cstrong\u003eDHCP 协议\u003c/strong\u003e： 动态主机配置协议，动态配置 \u003ccode\u003eIP\u003c/code\u003e 地址\u003cbr /\u003e3. \u003cstrong\u003eDNS\u003c/strong\u003e ：域名解析系统，将域名转变为机器刻度的 \u003ccode\u003eIP\u003c/code\u003e 地址\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e【ISO 和 TCP/IP 模型】\u003c/strong\u003e\u003c/p\u003e","title":"计算机网络面试题笔记"},{"content":"1. 单例模式有哪几种实现？如何保证线程安全？ 首先，单例模式和工厂模式都是一种设计模式。单例模式当中，一个类只允许创建一个对象(或者说实例)， 那这个类就是单例类。单例类是不可以被继承的，也没有了多态的特性。\n【单例类的实现方式】\n常规单例模式有五种写法，但是编写代码的过程当中，要注意以下几点：\n构造器需要私有化 暴露一个公共获取单例对象的接口 （obj.getInstance()） 是否支持懒加载 延迟加载 是否线程安全 五种写法为：\n饿汉式： 类加载的时候，就一起把 instance 静态实例创建好了，所以创建的过程市线程安全的。\n饿汉式的单例模式虽然不支持懒加载，有点浪费资源。但其实不会占用太多资源，并且如果一个实例初始化的过程比较复杂，就应该放在启动的时候来处理，避免运行时卡顿或发生问题， 满足fail-fast 失败快速解决的设计原则\npublic class EagerSingleton { private static Singleton instance = new Singleton(); private Singleton (){} public static Singleton getInstance() { return instance; } } 懒汉式：相较于饿汉式的方式，修改成延迟加载的模式。注意getInstance()方法没有上锁的话，在大量线程并发请求的时候，可能创建多个实例。\npublic class Singleton { private static Singleton instance; private Singleton (){} public synchronized static Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } } 双重检查锁：饿汉式锁不支持延迟加载，然后懒汉式锁的粒度比较大，不支持高并发。双重检查锁可以实现既延迟加载，又支持高并发。其实就是在判断了没有实例之后，再进行上锁，创建实例。 但是实例必须用volatile 修饰，不然new 操作创建对象时，容易出现重排序的问题。\npublic class DclSingleton { // volatile如果不加可能会出现半初始化的对象 // 现在用的高版本的 Java 已经在 JDK 内部实现中解决了这个问题（解决的方法很简单，只要把对象 new 操作和初始化操作设计为原子操作，就自然能禁止重排序）,为了兼容性我们加上 private volatile static Singleton singleton; private Singleton (){} public static Singleton getInstance() { if (singleton == null) { synchronized (Singleton.class) { if (singleton == null) { singleton = new Singleton(); } } } return singleton; } } 静态内部类：利用Java的内部类，再调用getInstance()方法的时候，直接返回内部类的实例。他会再调用方法之后，创建内部类的实例对象。实例的唯一性和创建过程的线程安全性，都有JVM来保证。这种方法既是线程安全的，又能够做延迟加载。\npublic class InnerSingleton { /** 私有化构造器 */ private Singleton() { } /** 对外提供公共的访问方法 */ public static Singleton getInstance() { return SingletonHolder.INSTANCE; } /** 写一个静态内部类，里面实例化外部类 */ private static class SingletonHolder { private static final Singleton INSTANCE = new Singleton(); } } 枚举：通过Java枚举类型本身的特性，保证实例创建线程的安全性和实例的唯一性。\n// 使用枚举实现单例模式 public enum Singleton { INSTANCE; // 单例中的方法示例 public void doSomething() { System.out.println(\u0026#34;单例方法执行\u0026#34;); } } // 使用方法： Singleton.INSTANCE.doSomething(); 也可以用单例项作为枚举的成员变量，累加器可以像下面这样编写：\npublic enum GlobalCounter { INSTANCE; private AtomicLong atomicLong = new AtomicLong(0); public long getNumber() { return atomicLong.incrementAndGet(); } } 【单例模式的安全问题】\n反射入侵：如果想要阻止其他人构造实例，仅仅私有化构造器还是不够的，因为我们可以利用反射机制来获取私有构造器进行构造。如果要避免这种情况发生，可以再构造器当中进行判断实例是否已存在，避免多次利用构造器构造实例\npublic class Singleton { private volatile static Singleton singleton; private Singleton (){ if(singleton != null) throw new RuntimeException(\u0026#34;实例：【\u0026#34; + this.getClass().getName() + \u0026#34;】已经存在，该实例只允许实例化一次\u0026#34;); } public static Singleton getInstance() { if (singleton == null) { synchronized (Singleton.class) { if (singleton == null) { singleton = new Singleton(); } } } return singleton; } } // 利用反射机制来入侵构造实例 @Test public void testReflect() throws NoSuchMethodException, InvocationTargetException, InstantiationException, IllegalAccessException { Class\u0026lt;DclSingleton\u0026gt; clazz = DclSingleton.class; Constructor\u0026lt;DclSingleton\u0026gt; constructor = clazz.getDeclaredConstructor(); constructor.setAccessible(true); boolean flag = DclSingleton.getInstance() == constructor.newInstance(); log.info(\u0026#34;flag -\u0026gt; {}\u0026#34;,flag); } 序列化与反序列化：如果单例存到文件流当中，再进行反序列话，也不是同一个实例。但是可以用readResolve()的方法，将返回值作为反序列化的结果，而不会克隆一个新的实例，保证jvm当中只有一个实例存在。\n@Test public void testSerialize() throws IllegalAccessException, NoSuchMethodException, IOException, ClassNotFoundException { // 获取单例并序列化 Singleton singleton = Singleton.getInstance(); FileOutputStream fout = new FileOutputStream(\u0026#34;D://singleton.txt\u0026#34;); ObjectOutputStream out = new ObjectOutputStream(fout); out.writeObject(singleton); // 将实例反序列化出来 FileInputStream fin = new FileInputStream(\u0026#34;D://singleton.txt\u0026#34;); ObjectInputStream in = new ObjectInputStream(fin); Object o = in.readObject(); log.info(\u0026#34;他们是同一个实例吗？{}\u0026#34;,o == singleton); // 如果直接获取，反序列化后的不是同一个实例 } // 添加readResolve()来解决序列化和反序列化问题 public class Singleton implements Serializable { // 省略其他的内容 public static Singleton getInstance() { } // 需要加这么一个方法 public Object readResolve(){ return singleton; } } 【为什么要用单例模式】\n为了全局唯一：系统中如配置类、全局计数器等类型，应该都都只能保存一份数据，不应该有多份数据。\n配置类：系统仅有一个配置文件，加载到内存后映射成唯一的配置实例 全局计数器：用于数据统计、生成全局递增id 等功能，必须要是唯一的，否则可能导致统计无效、ID 重复等问题。 // 全局id生成器 public class GlobalCounter { private AtomicLong atomicLong = new AtomicLong(0); private static final GlobalCounter instance = new GlobalCounter(); // 私有化无参构造器 private GlobalCounter() {} public static GlobalCounter getInstance() { return instance; } public long getId() { return atomicLong.incrementAndGet(); } } // 查看当前的统计数量 long courrentNumber = GlobalCounter.getInstance().getId(); 处理资源访问冲突：假如需要日志输出的功能，可以使用单例i面资源访问冲突\npublic class Logger { private String basePath = \u0026#34;D://log/\u0026#34;; private static Logger instance = new Logger(); private FileWriter writer; private Logger() { File file = new File(basePath); try { writer = new FileWriter(file, true); //true表示追加写入 } catch (IOException e) { throw new RuntimeException(e); } } public static Logger getInstance(){ //确保全局只有一个logger实例对象 return instance; } public void log(String message) { try { writer.write(message); } catch (IOException e) { throw new RuntimeException(e); } } public void setBasePath(String basePath) { this.basePath = basePath; } } 【单例模式存在的问题】\n无法支持面向对象编程OOP： OOP 的三大特性是封装、继承、多态。单例把构造函数私有化了，不支持继承和多态。所以无法对它进行拓展。 很难横向拓展：单例类只能有一个对象实例，如果后面需要进行拓展，创建多个实例。必须修改源码，无法友好拓展。 【不同作用范围的单例模式】\n线程级别单例：单例类对象是进程唯一的，如果想要线程唯一。在不使用ThreadLocal的时候，可以采用ConCurrentHashMap 的方式，用线程id为key， 实例为value。每个线程的存取都从共享的 map 当中进行操作。\npublic class Connection { private static final ConcurrentHashMap\u0026lt;Long, Connection\u0026gt; instances = new ConcurrentHashMap\u0026lt;\u0026gt;(); private Connection() {} public static Connection getInstance() { Long currentThreadId = Thread.currentThread().getId(); instances.putIfAbsent(currentThreadId, new Connection()); return instances.get(currentThreadId); } } 容器级别的单例：将单例的作用范围由进程切换到一个容器，可能会更加方便我们进行单例对象的管理。这也是Spring 的核心思想。Spring 提供一个单例容器，确保一个实例是容器级别的单例，并且在容器启动时完成初始化。具体优势如下：\n所有的bean 都以单例的形式存放在容器中，避免大量的对象被创建，造成JVM 内存抖动严重，频繁GC。 程序启动时，初始化单例bean， 满足fast-fail，将所有构建过程的异常暴露在启动时，而非运行时。 缓存了所有单例bean，启动的过程相当于预热的过程，运行时不必进行对象创建，效率更高。 容器管理bean的生命周期，结合依赖注入使得解耦更加彻底、扩展性更好。 2. 什么是策略模式？一般用在什么场景？ 策略模式是行为设计模式的一种，通过定义一系列的算法类。允许在运行时动态选择算法，从而实现更加灵活的代码结构。该模式用于组织和调用这些算法，让程序结构变得更加灵活，具有更好的维护性和扩展性。\n策略模式一般用于当一个功能存在多种算法的时候，需要根据不同的情况使用不同的计算算法(都封装成类的)。这样就可以避免利用大量的if-else 或者 switch-else\n【为什么要用策略模式】\n避免程序存在判断或选择分支语句：当程序存在大量的 if-else 或者 switch-else 判断语句，代码可能变得难以维护 避免破坏现有功能：当算法的实现经常变更或需要拓展的时候，直接修改代码可能会破坏现有功能。 【策略模式的场景】\n多种算法可互换：需要动态选择算法，例如排序算法的选择。有很多种排序算法，可以把不同的排序方式封装成一个独立的算法类 (快速排序、归并排序、直接插入排序等) 避免条件语句：采用策略模式替换掉代码当中的大量if-else 或 switch 语句 与上下文独立：客户端不需要知道具体的实现细节，只需以来抽象策略。 【策略模式典型应用场景】\n支付系统：支持多种支付方式，比如微信、支付宝、信用卡 数据压缩：提供不同的压缩算法 日志策略：根据日志级别动态选择记录策略 【策略模式的组成】\nStrategy 策略：用来约束一系列具体的策略算法。Context 上下文使用这个接口来调用具体的策略实现定义的算法。如果多个算法具有公共功能的化，把Strategy 实现为抽象类，然后把多个算法的功能实现到Stragy 里面。 (比如多种排序算法，都放在 Strategy 抽象类里面) ConcreteStrategy 具体策略： 具体的策略实现，负责实现Strategy 策略的接口 (多种排序算法的具体实现) Context 上下文：上下文是负责和具体的策略类交互，通常上下文会吃有一个真正的策略实现 (就是调用哪个排序方法，比如说 main 函数) 3. 什么是模板方法模式？一般用在什么场景？ 模板方法就是在抽象类里面定义好算法的骨架，具体步骤在子类实现。\n【模板方法特点】\n算法骨架：在基类中定义一个算法的固定执行步骤，具体实现步骤交给子类实现 复用代码：子类复用基类中定义的公共逻辑，只需要实现特定的逻辑 遵循开闭规则：模板方法是扩展开放，修改闭合的 【典型使用场景】\n数据请求处理: 读取数据、处理数据、输出结果 Web请求处理：解析请求、处理逻辑、返回响应 String Template 字符串模板 String name = \u0026#34;World\u0026#34;; String greeting = STR.\u0026#34;Hello, \\{name}!\u0026#34;; System.out.println(greeting); // 输出: Hello, World! 4. 谈谈你了解的最常见的几种设计模式，说说他们的应用场景 【常见的设计模式】\n单例模式：保证系统中一个类只有一个实例对象，比如全局配置、全局计数器、数据库连接池 策略模式：封装一组算法让他们之间能够相互替代，避免大量的if-else 和 switch-case 语句，比如用户选择不同的支付策略，或者调用不同的排序算法。 模板模式：提炼核心流程封装成一个方法，比如像支付逻辑(参数校验、调起支付接口、修改支付状态)，除了调起支付接口以外，其他的流程基本一致。所以可以封装成模板方法，然后把调起支付接口的操作，在具体实现方法当中重写该方法。 简单工厂模式：获取不同的对象时可以使用，将对象的创建逻辑抽离复用。 外观模式：为子系统提供一组统一接口，隐藏内部实现细节，方便子系统直接调用，而无需关注实现细节(比如高德和百度的 SDK) 代理模式：通过创建代理对象来控制哦对实际对象的访问，例如Sping AOP切面编程采用代理模式来动态生成增强目标对象的代理 (通过 JDK 动态代理或者CGLIB代理) 。Sping AOP 默认优先使用 JDK 动态代理。当目标类未实现接口时，才会切换为 CGLIB 动态代理。 【Spring中的设计模式】\n5. 你认为好的代码应该是什么样的？ 【通俗易懂的讲】\n清晰易懂，保持简洁和易读性：代码简洁、直观，函数和变量命名都有意义，可读性非常强，有合理的注释。 高内聚低耦合：高内聚是指代码模块内部功能集中，每个模块都有单一职责。低耦合指的是不同模块之间的依赖关系尽量松散，修改一个模块的时候，其他模块受到的影响比较小。 可测试：每个模块都设计为独立的、可验证的单元，编写单元测试用例的时候，能够确保代码的正确性并且发现潜在问题。 易于扩展，遵循开闭原则：代码具有一定灵活性，能在不破坏现有功能的情况下，方便进行扩展和修改。 符合团队规范：代码风格和团队整体代码规范统一，有助于协助团队协作和代码审查。 减少硬编码、魔法值：尽量避免硬编码和魔法值的现象，方便后续进行修改。 【好代码具备以下特性】\n设计原则 代码特性 结果 单一职责 类或模块职责单一 降低类的复杂度，增强可读性和维护性 开闭原则 对扩展开放，对修改关闭 提高扩展性，减少对已有代码的修改 高内聚低耦合 模块职责明确，依赖关系松散 增强代码的可维护性和扩展性 接口隔离原则 接口小且专用 减少无关实现代码，增强接口的灵活性 依赖倒置 依赖于抽象而非具体实现 降低模块间的耦合度，提高代码灵活性 合成复用原则 优先使用组合而非继承 提高灵活性，避免继承导致的高聚合 里氏替换原则 子类可以无缝替换父类 确保继承体系的正确性，增强代码的稳定性 迪米特法则 减少类之间的依赖 降低耦合度，增强模块独立性 6. 工厂模式和抽象工厂模式有什么区别？ 【工厂模式】\n对象：创建一种类型的产品对象，比如让google创建安卓系统， 不同品牌的手机厂商(工厂子类)就可以根据安卓系统当中的功能，重写出其他的os 系统，比如鸿蒙系统、澎湃系统等等 工厂结构：有且只有一个抽象的工厂类，定义创建产品的抽象方法，然后具体的工厂子类去实现这个方法来实际创建具体的产品。比如 android 系统的源码是大家都可以看到的，其他厂商也可以根据android 系统的设计，重新实现部分函数，修改成其他的功能。 使用场景：当创建过程比较复杂，想把对象创建和使用分离时常用，比如创建数据库连接对象等简单的单一产品创建创建适用。 【抽象工厂模式】\n对象：用于创建一系列相关的产品对象，比如创建手机的时候，需要连带创建配套的充电器、耳机等配套产品 工厂结构：抽象工厂类定义了多个抽象创建方法，分别用于创建一系列相关的产品。更具体的工厂子类要实现这些抽象方法，提供一整套的具体产品的创建。 使用场景：当系统要创建多个相互依赖或者关联的对象的时候，确保这些对象搭配合理。比如游戏开发中创建不同风格(比如科技风格、古风)的角色、武器、场景等一整套相关的元素时，就适合用抽象工厂模式。 // 抽象产品A public interface ProductA { void use(); } // 具体产品A1 -\u0026gt; 手机 public class ConcreteProductA1 implements ProductA { @Override public void use() { System.out.println(\u0026#34;Using ConcreteProductA1\u0026#34;); } } // 具体产品A2 -\u0026gt; 电脑 public class ConcreteProductA2 implements ProductA { @Override public void use() { System.out.println(\u0026#34;Using ConcreteProductA2\u0026#34;); } } // 抽象产品B public interface ProductB { void eat(); } // 具体产品B1 -\u0026gt; 手机充电线 public class ConcreteProductB1 implements ProductB { @Override public void eat() { System.out.println(\u0026#34;Eating ConcreteProductB1\u0026#34;); } } // 具体产品B2 -\u0026gt; 电脑充电线 public class ConcreteProductB2 implements ProductB { @Override public void eat() { System.out.println(\u0026#34;Eating ConcreteProductB2\u0026#34;); } } // 抽象工厂 -\u0026gt; 把两个相互关联的抽象产品一起创建 public interface AbstractFactory { ProductA createProductA(); ProductB createProductB(); } // 具体工厂1 public class ConcreteFactory1 implements AbstractFactory { @Override public ProductA createProductA() { return new ConcreteProductA1(); } @Override public ProductB createProductB() { return new ConcreteProductB1(); } } // 具体工厂2 public class ConcreteFactory2 implements AbstractFactory { @Override public ProductA createProductA() { return new ConcreteProductA2(); } @Override public ProductB createProductB() { return new ConcreteProductB2(); } } // 使用抽象工厂创建产品 public class Client { public static void main(String[] args) { AbstractFactory factory1 = new ConcreteFactory1(); ProductA productA1 = factory1.createProductA(); ProductB productB1 = factory1.createProductB(); productA1.use(); productB1.eat(); AbstractFactory factory2 = new ConcreteFactory2(); ProductA productA2 = factory2.createProductA(); ProductB productB2 = factory2.createProductB(); productA2.use(); productB2.eat(); } } ","permalink":"https://swimmingliu.cn/posts/job/desgin-mode-interview-questions/","summary":"\u003ch2 id=\"1-单例模式有哪几种实现如何保证线程安全\"\u003e1. 单例模式有哪几种实现？如何保证线程安全？\u003c/h2\u003e\n\u003cp\u003e首先，单例模式和工厂模式都是一种设计模式。单例模式当中，一个类只允许创建一个对象(或者说实例)， 那这个类就是单例类。单例类是不可以被继承的，也没有了多态的特性。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【单例类的实现方式】\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e常规单例模式有五种写法，但是编写代码的过程当中，要注意以下几点：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e构造器需要私有化\u003c/li\u003e\n\u003cli\u003e暴露一个公共获取单例对象的接口 （\u003ccode\u003eobj.getInstance()\u003c/code\u003e）\u003c/li\u003e\n\u003cli\u003e是否支持懒加载 \u003ccode\u003e延迟加载\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e是否线程安全\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e五种写法为：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e饿汉式\u003c/strong\u003e： 类加载的时候，就一起把 \u003ccode\u003einstance\u003c/code\u003e 静态实例创建好了，所以创建的过程市线程安全的。\u003c/p\u003e\n\u003cp\u003e饿汉式的单例模式虽然不支持懒加载，有点浪费资源。但其实不会占用太多资源，并且如果一个实例初始化的过程比较复杂，就应该放在启动的时候来处理，避免运行时卡顿或发生问题， 满足\u003ccode\u003efail-fast\u003c/code\u003e 失败快速解决的设计原则\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-java\" data-lang=\"java\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eEagerSingleton\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"kd\"\u003eprivate\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003estatic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eSingleton\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003einstance\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003enew\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eSingleton\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\u003cspan class=\"w\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"kd\"\u003eprivate\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003eSingleton\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(){}\u003c/span\u003e\u003cspan class=\"w\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003estatic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eSingleton\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003egetInstance\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \t\u003c/span\u003e\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003einstance\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e懒汉式\u003c/strong\u003e：相较于饿汉式的方式，修改成延迟加载的模式。注意\u003ccode\u003egetInstance()\u003c/code\u003e方法没有上锁的话，在大量线程并发请求的时候，可能创建多个实例。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-java\" data-lang=\"java\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eSingleton\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"kd\"\u003eprivate\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003estatic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eSingleton\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003einstance\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"kd\"\u003eprivate\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003eSingleton\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(){}\u003c/span\u003e\u003cspan class=\"w\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003esynchronized\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003estatic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eSingleton\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003egetInstance\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003einstance\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kc\"\u003enull\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e            \u003c/span\u003e\u003cspan class=\"n\"\u003einstance\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003enew\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eSingleton\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\u003cspan class=\"w\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003einstance\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e双重检查锁\u003c/strong\u003e：饿汉式锁不支持延迟加载，然后懒汉式锁的粒度比较大，不支持高并发。双重检查锁可以实现既延迟加载，又支持高并发。其实就是在判断了没有实例之后，再进行上锁，创建实例。 但是实例必须用\u003ccode\u003evolatile\u003c/code\u003e 修饰，不然\u003ccode\u003enew\u003c/code\u003e 操作创建对象时，容易出现重排序的问题。\u003c/p\u003e","title":"设计模式面试题笔记"},{"content":"1. 什么是 Java 内存模型（JMM）？ JMM 是 Java内存模型 ， 它是Java虚拟机 JVM 定义的一种规范，用于描述多线程程序中的变量，像实例字段、静态字段和数组元素，他们如何在内存中存储和传递的规则。也就是规定线程啥时候从住内存里面读数据，啥时候把数据写回到住内存。JMM 的核心目标是确保多线程环境下的可见性、有序性和原子性, 避免硬件和编译器优化带来的不一致问题。\nJMM 当中包含主内存 (所有线程共享) 和 工作内存 （每个线程私有）两种内存。\n主内存：主内存是Java堆内存的一部分，是线程共享的区域，存储全局变量，比如静态变量、实例字段、数组元素等等。线程不能直接操作主内存，必须通过工作内存间接访问。 工作内存：每个线程私有的本地内存，缓存主内存的变量副本。线程对变量的读写操作均在工作内存种进行，修改后的结果需要同步会主内存。线程是通过内存屏障 ( volatile 关键字) 或者 同步操作 ( synchronized ) 实现主内存和工作内存的数据一致性的。 【可见性、有序性、原子性定义】\n可见性：确保一个线程对共享变量的修改，能够及时被另外一个线程看到。 volatile就是用来保证可见性的，强制线程每次读写的时候，直接从主内存当中获取最新值。 有序性：指线程执行操作的顺序。JMM允许某些指令重排序之后再提高性能，但会保证线程内的操作顺序不会被破坏。通过happens-before (线程A发生在线程B之前)的关系来保证跨线程的有序性。 原子性：操作不可分割，线程不会在执行的过程当中被打断。例如, synchronize 关键字能确保方法或代码块的原子性 【JMM作用】\n因为不同的操作系统都有一套独立的内存模型，但是Java为了满足跨平台的特性，它需要定义一套内存模型屏蔽个操作系统之间的差异。我们可以利用JMM当中定义好的从Java源码到CPU指令的执行规范，也就是使用synchronized 、volatile 等关键字，还有happens-before原则，就可以写出并发安全的代码了。 比如说，线程A和线程B同时操作 变量-1，假如最开始变量-1 是 0\n首先，线程A和线程B都读取了变量-1 然后，线程B对取到的变量-1自增为1，并写回主内存 此时，线程A对读取到的变量-1也自增1，并写回主内存。这就会导致线程B的操作失效了，出现并发安全问题。 如果有JMM，我们就可以在线程A要修改数据之前,让它采用CAS乐观锁的方式进行修改。再次去读主内存当中的值，然后修改之后，再判断一下主内存的值是否发生变化。如果没有发生变化，就写回主内存。如果发生变化，就要进行自旋。\n【注意】 工作内存是每个线程独立的内存空间，其他线程都是看不到的。主内存是Java堆内存的一部分，所有的实例变量、静态变量和数组元素都存储在主内存当中。\n【内存间交互操作类型 (8种原子操作)】\nlock 上锁：把一个变量表示为一条线程独占的状态 unlock 解锁： 把一个变量从独占状态中释放出来，释放后的变量才能被其他线程锁定 read 读取： 从主内存当中读取一个变量到工作内存中 load 载入：把read操作从主内存中得到的变量值放入工作内存的变量副本当中 use 使用：把工作内存当中的一个变量值传递给执行引擎 assign 赋值：把一个从执行引擎接收到的值赋给工作内存中的变量 store 存储：把工作内存中的一个变量的值传送给主内存中 write 写入：把store操作从工作内存中得到的变量值放入主内存的变量中 【volatile 特殊规则】\n可见性：对于 volatile 修饰的变量的写操作会立即刷新到内存中，任何线程对这个volatile 变量的读操作都能立即看到最新的值。 禁止指令重排序： 在对 volatile 变量进行读/写操作的时候，会插入内存屏障，禁止指令重排序。也就是该变量的写操作不能与之前的读/写操作重排序，它的都操作不能与之后的读/写操作重排序。 【Happens-Before 原则】\n见下一个问题\n2. 什么是Java的 happens-before 规则? happens-before 原则就是 JMM 当中定义操作间顺序的规则，确保操作的有序性和可见性。\n程序次序规则：线程当中所有操作都是按程序代码的顺序发生 监视器锁规则：解锁操作发生在同一个锁的随后的加锁操作之前，说白了，先解锁，后上锁 volatile 变量规则： volatile 变量的写操作发生在对改变量随后的读操作之前，先写后读 线程启动规则：线程A对线程B的Thread.start() 调用发生在这个新线程的每一个操作之前 线程终止规则：线程A所有的操作都发生在其他线程检测到线程A终止之前 线程中断规则：对线程的中断操作 (Thread.interrupt()) 发生在被中断线程检测到的中断时间之前 (通过Thread.interrupted() 或 Thread.isInterrupted() 进行检测) 对象终结规则： 一个对象的构造函数执行结束发生在这个对象的finalize() 方法之前 传递性： 如果A happens-before B，B happens-before C, 则 A happens-before C 3. Java 的 synchronized 是怎么实现的？ 【实现原理】\nsynchronized 关键字是以来 JVM 的Monitor (监视器锁)和 Object Header (对象头) 实现的。其中，重量级所依赖于 Monitor 监视器锁， 轻量级锁和偏向锁都依赖于对象头 (Object Header)\n【不同使用场景的区别】\n修饰方法：会在修饰的方法的访问标志中增加一个 ACC_SYNCHRONIZED 标志，每当有一个线程访问该方法时， JVM回去检测该方法的访问标志。如果包含ACC_SYNCHRONIZED 标志， 线程必须获得该方法对应的对象监视器锁 (对象锁)，也就是Monitor 当中的owner执行该线程。 然后再执行该方法，保持同步性。 修饰代码块：在代码块的前后分别插入 monitorenter 和 monitorexit 字节码指令， 可以理解为加锁和解锁 【可重入性】\nsynchronized 是可以重入的，每次获取一次锁。如果是当前线程的锁，计数器加1，锁释放的时候，计数器减1。直到计数器减为 0 为止，锁才真正释放\n【synchronized 锁升级】\nsynchronized 锁分为三种，偏向锁，轻量级锁，重量级锁。其升级次序为偏向锁(一个线程) -\u0026gt; 轻量级锁 (多个线程) -\u0026gt; 重量级锁 (多个线程竞争激烈)\n偏向锁：当有线程第一次获取锁的时候， JVM 会采用修改锁对象的对象头，将该线程标记为偏向状态。对象头里面会记录线程ID 和 对应的epoch 偏向锁版本。后续该线程再获取锁，基本没啥开销。 轻量级锁：当有另外的线程尝试去获取已经被偏向的锁时，锁会升级为轻量级锁。此时，申请上锁的过程中，JVM会在当前线程的栈帧（包括所有的局部变量、参数和返回地址）中创建一个锁记录Lock Record，让锁记录指向锁对象。然后用 CAS 替换锁对象的Mark Word， 并将Mark Word 的值存入锁记录。如果替换成功，锁对象的Mark Word 就变成当前线程的所锁记录。使用 CAS 操作的目的是减少锁竞争的开销。 重量级锁：当 CAS 失败无法获取锁的时候，JVM判定其为多个线程竞争锁激烈。锁会升级成为重量锁，会使用操作系统的互斥量 Mutex 来实现线程的阻塞和环形。若果获取锁成功，线程会被放入Monitor的 owner 当中 【锁消除和锁粗化】\n锁消除：JVM判断对象是否只在当前线程使用，如果只在当前线程使用，则消除不必要加的锁 锁粗化：多个锁频繁操作出现时，JVM会将这些锁操作合并，见锁获取和释放的开销。 【参考材料】 黑马程序员-synchronized锁升级\n【Synchronized 性能优化】\nsynchronized 在 JDK 1.6 之后进行了很多性能优化，主要包括下面的四种：\n偏向锁：如果一个锁被同一个线程多次获得， JVM 会把这个锁设置为偏向锁，减少获取锁的代价 轻量级锁：如果没有线程竞争，JVM 会将锁设置为轻量级锁，使用 CAS 操作代替互斥同步 锁粗化：JVM 在 JIT 编译的时候，会检测到一些没有竞争的锁，并将这些锁去掉，减少同步的开销 锁消除：JVM 会将一些短时间内连续的锁操作合并为一个锁操作，减少锁操作的开销。 [补充] 3. Java 中的 synchronized 轻量级锁是否会进行自旋？ synchronized 轻量级锁的阶段，只会通过 CAS 操作来替换对象头当中的 Mark Word 来获取锁，不会有自旋操作。如果 CAS 失败了之后，会直接膨胀为 重量级锁。如果获取重量级锁失败，会进行自旋操作。\n【synchronized 锁的四个阶段】\n无锁阶段：最开始，多个线程可能都不需要同步访问共享资源，因此可能不存在显式的锁。不存在任何锁的开销，这个阶段性能最高 偏向锁阶段：当某一个线程多次访问共享资源的时候，JVM 会认为这个线程在将来还会继续访问这个资源，所以使用偏向锁。偏向锁的上锁方式是，修改锁定对象的对象头，标记当前线程的 线程id。这样其他线程就没法儿获取这个锁，只有这个线程可以无竞争的访问资源。 轻量级锁阶段：当某一个线程尝试获取一个已经被偏向锁锁定的对象的时候，就会进入轻量级锁阶段。此时， JVM 会使用 CAS 操作修改对象头的Mark Word 为线程的Lock Record，来尝试获取锁。如果 CAS 操作成功，那么这个线程就获取了锁。 如果 CAS 失败，那么就会进入重量级锁阶段 重量级阶段：当轻量级锁阶段的 CAS 操作失败的时候，会升级为重量级锁。重量级锁意味着线程会进入阻塞状态，等待锁的释放。其他线程在获取重量级锁的时候，需要阻塞等待或进行上下文切换，可能会导致性能下降。如果重量级锁获取失败，会进行自选的操作。 4. AQS了解过吗? AQS (Abstract Queued Synchronizer简称，抽象的队列式同步器), 它其实就是把跟锁相关的操作进行抽象和封装的一个工具类。将排队、入队、加锁、中断这些方法提供出来，方便其他相关JUC 锁的使用，具体的加锁时机、入队时机都需要实现类自己控制。 AQS 通过维护一个共享状态 state 、一个先进先出 FIFO 的等待队列和一个条件队列，来管理线程对共享资源的访问。共享状态 state 用 volatile 修饰，表示当前资源的状态，保证了可见性和有序性。在独占锁中 (ReentrantLock 或者 synchronized), state 为 0 表示未被占用，为1 表示已被占用。假如当前共享资源已经被占用，线程获取资源失败，会被加入到AQS 的等待队列里面。这个队列是一个变体的 CLH 队列， 采用双向链表结构，其节点包含线程的引用、等待状态、前驱节点和后继节点的指针。AQS 的常见实现类有 ReentrantLock、CountDownLatch 、Semaphore 等等 其中，CLH 队列是一种基于链表的、公平的自旋锁算法，主要用于多线程环境中实现锁的公平分配。\n【AQS 工作流程】 公平锁和非公平锁的区别就在于，公平锁是直接放到队里面，不会主动去尝试 CAS 获取锁\n先进先出 FIFO 队列用来实现多线程的排队工作，当线程加锁失败时，就把这个线程封装成一个Node 节点置于队列尾部 当持有锁的线程释放锁的时候，AQS 会将等待队列中第一个线程唤醒，并让它重新尝试获取锁 【同步状态 - state】\nAQS 使用一个volatile int类型的成员变量state来表示同步状态， 当state = 0 的时候表示没有锁，当state = 1 的时候表示当前对象锁已经被占有了。提供了三种API， 分别用于获取状态、设置状态和采用CAS 更新状态\n// 同步状态 private volatile int state; // 获取状态 protected final int getState() { return state; } // 设置状态 protected final void setState(int newState) { state = newState; } // CAS更新状态 protected final boolean compareAndSetState(int expect, int update) { // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update); } 【FIFO队列 - Node】\n上面AQS 工作流程提到的Node 节点如下， Node 节点里面包含waitStatus 用于标记节点状态， thread 线程指针指向当前节点所代表的线程，还有前驱节点和后继结点指针。\n// Node类用于构建队列 static final class Node { // 标记节点状态。常见状态有 CANCELLED（表示线程取消）、SIGNAL（表示后继节点需要运行）、CONDITION（表示节点在条件队列中）等。 volatile int waitStatus; // 前驱节点 volatile Node prev; // 后继节点 volatile Node next; // 节点中的线程，存储线程引用，指向当前节点所代表的线程。 volatile Thread thread; } // 队列头节点，延迟初始化。只在setHead时修改 private transient volatile Node head; // 队列尾节点，延迟初始化。 private transient volatile Node tail; // 入队操作 private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // 必须先初始化 if (compareAndSetHead(new Node())) tail = head; } else { node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } 【同步队列和条件队列】\nAQS 有两种 FIFO 队列，同步队列和条件队列。同步队列用于锁的获取和释放，条件队列用于特定条件下管理线程的等待和唤醒。常用的ReentrantLock 就是基于同步队列实现的。\n同步队列的实现原理：当一个线程尝试获取锁失败的时候，AQS 会将该线程包装成一个 Node 节点加入到队列的尾部。这个节点会处于等待状态，直到所资源被其他线程释放。当锁被释放的时候，持有锁的线程会通知其他后继结点(如果存在的话)，后继结点会尝试获取锁，这个过程一直持续到线程成功获取锁或队列为空\nprivate Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // 尝试快速路径：直接尝试在尾部插入节点 Node pred = tail; if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } // 快速路径失败时，进入完整的入队操作 enq(node); return node; } private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // 队列为空，初始化 if (compareAndSetHead(new Node())) tail = head; } else { node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } 条件队列的实现原理：条件队列主要用于实现条件变量，实现了线程间的协调和通信。允许线程在特定条件不满足的时候挂起，等到其他线程改变了条件并显示的唤醒等待在该条件队列上的线程，典型的条件队列使用场景就是ReentrantLock 的 Condition\npublic class ConditionObject implements Condition, java.io.Serializable { // 条件队列的首尾节点 private transient Node firstWaiter; private transient Node lastWaiter; // ... } // ConditionObject是AQS的一个内部类，用于实现条件变量。条件变量用于线程间通信，允许一个或多个线程在特定条件成立之前等待，同时释放先关的锁。 public final void await() throws InterruptedException { // 如果当前线程在进入此方法之前已经被中断了，则直接抛出InterruptedException异常。 if (Thread.interrupted()) throw new InterruptedException(); // 将当前线程加入到等待队列中。 Node node = addConditionWaiter(); // 释放当前线程所持有的锁，并返回释放前的状态，以便以后可以重新获取到相同数量的锁。 int savedState = fullyRelease(node); // 中断模式，用于记录线程在等待过程中是否被中断。 int interruptMode = 0; // 如果当前节点不在同步队列中，则表示线程应该继续等待。 while (!isOnSyncQueue(node)) { // 阻塞当前线程，直到被唤醒或中断。 LockSupport.park(this); // 检查线程在等待过程中是否被中断，并更新interruptMode状态。 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } // 当节点成功加入到同步队列后，尝试以中断模式获取锁。 // 如果在此过程中线程被中断，且不是在signal之后，则设置中断模式为REINTERRUPT。 if (acquireQueued(node, savedState) \u0026amp;\u0026amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; // 如果节点后面还有等待的节点，从等待队列中清理掉被取消的节点。 if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); // 根据中断模式处理中断。 if (interruptMode != 0) reportInterruptAfterWait(interruptMode); } 当线程调用了Condition 的 await() 方法后，它会释放当前持有的锁，并且该线程会被加入到条件队列中等待。直到被另一个线程的signal() (唤醒等待队列中头节点对应的线程) 或者 signalAll()（唤醒所有等待的线程）方法唤醒或者被中断。\npublic final void signal() { if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first); } private void doSignal(Node first) { do { if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; } while (!transferForSignal(first) \u0026amp;\u0026amp; (first = firstWaiter) != null); } 【ReentrantLock、CountDownLatch、Semaphore 区别】\n对比维度 ReentrantLock CountDownLatch Semaphore 用途 互斥访问共享资源，支持可重入锁 等待多个线程完成操作后触发后续任务 控制同时访问共享资源的线程数量（限流） 同步方式 独占模式（Exclusive） 共享模式（Shared） 共享模式（Shared） 资源管理 通过 state 记录锁重入次数 通过 state 表示剩余需等待的计数 通过 state 表示可用许可证数量 释放机制 需显式调用 unlock() 释放锁 自动触发（countDown() 减至 0） 需显式调用 release() 归还许可 可重用性 可重复加锁/解锁（可重入） 一次性使用（计数归零后不可重置） 可重复获取/释放许可证 线程协作 基于条件变量 Condition 控制 无条件协作，仅等待计数归零 无协作，仅控制并发量 典型场景 替代 synchronized 的显式锁控制 主线程等待子线程初始化完成 数据库连接池、限流场景 【参考材料】\n从ReentrantLock的实现看AQS的原理及应用 【基本功】不可不说的Java“锁”事 5. Java 中 ReentrantLock 的实现原理是什么？ ReentrantLock 是基于 AQS 实现的一个可重入锁，支持公平锁和非公平锁两种方式。\n【ReentrantLock 结构】\n一个 state 变量: 用于表示锁的状态, state = 0 表示没有锁占用，state = 1 表示已经被占用 同步队列：用于锁的获取和释放。对于非公平锁，没有获取到锁的就会被放在这个队列里面。对于公平锁，所有的线程都是直接放到这个队列，依次等待获取锁。 条件队列：用于等待某个条件满足了之后，才让这些线程逐个获取锁。比如指定所有的线程必须在晚上2点开始扫描检查是否存在异常订单的情况，必须要等到晚上2点，这些线程才开始获取锁。 【CLH队列】\nCLH 是一种基于队列的自选锁，它适用于多处理器环境下的高并发场景。原理是通过维护一个隐式队列，让线程在等待锁的时候自旋在本地变量上，从而减少对共享变量的争用和缓存一致性流量。 它将争抢的线程组织成一个队列，通过排队的方式按序争抢锁。每个线程不再CAS 争抢一个变量，而是自选判断排在它前面的线程的状态，如果前面的线程状态为释放锁，那么后续的线程就抢锁。\nCLH 通过排队按序争抢解决了锁饥饿的问题 (锁饥饿就是有的线程长期抢不到锁)，通过 CAS 自选监听前面现成的状态避免总线风暴问题的产生。总线风暴是指短时间内大量并发CAS操作和缓存一致性协议产生的总线流量激增，会导致CPU利用率下降，内存访问延迟增加。 不过, CLH 的自旋期间线程会一直占用CPU资源，只适合锁等待比较短的场景。\n【AQS对CLH进行改造】\n为了防止CLH 自旋期间长期占用CPU资源的问题，AQS将自旋等待前置节点改成了阻塞线程。后续的线程没法儿主动去发现前面的线程是否释放了锁，只能等待前面线程通知后续线程锁被释放了，它采用去争夺锁。所以，AQS 把 CLH 改成了一个双向队列，让前面的线程可以通知后续的线程。如果后面的线程等待超时或者主动取消，则从队列中移除，后面的线程顶上来。\n【ReentrantLock 使用方法】\nReentrantLock 可重入锁：需要通过手动调用 lock() 和 unlock() 方法来获取和释放锁。支持更多高级功能，比如可中断的锁等待、定时锁等待、公平锁等待等\npublic class ReentrantLockDemo { // 构造时传入true表示使用公平锁 private final ReentrantLock lock = new ReentrantLock(true); // 可中断锁等待示例 public void interruptibleLockMethod() throws InterruptedException { lock.lockInterruptibly(); // 可中断等待 try { // 临界区代码 System.out.println(\u0026#34;获取锁成功（可中断等待）\u0026#34;); } finally { lock.unlock(); } } // 定时锁等待示例 public void timedLockMethod() throws InterruptedException { if (lock.tryLock(5, TimeUnit.SECONDS)) { // 等待5秒 try { // 临界区代码 System.out.println(\u0026#34;在规定时间内获取到锁\u0026#34;); } finally { lock.unlock(); } } else { System.out.println(\u0026#34;未在规定时间内获取到锁\u0026#34;); } } public static void main(String[] args) { ReentrantLockDemo demo = new ReentrantLockDemo(); Thread t1 = new Thread(() -\u0026gt; { try { demo.interruptibleLockMethod(); } catch (InterruptedException e) { System.out.println(\u0026#34;线程1等待时被中断\u0026#34;); } }); Thread t2 = new Thread(() -\u0026gt; { try { demo.timedLockMethod(); } catch (InterruptedException e) { System.out.println(\u0026#34;线程2等待时被中断\u0026#34;); } }); t1.start(); t2.start(); // 可根据需要中断线程 t1.interrupt(); } } 6. 什么是 Java 的 CAS（Compare-And-Swap）操作？ CAS 是一种硬件级别的原子操作，用于实现无锁并发编程，使用比较和交换的方式确保线程安全。CAS 的作用就是保证无锁并发，而且CAS操作是原子的，保证了线程安全。\n【CAS过程】\n比较：CAS 在每次操作之前，会先检查内存当中的某个值是否与预期值相等 交换：如果发现同预期值相同，则将内存中的值更新为新值 自旋重试：如果发现和预期值不相同，说明其他线程已经修改了该值。它会在一定次数内，不断获取最新的内存值，更新预期值，然后再次尝试 CAS 操作。 【CAS存在的问题】\nABA问题：CAS 操作中，如果一个变量值被其他线程从A变成B，然后又变回A. CAS 无法检测到这种变化，可能会导致错误。 自旋开销：CAS 操作通常是通过自旋完成的，可能会导致CPU资源浪费，尤其是在高并发的情况下。 单变量控制：CAS 操作只适用单个变量的更新，不能涉及多个变量的复杂操作。 总线风暴：如果CAS修改同一个变量的并发很高，可能会导致总线风暴。 【总线风暴】\n总线风暴是指短时间内大量并发CAS操作和缓存一致性协议产生的总线流量激增，会导致CPU利用率下降，内存访问延迟增加。因为lock 前缀指令会把写缓冲区的所有数据立即刷新到主内存中，在对称多处理架构下，每个CPU都会通过嗅探总线来检查自己的缓存是否过期。如果某个CPU刷新自己的数据到驻村，就会通过总线通知其他CPU过期对应的缓存，实现内存屏障，保证一致性。 通过总线来回通信成为Cache 一致性流量，如果这个流量过大，总线就会成为瓶颈，导致本地缓存更新延迟。 所以，如果 CAS 修改同一个变量并发很高，就会导致总线风暴，出现性能瓶颈。\n7. 什么是 Java 中的 ABA 问题？ ABA 问题是指多线程环境下，某个变量的值在一顿时间内经历了从 A 到 B 再到 A 的变化，这种变化可能会被CAS 判定为值没有变化，从而导致线程发生错误的判断和操作。\n【ABA线程示例】\n下面的代码当中，如果线程A读取了oldHead， 此时另外一个线程B修改了栈的内容，然后将 oldHead 移除 (将栈顶元素从A 变成 B ， 再变成A)， 当线程A再次执行 compareAndSet 函数的时候，尽管值是一样的(oldHead没有变化)，但实际上栈的状态已经被修改过，可能导致数据不一致的问题。\npublic class LockFreeStack\u0026lt;T\u0026gt; { private AtomicReference\u0026lt;Node\u0026lt;T\u0026gt;\u0026gt; head = new AtomicReference\u0026lt;\u0026gt;(); public T pop() { Node\u0026lt;T\u0026gt; oldHead; Node\u0026lt;T\u0026gt; newHead; do { oldHead = head.get(); if (oldHead == null) { return null; } newHead = oldHead.next; } while (!head.compareAndSet(oldHead, newHead)); return oldHead.value; } } 【解决ABA问题的办法】\n引入版本号：在每次更新一个变量的时候，不仅更新变量的值，还更新一个版本号。CAS 操作在比较的时候，除了比较值是否一致，还比较版本号是否匹配。Java 当中的 AtomicStampReference 提供了版本号机制来避免 ABA 问题。每次更新stampedRef 的时候，都会一起更新对应的版本号\nAtomicStampedReference\u0026lt;Integer\u0026gt; stampedRef = new AtomicStampedReference\u0026lt;\u0026gt;(1, 0); int[] stampHolder = new int[1]; Integer ref = stampedRef.get(stampHolder); 使用AtomicMarkableReference：在变量的引用上标记一个布尔值，用来区分是否发生了特定的变化。不使用版本号，直接用标记位来追踪状态的变化。\nAtomicMarkableReference\u0026lt;Integer\u0026gt; markableRef = new AtomicMarkableReference\u0026lt;\u0026gt;(1, false); 8. 你了解 Java 线程池的原理吗？ 线程池是用来管理线程的资源池，当需要用线程的时候，直接从线程池里面取就可以了。使用完线程之后，不会立即销毁，而是等待下一个任务。\n【为什么要使用线程池】\n减少资源的消耗：通过重复利用已经创建的线程，避免重复创建线程和销毁线程造成的消耗 提高响应速度 避免线程抢占过多资源：如果线程频繁创建系统资源，会降低系统的稳定性。而且使用线程池进行统一分配、调优和监控。 【如何创建线程池】\n通过 ThreadPoolExecutor 构造函数创建\n// ThreadPoolExecutor 构造函数 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); } // 用ThreadPoolExecutor创建看对象 ThreadPoolExecutor executor = new ThreadPoolExecutor( 2, // corePoolSize 核心线程数，即使空闲也不会被回收 5, // maximumPoolSize 最大线程数，当任务队列满时会创建新线程，但不能超过此值。 60L, TimeUnit.SECONDS, // keepAliveTime 非核心线程的空闲存活时间(单位由unit参数指定) new LinkedBlockingQueue\u0026lt;\u0026gt;(10), // 任务队列 (如LinkedBlockingQueue/ArrayBlockingQueue) Executors.defaultThreadFactory(), // 线程工厂（可设置线程名称、优先级等） new ThreadPoolExecutor.CallerRunsPolicy() // 拒绝策略(如 AbortPolicy 抛出异常，CallerRunsPolicy 由提交线程执行任务) ); 通过 Executor 框架的工具类 Executors 来创建\nExecutor 当中包含五种不同的线程池\n线程池类型 特性 固定大小线程池 FixedThreadPool 固定线程数量的线程池。核心线程数量和最大线程数量是一致的。有新任务提交并且有空闲线程就立即执行，否则存放到请求队列当中 单线程线程池 SingleThreadExecutor 只有一个线程的线程池。如果线程执行发生异常，线程池会重新创建一个线程来执行后续的任务。适合用于保证任务按照提交顺序执行 可缓存线程池 CachedThreadPool 根据实际情况调整线程数量的线程池，优先使用可复用的线程。如果当前线程不够用，会创建新的线程，最多创建的个数是int 最大值 定时任务线程池 ScheduledThreadPool 在一定时间后，或者定时去执行任务的线程池 单线程定时任务线程池 SingleThreadScheduled 和定时任务线程池基本一样，相当于定时任务线程池里面只有一个线程 【注意】 一般不推荐使用 Executors 去创建线程，而是使用ThreadPoolExecutor 的方式创建，避免资源耗尽的风险。\n【Executors 的弊端】\n固定大小线程池 FiexedThreadPool 和 SingleThreadPool：允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM 内存不足 可缓存线程池 CachedThreadPool 和 定时任务线程池 ScheduledThreadPool： 允许创建线程的数量为 Integer.MAX_VALUE， 可能会创建大量线程，从而导致 OOM 内存不足 定时任务线程池 ScheduledThreadPool 和 单线程定时任务线程池 SingleScheduledThreadPool : 使用的无界的延迟阻塞队列 DelayedWorkQueue 用来存放后续的线程，任务队列的最大长度为 Integer.MAX_VALUE， 可能会堆积大量的请求，从而导致 OOM 内存不足 // 固定大小线程池 newFixedThreadPool ExecutorService executor = Executors.newFixedThreadPool(5); // 核心线程数=最大线程数=5 // 单线程线程池 newSingleThreadExecutor ExecutorService executor = Executors.newSingleThreadExecutor(); // 可缓存线程池 newCachedThreadPool ExecutorService executor = Executors.newCachedThreadPool(); // 定时任务线程池 newScheduledThreadPool ScheduledExecutorService executor = Executors.newScheduledThreadPool(3); // 延迟执行 executor.schedule(() -\u0026gt; System.out.println(\u0026#34;Delayed Task\u0026#34;), 3, TimeUnit.SECONDS); // 周期性执行 executor.scheduleAtFixedRate(() -\u0026gt; System.out.println(\u0026#34;Periodic Task\u0026#34;), 1, 5, TimeUnit.SECONDS); 【线程池的主要参数】\n线程池的主要参数有 7 个，分别是核心线程池大小 corePoolSize、 最大线程池大小 maximumPoolSize、线程存活时间和它的单位、存放执行任务的阻塞队列 workQueue、线程工厂 threadFactory 、拒绝策略 handler\n参数名称 类型 特性 核心线程池大小 corePoolSize int 线程池核心线程数量。默认情况下，线程池中的线程数量 \u0026lt;= 核心线程数量 coolPoolSize，即使线程是空闲状态，都不会删除的线程。 最大线程池大小 maximumPoolSize int 线程池最多可以容纳的线程数量。如果阻塞队列已经满了，但是当前线程数 \u0026lt; 最大线程池大小 maximumPoolSize，则会继续创建线程。如果大于等于，就执行拒绝策略。 线程存活时间 keepAliveTime long 线程池中大于核心线程 corePoolSize 的其他 非核心线程 处于空闲状态下的存活时间。超过该时间就会被回收销毁 存活时间单位 unit TimeUnit 线程存活时间的单位 阻塞队列 workQueue BlockingQueue\u0026lt;Runnable\u0026gt; 阻塞工作队列，没有空闲的线程可以执行的时候，新的任务会被放在阻塞队列里面 线程工厂 threadFactory ThreadFactory Executor 创建新线程的时候会用到，可以给线程取名字 拒绝策略 handler RejectedExecutionHandler 拒绝策略 public ThreadPoolExecutor(int corePoolSize, // 核心线程池大小 int maximumPoolSize, // 最大线程池大小 long keepAliveTime, // 线程存活时间 TimeUnit unit, // 时间单位（如秒、毫秒等） BlockingQueue\u0026lt;Runnable\u0026gt; workQueue,//用于存放待执行任务的阻塞队列 ThreadFactory threadFactory, // 线程工厂，用于创建新线程 RejectedExecutionHandler handler) { // 拒绝策略处理器 if (corePoolSize \u0026lt; 0 || // 核心线程池大小必须大于或等于0 maximumPoolSize \u0026lt;= 0 || // 最大线程池大小必须大于0 maximumPoolSize \u0026lt; corePoolSize || // 最大线程池大小不能小于核心线程池大小 keepAliveTime \u0026lt; 0) // 线程存活时间不能小于0 throw new IllegalArgumentException(); // 参数不合法，抛出异常 if (workQueue == null || threadFactory == null || handler == null) // 参数不能为空 throw new NullPointerException(); // 参数为空，抛出空指针异常 this.corePoolSize = corePoolSize; // 设置核心线程池大小 this.maximumPoolSize = maximumPoolSize; // 设置最大线程池大小 this.workQueue = workQueue; // 设置任务队列 this.keepAliveTime = unit.toNanos(keepAliveTime); // 将线程存活时间转换为纳秒 this.threadFactory = threadFactory; // 设置线程工厂 this.handler = handler; // 设置拒绝策略处理器 } 【线程池的工作原理】\n线程池的工作原理， 可以理解为去银行办业务。具体的工作流程如下：\n当前线程提交任务 （准备去存钱） 判断线程池是否还在运行，如果没有直接调用拒绝策略 （银行柜台今天都没人， 快滚） 如果线程池还在运行，则判断已有线程数是否小于核心线程数，如果小于核心线程数，添加工作线程直接执行 （有空闲的柜台小姐姐，可以帮忙办理业务） 如果已有线程数大于等于核心线程数，则判断阻塞队列是否满了，如果没满，将其放入阻塞队列当中。（柜姐忙不过来了，先去排队等着） 如果阻塞队列已经满了，则判断当前线程数是否超过了最大线程数。如果没有，则创建新的线程。（排队的人太多了，已经排不下了。多开一个柜台，分配一个柜姐去办理业务） 如果超过了最大线程数，直接根据拒绝策略进行处理。（已经没有多的柜姐了，只能让他滚蛋了） 【核心线程支持被回收吗？】\n如果线程池用于周期性使用、频率不高（周期间有明显空闲时间）的场景，可以将 allowCoreThreadTimeOut (boolean value) 方法参数设为 true， 回收空闲的核心线程 (时间间隔还是由 keepAliveTime 指定)\npublic void allowCoreThreadTimeOut(boolean value) { if (value \u0026amp;\u0026amp; keepAliveTime \u0026lt;= 0) // 检查存活是否合法 throw new IllegalArgumentException(\u0026#34;Core threads must have nonzero keep alive times\u0026#34;); if (value != allowCoreThreadTimeOut) { allowCoreThreadTimeOut = value; if (value) interruptIdleWorkers(); } } 【线程池满了，有哪些拒绝策略?】\n策略名称 特性 终止策略 AbortPolicy (默认) 抛出异常 RejectExecutionException 来拒绝新任务的处理 调用者运行策略 CallerRunsPolicy 让调用线程池的execute方法的线程，自己执行任务。如果调用的线程已经被关闭，则丢弃该任务。这种策略会降低新任务的提交速度，影响整体的性能。如果在承受延迟的范围内，所有任务都可以正常执行，可以选择该策略 丢弃策略DiscardPolicy 不处理新任务，直接丢弃 最早未处理丢弃策略DiscardOldestPolicy 丢弃最早没有被处理的任务请求 【调用者运行策略 CallerRunsPolicy 有什么风险？如何解决？】\n如果采用 CallerRunsPolicy 策略的任务执行时间比较长，并且处理提交任务的是主进程。可能会阻塞主进程处理其他的任务，影响程序正常运行。\n【解决方案】\n**尽量避免调用拒绝策略 **（利用服务器资源）\n调大 maximumPoolSize 最大线程参数，多添加一些线程，充分利用 CPU。提高任务的处理速度，避免在 阻塞队列BlockingQueue 的任务过多导致内存用完 增加阻塞队列 BlockingQueue 的大小并调整堆内存（新增的数据，放在堆内存），容纳更多的任务 如果服务器资源有限，需要保证任务不被丢弃\n实现 RejectExecutionHandler 接口自定义拒绝策略，当线程池的阻塞队列满了知乎，将没法儿处理的任务存储到 MySQL 数据库里面 实现一个继承阻塞队列 BlockingQueue 的混合队列，该队列结合 ArrayBlockingQueue 和数据库。重写 take() 方法，会优先从数据库读取最高的任务，如果没有，则从 ArrayBlockingQueue 中取任务 【线程池常用的阻塞队列有哪些？】\n阻塞队列名称 特性 绑定的线程池类 有界阻塞队列 LinkedBlockingQueue 底层由链表实现，容量为 int 的最大值 FixedThreadPool、SinglThreadExecutor **同步队列 SynchronousQueue ** 保证对于提交的任务，如果有空闲线程，就用空闲线程处理。否则新建线程来处理任务 CachedThreadPool 延迟队列 DelayedWorkQueue 任务按照延迟时间长短进行排序，不按照原来的放入顺序进行排序。内部采用 “堆” 的数据结构，确保每次出队任务是当前队列汇总执行时间最靠前的 ScheduledThreadPool、SingleScheduledThreadPool 有界阻塞队列 ArrayBlockingQueue 底层由数组实现，容量一旦创建就不能修改 【线程池的参数一般如何设置？】\n线程池的参数可以根据任务的类型来区分，可以分为两种不同的情况，分别为 CPU 密集型和 I/O 密集型\nCPU 密集型：corePoolSize = CPU 核心数目 + 1\n这一类的任务消耗的主要是 CPU 资源，比 CPU 核心数多的一个线程，用来防止进程因为中断而被暂停（比如说缺页中断）\nI/O 密集型：corePoolSize = CPU 核心数目 * 2\n这一类的任务，系统大部分时间在处理 I/O 交互， 线程处理 I/O 的时候，不占 CPU 资源。所以，可以把CPU 让给其他线程。最极端的情况就是有 CPU 核心数目这么多的线程在处理 I/O， 刚好 CPU 全部空出来了。\n【注意】 如果线程数目设置的过多，会增加上下文切换的成本。上下文切换就是当线程的时间片用完了重新处于就绪状态，把CPU让给其他线程，这个过程就是一次上下文切换。\n【线程池的 shutdown() 和 showdownNow() 的作用和区别】\nshutdown()：设置状态为shutdown，让正在执行的任务继续执行，还没有执行的任务中断。此时不能往线程池中添加任务，否则抛出RejectedExecutionException 异常。\npublic void shutdown() { // 获取线程池的主锁（ReentrantLock），用于同步关闭操作 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 加锁，防止并发修改线程池状态 try { // 1. 检查是否有权限关闭线程池（例如安全管理器限制） checkShutdownAccess(); // 2. 将线程池状态推进到 SHUTDOWN，阻止新任务提交（但允许处理队列中的任务） advanceRunState(SHUTDOWN); // 3. 中断所有空闲的工作线程（正在等待任务的线程） interruptIdleWorkers(); // 4. 调用钩子方法，供子类扩展（如 ScheduledThreadPoolExecutor 取消延迟任务） onShutdown(); // hook for ScheduledThreadPoolExecutor } finally { mainLock.unlock(); // 释放锁 } // 5. 尝试终止线程池（若队列为空且没有活动线程） tryTerminate(); } shutdownNow()：返回哪些还没有被执行的任务，然后尝试终止线程。尝试终止线程是调用 Thread.interrupt() 方法来实现的。shutdownNow() 不代表线程池一定立即退出，可能要等所有正在执行的任务完成之后才退出。\npublic List\u0026lt;Runnable\u0026gt; shutdownNow() { List\u0026lt;Runnable\u0026gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { checkShutdownAccess(); advanceRunState(STOP); interruptWorkers(); tasks = drainQueue(); } finally { mainLock.unlock(); } tryTerminate(); return tasks; } 【线程池当中的线程执行异常之后，销毁还是复用？】\n此处需要分成两种提交任务的方式来区分，分别是 execute() 和 submit() 方式\n使用 execute() 提交任务，新线程替换老线程：当任务通过 execute() 提交到线程池并且在执行过程中，抛出异常的时候。如果异常没有在任务当中进行try-catch，会导致当前线程终止。异常会打印在控制台或者日志文件里面。线程池检测到线程终止之后，会创建新线程替换原来的线程，维持配置的线程数不变。 使用 submit() 提交任务，线程不终止：如果在任务执行的过程中发生异常，不会终止当前的线程，也不会直接打印异常。异常会被封装在 submit() 返回的Future 对象里面。调用 Future.get() 可以看到 ExecutionException。此时线程不会因为异常而终止，还在线程池里面，准备执行后续任务。 【如何给线程命名？】\n借助 guava 中的 ThreadFactoryBuilder\npublic class ThreadFactoryBuilderDemo { static final String threadNamePrefix = \u0026#34;test-thread-name-prefix:\u0026#34;; public static void main(String[] args) { ThreadFactory threadFactory = new ThreadFactoryBuilder() .setNameFormat(threadNamePrefix + \u0026#34;---- SwimmingLiu\u0026#34;) .setDaemon(true) .build(); ThreadPoolExecutor poolExecutor = new ThreadPoolExecutor( 1, 2, 60, TimeUnit.SECONDS, new ArrayBlockingQueue\u0026lt;\u0026gt;(1), threadFactory); Runnable target = () -\u0026gt; { String name = Thread.currentThread().getName(); System.out.println(name); }; poolExecutor.execute(target); poolExecutor.execute(target); poolExecutor.shutdown(); /* 输出: test-thread-name-prefix:---- SwimmingLiu test-thread-name-prefix:---- SwimmingLiu */ } } 自定义实现 ThreadFactory 接口\n// 线程工厂，它设置线程名称，有利于我们定位问题。 public final class NamingThreadFactory implements ThreadFactory { private final AtomicInteger threadNum = new AtomicInteger(); private final String name; // 创建一个带名字的线程池生产工厂 public NamingThreadFactory(String name) { this.name = name; } @Override public Thread newThread(Runnable r) { Thread t = new Thread(r); t.setName(name + \u0026#34; [#\u0026#34; + threadNum.incrementAndGet() + \u0026#34;]\u0026#34;); return t; } } 【如何用两个线程按照顺序打印奇数和偶数】\npublic class PrintOddorEven { // 两个线程按照顺序打印奇数和偶数 private static final Object lock = new Object(); // synchronized锁对象 private static int count = 1; private static final int MAX_COUNT = 10; public static void main(String[] args) { Runnable printOdd = () -\u0026gt; { synchronized (lock) { while (count \u0026lt;= MAX_COUNT) { if (count % 2 != 0) { System.out.println(Thread.currentThread().getName() + \u0026#34;:\u0026#34; + count ++); lock.notify(); } else { try { lock.wait(); } catch (Exception error) { error.printStackTrace(); } } } } }; Runnable printEven = () -\u0026gt; { synchronized (lock) { while (count \u0026lt;= MAX_COUNT) { if (count % 2 == 0) { System.out.println(Thread.currentThread().getName() + \u0026#34;:\u0026#34; + count ++); lock.notify(); } else { try { lock.wait(); } catch (Exception error) { error.printStackTrace(); } } } } }; Thread printOddThread = new Thread(printOdd, \u0026#34;printOdd\u0026#34;); Thread printEvenThread = new Thread(printEven, \u0026#34;printEven\u0026#34;); printOddThread.start(); printEvenThread.start(); } } 9. 你使用过哪些 Java 并发工具类？ 面试官，您好。我使用过 ConcurrentHashMap、BlockingQueue、CountdownLatch、AtomicInteger、Semaphore 、CyclicBarrier 这些工具类。\n【 CountDownLatch 】\nCountDownLatch 是 JUC 包中的一个同步工具类，用来协调多个线程之间的同步。允许一个或者多个线程等待，直到其他线程中执行的一组操作完成。一般适用于主线成需要等待多个子线程完成任务的场景。CountDownLatch 是通过一个计数器实现的，该计数器最开始记录需要等待的线程的总个数，由线程来进行递减，直至为 0\n// 王者荣耀，等待五位英雄加载完成之后，才能开始游戏 // countDownLatch.countDown(); 就相当于 notify() // countDownLatch.await(); 就相当于 wait() // new CountDownLatch(int count), 创建一个带有给定计数器的 CountDownLatch public static void main(String[] args) throws InterruptedException { CountDownLatch countDownLatch = new CountDownLatch(5); Thread daqiao = new Thread(() -\u0026gt; { System.out.println(\u0026#34;大乔已就位！\u0026#34;); countDownLatch.countDown(); // 释放信号 }); Thread lanlingwang = new Thread(() -\u0026gt; { System.out.println(\u0026#34;兰陵王已就位！\u0026#34;); countDownLatch.countDown(); }); Thread anqila = new Thread(() -\u0026gt; { System.out.println(\u0026#34;安其拉已就位！\u0026#34;); countDownLatch.countDown(); }); Thread nezha = new Thread(() -\u0026gt; { System.out.println(\u0026#34;哪吒已就位！\u0026#34;); countDownLatch.countDown(); }); Thread kai = new Thread(() -\u0026gt; { System.out.println(\u0026#34;铠已就位！\u0026#34;); countDownLatch.countDown(); }); daqiao.start(); lanlingwang.start(); anqila.start(); nezha.start(); kai.start(); countDownLatch.await(); //等待信号 System.out.println(\u0026#34;全员就位，开始游戏！\u0026#34;); } 【场景题】 假如要查10万多条数据，用线程池分成20个线程去执行，怎么做到等所有的线程都查找完之后，即最后一条结果查找结束了，才输出结果。\npublic class CountDownLatchTest { private static int count = 100000; private static final int THREAD_TOTAL_NUMS = 20; private static final int BATCH_SIZE = count / THREAD_TOTAL_NUMS; @Test public void test() throws InterruptedException { CountDownLatch latch = new CountDownLatch(THREAD_TOTAL_NUMS); ExecutorService executor = Executors.newFixedThreadPool(THREAD_TOTAL_NUMS); ConcurrentLinkedQueue\u0026lt;String\u0026gt; results = new ConcurrentLinkedQueue\u0026lt;\u0026gt;(); // 存放查询结果 for (int i = 0; i \u0026lt; THREAD_TOTAL_NUMS; i++) { int start = i * BATCH_SIZE; int end = (i == THREAD_TOTAL_NUMS - 1) ? count : (start + BATCH_SIZE); executor.submit(() -\u0026gt; { try { for (int k = start; k \u0026lt; end; k++) { results.add(\u0026#34;Data - \u0026#34; + k); } System.out.println(Thread.currentThread().getName() + \u0026#34;已处理数据：[\u0026#34; + start + \u0026#34;, \u0026#34; + (end - 1) + \u0026#34;]\u0026#34;); } finally { latch.countDown(); } }); } latch.await(); executor.shutdown(); System.out.println(\u0026#34;查询完毕，查询结果的总数：\u0026#34; + results.size()); } } 【 CyclicBarrier 】\nCyclicBarrier 就是可循环使用的屏障，主要用于让一组线程到达一个屏障（或者叫同步点）的时候，阻塞这部分线程。直到最后一个线程到达屏障，屏障才会开门，所有被屏障拦截的线程才会继续运行。 CyclicBarrier 和 CountDownLatch 很相似，都可以协调多线程的结束动作。\nimport java.util.concurrent.BrokenBarrierException; import java.util.concurrent.CyclicBarrier; public class CyclicBarrierDemo { final static int threadCount = 3; static CyclicBarrier barrier = new CyclicBarrier(threadCount, () -\u0026gt; System.out.println(\u0026#34;所有线程都抵达该屏障，执行后续....\u0026#34;)); public static void main(String[] args) { for (int i = 0; i \u0026lt; threadCount; i++) { new T(barrier).start(); } /*输出: Thread-2 正在执行任务... Thread-1 正在执行任务... Thread-0 正在执行任务... Thread-0 到达屏障 Thread-1 到达屏障 Thread-2 到达屏障 所有线程都抵达该屏障，执行后续.... */ } } class T extends Thread { private CyclicBarrier barrier; public T(CyclicBarrier barrier) { this.barrier = barrier; } @Override public void run() { System.out.println(Thread.currentThread().getName() + \u0026#34; 正在执行任务...\u0026#34;); try { Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + \u0026#34; 到达屏障\u0026#34;); this.barrier.await(); // 等待其他线程 } catch (InterruptedException | BrokenBarrierException e) { throw new RuntimeException(e); } } } 【 CountDownLatch 和 CyclicBarrier 区别】\n使用次数：CountDownLatch 是一次性的（达到条件就结束了），CyclicBarrier 是可以重复利用的，可以设置多个屏障 （多个结束条件） 是否能够等待其他线程：CountDownLatch 中的各个子线程都不会等待其他线程，只能完成自己的任务。 CyclicBarrier 的各个线程可以等待其他线程 特性 CountDownLatch CyclicBarrier 使用次数 一次性的，不同的线程在同一个计数器上工作，直到计数器为 0 可重复利用，每个线程都会等待其他线程完成任务，然后拆除对应的屏障 面向对象 任务数 线程数 （所有线程都完成任务，拆除屏障） 定义方式 指定任务数，这部分任务由哪些线程完成无所谓 指定需要参与协作的线程数，这些线程必须调用await() 结束条件 计数器为 0 ，就直接结束了 所有线程完成任务之后，可以重复利用 出现异常 某个线程出现问题，其他线程不受影响 某个线程出现问题（中断、超时），则处于await() 的线程会出问题 【Semaphore 信号量】\nSemaphore 信号量是用来控制同时访问t特定资源的线程量，通过协调各个线程，保证合理的使用公共资源。Semaphore 的常规用途是用作流量控制，比如说连接数据库的线程数量, 数据库连接数量是需要控制的。 假如有一个需求，需要读取 10w 个文件，然后存入数据库当中。因为大部分都是 I/O 操作，属于 I/O 密集型，可以采用多线程进行操作。但是，数据库的连接数量是有限的（假如是 10 个），所以必须要控制只有 10 个线程来连接数据库。这个时候，就需要用Semaphore 信号量来控制流量。\n// 下面设置的线程是30个，但是只允许10个线程并发执行。使用Semaphore当中的acquire和release来进行控制。 public class SemaphoreTest { private static final int THREAD_COUNT = 30; private static ExecutorService threadPool = Executors.newFixedThreadPool(THREAD_COUNT); private static Semaphore s = new Semaphore(10); public static void main(String[] args) { for (int i = 0; i \u0026lt; THREAD_COUNT; i++) { threadPool.execute(new Runnable() { @Override public void run() { try { s.acquire(); System.out.println(\u0026#34;save data\u0026#34;); s.release(); } catch (InterruptedException e) { } } }); } threadPool.shutdown(); } } 10. Synchronized 和 ReentrantLock 有什么区别？ 特性 Synchronized ReentrantLock 实现机制 Java内置的关键字，依赖 JVM 实现基本的同步机制, 基于监管器 Monitor （重量级） 和 对象头（偏向锁和轻量级锁）实现 JUC 类库提供的，基于 AQS （ AbstactQueuedSynchronizer ）抽象队列同步器实现 加锁/解锁 JVM 自动对代码块/方法进行加锁和释放锁 显示锁机制，需要通过 lock() 和 unlock() 手动管理锁的获取和释放 是否可重入 可重入 可重入 灵活性 不太灵活，只支持非公平锁，不支持设置超时时间、不支持中断，以及多条件判断。 比较灵活，支持公平锁和非公平锁，支持设置超时时间（避免死锁），可以中断，支持多条件判断 【Java 当中常用的锁有哪些？】\nsynchronized 同步锁：修饰方法或者代码块。线程进入synchronized 修饰的方法或者代码块的时候，会获取关联对象的锁 (一般会有一个 Object 类型的锁对象)。当线程退出该代码块或者方法的时候，锁会被释放。其他线程尝试获取同一个对象的锁，会被阻塞知道锁被释放。\nReentrantLock 可重入锁：需要通过手动调用 lock() 和 unlock() 方法来获取和释放锁。支持更多高级功能，比如可中断的锁等待、定时锁等待、公平锁等待等\nReadWriteLock 读写锁：允许多个读取线程同时访问共享资源，但是只允许一个写入者。读写锁一般用于读多写少的场景，可以提高并发性\n乐观锁和悲观锁\n乐观锁：通常不会锁定资源，只有在更新数据的时候，检查数据是否被其他线程修改。一般通常使用版本号和时间戳来实现 （ CAS 就是乐观锁）\n悲观锁：在访问数据前就锁定资源，就假设会出现最坏的情况，也就是数据可能被其他线程修改。 synchronized 和 ReentrantLock 都是悲观锁\n11. Java 中 volatile 关键字的作用是什么？ volatile 关键字可以保证变量的可见性和有序性，也就是保证线程对变量的修改是可见的，并且禁止指令重排序优化。当变量被声明为 volatile， 则指示 JVM 这个变量是共享且异变的，每次使用它的时候，需要从主存房中进行获取最新的变量值。\n可见性：当某个线程修改了 volatile 变量的值，新值会立即被刷新到主内存。其他线程在读取该变量的时候，可以获取最新的值。这样可以避免线程间由于缓存一致性问题导致读取到旧值的现象。（因为每个线程内部的栈帧会记录主内存中的读取的） 有序性（禁止指令重排序）: volatile 通过内存屏障来禁止特定情况下的指令重排序 （写屏障和读屏障），从而保证程序的执行顺序符合预期。对 volatile 变量的写操作会再前面加插入一个 StoreStore 写屏障，对 volatile 变量的读操作，则会在变量的后面插入一个 LoadLoad 读屏障。确保在多线程环境下，某些代码块的执行顺序的可预测性。 【volatile 关键字如何实现禁止指令重排序？】\n在主存当中，主要通过内存屏障类禁止特定类型的指令重新排序。(写前读后，volatile 禁止重排)\n写-写屏障 (Write-Write)：对 volatile 变量进行写操作之前，会插入一个写屏障。确保在该变量写操作之前的所有普通写操作都完成了。 读-写屏障 (Read-Write)：对 volatile 变量执行读操作之后，会插入一个读屏障。确保了对 volatile 变量的读操作后的普通读操作，不会提前到 volatile 读之前，确保读到最新的数据。 写-读屏障 (Write-Read) ：写-读屏障是最重要的屏障，这个屏障可以确保 volatile 写操作之前的内存操作 （包括写操作） 不会重排序到 volatile 读操作后，并且 volatile 读后的内存操作（包括读操作）不会重排序到volatile 写操作之前 【注意】 为了性能优化，JMM Java内存模型在不改变正确语义的情况下，允许编译器和处理器对指令序列进行重排序。\n【volatile 和 synchronized 区别】\nsynchronized ：synchronized 是排他性同步机制，确保多线程访问共享资源时的互斥性，同一时刻只允许一个线程访问。通过在代码块或者方法上，添加该关键字实现同步。可以确保原子性 volatile ：volatile 是轻量级同步机制，保证变量可见性和有序性 (禁止指令重排序)。变量声明成 volatile 的时候，线程读该变量的时候，直接从主内存当中读取，不使用工作内存当中的缓存。写操作立即刷回主内存，不缓存在本地内存 【volatile 应用场景】\n用于指示发生一个重要的一次性事件，比如完成了初始化或者请求停机\nvolatile boolean shutdownRequested; public void shutdown() { shutdownRequested = true; } public void doWork() { while(!shutdownRequested) { // 执行任务 } } volatile bean 模式：JavaBean 中的所有数据成员都是 volatile 类型的，并且 getter 和 setter 方法，除了获取或者设置相应的属性之外，不能包含任何逻辑。对于引用的数据成员，引用的对象必须是有效且不可变的。\npublic class Person { private volatile String firstName; private volatile String lastName; private volatile int age; public String getFirstName() { return firstName; } public String getLastName() { return lastName; } public int getAge() { return age; } public void setFirstName(String firstName) { this.firstName = firstName; } public void setLastName(String lastName) { this.lastName = lastName; } public void setAge(int age) { this.age = age; } } 写锁策略：通过内部锁和 volatile 变量减少公共代码路径的开销。计算器使用 synchronized 保证增量操作的原子性，并用 volatile 确保结果的可见性。如果更新不频繁，该方法性能更优。因为读操作只涉及 volatile 读取，比无竞争的锁获取开销还要小\n@ThreadSafe // 标识该类是线程安全的，需通过同步机制保证多线程访问的正确性 public class CheesyCounter { // 使用 volatile 保证可见性，但复合操作（如 value++）仍需同步 @GuardedBy(\u0026#34;this\u0026#34;) // 该字段受对象内部锁（this）保护，写操作必须持有锁 private volatile int value; // 读操作未加锁，依赖 volatile 的可见性保证 public int getValue() { return value; // volatile 保证读取最新值，但多线程下需注意\u0026#34;先验条件\u0026#34;的线程安全问题 } // 写操作通过 synchronized 保证原子性和可见性 public synchronized int increment() { return value++; // 同步锁确保复合操作（读-改-写）的原子性 } } 12. 请你讲讲ThreadLocal有什么问题？ ThreadLocal 参考材料\n正常的情况下面，使用 ThreadLocal 一般不会出现问题。但是在极端的情况下，比如数据比较多的时候，可能会出现下面的问题：\n内存泄露问题 ：ThreadLocal 的生命周期和线程的生命周期绑定，如果线程没有结束的话， ThreadLocal 就不会被释放。因为线程池中的线程可能被复用，如果 ThreadLocal 中的值不会自动清理，可能会发生内存泄露。 【注意】内存泄漏（Memory Leak）是指程序中已动态分配的内存未被正确释放，导致这部分内存无法被回收，长期占用系统资源的现象\n哈希冲突的处理方式，效率低：ThreadLocal 中的 ThreadLocalMap Hash冲突用的是线性探测法 (找到slotToExpunge ，然后逐个向前遍历找到合适的位置)。如果冲突的次数比较多，需要遍历的次数就很多了。另外，后面再次 get 查找该元素的时候，Hash命中之后，仍然需要向后遍历来找到对应的元素。优化方式是像 HashMap 一样改成数组 + 链表 + 红黑树 主动清理 key 为 null 的开销：ThreadLocal 需要主动清理 Entry 的 key 为空的对象，会带来一定的开销。因为 ThreadLocal 使用了弱引用来保证资源可以被释放，但是可能会产生一些 Entry 的 key 为 null，也就是无用的 Entry 存在。需要在使用 set 和 get 方法的时候，ThreadLocal 会清理掉无用的 Entry， 减轻内存泄露的发生。如果需要清理的Entry 对象很多，可能会导致 get 和 set 操作相对比较慢。\n13. 为什么 Java 中的 ThreadLocal 对 key 的引用为弱引用？ ThreadLocal 对 key 的引用采用弱引用可以防止内存泄露。如果 ThreadLocal 实例被不再需要的线程持有为强引用，即便线程结束之后，相关的 ThreadLocal 实例及其对应的数据可能无法被回收，可能导致内存持续占用。弱引用允许垃圾回收器在内存不足的时候，回收对象。如果当没有其他强引用指向某个 ThreadLocal 实例时，它可以被及时回收，避免长时间占用内存。\n【注意】 弱引用和软引用的区别如下：\n弱引用：当对象被弱引用关联的时候，垃圾回收器 GC 无论内存是否充足，都会在下次 GC 运行的时候，回收该对象。 软引用：当对象被虚引用的时候，垃圾回收器 GC 在内存不足的时候，会回收掉软引用对象来释放内存，一般用于实现内存敏感的缓存 (内存敏感指的是避免过度消耗内存，非常节约内存的使用) 【总结】\n弱引用：ThreadLocal 使用弱引用主要是为了防止内存泄露，但是也只能在一定程度上防止内存泄露。如果采用强引用的话，当主线程当中的 ThreadLocal 相关代码执行完毕，栈桢被弹出，Entry 对象仍然强引用着 ThreadLocal 对象，无法被垃圾回收。\nThreadLocal 底层原理：\n每个线程都有独立的 ThreadLocalMap ThreadLocalMap 的底层数据结构是一个数组，每个 ThreadLocalMap 当中包含多个 Entry对象，这些对象是存储在数组上，采用强引用 Entry 对象通过弱引用关联当前要使用的 ThreadLocal 对象，它的 key 就是 ThreadLocal， value 是我们需要设置的值，可以为任意 Java 对象类型。 ThreadLocal 通过强引用 value 保存设置的值 主线程当中使用 ThreadLocal 的时候，采用强引用指向 Entry 当中的 ThreadLocal 对象 采用弱引用之后，也只能在一定程度上防止内存泄露。在使用线程池等场景中，线程的生命周期可能长于 ThreadLocal 实例，ThreadLocalMap 可能一直被强引用，不会被垃圾回收。所以在使用完 ThreadLocal 后，需要调用 remove() 方法清理 ThreadLocalMap 中可能残留无用的键值对。\nThreadLocal 内部在执行 set 和 get 的过程当中，也会像后遍历去清理掉 key 为 null 的 Entry 对象。\n","permalink":"https://swimmingliu.cn/posts/job/java-juc-interview-questions/","summary":"\u003ch2 id=\"1-什么是-java-内存模型jmm\"\u003e1. 什么是 Java 内存模型（JMM）？\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eJMM\u003c/code\u003e 是 Java内存模型 ， 它是Java虚拟机 \u003ccode\u003eJVM\u003c/code\u003e 定义的一种规范，用于描述多线程程序中的变量，像实例字段、静态字段和数组元素，他们如何在内存中存储和传递的规则。也就是规定线程啥时候从住内存里面读数据，啥时候把数据写回到住内存。\u003ccode\u003eJMM\u003c/code\u003e 的核心目标是确保多线程环境下的\u003cstrong\u003e可见性\u003c/strong\u003e、\u003cstrong\u003e有序性\u003c/strong\u003e和\u003cstrong\u003e原子性\u003c/strong\u003e, 避免硬件和编译器优化带来的不一致问题。\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eJMM\u003c/code\u003e  当中包含\u003cstrong\u003e主内存\u003c/strong\u003e (所有线程共享) 和 \u003cstrong\u003e工作内存\u003c/strong\u003e （每个线程私有）两种内存。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e主内存\u003c/strong\u003e：主内存是Java堆内存的一部分，是线程共享的区域，存储全局变量，比如静态变量、实例字段、数组元素等等。线程不能直接操作主内存，必须通过工作内存间接访问。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e工作内存\u003c/strong\u003e：每个线程私有的本地内存，缓存主内存的变量副本。线程对变量的读写操作均在工作内存种进行，修改后的结果需要同步会主内存。线程是通过内存屏障 ( \u003ccode\u003evolatile\u003c/code\u003e 关键字) 或者 同步操作 ( \u003ccode\u003esynchronized\u003c/code\u003e ) 实现主内存和工作内存的数据一致性的。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e【可见性、有序性、原子性定义】\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e可见性\u003c/strong\u003e：确保一个线程对共享变量的修改，能够及时被另外一个线程看到。 \u003ccode\u003evolatile\u003c/code\u003e就是用来保证可见性的，强制线程每次读写的时候，直接从主内存当中获取最新值。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e有序性\u003c/strong\u003e：指线程执行操作的顺序。JMM允许某些指令重排序之后再提高性能，但会保证线程内的操作顺序不会被破坏。通过\u003ccode\u003ehappens-before\u003c/code\u003e (线程A发生在线程B之前)的关系来保证跨线程的有序性。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e原子性\u003c/strong\u003e：操作不可分割，线程不会在执行的过程当中被打断。例如, \u003ccode\u003esynchronize\u003c/code\u003e 关键字能确保方法或代码块的原子性\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e【JMM作用】\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e因为不同的操作系统都有一套独立的内存模型，但是Java为了满足跨平台的特性，它需要定义一套内存模型屏蔽个操作系统之间的差异。我们可以利用JMM当中定义好的从Java源码到CPU指令的执行规范，也就是使用\u003ccode\u003esynchronized\u003c/code\u003e 、\u003ccode\u003evolatile\u003c/code\u003e 等关键字，还有\u003ccode\u003ehappens-before\u003c/code\u003e原则，就可以写出并发安全的代码了。\n比如说，线程A和线程B同时操作 \u003ccode\u003e变量-1\u003c/code\u003e，假如最开始\u003ccode\u003e变量-1\u003c/code\u003e 是 \u003ccode\u003e0\u003c/code\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e首先，线程A和线程B都读取了\u003ccode\u003e变量-1\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e然后，线程B对取到的\u003ccode\u003e变量-1\u003c/code\u003e自增为\u003ccode\u003e1\u003c/code\u003e，并写回主内存\u003c/li\u003e\n\u003cli\u003e此时，线程A对读取到的\u003ccode\u003e变量-1\u003c/code\u003e也自增\u003ccode\u003e1\u003c/code\u003e，并写回主内存。这就会导致线程B的操作失效了，出现并发安全问题。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e如果有JMM，我们就可以在线程A要修改数据之前,让它采用CAS乐观锁的方式进行修改。再次去读主内存当中的值，然后修改之后，再判断一下主内存的值是否发生变化。如果没有发生变化，就写回主内存。如果发生变化，就要进行自旋。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【注意】\u003c/strong\u003e 工作内存是每个线程独立的内存空间，其他线程都是看不到的。主内存是Java堆内存的一部分，所有的实例变量、静态变量和数组元素都存储在主内存当中。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"JMM架构图\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/49ddf552-f9c8-11ef-99c5-c858c0c1deba\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【内存间交互操作类型 (8种原子操作)】\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003elock 上锁\u003c/strong\u003e：把一个变量表示为一条线程独占的状态\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eunlock 解锁\u003c/strong\u003e： 把一个变量从独占状态中释放出来，释放后的变量才能被其他线程锁定\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eread 读取\u003c/strong\u003e： 从主内存当中读取一个变量到工作内存中\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eload 载入\u003c/strong\u003e：把\u003ccode\u003eread\u003c/code\u003e操作从主内存中得到的变量值放入工作内存的变量副本当中\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003euse 使用\u003c/strong\u003e：把工作内存当中的一个变量值传递给执行引擎\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eassign 赋值\u003c/strong\u003e：把一个从执行引擎接收到的值赋给工作内存中的变量\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003estore 存储\u003c/strong\u003e：把工作内存中的一个变量的值传送给主内存中\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ewrite 写入\u003c/strong\u003e：把store操作从工作内存中得到的变量值放入主内存的变量中\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e【volatile 特殊规则】\u003c/strong\u003e\u003c/p\u003e","title":"(JUC) Java并发面试题笔记"},{"content":"1. 说说你知道的几种 I/O 模型 【常见的五大I/O模型】\n常见的五大I/O模式分别为: 同步阻塞I/O (Blocking I/O) BIO、非阻塞I/O (Non-blocking I/O) NIO、I/O多路复用、信号量驱动I/O、异步I/O AIO\n我们假如要烧水喝，看不同模型是怎么烧的水喝\nI/O 模型 特性 烧水案例 同步阻塞I/O BIO 数据从网卡到内核，再从内核到用户空间，都是阻塞操作。 自己动手烧水，一直盯着，等水烧开了，倒在杯子里喝。 非阻塞I/O NIO 数据从网卡到内核不阻塞，read不到数据直接返回，但是从内核到用户空间会阻塞 (用户轮询read) 自己动手烧水，隔两分钟看一下，水烧开没有。等水烧开了，倒在杯子里喝。 I/O多路复用 只有一个线程查看多个连接是否有数据准备就绪 (看从网卡能不能read到数据到内核) 找专门烧水的领居帮忙，他把水烧好了之后，会喊你来拿。但是你要自己倒在杯子里喝。 信号驱动I/O 数据从网卡到内核之后会自动通知用户程序，然后让他read读取数据 去烧水房烧水，全自动的，有个通知灯。水烧完了之后会按你家的门铃，但是有客人来了，也会按门铃 异步I/O AIO 全程不阻塞，拷贝到用户空间之后直接回调。 和多路复用类似，但是烧完水之后不用自己倒水，他帮你倒好了，还吹凉了，你过来喝就行。 【为什么会产生各种I/O】\n下图是两个不同主机上，应用程序传递数据的过程，借助该过程来理解 I/O 是如何产生的\nDMA（直接内存访问）是一种不经过CPU直接在网络适配器（网卡）和主机内存之间进行数据传输的机制，用于提升数据传输效率。\n【同步阻塞 I/O BIO】\n同步阻塞I/O BIO 的工作机制：应用程序被阻塞，直到数据复制到应用进程的缓冲区才返回。阻塞并意味着整个操作系统都被阻塞。其他程序还可以执行，不消耗CPU事件。同步阻塞 I/O BIO 中，应用程序发起 read 调用来读取数据之后，一直被阻塞，直到内核把数据copy到用户空间。该方案适合客户端连接数量不高的情况。下图的read 和 recvfrom 函数是一个意思。\n【非阻塞式 I/O NIO】\n非阻塞式 I/O NIO 的工作机制：应用程序执行read 系统调用之后，内核返回一个错误码。应用程序可以继续执行，但是需要不断的轮询 read 来获取 I/O是否完成，这种方式称之为 轮询 polling 。等到数据准备就绪，从内核空间copy到用户空间的时候，进程才被阻塞，直到内核copy完成。该方案比较低效，会不停的消耗CPU资源。\n【I/O 多路复用】\nI/O 多路复用是一种支持面向缓存的，基于通道I/O的操作方法，它是基于同步非阻塞I/O设计的。适合高负载、高并发应用。I/O 复用是通过 select 或者 poll 机制，让单个进程能够同时处理多个套接字的读写事件。当任一套接字可读的时候，被阻塞的进程会被唤醒并继续执行。和多进程或者多线程方案相比， I/O 复用避免了创建和切换 进程/线程带来的额外开销。在没有I/O复用的情况下，每次建立一个新的 Socket 连接 都需要单独启动一个线程来处理。\n【注意】I/O 多路复用相较于同步非阻塞I/O NIO 少了轮询调用 read 的操作 (轮询polling)， 减少了CPU资源的消耗。复用同一个线程，处理多个socket 中的事件，防止创建过多线程导致的上下文切换的开销。\nI/O 复用的具体工作流程：\n线程首先发起 select 调用，询问内核数据是否准备就绪 等待内核把数据准备好，用户线程再发起read 调用 数据从内核空间copy到用户空间，该过程应用程序还是阻塞的 【信号驱动 I/O】\n使用 sigaction 系统调用，内核立即返回。应用程序继续执行，内核等待数据准备就绪之后，发送 SIGIO 信号。应用程序受到信号之后，开始 read 系统调用，数据从内核空间复制到用户空间，该过程应用程序阻塞。 和 I/O 多路复用比较相似。\n【异步 I/O AIO】\n异步 I/O AIO 是基于事件和回调机制实现的，应用程序 read 系统调用之后，直接返回，完全不阻塞。当后台处理完之后，操作系统通知相应的线程进行后续的操作。\n【五大 I/O 模型比较】\n2. Select、Poll、Epoll 之间有什么区别？ 特性 select poll epoll 触发机制 水平触发 水平触发 边缘触发 文件描述符存储方式 位图 动态数组 红黑书 + 就绪链表 性能 随着文件描述符量增加，性能下降 ( O(N) ) 随着文件描述符量增加，性能下降( O(N) ) 监听列表为 O(1) ，调用事件回调 o(k) 【水平触发和边缘触发的区别】\n边缘触发：事件发生的时候只通知一次，需要用户立即处理，如果没有处理，后续不会再通知 水平触发：事件发生的时候会反复通知，直到处理完成 3. 线程和进程有什么区别？ 进程 (Process)：进程是运行中的程序实例，拥有独立的内存空间和系统资源。比如打开的微信/抖音/微博，都是一个单独的进程。\n线程 (Thread)：线程也叫轻量级的进程，比进程轻量。一般来说，一个进程里面有多个线程同时执行，并且共享进程的资源。在 Linux 当中，线程可以共享内存空间、文件句柄、网络连接等。\n协程：用户态轻量级线程，由程序控制切换，无需内核参与。协程切换只需要保存和恢复上下文，开销比线程小得多，适合处理高并发任务（比如异步I/O）\n【注意】 多线程不是越多越好，因为线程越多就会增加切换成本，可能导致系统负载过高。而且需要同步机制避免数据竞争和死锁问题。\n【进程和线程的区别】\n特性 进程 线程 本质 操作系统进行资源分配的基本单元 构成任务调度与执行的核心单元 开销 独立的代码和数据段，进程切换成本高 线程共享进程的资源，维护独立的堆栈和程序计数器，线程切换成本低 内存分配 每个进程分配独立的内存空间 除了CPU之外，系统不会给线程分配内存，线程组共享资源 稳定性 进程隔离性强，崩溃时不会影响其他进程 线程共享进程资源，崩溃可能导致整个进程异常终止 安全性 有独立的内存空间，安全性高 多个线程共享内存空间，存在数据竞争和线程安全的问题，需要用同步和互斥机制来解决 【JVM 视角下的进程和线程】\n一个进程可以有多个线程，多个线程之间共享堆和方法区 (元空间)，但是各自有独立的程序计数器、虚拟机栈和本地方法栈，确保线程间执行的上下文彼此隔离。\n线程共享数据区：堆、方法区 ( JDK8 之后叫元空间)、执行引擎 线程隔离区域：程序计数器、虚拟机栈、本地方法栈、每个线程都有独立的脚本 【进程切换和线程切换的区别】\n时间效率：线程切换比进程切换快，因为线程共享地址空间，而进程需要切换页面和上下文（涉及更多资源） 空间效率：线程共享内存和文件资源，数据交换不需要内核参与，效率更高；进程切换涉及更复杂的上下文保存和恢复。 【进程和线程切换的上下文是什么？】\n进程控制块 (process control block) PCB 数据结构是用来描述进程的\nPCB是进程存在的唯一标识，其中包含\nPCB内容：进程唯一标识符、状态信息（创建、就绪、运行、阻塞、结束）、优先级、资源分配清单（内存和文件句柄）、CPU寄存器值等 进程状态变迁：创建、就绪、运行、阻塞、结束，五种状态当中进行切换 【进程的上下文切换】\n进程的上下文：包含虚拟内存、栈、全局变量 等用户空间的资源，还包括内核堆栈、寄存器等内核空间的资源。\n进程上下文切换：将上一个进程 进程A 的上下文保存到当前进程 进程B 的PCB中，当需要运行另外一个进程 进程A 的时候，需要从 进程B 的PCB取出上下文，恢复到CPU中，使得 进程A 可以从中断点继续执行。\n进程切换发生的场景\n时间片用完：某个进程的时间片用完了，进程变为就绪态 资源不足：某个进程所需要的资源不足，会被挂起，变成就绪挂起状态 主动挂起：进程被主动挂起 优先级不足：遇到更高优先级的进程，需要被调度成阻塞状态 硬件中断：突然断电了 【线程的上下文切换】\n不同进程内的线程切换：相当于不同进程之间的上下文切换 （比如两个单线程的进程） 同一个进程内的线程切换：因为虚拟内存是共享的，所以切换的过程中，虚拟内存（堆、方法区、执行引擎）不动，只切换线程的私有数据 （本地方法栈、虚拟机栈）、寄存器等共享的数据 【文件句柄、内存空间、网络连接】\n文件句柄：文件句柄是操作系统给进程打开的每个文件分配的唯一整数标识符，用来跟踪文件的位置、权限等状态信息。比如区餐厅点餐，服务员给一个牌子（桌号）。这个牌子就是句柄，代表你的桌子。服务员不知道你是谁，只能通过桌号，找到你的桌子，给你上菜。\n内存空间：内存空间包含代码段、数据段、堆区、栈区、文件映射段\n代码段：存放二进制可执行代码，通常是只读的 数据段：存放全局变量和静态变量，分为已初始化数据区和未初始化数据区 (BSS段) 堆区：用于动态分配内存 栈区：存放函数的局部变量、参数、返回地址等，大小固定 文件映射段：包括动态库、共享内存等 (mmap 分配内存) 网络连接：Linux里面，网络连接是一种特殊的文件，可以通过文件句柄进行操作。一般是用来两台计算机之间通过网络协议 (TCP/IP) 建立的通信信道。\n4. 进程之间的通信方式有哪些？ 【为什么进程需要进行通信？】\n不同的进程有不同的用户地址空间，进程A的全局变量，进程B是看不到的。进程之间想要交换数据需要通过内核，在内核开辟缓冲区。进程A从用户空间copy数据到内核缓冲区，进程B再从内核缓冲区读走数据，实现进程之间的通信。\n【进程之间的通信方式】\n管道/匿名管道：管道是一种单向通信的方式，用于父进程和子进程之间，或者同一主机上的不同进程之间传递数据。可以是匿名的，也可是命名的。\nps -ef | grep [name] # Linux指令的|就是匿名管道 命名管道：和匿名管道类似，遵循先进先出原则，以磁盘文件的形式存在，可以实现本机任意两个进程的通信。\nmkfifo pipeDemo # 创建命名管道 echo \u0026#34;Hello! World!\u0026#34; \u0026gt; pipeDemo # 向管道内写入数据 cat \u0026lt; pipeDemo # 读取pipeDemo管道的数据,显示 Hello! World! 信号：异步的通信方式，通知接受进程某个事件已经发生，一般用于进程之间发送中断或者终止命令。\n信号量：信号量是一种同步原语，用于管理对共享区域的访问，可以用来实现进程间的互斥访问和同步操作。\n消息队列：消息队列是链表形式的，遵循先进先出的原则。允许进程A向进程B发送消息，消息在队列中按照顺序存储。但是读取的过程中，进程B不一定非要按照现金先出的顺序读取，可以随机查询。\n共享内存：共享内存允许多个进程访问同一块内存区域，可以看见其他进程对共享进程的更新，从而实现快速的数据交换。但是需要注意数据同步的问题，避免出现数据一致性问题。\n套接字 (socket)：套接字其实就是协议+IP+端口，允许在网络上的不同主机上面的进程进行通信，比如说微信/飞书发消息。\n文件：进程可以通过读写文件来进行通信，这种方式通常用于进程之间的间接通信，比如临时文件或者共享文件。\n【消息队列详解】\n消息队列就是保存在内核中的消息链表，消息队列的生命周期随内核存在而存在。如果不主动释放或者不关闭系统，则会一直存在。匿名管道的生命周期是随进程存在而存在的，进程结束就销毁了。和管道不同，消息队列不需要其他进程在队列上面等待消息到达，可以随时往消息队列里面写入消息。\n消息队列的缺点：\n通信不及时：因为不需要其他进程在消息队列等着，进程只有轮询检查消息队列，如果有时间间隔，肯定会有没来得及看消息的时候 数据大小存在限制：消息队列不适合传输比较大的数据，而且需要把数据从用户态copy到内核态里面 【共享内存】\n进程A和进程B都拿出一块虚拟地址空间映射到相同物理内存，一个进程写入，另外一个进程就可以马上看到，不用从用户态copy数据到内核态，提高进程间的通信速度。但是需要某种同步机制(比如信号量)来达到进程之间的同步和互斥 （比如进程A需要通过信号量通知进程B，它正在写入）。另外，两个进程写同一个地址，先写的进程会发现内容被覆盖了。\n【信号量机制】\n信号量是用来防止进程之间因为竞争共享资源的，而造成的数据错乱。引入保护机制，使得共享的资源在任意时刻只能被一个进程访问。信号量是整型计数器，用于实现进程间的互斥和同步，不是用来缓存进程之间的通信数据的。信号量有两种操作，P 操作和 V 操作：\nP 操作：将信号量减去1，如果相减之后信号量 \u0026lt; 0，则表明资源被占用。如果信号量 \u0026gt;= 0， 表明资源还可以继续使用 V 操作：将信号量加上1，如果相加之后信号量 \u0026lt;= 0, 说明有阻塞进程，唤醒该进程运行。如果相加之后，信号量 \u0026gt; 0，则表明没有阻塞进程，直接运行。 如果信号量初始化为 1，代表是互斥信号量。如果初始化为 0，代表是同步信号量。\n【基于TCP协议通信的套接字socket编程模型】\nTCP套接字通信 服务端和客户端初始化套接字 socket 的 文件描述符 服务端 bind 绑定 IP 和 端口， listen 监听 ，accept 等客户端进行连接 客户端 connect 向服务端地址和端口发起连接请求 服务端 accpet 返回传输 socket 文件描述符 客户端 write 写入数据，服务端 read 读取 客户端 close 的时候，服务端 read 会读取到 EOF (End of File)， 处理完数据之后，服务端 close 关闭链接 UDP套接字通信：每次通信的时候调用sendto 和 recvfrom()， 都需要传入目标主机的IP地址和端口 5. 进程间的调度算法知道吗？ 先来先服务 (FCFS, First Come First Service)：按照进程到达的先后顺序进行调度，先到达的进程先执行，后达到的进程后执行。就像区银行取钱，挨个排队一样。\n最短作业优先 (SJF, Short Job First)：按照进程的执行时间进行排序，执行时间短的进程优先执行，以减少平均等待时间。但是，可能会出现饥饿现象，执行时间长的程序，可能要等很久才能被执行。可以类比成银行让客户按照办理业务的时间进行排队，依次处理。\n优先级调度：给每个进程分配一个优先级，根据优先级高低进行调度，优先级高的进程先执行。但是，优先级较低的程序需要等很久才能执行，可能会出现饥饿现象。\n时间片轮转 (PR)：将CPU时间分成多个时间片，每个进程轮流占用一个时间片，如果一个进程在该时间片结束的时候还没有执行完成，则将其移到队列末尾，等待下一次调度。\n多级反馈队列调度 (MFQS, Multilevel Feedback Queue Scheduling)：多级的意思是有多个队列，每个队列的优先级从高到低，优先级越高时间片越短（为了避免优先级低的进程被饿死了）。反馈的意思是如果有新的进程进入优先级高的队列的时候，立即停止当前运行的进程，转到优先级最高的队里去从头运行。（让优先级高的队列，得到快速处理的保障）具体工程流程如下：\n设置多个队列，每个队列赋予不同的优先级，优先级从高到低，同时优先级越高的队列，时间片设置的越短 如果有新的进程，会把它放到第一级队列的末尾，按照先来先服务的原则排队等待被调度。如果在第一级队列规定时间片没有运行完成，则将其转入第二级队列末尾，直到完成为止。 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行的时候，有新进程进入较高优先级的队列，则停止当前运行的进程，并且将其移动到原来队列的队尾。然后从较高优先级队列开始，重复刚才的过程。 6. 网络I/O阻塞的原因？ 网络I/O会被阻塞是因为进行网络数据传输的过程中，操作系统在等待数据的发送或接收完成之前，进程将被挂起，直到数据传输完成之后才恢复进程执行。\n网络I/O阻塞的主要原因：\n等待数据到达或发送完成：当进程尝试从网络套接字 socket 读取数据的时候，如果数据还没到达（数据未就绪），操作系统会让进程进入阻塞状态，直到数据到达为止。同样，数据未能立即发出去的时候，发送操作也可能被阻塞，等待缓冲区有空闲空间。 系统资源有限：当系统资源（网络缓冲区、连接数）被占满的时候，进一步的I/O请求可能会被阻塞，等待资源释放后才能继续。 默认的阻塞行为：大多数网络API (比如recv、send、accept等) 在默认情况下都是阻塞的，调用这些API的时候，如果条件不满足，会让调用者等待，直到I/O操作完成。 7. 什么是用户态和内核态？ 运行模式 权限级别 可执行操作 特点 用户态 较低 不能直接访问硬件或者越权操作，需要通过系统调用让内核执行敏感操作 安全性高，程序出现问题，不会影响系统的稳定性。 内核态 较高 可直接访问硬件资源并执行如内存管理、进程调度等于越权操作 能够高效管理硬件和系统资源 用户态和内核态是 CPU 的状态，描述了CPU在执行指令是的特权级别和范围权限。进程运行的过程当中，可能会因为CPU状态的切换，在用户态和内核态之间更替。\n简单来说，一个进程当中，如果CPU 是用户态就是线程运行进程本身的程序代码，如果 CPU 是内核态就是把线程交给操作系统运行。\nCPU是用户态，进程只能访问自己的存储空间：用户态下，进程不能直接使用系统资源，只能访问自己的存储空间，不能越权访问系统的资源。也不能改变CPU的工作状态（用户态、内核态、空闲状态）。在用户态下，进程无法修改CPU的工作状态。在内核态下，操作系统可以通过修改CPU寄存器的值来切换权限，实现内核态和用户态的切换。 CPU是内核态，进程可以通过os访问系统资源：内核态下，进程可以通过执行操作系统的程序，来直接使用计算机的所有硬件资源。但是，必须从用户态切换到内核态才可以，这样也保证了安全性和稳定性。 【为什么要区分用户态和内核态】\n因为 CPU 的所有指令当中，有部分指令是非常危险的，操作不当就会导致系统崩溃。而且部分指令可能涉及到硬件的操作，参数很多，很容易出问题。所以凡是涉及到 I/O 读写，内存分配等硬件资源的操作的时候，为了保证安全性和稳定性，往往不能让进程直接操作，而是通过系统调用（调用操作系统的程序）让 CPU 从用户态切换到内核态，程序在内核态下面运行。\n其中，CPU 的指令是有权限分级的，不同级别的权限包含不同的 CPU 指令集。比如 InterCPU 把 CPU 的指令集操作权限从高到低分为四个级别：ring0、ring1、ring2、ring3。\n【注意】\nring3 的权限最低，只能使用常规的 CPU 指令集，不能使用操作硬件资源的 CPU 指令集，比如I/O读写、网卡访问、申请内存等操作都不可以。ring0 的权限最高，可以使用所有的 CPU 指令集 Linux系统当中只采用了 ring0 和 ring3 这两个权限。ring0 对应的就是内核态，程序完全在操作系统内核当中运行。ring3 对应的是用户态，程序在自己的存储空间当中运行。 【用户态和内核态的空间】\n在内存资源的使用上，操作系统对用户态和内核态也做了限制。内存结构如下图所示，包含了内核空间和用户空间（程序代码和数据、堆内存、栈内存、命令行参数和环境变量等）。每个进程创建的时候，都会分配虚拟空间地址，和内存结构一样。虚拟空间就记录，对应的在实际内存中存放的位置。虚拟地址空间与物理内存通过**内存管理单元（MMU）和页表（Page Table）**实现动态映射。例如，在Linux ( 32 位系统)下，总共的内存空间是 2^32 bytes = 4GB ，内核态为 1G，用户态为 3G。 **【注意】**内核态的地址空间存放整个内核的代码，所有的内核模块和内核维护的数据，这一部分是所有进程共享的。所有进程的内核态逻辑地址是共享同一块内存地址的。同时 CPU 处于内核态的时候，进程可以操作全部范围的虚拟空间地址，并且属于内核态的高位虚拟空间只有内核态下，程序才能操作。\n【用户态和内核态的切换】\n用户态和内核态的切换具有一定的开销，下面是从用户态切换到内核态的流程（比如发起 I/O 调用）\n保留用户态的现场 （上下文、程序计数器（寄存器）、用户栈） 复制用户参数，从用户栈切换到内核栈，CPU 进入内核态 额外的检查 （因为内核代码对用户是不信任的） 执行内核态中相关的代码 复制内核态代码执行结果，回到用户态 恢复用户态现场（上下文、程序计数器（寄存器）、用户栈） 从用户态主动切换到内核态，需要有入口才行，操作系统提供了统一的入口（系统调用）。系统调用就是一组通用的访问接口，这些接口就叫系统调用。\n【用户态什么时候切换到内核态】\n系统调用：用户态进程通过系统调用向操作系统申请资源完成工作，比如 fork() 创建子进程，就是一个创建新进程的系统调用。系统调用的核心是系草系统为用户特别开放的一个中断来实现的，成为软中断。 异常：当 CPU 在执行用户态的进程的时候，发生了一些没有预知的异常。此时，当前运行进程会切换到处理该异常的内核态中的相关进程，就是从用户态切换到内核态了。比如出现缺页异常 中断：当 CPU 在执行用户态的进程的时候，外围设备完成用户请求的操作之后，会向 CPU 发出相应的中断信号。此时， CPU 会暂停执行下一条即将执行的指令，转到与中断信号对应的内核态下的处理程序去执行，从用户态切换到了内核态。比如硬盘读写完成，系统会切换到硬盘读写的中断处理程序中执行后边的操作。 ","permalink":"https://swimmingliu.cn/posts/job/operation-system-interview-questions/","summary":"\u003ch2 id=\"1-说说你知道的几种-io-模型\"\u003e1. 说说你知道的几种 I/O 模型\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e【常见的五大I/O模型】\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e常见的五大I/O模式分别为: 同步阻塞I/O (Blocking I/O) \u003ccode\u003eBIO\u003c/code\u003e、非阻塞I/O (Non-blocking I/O) \u003ccode\u003eNIO\u003c/code\u003e、I/O多路复用、信号量驱动I/O、异步I/O \u003ccode\u003eAIO\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e我们假如要烧水喝，看不同模型是怎么烧的水喝\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e\u003cstrong\u003eI/O 模型\u003c/strong\u003e\u003c/th\u003e\n          \u003cth\u003e特性\u003c/th\u003e\n          \u003cth\u003e烧水案例\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e同步阻塞I/O \u003ccode\u003eBIO\u003c/code\u003e\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e数据从网卡到内核，再从内核到用户空间，都是阻塞操作。\u003c/td\u003e\n          \u003ctd\u003e自己动手烧水，一直盯着，等水烧开了，倒在杯子里喝。\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e非阻塞I/O \u003ccode\u003eNIO\u003c/code\u003e\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e数据从网卡到内核不阻塞，\u003ccode\u003eread\u003c/code\u003e不到数据直接返回，但是从内核到用户空间会阻塞 (用户轮询\u003ccode\u003eread\u003c/code\u003e)\u003c/td\u003e\n          \u003ctd\u003e自己动手烧水，隔两分钟看一下，水烧开没有。等水烧开了，倒在杯子里喝。\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003eI/O多路复用\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e只有一个线程查看多个连接是否有数据准备就绪 (看从网卡能不能\u003ccode\u003eread\u003c/code\u003e到数据到内核)\u003c/td\u003e\n          \u003ctd\u003e找专门烧水的领居帮忙，他把水烧好了之后，会喊你来拿。但是你要自己倒在杯子里喝。\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e信号驱动I/O\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e数据从网卡到内核之后会自动通知用户程序，然后让他\u003ccode\u003eread\u003c/code\u003e读取数据\u003c/td\u003e\n          \u003ctd\u003e去烧水房烧水，全自动的，有个通知灯。水烧完了之后会按你家的门铃，但是有客人来了，也会按门铃\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e异步I/O \u003ccode\u003eAIO\u003c/code\u003e\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e全程不阻塞，拷贝到用户空间之后直接回调。\u003c/td\u003e\n          \u003ctd\u003e和多路复用类似，但是烧完水之后不用自己倒水，他帮你倒好了，还吹凉了，你过来喝就行。\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003cimg alt=\"IO五种模型\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/3bbe065d-f63f-11ef-a797-c858c0c1deba\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【为什么会产生各种I/O】\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e下图是两个不同主机上，应用程序传递数据的过程，借助该过程来理解 \u003ccode\u003eI/O\u003c/code\u003e 是如何产生的\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eDMA（直接内存访问）是一种不经过CPU直接在网络适配器（网卡）和主机内存之间进行数据传输的机制，用于提升数据传输效率。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e\u003cimg alt=\"两个主机的应用程序是如何通信的\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/c3fa5783-0332-11f0-9b6e-c858c0c1debd\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【同步阻塞 I/O \u003ccode\u003eBIO\u003c/code\u003e】\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e同步阻塞I/O \u003ccode\u003eBIO\u003c/code\u003e 的工作机制：应用程序被阻塞，直到数据复制到应用进程的缓冲区才返回。阻塞并意味着整个操作系统都被阻塞。其他程序还可以执行，不消耗CPU事件。同步阻塞 I/O \u003ccode\u003eBIO\u003c/code\u003e 中，应用程序发起 \u003ccode\u003eread\u003c/code\u003e 调用来读取数据之后，一直被阻塞，直到内核把数据copy到用户空间。该方案适合客户端连接数量不高的情况。下图的\u003ccode\u003eread\u003c/code\u003e 和 \u003ccode\u003erecvfrom\u003c/code\u003e 函数是一个意思。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"同步阻塞IO结构图\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/c5e8e28c-0332-11f0-bf73-c858c0c1debd\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【非阻塞式  I/O \u003ccode\u003eNIO\u003c/code\u003e】\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e非阻塞式  I/O \u003ccode\u003eNIO\u003c/code\u003e 的工作机制：应用程序执行\u003ccode\u003eread\u003c/code\u003e 系统调用之后，内核返回一个错误码。应用程序可以继续执行，但是需要不断的轮询 \u003ccode\u003eread\u003c/code\u003e 来获取 I/O是否完成，这种方式称之为 \u003cstrong\u003e轮询 \u003ccode\u003epolling\u003c/code\u003e\u003c/strong\u003e 。等到数据准备就绪，从内核空间copy到用户空间的时候，进程才被阻塞，直到内核copy完成。该方案比较低效，会不停的消耗CPU资源。\u003c/p\u003e","title":"操作系统面试题笔记"},{"content":"个人简历详情查看 -\u0026gt; 个人简历页\n1. 异步秒杀机制的异步是如何实现的? 【正常秒杀的顺序】\n查询优惠券 -\u0026gt; 判断秒杀库存 -\u0026gt; 查询订单 -\u0026gt; 校验是否一人一单 -\u0026gt; 扣减库存 -\u0026gt; 创建订单\n【异步秒杀】\n为了实现用户异步下单，其实就是把是否能够下单的判断逻辑和下单的操作拆分开。\n采用Redis来判断是否有足够的库存和校验一人一单 如果满足条件，把用户、订单id、商品id保存到阻塞队列，直接给用户返回秒杀成功。 如果不满足条件，直接返回秒杀失败。 后台线程会去执行queue里边的消息 这样就可以实现异步的秒杀下单了，那么如果实现判断秒杀库存和校验一人一单呢？\n【秒杀库存 + 一人一单】\n用户下单之后，判断redis当中的库存key的value是否大于0 value \u0026gt; 0 -\u0026gt; 第2步 value \u0026lt;= 0 -\u0026gt; 直接返回库存不足 （返回1） 如果库存充足，判断redis当中的秒杀商品key的 set 集合是否已包含userid 包含userid， 说明用户已经下单了，直接返回当前用户已下单 (返回2) 不包含 userid -\u0026gt; 第3步 如果用户没有下单，将用户的 userid 存入 set 里面 (返回0) 【注意】 整个操作是原子性的，这样就确保了不会出现超卖现象和一人多单现象\n-- 1.参数列表 -- 1.1.秒杀商品id local voucherId = ARGV[1] -- 1.2.用户id local userId = ARGV[2] -- 1.3.订单id local orderId = ARGV[3] -- 2.数据key -- 2.1.库存key local stockKey = \u0026#39;seckill:stock:\u0026#39; .. voucherId -- 2.2.秒杀商品订单key local orderKey = \u0026#39;seckill:order:\u0026#39; .. voucherId -- 3.脚本业务 -- 3.1.判断库存是否充足 get stockKey if(tonumber(redis.call(\u0026#39;get\u0026#39;, stockKey)) \u0026lt;= 0) then -- 3.2.库存不足，返回1 return 1 end -- 3.2.判断用户是否下单 SISMEMBER orderKey userId if(redis.call(\u0026#39;sismember\u0026#39;, orderKey, userId) == 1) then -- 3.3.存在，说明是重复下单，返回2 return 2 end return 0 【阻塞队列实现下单】\n初始化一个SingleThreadExecutor 线程池，用于完成后续的下单操作 判断上面lua脚本执行后的返回值 如果返回值为0， 说明用户满足下单的资格 -\u0026gt; 第2步 如果返回值不为0， 说明用户下单失败，返回异常信息 将userid、优惠商品id、订单id等信息都存入阻塞队列(ArrayBlockingQueue)里面，返回订单id 线程池会异步获取阻塞队列里面的订单信息，然后创建订单。 2. 如果用MySQL数据库，如何解决超卖现象 超卖现象的产生是因为多线程并发的时候，出现了库存扣为负数的现象。\n假如A线程查询时，库存为1 。随后，B线程查询库存也为1 A线程完成下单之后, 库存减为0。此时，B线程又完成下单，库存扣减为-1。 【MySQL如何解决超卖问题】\n一般超卖问题都是采用乐观锁进行解决，也就是CAS 自旋。其实，就是判断读取前和第二次读取的，是否出现了数据不一致的情况。如果数据不一致，说明被其他人修改过，就放弃当前的操作。如果没有，就正常修改。\n【乐观锁】\n乐观锁会有一个版本号，每次操作数据会对版本号+1。再提交回数据是，会去校验是否比之前的版本是否大于1。如果超过1， 则说明当前的数据被修改过。\n乐观锁有一个变种是CAS，利用CAS进行无锁化机制加锁，var5 是操作前读取的内存值，while 中的var1+var2 是预估值，如果预估值 == 内存值，则代表中间没有被人修改过，此时就将新值去替换 内存值\nint var5; do { var5 = this.getIntVolatile(var1, var2); } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; 【MySQL如何解决一人一单】\n就是判断当前用于在数据库里面是否有订单, 可以用count() 去统计一下该用户秒杀订单的数量。如果大于0，则说明他已经买过商品了，就不能重复下单了。\n","permalink":"https://swimmingliu.cn/posts/job/personal-interview-hot-question/","summary":"\u003cp\u003e个人简历详情查看 -\u0026gt; \u003ca href=\"https://rxresu.me/dashboard/resumes\"\u003e个人简历页\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"1-异步秒杀机制的异步是如何实现的\"\u003e1. 异步秒杀机制的异步是如何实现的?\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e【正常秒杀的顺序】\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e查询优惠券 -\u0026gt; 判断秒杀库存 -\u0026gt; 查询订单 -\u0026gt; 校验是否一人一单 -\u0026gt; 扣减库存 -\u0026gt; 创建订单\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【异步秒杀】\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e为了实现用户异步下单，其实就是把是否能够下单的判断逻辑和下单的操作拆分开。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e采用Redis来判断是否有足够的库存和校验一人一单\n\u003cul\u003e\n\u003cli\u003e如果满足条件，把用户、订单id、商品id保存到阻塞队列，直接给用户返回秒杀成功。\u003c/li\u003e\n\u003cli\u003e如果不满足条件，直接返回秒杀失败。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e后台线程会去执行queue里边的消息\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e这样就可以实现异步的秒杀下单了，那么如果实现判断秒杀库存和校验一人一单呢？\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"1653561657295\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/8f260a35-f4b5-11ef-a915-c858c0c1deba\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【秒杀库存 + 一人一单】\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e用户下单之后，判断redis当中的库存key的value是否大于\u003ccode\u003e0\u003c/code\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003evalue \u0026gt; 0\u003c/code\u003e -\u0026gt; 第2步\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003evalue \u0026lt;= 0\u003c/code\u003e -\u0026gt; 直接返回库存不足 （返回\u003ccode\u003e1\u003c/code\u003e）\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e如果库存充足，判断redis当中的秒杀商品key的 \u003ccode\u003eset\u003c/code\u003e 集合是否已包含\u003ccode\u003euserid\u003c/code\u003e\n\u003cul\u003e\n\u003cli\u003e包含\u003ccode\u003euserid\u003c/code\u003e， 说明用户已经下单了，直接返回当前用户已下单 (返回\u003ccode\u003e2\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003e不包含 \u003ccode\u003euserid\u003c/code\u003e -\u0026gt; 第3步\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e如果用户没有下单，将用户的 \u003ccode\u003euserid\u003c/code\u003e 存入 \u003ccode\u003eset\u003c/code\u003e 里面 (返回\u003ccode\u003e0\u003c/code\u003e)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e【注意】\u003c/strong\u003e 整个操作是原子性的，这样就确保了不会出现\u003cstrong\u003e超卖现象和一人多单现象\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-lua\" data-lang=\"lua\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 1.参数列表\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 1.1.秒杀商品id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003elocal\u003c/span\u003e \u003cspan class=\"n\"\u003evoucherId\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eARGV\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 1.2.用户id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003elocal\u003c/span\u003e \u003cspan class=\"n\"\u003euserId\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eARGV\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 1.3.订单id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003elocal\u003c/span\u003e \u003cspan class=\"n\"\u003eorderId\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eARGV\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 2.数据key\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 2.1.库存key\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003elocal\u003c/span\u003e \u003cspan class=\"n\"\u003estockKey\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;seckill:stock:\u0026#39;\u003c/span\u003e \u003cspan class=\"o\"\u003e..\u003c/span\u003e \u003cspan class=\"n\"\u003evoucherId\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 2.2.秒杀商品订单key\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003elocal\u003c/span\u003e \u003cspan class=\"n\"\u003eorderKey\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;seckill:order:\u0026#39;\u003c/span\u003e \u003cspan class=\"o\"\u003e..\u003c/span\u003e \u003cspan class=\"n\"\u003evoucherId\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 3.脚本业务\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 3.1.判断库存是否充足 get stockKey\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kr\"\u003eif\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etonumber\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eredis.call\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;get\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003estockKey\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"kr\"\u003ethen\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e-- 3.2.库存不足，返回1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kr\"\u003ereturn\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kr\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 3.2.判断用户是否下单 SISMEMBER orderKey userId\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kr\"\u003eif\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eredis.call\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;sismember\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eorderKey\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003euserId\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"kr\"\u003ethen\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e-- 3.3.存在，说明是重复下单，返回2\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kr\"\u003ereturn\u003c/span\u003e \u003cspan class=\"mi\"\u003e2\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kr\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kr\"\u003ereturn\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003e【阻塞队列实现下单】\u003c/strong\u003e\u003c/p\u003e","title":"个人简历常问问题"},{"content":"1. Redis主从复制的原理 【主从复制的原理】\n同步：从节点向主节点发送psync命令进行同步，从节点保存主节点返回的 runid 和 offset 全量复制：如果是第一次连接或者连接失败且repl_backlog_buffer 缓存区不包含slave_repl_offset， 则生成主节点的数据快照(RDB文件)发给从节点 增量复制：全量复制完毕后，主从节点之间会保持长连接。如果连接没有断开或者slave_repl_offset仍然在repl_backlog_buffer中，则将后续的写操作传递给从节点，让数据保持一致。 【全量复制细节】\n全量复制的过程是基于TCP长连接的，主要流程如下\n从节点发送psync ? -1表示需要建立连接进行同步，主节点返回主节点ID runid 和 复制进度offset (第一次同步用 -1 表示)。从节点接受之后，保存主节点的信息。 主节点执行bgsave命令生成数据快照RDB文件，然后将RDB文件发送给从节点。从节点接受文件后，清除现有的所有数据，然后加载RDB文件 如果在制作数据快照RDB文件的过程当中，主节点接收到了新的写操作，主节点会将其记录在repl buffer 里面。然后将repl buffer当中的写操作发给从节点，让其数据保持一致。 【增量复制细节】\n如果主从节点意外断开连接，为了保持数据的一致性，必须重新同步数据。如果使用全量复制来保持一致性的话，开销太大，所以采用增量复制。\n增量复制的具体流程如下：\n连接恢复后，从节点会发送psync {runid} {offset}， 其中主节点ID runid 和 复制进度offset用于标识是哪一个服务器主机和复制进度。 主节点收到psync 命令之后，会用conitnue响应告知从节点，采用增量复制同步数据 最后，主节点根据offset查找对应的进度，将断线期间未同步的写命令，发送给从节点。同时，主节点将所有的写命令写入repl_backlog_buffer， 用于后续判断是采用增量复制还是全量复制。 【注意】从节点 psync 携带的 offset 为 slave_repl_offset。如果 repl_backlog_buffer包含slave_repl_offset 对应的部分，则采用增量复制，否则采用全量复制。repl_backlog_buffer的默认缓冲区大小为1M\n【为什么要主从复制】\n备份数据：主从复制实现了数据的热备份，是持久化之外的数据冗余方式 故障恢复：当主节点宕机之后，可以采用从节点提供服务。 负载均衡: 主从复制实现了读写分离，只有主节点支持读写操作，从节点只有读操作。在读多写少的场景下，可以提高Redis服务器的并发量。 2. Redis集群的实现原理是什么? 【Redis集群基本知识】\n定义: Redis集群由多个实例组成，每个实例存储部分数据 (每个实例之间的数据不重复) 。 【注】集群和主从节点不是一个东西，集群的某一个实例当中可能包含一个主节点 + 多个从节点\n为什么用 问题 解决方案 容量不足 数据分片，将数据分散不存到不同的主节点 高并发写入 数据分片，将写入请求分摊到多个主节点 主机宕机问题 自动切换主从节点，避免影响服务， 不需要手动修改客户端配置 节点通信协议：Redis集群采用Gossip协议, 支持分布式信息传播、延迟低、效率高。采用去中心化思想，任意实例(主节点)都可以作为请求入口，节点间相互通信。 分片原理： 采用哈希槽(Hash Slot)机制来分配数据，整个空间可以划分为16384 (16 * 1024)个槽。 每个Redis负责一定范围的哈希槽,数据的key经过哈希函数计算之后对16384取余可定位到对应的节点。 【集群节点之间的交互协议】\n为什么用Gossip协议 分布式信息传播：每个节点定期向其他节点传播状态信息，确保所有节点对集群的状态有一致视图 (采用ping 发送 和 pong 接受，就像检查心跳一样 ) 低延迟、高效率：轻量级通信方式，传递信息很快 去中心化：没有中心节点，任意实例(主节点)都可以作为请求入口，节点间相互通信。 Gossip协议工作原理 状态报告和信息更新：特定时间间隔内，向随机的其他节点报告自身情况 （主从关系、槽位分布）。其他节点接收到之后，会相应的更新对应的节点状态信息 节点检测：通过周期性交换状态信息，可以检测到其他节点的存活状态。预定时间内未响应，则标记为故障节点。 容错处理：如果某个节点故障之后，集群中的其他节点可以重新分配槽位，保持系统的可用性 【哈希槽的相关机制】\n假定集群中有三个节点，Node1 (0 - 5460)、Node2(5461-10922)、Node3(10923-16383)\n集群使用哈希槽的流程如下：\n计算哈希槽 使用CRC16哈希算法计算user:0001的CRC16的值 将CRC16的值对16384进行取余 (哈希槽 = CRC16 % 16383) 假如CRC16为12345，哈希槽 = 12345 % 16383 = 12345 确定目标节点 ：查询到12345为Node3的存储的键，向该节点发送请求 当前非对应节点 ：假设当前连接的节点为Node1，Node1将返回MOVED错误到客户端，并让客户端根据MOVED携带的Node3的信息(ip和端口)重新进行连接，最后从新发送GET user:0001请求，获得结果。 3. Redis的哨兵机制（Sentinel）是什么？ 【哨兵作用】\n监控：哨兵不断监控主从节点的运行状态,定时发送ping进行检测 故障转移: 当主节点发生故障时, 哨兵会先踢出所有失效的节点, 然后选择一个有效的从节点作为新的主节点, 并通知客户端更新主节点的地址 通知: 哨兵可以发送服务各个节点的状态通知，方便观察Redis实例的状态变化。（比如主节点g了，已经更换为新的主节点） 【哨兵机制的主观下线和客观下线】\n主观下线：哨兵在监控的过程中，每隔1s会发送 ping 命令给所有的节点。如果哨兵超过down-after-milliseconds 所配置的时间，没有收到 pong 的响应，就会认为节点主观下线。\n客观下线：某个哨兵发现节点主线下线后，不能确认节点是否真的下线了（可能是网络不稳定），就询问其他的哨兵是否主观下线了。等待其他哨兵的确认，进行投票，如果超过半数+1 (总哨兵数/2 + 1)，就认定为客观下线。\n【注】客观下线只对主节点适用，因为从节点也没必要这样子判断，g了就g了呗。\n【哨兵leader如何选举】\n哨兵leader是采用分布式算法raft选出来的。具体流程如下：\n候选人：当哨兵判断为主观下线，则可以当选候选人 投票：每个哨兵都可以投票，但是只能投一票。候选者会优先投给自己。 选举：选取投票结果半数以上的候选人作为leader (哨兵一般设置为奇数，防止平票) 【主节点如何选举】\n哨兵判断主节点客观下线之后，会踢出所有下线的节点，然后从有效的从节点选新的主节点。选取依据如下：\n优先级：按照从节点的优先级 slave-priority，优先级的值越小越高。 主从复制offset值：如果优先级相同，则判断主从复制的offset值哪一个大，表明其同步的数据越多，优先级就越高。 从节点ID：如果上述条件均相同，则选取ID较小的从节点作为主节点。 4. Redis Cluster 集群模式与 Sentinel 哨兵模式的区别是什么？ Cluster集群模式：集群模式用于对数据进行分片，主要用于解决大数据、高吞吐量的场景。将数据自动分不到多个Redis实例上，支持自动故障转移（如果某个实例失效，集群会自动重写配置和平衡，不需要手动进行调整，因为内置了哨兵逻辑） Sentinel哨兵模式: 哨兵模式用于保证主从节点的高可用，读写分离场景。如果主节点宕机，哨兵会将从节点升为主节点。 5. Redis 在生成 RDB 文件时如何处理请求？ 首先，Redis生成RDB文件的操作是异步的，由fork子线程进行，主线程用于处理客户端的请求。下面具体说明生成RDB文件的流程\n【生成RDB文件原理】\n使用bgsave命令，开启fork子线程进行操作 fork子线程会复制主线程对应的页表（里面包含了需要操作数据的物理地址） 如果过程中，主线程接收到写命令，需要修改数据。主线程会将对应数据的所在页面复制一份，子线程仍然指向老的页面。（老的数据才叫数据快照） 【注意事项】\nRDB处理的时间比较长，过程中会发生大量的磁盘I/O和CPU负载。如果RDB生成的时间过长，并且Redis的写并发高，就可能出现系统抖动的现象，应该选取Redis使用频率较低的时间段生成RDB文件。\n[补充] 5. Redis的持久化机制有哪些？ Redis的持久化机制分为三种，RDB 、AOF 和 混合持久化这三种方式。不过 RDB 和 AOF 各有优缺点，所以一般不会单独使用，而是采用混合持久化机制。\n持久化方案 说明 优缺点 适用场景 RDB 数据快照 将内存当中的数据定期保存为dump.rdb， 记录某个时刻的数据快照 文件小，性能高，恢复快。但是数据丢失风险高，fork会阻塞主进程。 适合低频备份的场景，比如冷备份，灾难恢复，全量数据加载(主从复制) AOF 追加日志 将每个写操作记录到日志文件appendonly.aof， 通过重放日志文件恢复数据 数据更安全，文件可读性强。但是文件体积大，恢复速度慢，性能开销大 适合对持久化实时性要求高的场景，例如金融交易，用户数据保存等。 混合持久化 结合RDB 和 AOF 的优点，先生成RDB快照文件，再记录快照之后的写操作到日志文件当中。 适合需要快速恢复且尽量保证减少数据丢失的场景，一般用于生产环境 下面具体说一下不同持久化机制的执行过程\n【RDB 持久化】\n定时生成 RDB：Redis定期根据配置触发 RDB 快照 （或者主动用bgsave命令手动触发） fork 子进程： 主进程判断是否有正在执行的子进程，如果有，直接返回。如果没有，则 fork 创建一个新的子进程用于持久化数据 （fork 的过程，主进程是阻塞等待的） 子进程更新RDB文件： 子进程将数据异步写入临时 RDB 文件，完成后替换旧的 RDB 文件。同时发信号给主进程，主进程更新一下 RDB 数据快照的统计消息 【注意】 采用bgsave 而 不采用save 命令的原因是，save 命令在生成 RDB文件的过程中，会阻塞Redis执行其他操作。\n那么子进程在生成RDB临时文件的过程中，如果客户端对Redis发起新的写操作。Redis同样可以处理这些命令, 这种方式就是写时复制技术。\n【写时复制技术】\nRedis在执行bgsave命令的时候，会通过fork 创建子进程。为了节约内存，父子进程是共享同一片内存数据的。创建子进程的时候，会复制父进程的也表，但是页表指向的物理内存还是同一个。当客户端向Redis发起新的写操作时，物理内存会被复制一份。子进程仍然指向之前的内存地址 (数据快照)，主进程指向复制的物理内存地址，并完成写操作。\n【优缺点】\n优点：写时复制技术可以减少子进程的内存消耗，加快创建速度(fork 子进程，会阻塞父进程)。由于子进程共享内存当中的数据，创建后可以直接读取主进程中的内存做数据，然后把数据写入RDB文件。 缺点：客户端在写时复制操作的时候，不会把新的数据记录到RDB文件中。如果Redis在生成RDB文件后，马上宕机，那么主进程新写入的这些数据都丢失了。另外，如果数据被修改，每次复制的过程都会制造两份内存，内存占用就是之前的两倍了。 【AOF 日志文件生成过程】\nAOF 是通过把Redis的每个写操作追加到日志文件 appendonly.aof 实现持久化的方式。Redis每次重启时,会重放日志文件的命令来恢复数据。口诀：先写内存，再写日志， 过大重写。\n先写内存：每次写操作都会被写入内存的AOF缓冲当中 再写日志：然后从AOF 缓冲中同步到磁盘 (三种写回策略) 过大重写：当AOF 文件过大的时候，Redis会触发AOF 重写，将冗余命令合并，生成新的AOF 文件 【注意】 先写内存，再存日志可以避免额外的检查开销 (只存执行成功的指令)，而且不会阻塞当前操作，指令只想成功后，才将命令记录到AOF日志文件。但是如果还没写完AOF 文件就宕机了，会导致数据丢失。执行写命令和记录到日志都是主线程操作，可能会造成阻塞风险。\n写会策略配置 写回时机 作用 always 同步写回 每次都fsync 同步数据到磁盘，性能最低。如果写入AOF文件期间Redis宕机，则无法通过AOF 进行恢复 everysec 每秒写回 每秒调用一次fsync写回磁盘，安全和性能居中，Redis最多丢1s的数据 no 操作系统决定写回时间 性能高，安全性低 【AOF重写机制】 当Redis检测到AOF 文件过大的时候，会触发AOF 重写机制\n创建子进程：Redis通过BGREWRITEAOF命令创建一个子进程来进行AOF 重写 生成新AOF 文件：子进程基于当前数据库状态，将每个键的最新值转换为写命令，并写入AOF文件 处理新写入的命令：重写期间，把客户端新的写操作同时追加到现有的AOF文件和缓存区的AOF重写缓冲里面 合并新的写入指令：子进程完成AOF文件重写之后，需要确保AOF文件当中的写操作都是最新的。 替换旧的AOF 文件： 最后用新的AOF文件替换旧的AOF文件 **【MP-AOF】**Redis 7.0 采用 Multi-Part Append Only File 解决 AOF 当中的内存开销大(AOF 缓存和AOF 重写缓存包含大量重复数据)、CPU开销大(主进程需要耗时将数据写入AOF 重写缓存，然后传给子进程，子进程要耗时把AOF 重写缓存写入新的AOF 文件)、磁盘开销大(同一份数据会被写入两次，一次写入当前AOF文件，另一次写入新AOF 文件)。其处理过程如下：\n将一个AOF文件拆分成多个文件\n一个基础文件 basefile, 代表数据的初始快照 一个增量文件 incremental files，记录自基础文件创建以来的所有写操作， 可以有多个该文件 基础文件和增量文会放到一个单独的目录中，并且由一个清单文件 manifest file 进行统一跟踪和管理 该方案可以避免写入多个和AOF相关的缓存，子进程独立写基础AOF文件，进程之间无交互，不用切换上下文。\n【为什么Redis需要持久化】 Redis是基于内存的数据库，所有数据存储在内存里面。如果Redis发生了宕机事件，内存中的数据就会全部丢失。为了保证数据的安全，Redis采用持久化机制，让数据保存在磁盘中，方便宕机后进行恢复。如果没有持久化机制，Redis需要从数据库(MySQL)当中恢复数据, 可能会出现下面的问题：\n**性能瓶颈 + 恢复缓慢 **：后端数据库无法向Redis一样快速提供数据。如果数据量比较大，恢复就会变得非常缓慢。 系统压力：恢复的过程比较久，就会给数据库带来很大压力，影响其他的业务。 6. Redis集群会出现脑裂问题吗？ 脑裂定义: 在网络分区的情况下，Redis同一个集群的实例当中出现多个主节点，导致数据不一致。\n脑裂发生的原因：比如当前集群实例是一主+两从的模式，当网络发送分区，分为A区和B区。主节点(原)被分到A区,其他节点和哨兵集群都在B区。哨兵机制无法检测到A区的原主节点, 只能重新选取新的主节点(新)。此时，集群当中就有两个主节点，A区的主节点(原)被写入的新数据不会同步到B区的节点上。会出现数据不一致的情况。\n如何避免脑裂：min-slaves-to-write 主节点写操作所要求有效从节点个数、min-slaves-max-lag 从节点的最大延迟。比如 min-slaves-to-write = 3 和min-slaves-max-lag = 10 表明需要至少3个延时低于10s的从节点才可以接受写操作。\n【注意】脑裂并不能够完全避免，比如说在选举主节点的过程中，主节点(原)突然恢复了，然后发现主节点和从节点的延迟都不超过10s，客户端正常在主节点(原)进行写操作。等选举完毕，选出新的主节点，让主节点(原) slaveof 为从节点。选举时间写入的数据会被覆盖，就出现了数据不一致的现象。\n7. Redis如何实现分布式锁？ 分布式锁原理：Redis分布式锁由set ex nx 和 lua 脚本组成，分别对应加锁和解锁操作\n为什么用 set ex nx：某个进程对指定key执行 set nx 之后， 返回值为1，其他进程想要对相同的key获取锁，会发现key已存在，返回值为0。这样就是实现了上锁的操作。但是，如果A进程上完锁突然挂了，其他进程就永远不可能拿到锁。所以，设置一个ex过期时间，让其不要一直占用着锁。\n【注意】set ex nx设置value的时候，必须采用唯一值，比如uuid。 不然可能出现如下情况:\nA进程正常申请锁，值设为1。 A进程上锁后, 执行过程时间比较长, 以至于锁已经过期了, A进程还没执行完. 此时，B进程申请锁，值也设为1. 同时，A进程执行完毕, 使用lua脚本把锁删除了 B进程此时还在执行程序，一脸懵逼。（不是，哥们儿，我锁呢？谁偷了我的锁！！！） 为什么用 lua 进行解锁：如上述注意事项所说的一样，A进程执行完毕之后, 会删除锁. 假如他们的值都采用了uuid保证了唯一性。可能会出现下面的情况\nA进程先判断key和其值是否为对应的uuid，然后再删除锁. A进程准备删除锁之前, 锁过期了. B进程同时获取了锁 A进程再删除了该锁 (B进程申请的锁)，发生了误删的现象 所以需要用lua脚本保证解锁的原子性，就可以避免上述问题\n8. Redis的Red Lock是什么？你了解吗? Red Lock定义: 一种分布式锁的实现方案，主要用于解决分布式环境中使用Redis分布式锁的安全性问题 为什么用Red Lock: 假如我们采用一主+两从+哨兵方式部署Redis，如果有A进程在使用分布式锁的过程当中，主节点发送了主从更换，但是原主节点的锁信息不一定同步到新主节点上。所以当前新主节点可能没有锁信息，此时另外的B进程去获取锁，发现锁没被占，成功拿到锁并执行业务逻辑。此时两个竞争者（A和B进程）会同时操作临界资源，会出现数据不一致的情况。 Red Lock实现原理 : 假如当前有五个实例，不需要部署从节点和哨兵，只需要主节点。注意当前的五个实例之间没有任何关系，不进行任何的信息交互 (不同于Redis Cluster集群模式)。对五个实例依次申请上锁，如果最终申请成功的数量超过半数(大于总数/2 + 1)，则表明红锁申请成功。按照下面的流程进行操作： 客户端获取当前时间 t1 客户端依次对五个实例进行set ex nx 操作，锁的过期时间为 t_lock (远小于锁的总过期事件)。如果当前节点请求超时，则立马请求下一个节点。 当获取的锁超过半数，则获取当前的时间 t2。获取锁的过程总耗时t = t2 - t1。如果t小于锁的过期时间 t_lock，则可以判断为加锁成功，否则加锁失败。 加锁成功，则执行业务逻辑。若加锁失败，则依次释放所有节点的锁。 Red Lock是否安全：先说结论，不一定安全\n当前有两个客户端(Client1 和 Client2)，首先Client1 正常获取锁，然后突然被GC执行垃圾回收机制了。在GC的过程当中，Client1 的锁超时释放了，Client2开始申请并获得锁。然后Client2 写入数据并释放锁。 后面Client1 在GC 结束之后又写入数据， 此时就出现了数据不一致的情况。\n9. 说说 Redisson 分布式锁的原理? 【Redisson分布式锁定义】\nRedisson分布式锁是一种基于Redis实现的分布式锁，利用Redis的原子性操作来确保多线程、多进程或多节点系统中，只有一个线程能够获得锁。避免并发操作导致的数据不一致问题。\n主要可以分为四个部分来讲：锁的获取、锁的续期、可重入锁、锁的释放\n【锁的获取】\n执行 exist ，判断锁是否存在 若存在 ，判断唯一标识是否对应。若唯一标识相同 -\u0026gt; 第 3 步 ; 若不同，说明当前锁别其他进程占用 -\u0026gt; 第2 步 若不存在 ，直接 tryLock() 上锁 -\u0026gt; 第 3 步 使用pttl查询锁剩余的过期时间，后续可以再次获取 执行hincrby，设置重入计数为1 （可重入锁才有这一步操作） 执行pexpire， 设置锁的过期时间 （为了防止任务还没执行完，锁就过期了。Redisson实现了用看门狗机制来为锁进行自动续期） 【可重入锁】\n一般是在线程已经获取锁的基础上，为了后续还能拿到锁。因为假如increment()和anotherMethod都需要用到Counter锁。当increment()拿到锁之后，又调用anotherMethod()又需要获取锁。如果不能二次获取锁，那就陷入死锁了。所以，Redisson才搞了可重入锁\npublic class Counter { private int count = 0; public synchronized void increment() { count++; anotherMethod(); } public synchronized void anotherMethod() { // 可以再次获取相同的锁 count++; } } 可重入锁是在获取锁的基础上，多了一层逻辑。具体实现如下：\n实现锁的获取的所有功能 执行hexist 判断是否锁已经存在，且唯一标识匹配(线程id相关)，所以不能直接用exist判断锁是否存在 如果自己的锁存在，用hincrby把重入次数加一 用pexpire，设置锁的过期时间 如果没有获取成功锁，就和上面一样，用pttl查询锁的过期剩余时间 【锁的释放】\n用hexist判断线程自己的锁是否存在，需要判断唯一标识 如果存在 -\u0026gt; 第2步 如果不存在 -\u0026gt; 直接返回，不需要做解锁操作，因为是别人的锁 用hincry减少一次锁的可重入次数 (增加-1 就是减少一次) 判断锁的可重入次数是否大于 0 如果大于 0， 说明还有函数在使用这个锁，则重新设置过期时间 如果等于 0 -\u0026gt; 第4步 用 del 删除对应的key 用 publish 广播通知其他等待锁的进程，此时释放锁了 【Redisson锁的类型】\n公平锁：和可重入锁类似，确保多个线程按请求顺序获得锁 读写锁: 支持读写分离，多个线程同时获得读锁，而且锁是独占的 信号量与可数锁: 允许多个线程同时持有锁，适用于资源的限流和控制。 10. Redisson 看门狗（watch dog）机制了解吗？ 【为什么用看门狗机制】\n因为如果进程获取锁之后，用户的业务逻辑还没有执行完成，锁就过期了。此时，其他进程抢占临界资源，会导致数据不一致的问题。\n【看门口机制的执行流程】\n判断用户是否设置过期时间 (判断 leaseTime \u0026gt; 0 ，默认 leaseTime 为 -1 ) 如果设置了过期时间，不启用看门狗机制，等到指定的过期时间，锁自动释放。 如果没有设置过期时间 -\u0026gt; 第2步 Redssion会启动一个定时任务，用于自动续期锁的过期时间。 定时任务中，设置锁的超时时间默认为30s， 每间隔总时长的1/3，也就是10s。定时任务会自动锁进行续期，续期时间为30s 当客户端主动释放锁，那么Redisson就会取消看门狗机制。 【注意】 如果客户端主动释放锁之前，服务器突然宕机了，定时任务没法儿继续执行。等看门狗机制设置的过期时间到了，锁就自动释放了。所以，不会出现一直占用锁的情况。\n11. Redis 实现分布式锁时可能遇到的问题有哪些？ 业务未执行完，锁提前到期：用户的业务逻辑还没执行完毕，锁提前过期了。被其他的进程获取了锁，同时抢占临界资源，可能出现数据不一致的情况。\n【解决方法】\n通常要保证用户的业务逻辑需要在锁过期之前执行完，因此需要把锁的过期时间稍微设大一些。也不能太大，这样其他程序就拿不到锁，就会降低系统的整体性能。或者使用Redisson分布式锁，会自动调用看门狗机制，定时续期锁，直到任务执行完毕，就不续期锁了。\n单点故障问题：如果只部署了一个Redis节点，当实例宕机或者不可用的时候。整个分布式锁服务将无法完成工作，阻塞业务的正常执行。\n【解决方法】\n可以利用Redis Cluster集群机制，部署多个Redis实例，采用一主+两从的哨兵机制。当某个实例宕机时, 哨兵会自动选举新的有效节点作为主节点。\n主从同步但锁未同步问题：主从复制的过程是异步实现的，如果Redis主节点获取到锁，但是还没同步到从节点。此时，主节点突然宕机，然后哨兵选择新的主节点。但是，由于主从同步没有完成，现在其他客户端可以正常获取锁。就会导致多个应用同时获取锁，会出现数据不一致的问题。\n网络分区问题：在网络不稳定的情况下，客户端和Redis可能会中断再重连。如果没有设置锁的过期时间，那么可能导致锁无法正常释放。如果有多个锁，可能还会引发死锁的现象。\n【多锁死锁现象】\n有两个资源A和B，分别由锁LockA和LockB保护。\n客户端1先获取LockA，然后尝试获取LockB。\n客户端2先获取LockB，然后尝试获取LockA\n如果客户端1拿到了LockA，客户端2拿到了LockB。突然网络不稳定，锁无法正常释放。然后客户端1等待LockB，客户端2等待LockA，就会形成死锁。\n时钟漂移问题：因为Redis分布式锁依赖锁的过期时间来判断是否过期，如果出现时钟漂移，很可能导致锁直接失效。\n【解决方法】\n让所有节点的系统时钟从NTP服务进行同步，减少时钟漂移的影响。\n可重入问题：某个进程可能有多次调用锁，如果锁不能重入的话。当进程获取到锁后，再次申请获取锁，获取不到就死锁了。\n12. Redis为什么这么快? 基于内存: Redis存储的所有数据都存在内存里面，内存的访问速度比硬盘快，提升了读写速度 单线程模型 + I/O多路复用： Redis采用单线程+I/O多路复用的方式，避免了线程上下文切换和竞争条件，提高了并发处理效率 高效数据结构：提供String、List、Hash、Set、Sorted Set 五种数据结构，他们的操作复杂度大部分为O(1) 异步持久化: 持久化操作由子线程异步完成，减少了持久化对主线程的影响，提升了整体性能。 【注意】Redis从6.0开始对网络处理引入了多线程机制，提高I/O性能。网络请求可以并发处理，减少网络I/O等待的影响。但是，Redis 仍然保持了核心命令处理逻辑的单线程特性。\n【I/O多路复用技术】\nLinux多路复用技术允许多个进程的I/O注册到同一管道和内核交互，准备好数据之后再copy到用户空间，实现一个线程处理多个I/O流。 Linux下I/O多路复用有select、poll、epoll 三种，功能类似，细节不同 13. 为什么 Redis 设计为单线程？6.0 版本为何引入多线程？ 【Redis采用单线程的原因】\n基于内存操作，Redis的瓶颈主要是内存，多数操作的性能瓶颈不是CPU带来的 (增加多线程也没啥用) 单线程模型的代码简单，可以减少线程上下文切换的性能开销。 单线程结合I/O多路复用模型，能提高I/O利用率 【注意】 Redis的单线程是指网络请求模块和数据操作模块是单线程的, 但是持久化存储模块和集群支撑模块是多线程的。\n【为什么引入多线程】\n随着数据规模和请求量的增加，执行瓶颈主要在网络I/O部分。引入多线程可以提高网络I/O的速度。但是，Redis内核去还是保持单线程处理，比如读写命令部分还是单线程，所以线程安全问题就不存在了。\n【Redis多线程I/O场景下的结构】\n14. 如何使用Redis快速实现布隆过滤器? Redis可以使用位图Bitmap或者用Redis模块RedisBloom来实现布隆过滤器\n位图 bitmap 实现 bitmap 本质是一个位数组，提供了setbit和getbit来设置和获取某个值，可以用来标识某个元素是否存在 对应给定的key，可以用哈希函数来计算位置索引。如果位图中的值为1， 表示该元素可能存在 RedisBloom 模块实现：封装了哈希函数和位图大小，可以直接用于创建和管理布隆过滤器 【布隆过滤器原理】\n布隆过滤器是由一个位数组+k个独立的哈希函数组成。每次验证某个key对应的数据是否存在的时候，需要k个哈希函数都对其进行运算，如果位数组中的值都为1，说明该key对应的数据可能存在。只要有一个位置不为1， 就说明key对应的数据一定不存在。\n为什么k个函数查到的值都为1， 也不能说明key对应的数据一定存在呢？\n因为可能存在哈希冲突，比如key 和 key1 的k个hash函数的值都为1。但是key对应的数据在数据库里面，但是key1的数据不在数据库里面。\n15. Redis 中常见的数据类型有哪些？ 【Redis常见的五种数据结构】\n数据结构名称 底层 特性 适用场景 String SDS 简单动态字符串 String字符串 1.缓存数据：缓存Session、Token、序列化后的对象\n2. 分布式锁:set ex nx\n3.计数：用户单位时间访问次数，页面单位时间访问次数 List ListPack / QuickList / ZipList / LinkedList 双向有序链表，各节点都包含字符串 1. 信息流展示：历史记录、更新文章、更新动态\n2.消息队列：不推荐，缺陷多 Hash Dict / ZipList 无序散列表，存储键值对 存储信息：用户、商品、文章、购物车信息 Set Dict / Intset 无序去重集合，包含不同的字符串 1.不重复数据：点赞次数、下单次数\n2.共同资源：共同好友、统统粉丝、共同关注 (交集、并集)\n3.随机抽取: 抽奖系统、随机点名 ZSet ZipList / SkipList 跳表 + HashTable哈希表 有序集合，value包含member 成员和score分数，按照score 进行排序 1.各类排行榜：点赞排行版、热门话题排行榜\n2. 优先级/重要程度: 优先级队列 【其他数据结构】\n数据结构名称 特性 适用场景 BitMap 存储二进制数据，0 和1 1. 布隆过滤器： 防止缓存穿透\n2. 签到统计： 每日签到用 1 标记，未签到用0标记，可以快速统计某日签到人数和连续签到天数 HyperLogLog 基于概率算法实现，存储海量数据进行计数统计 一般用于页面的页面浏览量PV和独立访客数UV， 快速估算访问量 GEO 存储地理位置信息，经纬度坐标和位置名称 一般用于计算不同位置的距离，比如外卖单中计算配送距离 Stream 能够生成全局唯一消息id的消息队列 用于可靠消息传递、异步任务处理的场景 16. Redis 中如何保证缓存与数据库的数据一致性？ 为了保证缓存和数据库的数据一致性，有这么几种方案：\n先修改缓存，再修改数据库\n事务A准备修改指定id的 name 为 小张 ，先修改缓存 事务B准备修改指定id的 name 为 小王，先修改缓存, 然后修改数据库为小王 事务A修改数据库为 小张 (网络延迟)， 此时出现数据不一致的情况 先修改数据库，再修改缓存\n事务A准备修改指定id的 name 为 小张 ，先修改数据库 事务B准备修改指定id的 name 为 小王，先修改数据库, 然后修改缓存为小王 事务A修改缓存为 小张 (网络延迟)， 此时出现数据不一致的情况 先删除缓存，再修改数据库\n事务B读取指定id的name， 发现找不到缓存，读取数据库中的数据为小王\n事务A准备修改指定id的 name 为 小张 ，先删除缓存，然后修改数据库为 小张\n事务B修改缓存为小王 (读到空数据，返回来写)，此时出现数据不一致的情况\n先修改数据库，再删除缓存：基本不会出现问题 （除非删除缓存的请求失败）\n延迟双删，先删除缓存，再修改数据库，再删除缓存： 难以评定休眠时间\n如果要保证数据库和缓存的强一致性怎么办？\n用消息队列：把写策略里面的删除缓存操作加入到消息队列中，让消费者来操作数据。如果删除失败，则可以冲消息队列中重新读取，在一定重试次数下删除成功的话，将该消息删除。 （确保删除缓存成功） binlog + Canal: 模仿MySQL主从同步的方式，结合Canal 订阅MySQL的binlog。其实就是等MySQL写入数据库, 然后去删除缓存。 如果需要避免缓存失效 (比如热点Key), 如何设计呢?\n分布式锁：同一时间只允许一个请求更新缓存，确保缓存和数据库一致。但是，可能会降低写性能 添加短暂过期时间：在先修改数据库再修改缓存的基础上，给缓存加一个短暂的过期时间，确保缓存不一致的情况时间比较少。 17. Redis 中跳表的实现原理是什么？ 跳表是由多层链表组成的，它是Redis中 ZSet 的底层结构。最底层存所有的元素，上层是下层的子集 (可以理解成一种索引)。跳表的插入、删除、查找操作，实现方式如下：\n查找：从最高层开始，通过范围确定位置，逐层向下查找，时间复杂度为 O(log n) 插入：从最高层开始，先逐层向下找到存放位置，然后随机确定新节点层数，插入并更新指针 删除：从最高层开始，通过范围确定位置，在各层更新指针保持结构 【Redis跳表结构】\nRedis的跳表相对于普通的跳表多了一个回退指针, 而且 score 是可以重复的。\n首先，我们可以看一下跳表的节点实现的原理\ntypedef struct zskiplistNode { //Zset 对象的元素值 sds ele; // 采用Redis字符串底层实现sds,用于存储数据 //元素权重值 double score; //后退指针 struct zskiplistNode *backward; // 用于指向前一个节点 //节点的level数组，保存每层上的前向指针和跨度 struct zskiplistLevel { struct zskiplistNode *forward; unsigned long span; // 当前层的跨度值 } level[]; } zskiplistNode; 上面的图片看起来比较抽象，可以按照下面的图片进行理解。上述的查找、删除、插入操作，其实都是先从level[0] 开始进行遍历，然后找到合适的位置。再往下进入level[1]进行遍历，再找到合适的位置。一直重复这个操作，直到进入最底层，然后就可以确定位置了。\n然后，我们来看一下跳表的底层实现原理\ntypedef struct zskiplist{ struct zskiplistNode *header, *tail, // 头节点和尾节点 unsigned long length,\t// 跳表长度 int level; // 跳表的最大层数 } zskiplist; 【注意】跳表的头节点、尾节点、跳表长度、跳表的最大层数都可以在o(1)时间复杂度进行访问\n【跳表查询过程细节】\n从头节点的最高层开始，逐一遍历每一层 遍历某一层节点时，根据节点的 SDS 类型元素和元素权重进行判断 如果当前节点权重 \u0026lt; 要查找的权重， 继续向前遍历 如果当前节点权重 = 要找的权重 \u0026amp;\u0026amp; 当前节点的 SDS 类型数据 \u0026lt; 要查找的数据，继续向前遍历 如果上面两个条件都不满足或者下一个节点为空，则跳到下一层level数组里面，继遍历续查找 如果当前当前节点权重 = 要找的权重 \u0026amp;\u0026amp; 当前节点的 SDS 类型数据 = 要查找的数据， 返回当前节点值，查询结束 【跳表的插入细节】\n参数检查和初始化：检查要插入的节点的score是否为NaN，初始化遍历指针x指向跳表的头节点，定义update 数组记录每层查找的最右节点 (后续要修改它的指针)，rank 数组记录每层跨越的节点数。 查找插入位置：和上面查找过程一样，从最高层开始，逐层往下查询。每一层中，把满足条件的最右节点记录在 update 数组中，并更新 rank 数组记录跨越的节点数。 生成新节点层数：调用zsRandomLevel 函数生新节点的随机层数。如果新节点层数 \u0026gt; 当前跳表总层数，则更新跳表最大层数，并初始化新增层的update 和 rank 数组数据。 创建并插入新节点：创建新节点，根据 update 和 rank 数组信息，在每一层插入节点，设置forward 指针 和 span 跨度值 更新其他节点的span值：对于没有触及到的层，更新 update 节点的 span 值 设置前后指针：设置新节点的backward指针，指向下一个节点。如果下一个节点为空，则更新跳表的tail指针。 更新跳表的长度：跳标的节点数 + 1， 返回插入的新节点指针。 【为什么ZSet要用跳表不用哈希表和平衡树】\n主要有三个原因：\n内存更少：跳表相比B树可以占用更少的内存，主要取决于如何设置节点层数的概率参数 局部性良好：跳表在执行ZRANGE 和 ZREVRANGE 等操作时，其缓存局部性表现良好，不比其他平衡树差 实现简单：跳表的代码更简单和易于调试 18. Redis Zset 的实现原理是什么？ ZSet 的实现方式有两种，第一种是压缩列表 Ziplist / 紧凑列表 Listpack，另一种是跳表 skiplist + 哈希表 HashTable。主要判断条件如下：\n元素数量 \u0026lt; zset-max-ziplist-entries zset压缩列表最大键值对个数 (默认是128) 每个元素大小(key 和 value 的长度) \u0026lt; zset-max-ziplist-value (默认为64) 【ZSet压缩列表结构】\nZSet 的 压缩列表结构和数组很相似，用一段连续的内存空间存储数据。每个节点都占用相邻的一小段内存，节点之间通过内存偏移量而非指针记录相对位置。\n【注意】压缩列表比传统的链表更加节省内存，但是压缩列表也有明显的缺点，它的修改成本高。\n倒序遍历都需要依赖上一个节点的长度prevlen，如果当前节点有修改，后续节点就需要修改prevlen 当prevlen \u0026gt; 当前节点编码类型的最大大小时，就需要改变编码类型，重新分配内存 后继节点重新分配内存后，其他后面的节点都会面临同样的情况，导致发生连锁更新。 压缩列表的头部分别有记录了三个重要属性：\n列表大小zlbytes: 整段列表在内存中占用的字节数 尾节点位置 zltail：从队列头到最后一个节点起始位置的内存偏移量。 节点数量 zllen： 总共的节点个数 每个节点当中又可以化分为三个部分：\n上一节点长度 prevlen：用于倒序遍历时确认上一节点的位置 节点编码 encoding：同时记录了长度和编码类型 数据 data：节点中存放的数据 【ZSet紧凑列表结构】\n紧凑列表的头部分别有记录两个重要属性：\n列表大小size: 整段列表在内存中占用的字节数 列表元素数量num：总共的元素个数 每个节点当中又可以化分为三个部分：\n节点编码 encoding：同时记录了长度和编码类型 数据 data：节点中存放的数据 节点长度len：节点编码encoding + 数据data的总长度。正向或反向遍历都依赖它完成 紧凑列表相比压缩列表的优点：无需记录上一节点的长度，上一节点重新分配内存后，本身节点无需做任何修改。\n【跳表 + 哈希表】\n当ZSet 处理比较大的数据的时候，会选择跳表+哈希表的方式。其中，跳表的节点保存指向member的指针和score，哈希表保存member和score之间对应的关系，方便实现高效的随机查找和范围查找。\n跳表的具体实现细节可以参考17. Redis Zset 的实现原理是什么？\n19. Redis 的 hash 是什么？ Hash 是 Redis五大常规数据结构(String、List、Hash、Set、ZSet)的一种，主要用于存储key-value 键值对集合。Hash 一般会用来存储商品的属性、用户的信息等等。\n【Hash底层数据结构】\nHash 的底层数据结构要分为Redis 6.0 和 7.0来看\nRedis 6.0: 压缩列表 zipList + 哈希表 HashTable Redis 7.0: 紧凑列表 Listpack + 哈希表 HashTable 当Hash当中的数据达到指定的阈值的时候，就会从压缩列表zipList/紧凑列表ListPack 转为哈希表HashTable。当满足下面两个条件的时候才能用压缩列表zipList/紧凑列表ListPack\n哈希类型的个数 \u0026lt; 哈希紧凑列表最大键值对个数 hash-max-listpack-entries (默认是512) 哈希的 key 和 value 的长度 \u0026lt; hash-max-ziplist-value 64 【为什么Hash会选择压缩列表 zipList /紧凑列表 ListPack呢?】\nHash 结构采用压缩列表 zipList /紧凑列表 ListPack的主要目的应该是基于省内存的角度去考虑。主要有两个原因吧：\n内存占用少： 压缩列表 zipList 和 紧凑列表 ListPack 都属于紧凑型的内存结构，没有哈希表那样存在额外的指针开销。哈希表为了维持快速查找的特性，内部才用了链表解决哈希冲突，每个哈希桶的内部都会带有指针，比较占用内存空间。另外的两个数据结构主要通过将数据存储在一块连续的内存，利用了计算机的局部性原理，从而使得内存占用最小。 时间复杂度：哈希表的访问速率是O(1)，但是如果冲突比较多，最坏也会降到(O(n))。因为冲突之后，就需要遍历链表或者查红黑树。但是 压缩列表 zipList 和 紧凑列表 ListPack 是连续数组存储，肯定能在O(1)的时间找到这个元素 【Redis中HashTable的结构】\nHashTable 就是由哈希表数组实现的，查询时间复杂度为O(1)， 效率比较快。具体数据结构如下\ntypedef struct dictht { //哈希表数组 dictEntry **table; //哈希表大小 unsigned long size; //哈希表大小掩码，用于计算索引值 (index = hash(key) \u0026amp; sizemask), sizemask = size - 1 unsigned long sizemask; //该哈希表已有的节点数量 unsigned long used; } dictht; 哈希节点dictEntry 由三个key、value 和 下一个哈希节点指针next组成\ntypedef struct dictEntry { //键值对中的键 void *key; // 键值对中的值 union { void *val; // 用于指向实际值的指针，比如存放string uint64_t u64; int64_t s64; double d; } v; //指向下一个哈希表节点，形成链表 struct dictEntry *next; } dictEntry; 【渐进式扩容rehash】\nRedis中的hash表结构会随着数据量的增大而扩容, 将数组的大小扩张为原来的两倍。在扩张的过程当中，由于容量的变化，会导致之前的节点，移动到新的位置，这个变化的过程就是 rehash 实现的。\nrehash 扩容的过程可以分为一下三步:\n增加哈希表2的空间：给哈希表2分配空间，一般是哈希表1的两倍。此时，rehash 索引的值rehashidx 从 -1 暂时变成 0。 迁移数据：将哈希表1的数据迁移到哈希表2 （迁移的过程，一般是在对指定节点做增删改查的时候，所以叫渐进扩容，有点类似 ConcurrentHashMap 的扩容机制），迁移之后，rehashidx + 1。 迁移过程分为多次完成。 释放原哈希表1：迁移完成之后，哈希表1的空间会被释放，并且把哈希表2设置为哈希表1。然后，哈希表2再创建一个空白的哈希表。为下一次 rehash 做准备。 【注意】 rehash的出发条件和其负载因子相关，负载因子 = 已存储的哈希表节点数量 / 哈希表总容量 。当达到下面的任一条件就可能触发。\n负载因子 \u0026gt;= 1 ， 资源相对紧张，如果Redis没有在执行bgsave 和 bgrewriteAOF 命令 (生成RDB文件和AOF文件)，就会触发 负载因子 \u0026gt;= 5，资源非常紧张，直接触发 20. Redis String 类型的底层实现是什么？（SDS） Redis中的 String 类型的底层实现是简单动态字符串 SDS, 结合 int 、embstr 、raw等不同的编码方式进行优化存储。\n【简单动态字符串 SDS 结构】\nlen 字符数组长度：表示整个 SDS 字符串数组的长度，获取长度时直接返回该值 (时间复杂度 o(1)) alloc 分配内存： 表示已分配字符数组的存储空间大小，通过alloc - len 可以计算剩余空间。可用于判断是否满足修改要求，解决缓冲区溢出的问题。 flags SDS类型: 一共有 sdshdr5、sdshdr8、sdshdr16、sdshdr32、sdshdr64 五种类型，后面的数字表示2的幂次方，能够灵活存储不同大小的字符串，节省内存空间 buf 存储数据的字符数组： 用于保存字符串，二进制数据等 struct __attribute__ ((__packed__)) sdshdr64 { uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; 【Redis底层结构 redisObject】\nBTW, Redis的底层结构就是redisObject。\nredisObject 包含数据类型，编码类型和数据指针三个元素。其中编码类型，包含int、embstr、raw 等类型\nstruct redisObject { unsigned type:4; // 数据类型（字符串、哈希等） unsigned encoding:4; // 编码类型（int、embstr、raw等） int64_t ptr; // 实际的数据指针，这里直接存储整数值 }; redisObject 的具体编码类型由下面几个条件决定：\n如果字符串对象保存的整数值能用long 类型表示，该对象会把整数值存储到ptr 数据指针指向的long 结构里面 （将 void* 转为 long），并将编码设置为int 如果字符串对象保存的字符串长度 \u0026lt;= 32 个字节，会用 上面提到的sds 保存字符串，并且把对象编码设置为embstr。 如果字符串对象保存的字符串长度 \u0026gt; 32 个字节，也会用上面提到的sds 保存字符串，并且把对象编码设置为raw。 【注意】\n上面32个字节是redis 2.0版本，redis 5.0 版本是44 个字节 embstr 和 raw编码区别：embstr 只调用一次内存分配函数，分配一块连续内存保存redisObject和 SDS。raw 调用两次内存分配函数，分别分配两块内存空间保存 redisObject 和 SDS。 21. Redis 中的缓存击穿、缓存穿透和缓存雪崩是什么？ (缓存三兄弟) 问题类型 说明 解决方案 缓存穿透 查询的数据是不存在的，数据库和缓存都没有。所有的请求都会绕过缓存，直接打到数据库上，可能会遭受恶意攻击。 1.请求参数校验 2. 缓存空值 3. 布隆过滤器 缓存雪崩 大量的缓存同时失效或者Redis宕机了，导致请求直接打到数据库，可能造成系统崩溃。 1. 设置随机过期时间 2.Redis 高可用集群 3.服务熔断或限流 缓存击穿 某个热点数据缓存失效，大量并发请求直接访问数据库，导致数据库压力剧增，性能下降。 1. 互斥锁 2. 逻辑过期 【缓存穿透具体解决方案】\n请求参数校验：如果请求参数含有非法字段，则直接返回错误，避免进一步查询缓存和数据库\npublic boolean validateRequest(String key) { if(key == null || key.isEmpty()) { return false;\t} } 缓存空值：如果查到不存在的数据，也将其存入缓存，value 采用 ”null“ 字符串。后续查询，直接返回给用户。\npublic Object getDataWithEmptyCache(String key) { //先从缓存中获取数据 String value = redisTemplate.opsForValue().get(key); //如果缓存为空 if (value == null) { Object databaseValue = queryFromDatabase(key);\t//从数据库中获取 if (databaseValue == null) { //缓存空值 redisTemplate.opsForValue().set(key, \u0026#34;null\u0026#34;, 60, TimeUnit.SECONDS); return null; } else { redisTemplate.opsForValue().set(key, databaseValue, 3600, TimeUnit.SECONDS); return databaseValue; } } return \u0026#34;null\u0026#34;.equals(value) ? null : value; // 如果是空值缓存，返回 null } 布隆过滤器：写入数据库时用布隆过滤器做一个标记，然后在用户请求的时候，确认缓存失效了。先通过布隆过滤器快速判断数据是否存在，如果不存在就直接返回。但是，布隆过滤器在一定程度上会出现误判。 因为可能会出现哈希冲突，导致一小部分请求穿透到数据库。 可以采用第三方工具类 Guava 实现布隆过滤器 ）\npublic class TestBloomFilter { public static void main(String[] args) { /** * 构造: * 第二个参数: expectedInsertions 期望插入的元素数量 * 第三个参数: 预测错误率 传入 0.01 表示预测正确的概率是 99% * */ BloomFilter\u0026lt;Integer\u0026gt; filter = BloomFilter.create( Funnels.integerFunnel(), 500, 0.01 ); filter.put(1); filter.put(2); filter.put(3); Assert.assertTrue(filter.mightContain(1)); Assert.assertTrue(filter.mightContain(2)); Assert.assertTrue(filter.mightContain(3)); Assert.assertFalse(filter.mightContain(1000)); } /* 当我们设计布隆过滤器时，为预期的元素数量提供一个合理准确的值是很重要的。 否则，我们的过滤器将以比期望高得多的比率返回误报。 让我们看一个例子。 假设我们创建了一个具有 1% 期望误报概率和预期一些元素等于 5 的过滤器， 但随后我们插入了 100,000 个元素： */ @Test public void testOverSaturatedBloomFilter() { BloomFilter\u0026lt;Integer\u0026gt; filter = BloomFilter.create( Funnels.integerFunnel(), 5, 0.01); IntStream.range(0, 100_000).forEach(filter::put); Assert.assertTrue(filter.mightContain(1)); Assert.assertTrue(filter.mightContain(2)); Assert.assertTrue(filter.mightContain(3)); Assert.assertFalse(filter.mightContain(1000000)); //测试不通过 } } 【缓存雪崩具体解决方案】\n缓存雪崩要分为两种不同的情况来解决：大量key同时过期 和 Redis宕机\n【大量key同时过期】\n设置随机的过期时间：写入缓存的时候，给其在基础时间上 + 一个随机的过期时间 互斥锁： 保证同一时间只有一个请求来构建缓存 后台更新缓存：后台采用Scheduled 的方式检查缓存是否失效，如果失效了，就查询数据库更新缓存。 【Redis宕机】\n服务熔断或者限流机制：暂定服务对于缓存服务的访问，直接返回错误。或者启用限流规则，只允许商家请求发送数据库进行处理，过多的请求就会拒接。一般会使用Hystrix 或者 Sentinel 实现熔断或者限流\n@HystrixCommand(fallbackMethod = \u0026#34;fallbackMethod\u0026#34;) public String getDataFromCache(String key) { // 从 Redis 获取数据 return redisTemplate.opsForValue().get(key); } public String fallbackMethod(String key) { return \u0026#34;服务繁忙，请稍后重试！\u0026#34;; // 熔断处理逻辑 } 构建Redis缓存高可用集群: 如果单个缓存服务节点发生故障自动迁移访问流量到另外一个节点.\n【缓存击穿具体解决方案】\n互斥锁：同一时间只允许一个业务线程更新缓存。未获取互斥锁的请求，可以等待锁释放后读取缓存，或者返回空值/默认值。 (对数据一致性要求比较高)\n逻辑过期：不给缓存设置过期时间，value 采用 hash 的方式，设置一个逻辑过期时间。每次判断数据是否过期，未过期直接返回数据。如果已经过期了，则获取互斥锁重建缓存，然后释放锁。如果获取互斥锁失败，则返回已过期缓存数据。\n服务熔断或者限流机制\n22.Redis 数据过期后的删除策略是什么？ 【Redis过期删除策略】\nRedis采用的是 定期删除 + 惰性删除 的结合方式\n策略 实现方式 优缺点 定期删除 Redis每个一段时间 (默认为100ms 随机检查 一定数量的键，非全部key)，过期则删除 可以减少内存占用, 但是对CPU有一定消耗，且不能保证及时删除所有过期键 惰性删除 当客户端访问一个key时，Redis会检查是否过期，若过期则立即删除 对CPU友好，大量过期键未被访问时仍占用内存 【定期删除细节】\nRedis会周期性执行过期key检查，默认每100ms 执行一次 每次检查会随机抽取部分key，默认每次 20 个， 判断是否过期 为了避免过多的CPU占用，Redis限制检查的执行时间 (默认为执行时间的25%，也就是25ms) 和 过期键的比例 (默认只检查 10% ) 如果过期间比例超过限制，则会重复检查以提高清理效率 【为什么Redis删除不直接吧所有过期key都删除了？】\n定期删除不能除所有过期key原因: 如果一次性清理所有过期间,可能会导致Redis长时间阻塞，影响性能。随机抽样和时间限制的方式能在清理内存和性能之间取得平衡。 惰性删除不能删除所有过期key原因：惰性删除旨在访问key的时候触发，如果没有被访问到，就可能一致存在，无法清理。 【如何优化大量key集中过期的情况 - 缓存雪崩】\n设置随机过期时间：设置过期时间的时候，加上一个随机值 开启lazy free 机制： 配置 lazyfree-lazy-expire， 让过期的key删除操作由后台线程异步执行，减少主线程的压力 23. 如何解决 Redis 中的热点 key 问题？ 热点 key 是指访问频率显著高于其他 key 的键，通常表现为以下几种情况：\n类别 特性 QPS 集中 某个key 的QPS (每秒请求量) 占Redis总QPS的较大比例 带宽集中 某个key 的数据量较大(比如1MB 以上的hash 数据)，被频繁请求 CPU消耗集中 某个key的复杂操作(比如ZRANGE查询较大的ZSet数据) 占用Redis过多CPU时间 热点key 问题就是某个瞬间，大量的请求集中访问Redis里的同一个固定key，假如热点key过期，可能会导致缓存击穿，让大量的请求直接打到数据库里面。像热点新闻、热点评论、明星直播 这种读多写少的场景，就很容易出现热点key 问题。因为Redis的单节点查询性能一般在 2w QPS， 一般超过 这个数值，可能就会宕机。\n【热点key的危害】\n消耗CPU和带宽资源： 热点 key 可能占用Redis大部分资源，影响其他请求的处理时间 Redis宕机风险: 如果超过Redis所能承载的最大QPS， 可能会导致Redis宕机。然后大量的请求转发到后端数据库，导致数据库崩溃。 【如何发现热点key】\n根据业务经验判断：比如像明星八卦爆料、重大新闻、热点评论都会能会导致热点key。 好处是不需要消耗什么成本，坏处是无法预防突发情况。 Redis进行集群监控： 查看哪个Redis出现了 QPS 倾斜，出现QPS倾斜的实例有很大概率存在热点key hotkey 监控：命令行执行redis-cli 的时候添加--hotkeys 参数，它是基于scan + object freq 扫描目标出现频率时间的。但是需要设置maxmemory-policy 参数，来采用不同的淘汰手段： volatile-lfu (least frequently used)： 淘汰已经过期数据集中最不常用的数据 allkeys-lfu：当内存不足的时候，移除最不常用的key monitor 命令： 集合一些Redis的日志和相关分析工具进行统计, 非常消耗性能, 单客户端会消耗 50% 的性能 代理层收集：利用有些服务在请求Redis前会先请求代理服务的特点, 在代理层统一收集Redis热key数据。比如采用 京东的 JD-hotkey、有赞透明多级缓存解决方案(TMC) 客户端收集：在操作Redis前添加统计每个key的查询频次，将统计数据发送到聚合计算平台计算，之后查看结果。对性能消耗较低，但是成本比较大，需要介入聚合计算平台。 【如何解决热点key】\n多级缓存：结合使用一级缓存和二级缓存。一级缓存就是应用程序的本地缓存，比如JVM内存中的缓存，可采用Caffeine 、阿里巴巴jetcache )。 二级缓存是Redis缓存，当以及缓存中不存在的时候，再访问二级缓存。\n针对热点key请求, 本地一级缓存可以将同一个key的大量请求，根据网络层负载均衡到不同的机器节点上，避免全部打到单个Redis节点的情况，减少网络交互。但是需要耗费更多的经历去保证分布式缓存一致性，会增加系统复杂度。\n热点key备份：在多个Redis节点上备份热key，避免固定key总是访问同一个Redis节点。通过初始化时为key 拼接 0~2n (n为集群数量) 之间的随机数，让其散落在各个姐电商。若有热点key请求的时候，随机选一个备份的节点进行取值。可以有效减轻单个Redis节点的负担。 热点key拆分：将热点key拆分为多个带后缀名的key，让其分散存储在多个实例当中。客户端请求的时候按照规则计算出固定key，然后请求对应的Redis节点。比如“某音热搜某明星离婚”。可以拆分为多个带编号后缀的key存储在不同的节点，用户查询时根据用户id 算出要访问的对应节点。虽然用户只能看到一部分数据，等待热点降温后再汇总数据，挑选优质内容重新推送给未收到的用户。 【注意】 热点key备份和热点key拆分的区别在于，热点key备份是同一份数据全量复制到其他节点，热点key拆分是把一份数据拆分成多份。\nRedis集群 + 读写分离: 增加Redis从节点, 分散读请求压力。然后利用集群，可以将热点key拆分或者备份到不同的Redis实例上。 限流和降级：采用限流策略，减少对Redis的请求，在必要的时候返回降级的数据或者空值。 24. Redis 中的 Big Key 问题是什么？如何解决？ Redis当中的 Big Key (也可以叫big memory key)是指某个key 对应的value数据量过大，比如包含大量元素的List、Hash、Set、ZSet 或超长字符串), 可能会导致性能瓶颈和系统不稳定。 一般来说，String 类型的value 超过 1MB ，或者符合类型当中的元素超过5000个，就算big key。\n【Big Key 典型场景】\nString: 存储超大JSON文本、图片base64数据等 Hash：存储海量的字段，比如用户的行为记录 List / Set：存储百万个元素 ZSet： 包含大量的排序元素 【Big Key 导致的问题】\n性能问题：Redis是单线程处理机制，在处理big key的时候，需要更长的时间，阻塞工作流程，没法儿处理后面的命令。如果处理的时间过长，会导致客户端长时间未收到响应。另外，big key 占用的带宽过高，传输时间比较长，也容易导致阻塞。 内存问题：big key 会导致Redis内存变得很大，增加内存碎片化风险。单次大对象内存分配失败，可能导致整个Redis服务崩溃。集群模式下，会出现数据和查询倾斜的情况，big key 的 Redis节点会占用较多的内存 持久化问题：如果AOF写回策略为always，也就是说主线程执行完指令之后，把对应数据写入AOF文件后，直接 fsync 写入磁盘操作。如果是一个大key， 阻塞的时间可能比较就，同步到硬盘的过程很耗时。 【如何找Big Key】\n内置--bigkeys： 采用内置的--bigkeys命令，基于scan 查找所有的big key\nredis-cli --bigkeys 使用第三方工具\nhttps://github.com/sripathikrishnan/redis-rdb-tools https://github.com/weiyanwei412/rdb_bigkeys 【如何处理Big Key问题】\nBig Key 问题可以从下面说三个层面来解决：\n开发层面：将数据压缩后再存; 将大JSON对象拆分为多个小字段; 将数据保存为更合理的数据结构 (利用hash替代大字符串); 避免会造成阻塞的命令\n业务层面：调整存储策略，只存储必要的数据 (比如用户的收货地址等不常用信息不存储，只存储用户ID、姓名、头像等); 优化业务逻辑，使用更小的数据来满足业务要求; 规划好数据的生命\n架构层面：采用Redis集群的方式进行Redis部署，然后将大Key拆分散落到不同的服务器上面, 加快响应速度\n","permalink":"https://swimmingliu.cn/posts/job/redis-interview-questions/","summary":"\u003ch2 id=\"1-redis主从复制的原理\"\u003e1. Redis主从复制的原理\u003c/h2\u003e\n\u003cp\u003e【\u003cstrong\u003e主从复制的原理\u003c/strong\u003e】\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e同步：从节点向主节点发送\u003ccode\u003epsync\u003c/code\u003e命令进行同步，从节点保存主节点返回的 \u003ccode\u003erunid\u003c/code\u003e 和 \u003ccode\u003e offset\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e全量复制：如果是第一次连接或者连接失败且\u003ccode\u003erepl_backlog_buffer\u003c/code\u003e 缓存区不包含\u003ccode\u003eslave_repl_offset\u003c/code\u003e， 则生成主节点的数据快照(RDB文件)发给从节点\u003c/li\u003e\n\u003cli\u003e增量复制：全量复制完毕后，主从节点之间会保持长连接。如果连接没有断开或者\u003ccode\u003eslave_repl_offset\u003c/code\u003e仍然在\u003ccode\u003erepl_backlog_buffer\u003c/code\u003e中，则将后续的写操作传递给从节点，让数据保持一致。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e【全量复制细节】\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e全量复制的过程是基于TCP长连接的，主要流程如下\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e从节点发送\u003ccode\u003epsync ? -1\u003c/code\u003e表示需要建立连接进行同步，主节点返回主节点ID \u003ccode\u003erunid\u003c/code\u003e 和 复制进度\u003ccode\u003eoffset\u003c/code\u003e (第一次同步用 -1 表示)。从节点接受之后，保存主节点的信息。\u003c/li\u003e\n\u003cli\u003e主节点执行\u003ccode\u003ebgsave\u003c/code\u003e命令生成数据快照RDB文件，然后将RDB文件发送给从节点。从节点接受文件后，清除现有的所有数据，然后加载RDB文件\u003c/li\u003e\n\u003cli\u003e如果在制作数据快照RDB文件的过程当中，主节点接收到了新的写操作，主节点会将其记录在\u003ccode\u003erepl buffer\u003c/code\u003e 里面。然后将\u003ccode\u003erepl buffer\u003c/code\u003e当中的写操作发给从节点，让其数据保持一致。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg alt=\"Redis主从全量复制\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/ac630d4c-ef8d-11ef-a882-c858c0c1deba\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【增量复制细节】\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e如果主从节点意外断开连接，为了保持数据的一致性，必须重新同步数据。如果使用全量复制来保持一致性的话，开销太大，所以采用增量复制。\u003c/p\u003e\n\u003cp\u003e增量复制的具体流程如下：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e连接恢复后，从节点会发送\u003ccode\u003epsync {runid} {offset}\u003c/code\u003e， 其中主节点ID \u003ccode\u003erunid\u003c/code\u003e 和 复制进度\u003ccode\u003eoffset\u003c/code\u003e用于标识是哪一个服务器主机和复制进度。\u003c/li\u003e\n\u003cli\u003e主节点收到\u003ccode\u003epsync\u003c/code\u003e 命令之后，会用\u003ccode\u003econitnue\u003c/code\u003e响应告知从节点，采用增量复制同步数据\u003c/li\u003e\n\u003cli\u003e最后，主节点根据\u003ccode\u003eoffset\u003c/code\u003e查找对应的进度，将断线期间未同步的写命令，发送给从节点。同时，主节点将所有的写命令写入\u003ccode\u003erepl_backlog_buffer\u003c/code\u003e， 用于后续判断是采用增量复制还是全量复制。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e【注意】从节点 \u003ccode\u003epsync\u003c/code\u003e 携带的 \u003ccode\u003eoffset\u003c/code\u003e 为 \u003ccode\u003eslave_repl_offset\u003c/code\u003e。如果 \u003ccode\u003erepl_backlog_buffer\u003c/code\u003e包含\u003ccode\u003eslave_repl_offset\u003c/code\u003e 对应的部分，则采用增量复制，否则采用全量复制。\u003ccode\u003erepl_backlog_buffer\u003c/code\u003e的默认缓冲区大小为\u003ccode\u003e1M\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"Redis主从增量复制\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/ac9f21a3-ef8d-11ef-9016-c858c0c1deba\"\u003e\u003c/p\u003e\n\u003cp\u003e【\u003cstrong\u003e为什么要主从复制\u003c/strong\u003e】\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e备份数据\u003c/strong\u003e：主从复制实现了数据的热备份，是持久化之外的数据冗余方式\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e故障恢复\u003c/strong\u003e：当主节点宕机之后，可以采用从节点提供服务。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e负载均衡\u003c/strong\u003e:  主从复制实现了读写分离，只有主节点支持读写操作，从节点只有读操作。在读多写少的场景下，可以提高Redis服务器的并发量。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Redis主从读写分离\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/acad0d12-ef8d-11ef-b17f-c858c0c1deba\"\u003e\u003c/p\u003e\n\u003ch2 id=\"2-redis集群的实现原理是什么\"\u003e2. Redis集群的实现原理是什么?\u003c/h2\u003e\n\u003cp\u003e【\u003cstrong\u003eRedis集群基本知识\u003c/strong\u003e】\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e定义\u003c/strong\u003e: Redis集群由多个实例组成，每个实例存储部分数据 (每个实例之间的数据不重复) 。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e【注】集群和主从节点不是一个东西，集群的某一个实例当中可能包含一个主节点 + 多个从节点\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e为什么用\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e问题\u003c/th\u003e\n          \u003cth\u003e解决方案\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e容量不足\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e数据分片，将数据分散不存到不同的主节点\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e高并发写入\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e数据分片，将写入请求分摊到多个主节点\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e主机宕机问题\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e自动切换主从节点，避免影响服务， 不需要手动修改客户端配置\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e节点通信协议\u003c/strong\u003e：Redis集群采用Gossip协议, 支持分布式信息传播、延迟低、效率高。采用去中心化思想，任意实例(主节点)都可以作为请求入口，节点间相互通信。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e分片原理\u003c/strong\u003e： 采用哈希槽(Hash Slot)机制来分配数据，整个空间可以划分为\u003cstrong\u003e16384\u003c/strong\u003e (16 * 1024)个槽。 每个Redis负责一定范围的哈希槽,数据的key经过哈希函数计算之后对\u003cstrong\u003e16384\u003c/strong\u003e取余可定位到对应的节点。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Redis集群架构图\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/acc54635-ef8d-11ef-971e-c858c0c1deba\"\u003e\u003c/p\u003e","title":"Redis面试题笔记"},{"content":"1. 说说 Java 中 HashMap 的原理？ 【HashMap定义】\n结构：数组 + 链表 + 红黑树 (JDK 1.8 之后)\n默认值：初始容量为16 (数组长度)，负载因子为 0.75。当存储的元素为 16 * 0.75 = 12个时，会触发Resize() 扩容操作，容量 x 2 并重新分配位置。但是扩容是有一定开销的，频繁扩容会影响性能。另外，TREEIFY_THRESHOLD 转换为红黑树的默认链表长度阈值为 8, UNTREEIFY_THRESHOLD 从红黑树转换为链表的阈值为 6。 两个阈值采用不同值的原因是防止刚转换为红黑树，又变成链表，反复横跳，消耗资源。\n数组下标位置计算方法：首先使用key的hashCode()方法计算下标位置，然后通过 indexFor() (JDK 1.7 以前) 计算下标值。 JDK 1.7后，为了提高计算效率采用 (len - 1) \u0026amp; hash 来确定下标值。\n【注】数组的长度len 是2的幂次方时，(len - 1) \u0026amp; hash 等价于 hash % len。 这也是为什么数组长度必须是2的幂次方。\n【HashMap线程不安全】\n为了保证HashMap的读写效率高，它的操作是非同步的，也就是说读写操作没有锁保护。所以多线程场景下是线程不安全的。\n【HashMap不同版本区别】\nJDK 1.7: 数组 + 链表，链表部分采用头插法，多线程会导致出现环形链表。扩容会计算每个元素hash值，并分配到新的位置，开销大。 JDK 1.8：数组 + 链表 + 红黑树，采用高低位置来分配位置，即判断(e.hash \u0026amp; oldCap) == 0， 减少了计算hash的次数 【HashMap的PUT方法】\nHashMap在存储数据时，按照如下流程：\n判断数组table是否为空或长度为0，如果是第一次插入，需要对数组进行扩容 Resize() 计算key的数组索引值 index = hash(key) \u0026amp; (len - 1) 得到索引i , len 表示数组长度 判断table[i]是否为空？ 若为空，则直接插入 -\u0026gt; 第7步 若不为空 -\u0026gt; 第4步 判断key是否存在 若存在，直接覆盖 -\u0026gt; 第7步 若不存在 -\u0026gt; 第5步 判断table[i]是否为TreeNode 如果是TreeNode ，在红黑树中插入/覆盖 (同第4步，判断key是否存在) -\u0026gt; 第7步 如果不是 -\u0026gt; 遍历链表 -\u0026gt; 在链表中插入/覆盖 (同第4步，判断key是否存在) -\u0026gt; 第6步 如果是链表插入节点，判断链表长度listLen 是否 \u0026gt;= TREEIFY_THRESHOLD, 默认为8 如果 listLen \u0026gt;= 8，转换为红黑树 -\u0026gt; 第7步 如果 listLen \u0026lt; 8 -\u0026gt; 第7步 元素个数自增，判断是否大于阈值 threshold， 其中threshold = len * factor 默认为 16 * 0.75 = 12。若超过阈值，则对数组扩容 Resize() 【HashMap的GET方法】\n计算key的数组索引值 index = hash(key) \u0026amp; (len - 1) 得到索引i , len 表示数组长度 判断table[i]是否直接key.equals(k)命中 命中 -\u0026gt; 返回结果 未命中 -\u0026gt; 第3步 判断第一个节点是否为TreeNode 若是TreeNode，在红黑树中查找 若不是，遍历链表查找 返回查找结果 【Resize扩容操作】\nResize() 源码如下\n/** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */ final HashMap.Node\u0026lt;K,V\u0026gt;[] resize() { HashMap.Node\u0026lt;K,V\u0026gt;[] oldTab = table; // 记录Map当前的容量 int oldCap = (oldTab == null) ? 0 : oldTab.length; // 记录Map允许存储的元素数量，即阈值（容量*负载因子） int oldThr = threshold; // 声明两个变量，用来记录新的容量和阈值 int newCap, newThr = 0; // 若当前容量不为0，表示存储数据的数组已经被初始化过 if (oldCap \u0026gt; 0) { // 判断当前容量是否超过了允许的最大容量 if (oldCap \u0026gt;= MAXIMUM_CAPACITY) { // 若超过最大容量，表示无法再进行扩容 // 则更新当前的阈值为int的最大值，并返回旧数组 threshold = Integer.MAX_VALUE; return oldTab; } // 将旧容量*2得到新容量，若新容量未超过最大值，并且旧容量大于默认初始容量（16）， // 才则将旧阈值*2得到新阈值 else if ((newCap = oldCap \u0026lt;\u0026lt; 1) \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; oldCap \u0026gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr \u0026lt;\u0026lt; 1; // double threshold } // 若不满足上面的oldCap \u0026gt; 0，表示数组还未初始化， // 若当前阈值不为0，就将数组的新容量记录为当前的阈值； // 为什么这里的oldThr在未初始化数组的时候就有值呢？ // 这是因为HashMap有两个带参构造器，可以指定初始容量， // 若你调用了这两个可以指定初始容量的构造器， // 这两个构造器就会将阈值记录为第一个大于等于你指定容量，且满足2^n的数（可以看看这两个构造器） else if (oldThr \u0026gt; 0) // initial capacity was placed in threshold newCap = oldThr; // 若上面的条件都不满足，表示你是调用默认构造器创建的HashMap，且还没有初始化table数组 else { // zero initial threshold signifies using defaults // 则将新容量更新为默认初始容量（16） // 阈值即为（容量*负载因子） newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } // 经过上面的步骤后，newCap一定有值，但是若运行的是上面的第二个分支时，newThr还是0 // 所以若当前newThr还是0，则计算出它的值（容量*负载因子） if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; ft \u0026lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } // 将计算出的新阈值更新到成员变量threshold上 threshold = newThr; // 创建一个记录新数组用来存HashMap中的元素 // 若数组不是第一次初始化，则这里就是创建了一个两倍大小的新数组 @SuppressWarnings({\u0026#34;rawtypes\u0026#34;,\u0026#34;unchecked\u0026#34;}) HashMap.Node\u0026lt;K,V\u0026gt;[] newTab = (HashMap.Node\u0026lt;K,V\u0026gt;[])new HashMap.Node[newCap]; // 将新数组的引用赋值给成员变量table table = newTab; // 开始将原来的数据加入到新数组中 if (oldTab != null) { // 遍历原数组 for (int j = 0; j \u0026lt; oldCap; ++j) { HashMap.Node\u0026lt;K,V\u0026gt; e; // 若原数组的j位置有节点存在，才进一步操作 if ((e = oldTab[j]) != null) { // 清除旧数组对节点的引用 oldTab[j] = null; // 若table数组的j位置只有一个节点，则直接将这个节点放入新数组 // 使用 \u0026amp; 替代 % 计算出余数，即下标 if (e.next == null) newTab[e.hash \u0026amp; (newCap - 1)] = e; // 若第一个节点是一个数节点，表示原数组这个位置的链表已经被转为了红黑树 // 则调用红黑树的方法将节点加入到新数组中 else if (e instanceof HashMap.TreeNode) ((HashMap.TreeNode\u0026lt;K,V\u0026gt;)e).split(this, newTab, j, oldCap); // 上面两种情况都不满足，表示这个位置是一条不止一个节点的链表 // 以下操作相对复杂，所以单独拿出来讲解 else { // preserve order HashMap.Node\u0026lt;K,V\u0026gt; loHead = null, loTail = null; HashMap.Node\u0026lt;K,V\u0026gt; hiHead = null, hiTail = null; HashMap.Node\u0026lt;K,V\u0026gt; next; do { next = e.next; if ((e.hash \u0026amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } // 将新创建的数组返回 return newTab; } 单独分析中间链表拆分的代码\n定义两个链表 (lo 和 hi)， 包括头节点和尾节点 Node\u0026lt;K,V\u0026gt; loHead = null, loTail = null; Node\u0026lt;K,V\u0026gt; hiHead = null, hiTail = null; 按照顺序遍历table携带的链表的每个节点，如果(e.hash \u0026amp; oldCap) == 0，就放入lo链表，其他的放入hi链表 do { next = e.next; // 根据元素的哈希值和旧容量的位运算结果将元素分类 if ((e.hash \u0026amp; oldCap) == 0) { // if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next)!= null); 将原来的链表拆分为两个链表，然后将低位置元素存储到新数组原索引位置，将高位置元素存储到新数组原索引加旧容量的位置。 位置的高低按照 (e.hash \u0026amp; oldCap) == 0 来区分 // 将低位置元素存储到新数组原索引位置 if (loTail!= null) { loTail.next = null; newTab[j] = loHead; } // 将高位置元素存储到新数组原索引加旧容量的位置 if (hiTail!= null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } [补充] 1. Java 中 HashMap 的扩容机制是怎样的？ 【简单理解】\n每次扩容，新数组变成老数组的 2 倍， 所以新数组可以看成是老空间+一块一样大小的新空间。（两块数组）。 扩容的时候，如果原数组是单一的节点，则直接放入新数组里面。假如原数组长度为n， 新数组中的位置是e.hash \u0026amp; 2n -1，其实就是 e.hash % 2n 如果原数组是多个节点，就按照低位和高位来分。区分的方法，哈希值的二进制和原数组长度的二进制的最高位是否为1。如果为0，则为低位，否则为高位。（比如哈希值为3，二进制为011, 原数组长度为4， 二进制为100。就是看第 3 位是否为1） 然后低位链表，就放在新数组老空间那边。高位链表就放在新数组新空间那边，具体位置是原位置+老数组的长度 【具体流程】\n判断当前的容量是否已经达到最大容量，如果是，则直接返回原来的哈希表对象，不予扩容。 如果没有达到最大容量，则 new 一个原数组 2 倍大小的新数组，用来存放新的数据 遍历原数组，将原数组的数据都迁移到新的数组里面。 迁移的过程中，如果数组对应位置上，只有一个节点，直接用元素的哈希值和新数组的长度减1 进行与运算 (index = e.hash \u0026amp; (newCap - 1))，得到的结果就是新数组中的位置，复制过去即可 如果不止一个节点，会新建两个头节点和尾节点，可以看成两条链表，分为低位链表和高位链表。把原来的链表/红黑树拆分到低位链表和高位链表上 判断元素是否为TreeNode, 来判断是红黑树还是链表结构。 逐一遍历原数组红黑树/链表上的节点，每个节点的哈希值和原数组的长度进行与运算，判断结果是否为 0 (e.hash \u0026amp; oldCap == 0)，如果等于 0，则插入低位链表，如果不等于0，则插入高位链表。 最后，将低位链表，放入新数组中元素在原数组对应的下标位置。将高位链表放入，从旧位置往后移动原数组长度的位置，也就是旧位置下标 + 原数组大小作为高位链表的存放位置 最后，返回新的哈希表对象 2.ConcurrentHashMap了解吗? / Java 中 ConcurrentHashMap 1.7 和 1.8 之间有哪些区别？ 首先，提到 ConcurrentHashMap 我们要分成JDK 1.7 和 JDK 1.8 两个版本来看：\nJDK 1.7: 在1.7中， ConcurrentHashMap 采用分段锁。就是分成不同的segment，默认有16个。每个segment 中都包含多个的 HashEntry (可以理解成一个HashMap)。 锁的方式源于Segment,这个类实际集成了ReentrantLock\nJDK 1.8：在1.8中，ConcurrnetHashMap的数据结构和HashMap一样，它做了更小范围的锁控制。它的数组的每个位置上都有一把锁。如果需要扩容，会使用CAS 自旋操作保证线程安全，避免锁整个数组。如果是在链表/红黑树插入某个node，只需要用synchronize进行上锁。\n【JDK1.7和1.8扩容区别】\nJDK 1.7：当某个Segment内的HashMap 达到扩容阈值的时候，单独为该Segment进行扩容。\nJDK 1.8：大致可以分为三个特点全局扩容、基于CAS扩容、渐进式扩容\n全局扩容：1.8 因为取消了 1.7 里面的Segment， 本身是数组+链表+红黑树的结构。所以是一个全局的数组，当任意位置的元素超过阈值时，整个数组都会被扩容。\n基于 CAS 的扩容： 采用和 HashMap 相似的扩容机制，采用 CAS 操作确保线程安全，同时避免锁住整个数组。\n渐进式扩容：扩容不是一次性将所有数据重新分配，而是多个线程共同参与，逐步迁移就数据到新数组当中，降低扩容对性能的消耗。(假如当前数组长度为32，那么可以A线程负责0~15，B线程负责16~31)\n3. 为什么 Java 的 ConcurrentHashMap 不支持 key 或 value 为 null？ ConcurrentMap不支持key或value为 null 是为了避免歧义和简化代码实现方式\n因为多线程环境下，get(key) 方法如果返回 null ，不知道其表示的是key不存在还是value本来就是 null。为了避免这个歧义，代码就需要频繁的判断null是代表key不存在还是 value 本来就是 null，增加复杂度。\n【为什么HashMap支持 key 或 value 为null】\n因为HashMap设计的初衷就是单线程模式使用的，本身就是线程不安全的。在 HashMap 的实现中，null 键被特殊处理。当 key 为 null 时，HashMap 不会调用 hashCode() 方法，而是直接将 null 键存储在表的第一个桶（table[0]）中。这样可以避免 NullPointerException 。\n【注意】 像HashTable、ConcurrentSkipListMap、CopyOnWriteArrayList这些并发集合，都是线程安全的，都不支持key或value为 null\n4 . Java 中 ConcurrentHashMap 的 get 方法是否需要加锁？ ConcurrentHashMap 的 get 方法不需要加锁。因为get 方式是读取操作，不需要对资源做任何处理，所以每次只需要保证读取到最新的数据即可，所以不需要加锁。\n另外,ConcurrentHashMap 中 get 方法对于数组中的节点，是通过Unsafe 方法 getObjectVolatile() 来保证可见性的。对于链表或者红黑树节点，是采用volatile 关键字去修饰 val 和 next 节点的，也可以保证可见性。\n5. Java 中有哪些集合类？请简单介绍 Java中的集合类都是在java.util。 主要可以分为单列类型 Collection 和 双列 Map 两类来看。 其中单列 Collection 里面包括 (List、Set、Queue），具体如下图。\n【两个基本接口】\nCollection 单列集合接口：一个由单个元素组成的序列，这些元素要符合一条或多条规则。其中，List 是有序的，Set 是去重的， Queue 是符合队列规则的。 Map 双列集合接口： 一组键值对，可以用 key 来检索 value。 上面的 ArrayList 是采用索引来查找一个值。Map 可以采用另外一个对象来查找某个对象。 【List 系列】 List 接口的实现类用于存储有序的、允许重复的元素。必须按照元素插入顺序来保存他们。\nArrayList：擅长随机访问元素，但是在 List 的中间插入或者删除元素比较慢。适合读操作多的场景。 LinkedList：提供理想的顺序访问性能，在 List 的中间插入和删除元素的成本都比较低。 LinkedList 随机访问性能相对较差， 适合频繁插入和删除的场景。 Vector：基于动态数据实现，线程安全 (方法加锁)， 效率比较低，已经很少用了。 【Set 系列】 Set 接口的实现类用于存储不重复的元素。继承于Collection\nHashSet：无序，采用哈希表存储，查找和插入性能高。 LinkedHashSet：有序，采用哈希表 + 链表(存储插入顺序) TreeSet：排序 (或自定义排序)，采用红黑树实现，查找、插入、删除操作性能高。 【Queue 队列/优先系列】 Queue 接口的实现类用于处理先进先出的队列数据结构。\nPriorityQueue： 基于堆实现，用于优先级队列。元素按自然顺序或自定义顺序排列。不是FIFO的顺序，优先处理优先级搞的元素 LinkedList： 也实现了Queue 接口，支持双端队列结构。 Stack： 双端队列 【Map 系列】 键唯一，值可重复\nHashMap： 无序，数组 + 链表 + 红黑树， key 和 value 都可以为 null LinkedHashMap：有序，数组 + 链表 + 红黑树，额外链表记录插入顺序 TreeMap：红黑树实现，对key进行自然排序(或者自定义排序) HashTable: 数组 + 链表 + 红黑树，有sychronized 锁， 不允许key 和 value 为 null ，线程安全。 6. Java 中的 CopyOnWriteArrayList 是什么？ CopyOnWriteArrayList 是一种线程安全的ArrayList， 其主要的原理就和名字一样，在写的时候复制，写时复制。\nCopyOnWirteArrayList 的读操作不需要上锁，但是写操作会锁。而且进行写操作的时候，会复制一份原数组出来，然后在新的数组上进行写操作，读操作还是在老数组的基础上，适合读多写少的场景。到那时复制数组有一定的性能消耗，而且会消耗内存。\n","permalink":"https://swimmingliu.cn/posts/job/java-set-interview-questions/","summary":"\u003ch2 id=\"1-说说-java-中-hashmap-的原理\"\u003e1. 说说 Java 中 HashMap 的原理？\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e【HashMap定义】\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e结构：数组 + 链表 + 红黑树 (\u003ccode\u003eJDK 1.8\u003c/code\u003e 之后)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e默认值：初始容量为16 (数组长度)，负载因子为 0.75。当存储的元素为 16 * 0.75 = 12个时，会触发\u003ccode\u003eResize()\u003c/code\u003e 扩容操作，容量 x 2 并重新分配位置。但是扩容是有一定开销的，频繁扩容会影响性能。另外，\u003ccode\u003eTREEIFY_THRESHOLD\u003c/code\u003e 转换为红黑树的默认链表长度阈值为 8, \u003ccode\u003eUNTREEIFY_THRESHOLD\u003c/code\u003e 从红黑树转换为链表的阈值为 6。 两个阈值采用不同值的原因是防止刚转换为红黑树，又变成链表，反复横跳，消耗资源。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e数组下标位置计算方法：首先使用key的\u003ccode\u003ehashCode()\u003c/code\u003e方法计算下标位置，然后通过  \u003ccode\u003eindexFor()\u003c/code\u003e (\u003ccode\u003eJDK 1.7\u003c/code\u003e 以前) 计算下标值。 \u003ccode\u003eJDK 1.7\u003c/code\u003e后，为了提高计算效率采用 \u003ccode\u003e(len - 1) \u0026amp; hash\u003c/code\u003e 来确定下标值。\u003c/p\u003e\n\u003cp\u003e【注】数组的长度\u003ccode\u003elen\u003c/code\u003e 是2的幂次方时，\u003ccode\u003e(len - 1) \u0026amp; hash\u003c/code\u003e 等价于 \u003ccode\u003ehash % len\u003c/code\u003e。 这也是为什么数组长度必须是2的幂次方。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"HashMap底层结构\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/65f25922-ef8d-11ef-827a-c858c0c1deba\"\u003e\u003c/p\u003e\n\u003cp\u003e【\u003cstrong\u003eHashMap线程不安全\u003c/strong\u003e】\u003c/p\u003e\n\u003cp\u003e为了保证HashMap的读写效率高，它的操作是非同步的，也就是说读写操作没有锁保护。所以多线程场景下是线程不安全的。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【HashMap不同版本区别】\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eJDK 1.7: 数组 + 链表，链表部分采用头插法，多线程会导致出现环形链表。扩容会计算每个元素hash值，并分配到新的位置，开销大。\u003c/li\u003e\n\u003cli\u003eJDK 1.8：数组 + 链表 + 红黑树，采用高低位置来分配位置，即判断\u003ccode\u003e(e.hash \u0026amp; oldCap) == 0\u003c/code\u003e， 减少了计算hash的次数\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e【HashMap的PUT方法】\u003c/strong\u003e\u003c/p\u003e","title":"Java集合面试题笔记"},{"content":"1. 序列化和反序列化 1.序列化和反序列化：把对象转换为字节流，用于存储和传输；读取字节流数据，重新创建对象。 2.序列化不包括静态对象：序列化和反序列化的本质是调用对象的writeObject和readObject方法,来实现将对象写入输出流和读取输入流。但是，静态变量不属于对象，所以调用这两个方法就没法儿让静态变量参与。\n2. 什么是不可变类？ 1.不可变类：初始化之后，就不能修改的类。 2.修饰方法：final 和 private 修饰所有类和变量 3.不可修改：不暴露set方法，只能通过重新创建对象替代修改功能(String的replace方法) 4.优缺点： 优点：线程安全，缓存友好 缺点：频繁拼接和修改会浪费资源\n3. Exception和Error区别? 1.Exception和Error定义区别：Exception是可处理程序异常，Error是系统级不可回复错误 2.try-catch建议： 1.范围能小则小 2.Exception最好要写清楚具体是哪一个Exception(IOException) 3.null值等能用if判断的，不要用try-catch,因为异常比条件语句低效 4.finally不要直接return和处理返回值\n4. Java 中的 hashCode 和 equals 方法之间有什么关系？ 1、equals() 和 hashCode() 的关系\n如果两个对象euqals() 为 true， 则其 hashCode()一定相同 如果两个对象hashCode() 相同，其equals()结果不一定为true 2、为什么重写equals()之后，一定要重写hashCode()\n当重写equals() 之后，通常是重新定义了两个对象相等的逻辑。如果不重写hashCode()方法， 则在散列集合（HashMap 和 HashSet）中，可能无法正确存储和检索，因为两个相同的对象可能有不同的hash值。\n例如，下方Person类重写了equals() 方法，但是没有重新hashCode()\npublic class Person { private String name; private int age; @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null || getClass() != obj.getClass()) return false; Person person = (Person) obj; return age == person.age \u0026amp;\u0026amp; Objects.equals(name, person.name); } } 创建相同的对象，并添加到HashSet中\nPerson p1 = new Person(\u0026#34;Alice\u0026#34;, 25); Person p2 = new Person(\u0026#34;Alice\u0026#34;, 25); Set\u0026lt;Person\u0026gt; set = new HashSet\u0026lt;\u0026gt;(); set.add(p1); set.add(p2); 由于hashCode() 没有重写，所有两个相同的对象可能有不同的散列码，导致集合当中有两个相同的元素\n如何重写hashCode()?\n只需要让其hash值，采用equals()当中相同的判断条件生成合理的散列值即可\n@Override public int hashCode() { return Objects.hash(name, age); } 5. 接口和抽象类有什么区别？ 特性 接口 抽象类 设计角度 自上而下，先定义好我们需要的方法，然后在具体的类当中，实现该接口的方法 自下而上，写了很多类之后，发现他们有共性，可以把代码复用。因此封装成一个抽象类，减少代码冗余 方法实现 所有方法默认是 public 和 abstract 修饰 (JDK 8 之后可以设置default方法或者静态方法)，接口类可以是空的 (Serializable 序列化接口) 可以包含abstract 抽象方法 (无实现) 和 具体方法(有实现)，至少包含一个抽象方法 构造函数和成员变量 接口不能包含构造函数，所有成员变量默认为 public static final 常量 抽象类可以包含构造函数，成员变量可以有不同的修饰符，不一定是常量 多继承 一个类只能实现多个接口 抽象类只能单继承 【注意】\n接口和抽象类是不可以被实例化的，只能用来实现或者继承。\nJDK 9 之后，接口可以定义私有方法，用于default 方法的内部逻辑复用\n// 支付接口 interface PaymentInterface { // 支付方法 void pay(double amount); // 通知支付状态 void notifyPaymentStatus(String status); // 私有方法，用于检查支付金额是否合法 private boolean isAmountValid(double amount) { return amount \u0026gt; 0; } // default 方法，包含了对私有方法的调用 default void performPayment(double amount) { if (isAmountValid(amount)) { pay(amount); } else { System.out.println(\u0026#34;Invalid payment amount\u0026#34;); } } } 接口当中的 default 方法，实现对象可以直接调用，也可以进行重写。static 方法只能通过接口名调用\n6. JDK 动态代理和 CGLIB 动态代理有什么区别？ JDK 动态代理：基于反射机制和接口，要求所有代理类都必须实现某个接口 (目标对象至少实现一个接口) CGLIB：基于 ASM 字节码生成工具，通过继承的方式生成目标类的子类来实现代理，所以要注意 final 方法 （子类可以继承并使用父类的 final 方法，但不能重写（Override）该方法） 特性 JDK 动态代理 CGLIB 底层实现 接口 + 反射，通过反射调用目标对象的接口方法 生成子类的字节码 + 重写被代理类的方法 代理对象 必须实现接口 不需要实现接口 性能 创建代理开销小，方法调用开销大 方法调用开销小，创建代理开销大 (需要生成子类的字节码) 限制 不能代理没有接口的类 不能代理 final 类 和 final 方法 使用场景 需要实现接口的类 没有接口的类 Spring AOP 默认方式 AOP 默认采用JDK动态代理 目标类没有接口的时候，采用 CGLIB 【注意】在不同的jdk版本下，JDK 动态代理 和 CGLIB 的性能都不一样 (可参考 CGLIB与JDK动态代理的运行性能比较)\nJDK 1.6：运行次数少的情况下，JDK动态代理和CGLIB 基本没差，甚至JDK动态代理更快。当次数增加之后，CGLIB 会稍微快一些 JDK 1.7: 基本都是 JDK动态代理比较快，运行次数较少的情况下，JDK动态代理比CGLIB 快 30% 左右。当次数增加之后，JDK动态代理比CGLIB 快了接近一倍 JDK 1.8：和 JDK 1.7 表现基本一致 【JDK 动态代理详解】\nJDK 动态代理是通过反射机制，来实现代理接口中的方法的。通过 java.lang.reflect.Proxy 类 和 InvocationHandler 接口来实现代理， 代理对象只代理接口中的方法。当调用代理对象的方法的时候，代理类会拦截方法调用，然后通过 InvocationHandler.invoke() 方法执行额外的逻辑。 (AOP 切面编程的原理)\n例如，下面代码中，DataQuery 是接口， DatabaseDataQuery 实现该接口。JDK 动态代理要求被代理对象至少实现一个接口，以便代理类通过接口暴露代理行为。 通过 Proxy.newProxyInstance() 创建代理对象，需要三个参数：\n类加载器：Thread.currentThread().getContextClassLoader()， 用于加载代理类 接口列表：new Class[]{xxx.class}， 指定代理类应该实现的接口, 里面存放接口的 class 调用处理器 InvocationHandler：代理对象的实际逻辑是用实现这个InvocationHandler接口的类来晚来成的，比如CacheInvocationHandler 拦截代理方法，调用并添加额外逻辑。底层的实现逻辑其实就是反射机制。 // 接口 public interface DataQuery { String query(String queryKey); String queryAll(String queryKey); } // 目标实现类 public class DatabaseDataQuery implements DataQuery { @Override public String query(String queryKey) { // 他会使用数据源从数据库查询数据很慢 System.out.println(\u0026#34;正在从数据库查询数据\u0026#34;); return \u0026#34;result\u0026#34;; } @Override public String queryAll(String queryKey) { // 他会使用数据源从数据库查询数据很慢 System.out.println(\u0026#34;正在从数据库查询数据\u0026#34;); return \u0026#34;all result\u0026#34;; } } // 调用处理器：用于拦截方法 public class CacheInvocationHandler implements InvocationHandler { private HashMap\u0026lt;String,String\u0026gt; cache = new LinkedHashMap\u0026lt;\u0026gt;(256); private DataQuery databaseDataQuery; public CacheInvocationHandler(DatabaseDataQuery databaseDataQuery) { this.databaseDataQuery = databaseDataQuery; } public CacheInvocationHandler() { this.databaseDataQuery = new DatabaseDataQuery(); } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { // 1、判断是哪一个方法 String result = null; if(\u0026#34;query\u0026#34;.equals(method.getName())){ // 2、查询缓存，命中直接返回 result = cache.get(args[0].toString()); if(result != null){ System.out.println(\u0026#34;数据从缓存重获取。\u0026#34;); return result; } // 3、未命中，查数据库（需要代理实例） result = (String) method.invoke(databaseDataQuery, args); // 4、如果查询到了,进行呢缓存 cache.put(args[0].toString(),result); return result; } // 当其他的方法被调用，不希望被干预，直接调用原生的方法 return method.invoke(databaseDataQuery,args); } } // 测试类：如何使用JDK动态代理 public class Main { public static void main(String[] args) { // jdk提供的代理实现，主要是使用Proxy类来完成 // 1、classLoader：被代理类的类加载器，用于加载代理类 ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader(); // 2、代理类需要实现的接口数组 Class[] classes = new Class[]{DataQuery.class}; // 3、InvocationHandler CacheInvocationHandler cacheInvocationHandler = new CacheInvocationHandler(); DataQuery dataQuery = (DataQuery) Proxy.newProxyInstance(contextClassLoader, classes, cacheInvocationHandler); // 事实上调用query方法的使用，他是调用了invoke String result = dataQuery.query(\u0026#34;key1\u0026#34;); System.out.println(result); System.out.println(\u0026#34;--------------------\u0026#34;); result = dataQuery.query(\u0026#34;key1\u0026#34;); System.out.println(result); System.out.println(\u0026#34;--------------------\u0026#34;); result = dataQuery.query(\u0026#34;key2\u0026#34;); System.out.println(result); System.out.println(\u0026#34;++++++++++++++++++++++++++++++++++++\u0026#34;); // 事实上调用queryAll方法的使用，他是调用了invoke result = dataQuery.queryAll(\u0026#34;key1\u0026#34;); System.out.println(result); System.out.println(\u0026#34;--------------------\u0026#34;); result = dataQuery.queryAll(\u0026#34;key1\u0026#34;); System.out.println(result); System.out.println(\u0026#34;--------------------\u0026#34;); result = dataQuery.queryAll(\u0026#34;key2\u0026#34;); System.out.println(result); System.out.println(\u0026#34;--------------------\u0026#34;); } } 【CGLIB 动态代理详解】\nCGLIB (Code Generation Library) 代码生成库 是基于字节码操作的，它可以生成目标类的子类，并且重写目标类的方法来实现代理。通过继承方式拦截所有非 final 方法的调用。 CGLIB 使用的是 ASM 字节码生成框架，生成的是字节码级别的代理类。性能相对较好，但是生成代理类的开销比 JDK 动态代理 稍微大一些。\nMain 类当中，没有实现任何接口，这就是 CGLIB 的优势之一，不需要实现任何接口。 CGLIB 通过生成目标类的子类来实现代理。CGLIB 通过 Enhancer 类来创建代理对象，需要配置父类和拦截器。\n父类：enhancer.setSuperclass(DatabaseDataQuery.class) ，配置目标类作为父类 拦截器：enhancer.setCallback(new CacheMethodInterceptor()); ，配置拦截器，拦截所有非 final 方法的调用，和InvocationHandler 差不多，可以插入额外的逻辑。 // 拦截器：用于拦截方法 public class CacheMethodInterceptor implements MethodInterceptor { private HashMap\u0026lt;String,String\u0026gt; cache = new HashMap\u0026lt;\u0026gt;(); private DatabaseDataQuery databaseDataQuery; public CacheMethodInterceptor( ) { this.databaseDataQuery = new DatabaseDataQuery(); }; @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable { // 1、判断是哪一个方法 String result = null; if(\u0026#34;query\u0026#34;.equals(method.getName())){ // 2、查询缓存，命中直接返回 result = cache.get(args[0].toString()); if(result != null){ System.out.println(\u0026#34;数据从缓存重获取。\u0026#34;); return result; } // 3、未命中，查数据库（需要代理实例） result = (String) method.invoke(databaseDataQuery, args); // 4、如果查询到了,进行呢缓存 cache.put(args[0].toString(),result); return result; } return method.invoke(databaseDataQuery,args); } } // 测试类：如何使用CGLIB进行动态代理 public class Main { public static void main(String[] args) { //cglib通过Enhancer实现 Enhancer enhancer = new Enhancer(); //设置父类 enhancer.setSuperclass(DatabaseDataQuery.class); //设置一个拦截器，用来拦截方法 enhancer.setCallback(new CacheMethodInterceptor()); //创建代理类，其实就是目标类的子类 DatabaseDataQuery databaseDataQuery = (DatabaseDataQuery) enhancer.create(); databaseDataQuery.query(\u0026#34;Key1\u0026#34;); databaseDataQuery.query(\u0026#34;Key1\u0026#34;); databaseDataQuery.query(\u0026#34;Key2\u0026#34;); } } 7. 你使用过 Java 的反射机制吗？如何应用反射？ 反射机制定义：Java 的反射机制是指在运行的时候，获取类的结构信息 (比如方法、字段、构建函数) ，然后获取操作对象的一种机制。反射机制可以在运行的时候，动态创建对象、调用方法、访问字段，不需要在编译的时候知道这些信息。反射的核心类包括 Class、Constuctor、Method、Filed\n反射机制作用：\n动态获取类信息：包括类名、包名、父类等，不需要在编译的时候知道类的信息 动态创建对象：可以通过 Class 类或者 Constructor 对象的 newInstance() 动态创建对象，不需要在编译的时候知道对象的类型 动态调用对象的方法：通过 Method 类的 invoke() 方法实现 访问和修改对象的字段值：通过 Filed.set() 直接修改对象的值，和通过SetAccessible(true) 绕过访问限制 反射机制的应用场景： 一般的业务编码用不到反射机制，但是在框架上会用到反射机制。因为写框架的时候，很多场景是很灵活的，不能确定目标对象的类型，只能通过反射动态获取对象信息。比如 Spring 使用反射机制来读取和解析配置文件，从而实现 DI 依赖注入和 AOP 切面编程等功能。\nDI 依赖注入的具体实现，假如对指定类加上 @Service 注解，下面是具体的实现过程：\nSpring 在容器启动初始化的时候, 将所有带有@Service、@Component等注解的类，放入容器当中，注册为Bean Spring 容器启动的时候，会将带有@Autowired 注解的类进行标记，然后使用反射机制将所有的字段、方法、构造器进行注入 反射的使用方法：\n获取 Class 对象\nClass\u0026lt;?\u0026gt; clazz = Class.forName(\u0026#34;com.swimmingliu.MyClass\u0026#34;); // 或者 Class\u0026lt;?\u0026gt; clazz = MyClass.class; // 或者 Class\u0026lt;?\u0026gt; clazz = obj.getClass(); 创建对象 ：一般都采用 Constructor 来构造对象\nObject obj = clazz.newInstance(); // 已过时 Constructor\u0026lt;?\u0026gt; constructor = clazz.getConstructor(); Object obj = constructor.newInstance(); 访问字段：可以让私有对象可见，而且能够设置它的值\nField field = clazz.getField(\u0026#34;name\u0026#34;); // 假设 private String name; field.setAccessible(true); // 允许访问 private 字段 Object value = field.get(obj); field.set(obj, newValue); 调用方法：\nMethod method = clazz.getMethod(\u0026#34;myMethod\u0026#34;, String.class); Object result = method.invoke(obj, \u0026#34;param\u0026#34;); ","permalink":"https://swimmingliu.cn/posts/job/java-basic-interview-questions/","summary":"\u003ch2 id=\"1-序列化和反序列化\"\u003e1. 序列化和反序列化\u003c/h2\u003e\n\u003cp\u003e1.序列化和反序列化：把对象转换为字节流，用于存储和传输；读取字节流数据，重新创建对象。\n2.序列化不包括静态对象：序列化和反序列化的本质是调用对象的\u003ccode\u003ewriteObject\u003c/code\u003e和\u003ccode\u003ereadObject\u003c/code\u003e方法,来实现将对象写入输出流和读取输入流。但是，静态变量不属于对象，所以调用这两个方法就没法儿让静态变量参与。\u003c/p\u003e\n\u003ch2 id=\"2-什么是不可变类\"\u003e2. 什么是不可变类？\u003c/h2\u003e\n\u003cp\u003e1.不可变类：初始化之后，就不能修改的类。\n2.修饰方法：final 和 private 修饰所有类和变量\n3.不可修改：不暴露set方法，只能通过重新创建对象替代修改功能(\u003ccode\u003eString\u003c/code\u003e的replace方法)\n4.优缺点：\n优点：线程安全，缓存友好\n缺点：频繁拼接和修改会浪费资源\u003c/p\u003e\n\u003ch2 id=\"3-exception和error区别\"\u003e3. Exception和Error区别?\u003c/h2\u003e\n\u003cp\u003e1.Exception和Error定义区别：Exception是可处理程序异常，Error是系统级不可回复错误\n2.try-catch建议：\n1.范围能小则小\n2.Exception最好要写清楚具体是哪一个Exception(IOException)\n3.null值等能用if判断的，不要用try-catch,因为异常比条件语句低效\n4.finally不要直接return和处理返回值\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"Exception和Error区别\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/946b73cc-ef5d-11ef-95ab-c858c0c1deba\"\u003e\u003c/p\u003e\n\u003ch2 id=\"4-java-中的-hashcode-和-equals-方法之间有什么关系\"\u003e4. Java 中的 hashCode 和 equals 方法之间有什么关系？\u003c/h2\u003e\n\u003cp\u003e1、\u003ccode\u003eequals()\u003c/code\u003e 和 \u003ccode\u003ehashCode()\u003c/code\u003e 的关系\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e如果两个对象\u003ccode\u003eeuqals()\u003c/code\u003e 为 \u003ccode\u003etrue\u003c/code\u003e， 则其 \u003ccode\u003ehashCode()\u003c/code\u003e一定相同\u003c/li\u003e\n\u003cli\u003e如果两个对象\u003ccode\u003ehashCode()\u003c/code\u003e 相同，其\u003ccode\u003eequals()\u003c/code\u003e结果不一定为\u003ccode\u003etrue\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e2、为什么重写\u003ccode\u003eequals()\u003c/code\u003e之后，一定要重写\u003ccode\u003ehashCode()\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e当重写\u003ccode\u003eequals()\u003c/code\u003e 之后，通常是重新定义了两个对象相等的逻辑。如果不重写\u003ccode\u003ehashCode()\u003c/code\u003e方法， 则在散列集合（\u003ccode\u003eHashMap\u003c/code\u003e 和 \u003ccode\u003eHashSet\u003c/code\u003e）中，可能无法正确存储和检索，因为两个相同的对象可能有不同的\u003ccode\u003ehash\u003c/code\u003e值。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e例如，下方Person类重写了\u003ccode\u003eequals()\u003c/code\u003e 方法，但是没有重新\u003ccode\u003ehashCode()\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-Java\" data-lang=\"Java\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003ePerson\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"kd\"\u003eprivate\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"kd\"\u003eprivate\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eage\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"nd\"\u003e@Override\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003eboolean\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003eequals\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eObject\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eobj\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003ethis\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eobj\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kc\"\u003etrue\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eobj\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kc\"\u003enull\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e||\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003egetClass\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e!=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eobj\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003egetClass\u003c/span\u003e\u003cspan class=\"p\"\u003e())\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kc\"\u003efalse\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"n\"\u003ePerson\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eperson\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ePerson\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eobj\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eage\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eperson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eage\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eObjects\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eequals\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eperson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e创建相同的对象，并添加到\u003ccode\u003eHashSet\u003c/code\u003e中\u003c/p\u003e","title":"Java基础题面试笔记"},{"content":"1.MySQL 中的数据排序是怎么实现的？ 1.排序方法：索引排序和文件排序 (filesort)\n2.索引排序：如果order by xxx的字段为索引字段，则利用索引进行排序。效率最高，索引默认有序。\n3.文件排序 (filesort)：内存排序(单路排序和双路排序)和磁盘排序，具体取决于排序数据的大小。其中，内存排序使用单路排序或双路排序，取决于max_length_for_sort_data(默认为4096个字节)\n4.双路排序：取row_id(如果有主键，则为主键)和select a,b,c order by xxx的xxx字段放入sort_buffer(排序缓存)中，将排序后的row_id回表查询a,b,c\n5.单路排序: 直接把要查的所有字段放入sort_buffer里，排序后直接得到结果集合\n6.磁盘排序（归并排序）:将数据分为多份文件，单独对文件进行排序，然后合并成一个有序的大文件\n2. MySQL 的 Change Buffer 是什么？它有什么作用？ 1.ChangeBuffer定义：Change Buffer是InnoDB缓冲当中的一块缓存区，用于暂存二级索引的修改，避免二级索引页修改产生的随机IO 2.ChangeBuffer注意事项：只能用于二级索引，不能用于其他任何索引，包括主键索引和唯一索引都不行。 3.如果ChangeBuffer挂了，更改操作未执行，是否会出现脏数据？ 首先，ChangeBuffer也会保存在磁盘空间里面，redo log会记录Change Buffer当中的修改操作，确保数据一致性。\n知识拓展1：一级索引和二级索引区别\n一级索引（聚簇索引）：数据表的主键索引，数据和索引存储在同一B+树的叶子节点中。每个表只能有一个一级索引。\n二级索引（非聚簇索引）：除主键外的其他索引，叶子节点存储索引列的值和对应的主键值。通过二级索引查询时，需要先通过二级索引获取主键值，再通过主键值查询数据，这个过程称为“回表”。\n知识拓展2: MySQL中有哪些常见索引？都有什么区别？\n在MySQL中，索引是提高查询效率的关键工具。常见的索引类型包括主键索引、唯一索引、普通索引、全文索引和空间索引。\n1. 主键索引（Primary Key Index）\n定义：主键索引是一种特殊的唯一索引，用于唯一标识表中的每一行数据。每个表只能有一个主键索引，且主键列的值不能为空。 特点：主键索引的叶子节点存储完整的数据行，因此查询效率高。在InnoDB存储引擎中，主键索引是聚簇索引，数据存储与索引结构合并。 2. 唯一索引（Unique Index）\n定义：唯一索引确保索引列的每个值都是唯一的，但允许有空值。与主键索引类似，不同之处在于唯一索引允许列值为NULL。 特点：唯一索引的叶子节点存储索引列的值和对应的主键值。在InnoDB中，唯一索引是非聚簇索引，数据存储与索引结构分开。 3. 普通索引（Index）\n定义：普通索引是最基本的索引类型，没有任何限制。索引列的值可以重复，也可以为NULL。 特点：普通索引的叶子节点存储索引列的值和对应的主键值。在InnoDB中，普通索引是非聚簇索引，数据存储与索引结构分开。 4. 全文索引（Fulltext Index）\n定义：全文索引用于对文本数据进行全文搜索，适用于MyISAM存储引擎。它允许对文本字段进行复杂的搜索，如查找包含特定单词的记录。 特点：全文索引的叶子节点存储文档的词项信息。在MyISAM中，全文索引是非聚簇索引，数据存储与索引结构分开。 5. 空间索引（Spatial Index）\n定义：空间索引用于对地理空间数据进行索引，支持空间数据类型的快速查询。它适用于存储地理位置、地图等空间数据的表。 特点：空间索引的叶子节点存储空间数据的索引信息。在MyISAM中，空间索引是非聚簇索引，数据存储与索引结构分开。 总结：\n主键索引：用于唯一标识每一行数据，值不能为空。 唯一索引：确保索引列的值唯一，但允许有空值。 普通索引：最基本的索引类型，允许重复和空值。 全文索引：用于对文本数据进行全文搜索，适用于MyISAM存储引擎。 空间索引：用于对地理空间数据进行索引，支持空间数据类型的快速查询。 3. 详细描述一条 SQL 语句在 MySQL 中的执行过程。 连接器判断用户是否成功建立连接，数据库连接的权限校验 连接器会查询缓存，key 是 SQL 语句，value 是查询结果。如果命中，直接返回查询结果。(MySQL 8.0之后，就移除这个功能了)。 分析器分析SQL语法和词法是否有误 优化器生成SQL的执行计划，确定使用的索引和调整where的执行顺序（包括连表顺序） 执行器判断当前用户是否有权限查询该表，然后执行该SQL语句 [参考文献] 执行一条 select 语句，期间发生了什么？\n[补充] 3. MySQL 日志：undo log、redo log、binlog 有什么用？ undo log（回滚日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的原子性，主要用于事务回滚和 MVCC。 redo log（重做日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的持久性，主要用于掉电等故障恢复； binlog （归档日志）：是 Server 层生成的日志，主要用于数据备份和主从复制；\n直接看参考文献当中的七个问题和其解决方案\n[参考文献] MySQL 日志：undo log、redo log、binlog 有什么用？\n4. MySQL 的存储引擎有哪些？它们之间有什么区别？ InnoDB : 支持事务、行锁、外键; 高并发性能、支持高负载的OLTP应用 (银行交易、电子商务订单、库存管理等); 聚集索引存储，检索效率高\nMyISAM: 表锁、不支持事务和外键; 适用于读多写少的场景(数据仓库); 较高读性能和j较快的表级锁定\nMEMORY: 存储在内存中，速度快，重启后数据丢失; 适用于临时数据存储和快速存储\n5. MySQL 的索引类型有哪些？ 划分方向 索引类型 数据结构 B+树索引、Hash索引、倒排索引 (全文索引)、R-树索引 (多维空间树)、位图索引(Bitmap) 物理存储 聚簇索引、非聚簇索引 字段特性 主键索引、唯一索引、普通索引(二级索引、辅助索引)、前缀索引 字段个数 单列索引、联合索引 6. MySQL InnoDB 引擎中的聚簇索引和非聚簇索引有什么区别？ 聚簇索引：就像是图书馆里按照书籍主题顺序摆放的书架。在这个书架（也就是聚簇索引）上，每本书（也就是数据库中的行数据）都是按照某个主题（通常是主键）来排列的。所以，当你想要找某一主题的书时，只要知道主题名（主键值），就能很快在书架上找到它，而且相邻主题的书也是挨在一起的，找起来很方便。但是，这种方式的缺点是，如果你想要改变某本书的主题（更新主键），可能就需要移动整本书到新的位置，甚至可能需要重新整理整个书架（数据页），这样就比较麻烦了。\n非聚簇索引：则更像是图书馆里的一个索引卡片箱。在这个卡片箱里，每张卡片（也就是非聚簇索引的节点）上都写着书籍的主题（索引列的值）和书籍在书架上的位置（主键值或ROWID）。当你想要找一本书时，可以先在卡片箱里找到对应的卡片，然后根据卡片上的位置信息去书架上找书。这种方式的好处是灵活，你可以为不同的书籍主题制作多张卡片，方便从不同的角度查找书籍。但是，坏处是每次找书都需要两步：先在卡片箱里找卡片，再去书架上找书，这样可能会比直接在书架上找书要慢一些。\n总的来说，聚簇索引和非聚簇索引的主要区别在于它们如何存储数据和索引，以及它们如何影响数据的查询和更新操作。聚簇索引将数据直接存储在索引上，查询效率高，但更新操作可能较复杂；而非聚簇索引则通过索引指向数据，提供了更多的灵活性，但查询时可能需要额外的步骤。在选择使用哪种索引时，需要根据具体的应用场景和查询需求来决定。\nMySQL InnoDB的聚簇索引和非聚簇索引就像图书馆的两种找书的方式。 1.聚簇索引：图书馆在书架上(聚簇索引)摆放各种编号(主键名称)的书本(数据库中每一行的数据)。当你需要从图书馆找某一本书时，只需要知道书籍的编号(主键值)，就能够快速找到他。它的缺点是，如果需要换某一本书的编号(更新主键)，就需要移动整本书到新的位置，甚至重新整理书架(数据页)。这也是推荐使用select *的原因，因为如果需要查找索引列的数据，直接用二级索引就可以找到数据。例如通过姓名（二级索引）查询id(主键索引)，直接用二级索引就可以拿到对应的id.但是如果用select *,数据库就会回表查询其他的数据（性别，年龄等等）。 2.非聚簇索引：就像图书馆单独设置编号卡片箱，每张卡片(非聚簇索引)上包含了书籍名称(索引列的值)和书籍在书架上的编号位置(主键值或者ROWID)。当你想要找某本书的时候，可以根据卡片里面对应的编号进行查找。坏处是每次都需要两步走，查找起来没那么方便。 总结：聚簇索引是包含数据的，所以查找起来方便，但是更新操作开销大。非聚簇索引不包含数据，只包含索引列的值和其指向的数据索引，需要两步走才能查到数据。\n7. MySQL 中的回表是什么？ 回表：用二级索引中的主键取聚簇索引中查找数据行的过程 为什么需要回表：使用非聚簇索引的二级索引查询时，只能查到索引列的值和其主键值，无法获取其他数据 回表的缺点：回表会带来随机I/O, 频繁回表会导致效率非常低。所以不推荐使用 select * 回表的其他场景：当查询的部分列没有包含在索引中时，即便使用了索引，也需要会去获取缺失的列数据，称为覆盖索引缺失。 覆盖索引缺失发送场景：select 语句当中包含了非索引列; 索引的类型为Hash和full-text索引 （不存储列的值），不支持覆盖索引。 如何减少回表：MySQL5.6之后，引入了提高查询效率的优化技术，默认开启。允许MySQL用索引查找数据时，将部分查询条件下推到索引引擎层来过滤，减少了需要读取的数据行。 8. MySQL索引的最左前缀匹配原则是什么? 最左前缀匹配原则的定义：使用联合索引的时候，查询的条件必须从索引的最左侧开始匹配。如果联合索引包含多个列，查询条件必须包含第一个列，然后是第二个列，以此类推。 最左前缀匹配原则的原理：联合索引在B+树中的排列方式遵循从左到右的原则，例如联合索引(a, b, c)，在查询时，首先按照a的值进行排序，如果a的值相同，再查b的值，以此类推。 常见场景：= 、\u0026gt;= 、\u0026lt;= 、 BETWEEN 、like (xx%) 都包含等值的情况，可以定位到某个数，然后进行范围扫描，不会出现停止匹配的现象。但是 \u0026gt; 和 \u0026lt; 则不行。 部分不符合最左前缀匹配原则也能使用索引的原因：MySQL8当中引入了 Skip Can Range Access Method, 将缺失的左边的值查出来，如果左边缺失的列数据量少，则拼凑左边的索引，让SQL符合最左前缀匹配原则。 9. MySQL的覆盖索引是什么？ 覆盖索引定义：查询的所有字段都是二级索引，从而使查询可以直接访问二级索引二不需要访问实习的表数据(主键索引)。 覆盖索引优点：减少I/O操作 ; 提高查询速度 (索引比表数据更加紧凑); 减少内存占用 (读取的索引页面而不是表数据页面) 10. MySQL的索引下推 (ICP) 是什么? 索引下推(ICP)定义: 减少回表查询，提高查询效率的行为。允许MySQL使用索引查找数据的时候，将部分查询条件下推到存储引擎层进行过滤，从而减少需要从表中读取的数据行，减少I/O。\n应用场景：比如当前表建了一个联合索引(a, b, c)，使用where条件的时候，由于b用得是 like '%xxx%' 需要回表查询 (like 'xx%' 不需要)。即先查询a = '1' 的数据， 然后回表查询，最后进行where条件的过滤。如果使用索引下推之后 (MySQL 5.6)，在查询晚a = '1'的数据之后，可以先由存储引擎层进行where条件过滤，然后再回表查询， 减少回表查询的次数。\nSELECT * FROM people WHERE a=\u0026#39;1\u0026#39; AND b LIKE \u0026#39;%123%\u0026#39; 如联合索引index_name_age，假设数据库中有数据（张三，18）、（张三，28）、（张三，48）、（张三，8)\n【没有索引下推】查询name=\u0026lsquo;张三\u0026rsquo;和age\u0026gt;30的数据时，会先匹配有四条数据name=\u0026lsquo;张三\u0026rsquo;匹配成功，回表四次查询出带有name=\u0026lsquo;张三\u0026rsquo;的四条数据，然后再根据age\u0026gt;30对这四条数据进行范围查找\n【使用索引下推】查询name=\u0026lsquo;张三\u0026rsquo;和age\u0026gt;30的数据时，会先匹配有四条数据name=\u0026lsquo;张三\u0026rsquo;匹配成功，然后age\u0026gt;30的数据，过滤完成后，再用主键索引去进行一次回表操作\n11. MySQL建索引需要注意哪些事项？ 【索引适合场景】\n频繁使用where 、order by 、group by、distinct 的字段 (加快操作速度) 关联字段 (如果没有索引，连接的过程中，每个只都会进行一次全表扫描) 【不适合场景】\n字段频繁更新 (更新除了修改数据外，还需要维护索引信息 =\u0026gt; 调整B+树会降低性能) 字段值重复率高（区分度低，建立索引更加消耗资源） 参与列计算的字段 (索引会失效) 长字段 (text、 longtext) ：长字段占据的内存大，提升性能不明显。 【注】索引不是越多越好，因为每次修改都需要维护索引数据，消耗资源\n12. MySQL中使用索引一定有效吗？如何排查索引效果？ 【索引失效的情况】\n联合索引不符合最左匹配原则 对索引列使用了运算(where id + 3 = 8)、函数 (lower()、count())、like '%xx%' 等操作 对索引列和非索引列使用 or 操作 (where name = \u0026quot;swimmingliu\u0026quot; or age = 34) 索引列类型不匹配导致的强制转换 (where name = 1 ==\u0026gt; where CAST(name AS signed int) = 1) 【如何查看失效】\n利用explain命令 (前面最好加上analyse table xxx)\nEXPLAIN 的 type 表示查询的访问类型，影响查询的效率。常见的值：\nref: 使用索引，查找匹配某个单一列的值（比如通过外键查找）。比 range 更高效。 range: 使用索引扫描某个范围内的值，适用于 BETWEEN、\u0026gt; \u0026lt; 等条件。 index: 全索引扫描，扫描整个索引结构，不读表数据，通常效率比全表扫描好。 all: 全表扫描，没有使用索引 总结：ref \u0026gt; range \u0026gt; index \u0026gt; all。\n13. MySQL的索引数是否越多越好？why? 索引不是越多越好，因为对索引字段进行更新操作，需要调整B+树的结构，会导致数据库增加开销。\n【注】阿里巴巴规范上表示索引一般不超过16个\n**【时间开销】**进行增删改操作的时候，索引也必须更新。索引越多，需要修改的地方就越多，时间开销大。B+树可能会出现页分裂、合并等操作，时间开销更大。\n【空间开销】 建立二级索引，都需要新建一个B+树，每个数据页面都是16KB。如果数据大，索引又多，占用的空间不小。\n14. 为什么 MySQL 选择使用 B+ 树作为索引结构？ 【B+树的优势】\n高效的查找性能：B+树是一种自平衡树，每个叶子结点到根节点的路径长度相同。增删改查的事件复杂度都是O(logn)，且具有一定的冗余节点，删除节点的时候，树的结构变化较小。 I/O次数相对较少：首先，B+树不会像红黑树一样，随着数据的增多树变得越来越高，它是多叉树。计算机访问数据时，往往具有局部性原理。当读取一个节点时，B树和B+树会将多个相关的数据加载到内存中，后续直接从内存反问，减少了磁盘的I/O。另外，相较于B树来说， B+树所有的数据都存放在叶子节点，而不像B树会在非叶子节点存储数据。B+树的非叶子节点仅存储索引值/主键和页面指针。 对范围查询友好：B+树的叶子节点之间通过链表链接。当使用between语句时，会从根节点找到满足条件的起始记录。然后从起始记录，沿着叶子结点的链表进行顺序遍历。 【B+树存在的部分缺点】\n当插入和删除节点，会触发分裂和合并操作，保持树的平衡，有一定的开销。\n【跳表】\n跳表其实就是一个多级链表，为了让链表更高效的查询。在不同的部分插入高级索引，让其能够缩小查找范围。有一种二分的思想在里面。其中，Redis的有序集合(sorted set)底层的结构就是跳表结构。\n【为什么MySQL不用跳表而用B+树】\n跳表的I/O效率低：B+树通常只有3~4层，可以存储海量的数据。B+树的节点大小设计适配磁盘页的大小，磁盘页能够顺序存储大量数据。一次磁盘I/O操作就能读取节点的数据，减少I/O。跳表是多级索引的结构，虽然可以加速查找，但是其查找的过程当中会涉及到多次随机的I/O。 范围查询： B+树的叶子节点是有序链表，在采用between时，能够找从叶子结点按照链表顺序遍历即可。跳表虽然支持范围查询，但是实现起来很复杂， 而且其多层的索引结构，范围查询时不能像B+树那样直接高效。 跳表维护成本高：B+树在增删改的时候，又高效的算法平衡树结构，确保性能稳定。而跳表在新增和删除操作的时候，涉及多层链表的调整，开销较大，容易出现性能波动。 跳表内存占用大：B+树的节点紧凑，非叶子节点只存储索引项和页面指针。而跳表除了每个节点存储数据以外，还需要额外的开销存储多层索引。相同数据量下，跳表的开销比B+树大得多。 15. MySQL 三层 B+ 树能存多少数据？ 算法名称 数据页大小 叶子节点存储的数据记录大小 (假设) 节点的索引值(主键大小) 节点的页面指针大小 B+树 16KB 1KB 8B （bigint） 6B 【三层B+树存储数据计算】\nnodesCount = 16 * 1024 / (6 + 8) = 1170 // 每个节点可以存多少个子节点 recordCount = 16KB / 1KB = 16 // 每个节点可以存多少条数据记录 dataCount = nodesCount * nodesCount * recordCount = 1170 * 1170 * 16 = 21,902,400 所以如果一条数据为1KB大小，B+树大约能存2000w条数据 【拓展】\nMySQL的InnoDB引擎中，B+树m每个节点的数据页大小可以通过调整innodb_page_size来修改 (一般为 4KB / 8KB / 16KB)\n16. MySQL如何进行SQL调优 分为预防和解决慢查询两个角度阐述。总结起来就三点，命中索引、减少回表、减少I/O.\n【预防】\n合理设计索引，减少回表次数，减少I/O 避免 select * 操作。因为正常情况下，部分字段是没有二次索引的，它会用主键id或者rowid 进行回表查询，会增加系统的I/O。 避免让索引失效，比如对索引字段进行计算、聚合函数、非同类型比较 (强制转换)和范围查询 (\u0026gt;、\u0026lt;、like %xxx%)。还有联合索引不匹配最左前缀原则 避免对非索引字段，使用group by、order by、dinstinct等函数 连表查询的是否需要保持不同字段的字符集一致，不然也会导致全表扫描。比如A表用utf-8，B表用latin1，查询的是否需要进行字符集转换，需要额外的计算，不能使用索引。 【解决慢查询】\n开启慢SQL日志记录功能，使用set global slow_query_log = \u0026quot;ON\u0026quot;， 默认是关闭的。设置一个查询延迟的阈值，把超过规定时间的SQL查询找出来。 利用explain关键字分析慢SQL的原因，比如看看是否有索引失效、select *等情况 17. 如何使用MySQL的EXPLAIN语句进行查询分析? 【EXPLAIN查询结果解释】\n名称 id select_type type key rows Extra 中文名称 查询的执行顺序 查询的类型 访问类型 关键索引 扫描行数 额外信息 说明 值越大优先级越高 SIMPLE简单查询、PRIMARY主查询、SUBQUERY 子查询 const \u0026gt; eq_ref \u0026gt; ref \u0026gt; range \u0026gt; index \u0026gt; ALL 实际用到的索引 值越小越好 Using index 表示覆盖索引、Using where 表示where条件过滤、Using temporary 表示临时表、Using filesort 表示需要额外的排序步骤 【type说明】\nsystem: 表明查询的表只有一行 (系统表)\nconst : 表明查询的表最多只有一行匹配结果。通常是查询条件为主键或唯一索引， 并且是常量比较。\neq_ref: 表明对于每个来自钱一张表的行，MySQL只访问一次该表，通常发生在链接查询中使用主键或唯一索引的情况下。\nref：MySQL 使用非唯一索引查询。查询的条件是非唯一的\nrange: MySQL 会扫描表的一部分，不是全部行。通常出现在索引的范围查询中 (比如\u0026gt;=、\u0026lt;=、BETWEEN)\nindex: 表示MySQL扫描索引中的所有行，但不是扫描表的所有行。\nall：表示需要扫描表的所有行，全表扫描。一般出现在没有索引的查询条件中。\n18. 请详细描述 MySQL 的 B+ 树中查询数据的全过程 【B+树查询过程】\n可以类比成去电影院 (4号厅 ) 找位置 的过程\n买票进门，从根节点(Page 20)出发，主键值为4, 范围在[1,5)中间，需要到 Page 2 非叶子节点查询 进入 Page 2 非叶子节点，主键值大于3，需要到Page 5 的叶子节点查询 进入Page 5 的叶子节点，通过Page Directory 内的槽查找记录，使用二分法快速定位查询记录在那个槽。 定位到槽之后遍历所有的记录，找到主键为 4 的记录 【Page Directory 页目录查找过程】\n假如页目录当中有5个槽，现在需要查找主键值为3的记录。查找过程如下：\n二分查找定位到槽2 槽2的最大记录是4，记录二分查找定位到槽1 槽1的最大记录是2，因为3 \u0026gt; 2， 直接向前遍历查询到主键值为 3 的记录 【B+树数据页的结构】\nInnoDB 当中B+树的每个节点以数据页(Page)为单位存储，每页默认大小为16KB。\n文件头： 记录叶子节点的上下页 (因为叶子节点是双向链表连接起来的) 最大和最小记录：表示页面当中最小的记录和最大的记录 （虚拟的记录） 在真实行记录的两侧 页目录: 数据页被分为若干个组，每个组对应一个槽 (Slot)。页目录内记录这些槽的位置，实现基于当前数据也的二分查找的快速定位。 【B+树的优势】\n参见问题14. 为什么 MySQL 选择使用 B+ 树作为索引结构？\n19. MySQL 中 count(*)、count(1) 和 count(字段名) 有什么区别？ 【效率层面】 count(*) ≈ count(1) \u0026gt; count(唯一索引) \u0026gt; count(主键) \u0026gt; count(其他字段)\n【具体区别】\n类型 统计内容 说明 count(*) 表中所有记录，包括NULL值 直接统计表的记录数，不依赖字段内容。MySQL特定优化，开销最低 count(1) 表中所有记录，包括NULL值 参数1被视为常量，不依赖字段内容。未优化，性能略低于count(*) count(唯一索引) 唯一索引字段中的所有非 NULL 的记录 遍历非聚簇索引统计字段行数，因为没有NULL 值，所以结果和count(*)差不多 count(主键) 主键字段中的所有非 NULL 的记录 遍历聚簇索引统计主键字段行数，因为没有NULL 值，所以结果和count(*)差不多。但是，有回表操作，会产生额外的I/O。 count(其他字段) 其他字段中的所有非 NULL 的记录 读取字段值，判断是否未NULL。如果记录较大，性能较差。 20. MySQL 中 varchar 和 char 有什么区别？ 【主要区别】\n特点 char varchar 长度 固定长度，不足的用空格补齐 (InnoDB会自动忽略补齐的空格) 非固定长度 存储空间 始终占用固定长度空间 随着长度的变化而变化，还有1~2字节的额外空间，用于说明长度信息 性能影响 如果长度忽大忽小，可能浪费 比较节省空间 使用场景 存储长度固定且较短的字符串 存储变化或稍微较长的字符串 【注意事项】\nvarchar 长度不要太大：因为MySQL在利用order by排序的过程当中，会用到 sort_buff。如果varchar所设定的长度过大，就会使用双路排序。而双路排序在对排序字段排序之后，只能拿到主键值和索引列的值。需要使用主键值再进行回表查询操作，会增加系统的I/O，降低系统性能。 varchar(n) 当中的n 表示的是字符数，而不是字节数。通常最大行长度是 65535 字节，如果允许未null， 需要额外一个字节标注是否未null。 而varchar 需要1~2个字节来标注字段的长度。所以，支持的最大长度为65535-2 = 65533 字节。一般情况下，UTF-8字符集占用3个字节。所以，最大字符数n 为 65533 / 3 = 21844 个字符 21. MySQL 是如何实现事务的？ 【事务四个特性 - AIDC】\n原子性：事务要么全部执行成功，要么全部执行失败 隔离性：并发的事务之间相互是不干扰的，可见性由隔离级别进行控制。MySQL的默认隔离级别是RR，可重复读 持久性：事务一旦提交，确保修改的数据会被永久保存 一致性：事务执行前后，数据库要保持一直的状态，所有的业务规则、约束和触发器的规则必须满足。 【如何实现事务】\n实现事务其实就是要确保满足事务的四个特性，如何满足呢？\n原子性：通过Uodo Log 实现，从事务开始的时候，Undo Log 里面会存储事务的反向操作。就是保存数据的历史版本把，用于事务的回滚，让事务执行失败之后可以恢复到之前的样子。\n隔离性: 通过锁和MVCC 多版本并发控制来实现的，主要是控制不同隔离级别下事务间的方法，确保事务之间不相互干扰。\n持久性：通过Redo Log来实现的，Redo Log会记录事务对数据库的所有修改操作。当MySQL发送宕机或崩溃的时候，可以根据Redo Log 里面的记录来恢复数据。满足事务的持久性。\n一致性： 其实事务的一致性就是AID实现的，也就是说事务是通过原子性、隔离性、持久性来满足一致性的。\n22. MySQL有哪些锁的类型? 【按粒度分类】\n全局锁: 对整个数据库进行加锁，处于只读的状态，一般用于数据库逻辑备份。这个时候所有的数据操作(增删改)和表结构操作(ALTER 和 DROP)都会被阻塞。 表级锁: 锁的是整张表。实现比较简单，资源消耗低。 行级锁：锁的是某一行。粒度最小，支持高并发。但是加锁的开销大，可能导致死锁。 【按功能分类】\n共享锁 (S 锁, share Lock): 读锁，顾名思义是共享的，所以可以共享锁之间可以兼容，一般用于事务读取数据的时候 排他锁 (X 锁, exclusive lock)：写锁，顾名思义是拒绝别人的，所以不允许多个事务同时获取，排他锁之间不兼容。一般用于事务修改记录的时候。 -- 添加共享锁 SELECT ... LOCK IN SHARE MODE;\t-- 共享锁 SELECT ... FOR SHARE # MySQL 8.x 版本 -- 排他锁 SELECT .... FOR UPDATE; 【全局锁】\n直接锁住整个数据库，处于只读模式。业务只能读取数据，不能更新数据。\nFLUSH TABLES WITH READ LOCK 【表级锁】\n表锁\n表级共享锁：阻止其他会话对表的写操作，当前会话只能读该表，不能访问其他表 表级排他锁：阻止其他会话对标进行任何操作（读和写），当前会话只能读该表，不能访问其他表 # 添加表级共享锁 lock tables user read; # 添加表级别排它锁 lock tables user write; 元数据锁：事务执行SELECT 的时候，其他线程的DDL操作(ALTER、DROP)操作会被阻塞，直到事务提交\n意向锁\n意向共享锁 (IS)：表明有意向对该表某些记录添加共享锁 (S 锁) 意向排他锁 (IX)：表明有意向对该表某些记录添加排他锁 (X 锁) 意向锁之间相互兼容，不会和行级别的共享锁和排他锁发生冲突。但是，意向排他锁和共享锁、排他锁之间是冲突的。\n锁名称 S X IS IX S ✅ ❌ ✅ ❌ X ❌ ❌ ❌ ❌ IS ✅ ❌ ✅ ✅ IX ❌ ❌ ✅ ✅ 自增锁\n用于主键自增的一种锁。事务向有自增列的表插入数据是会先获取自增锁，拿不到锁就被阻塞。但是可以通过修改innodb_autoinc_lock_mode自增锁模式进行调整，自增锁的具体实现方式：\n自增锁模式 介绍 说明 0 传统模式 采用AUTO-INC 锁，语句执行结束释放 1 连续模式 对普通insert，自增锁申请后马上释放。对于批量插入，等语句执行结束之后释放 2 交错模式 申请自增主键后马上释放，无需等待语句执行完 【行级锁】\n记录锁\n事务对某条记录加S锁，其他记录也可以加，但是不能加X锁 事务对某条记录加X锁，其他事务既不能加S锁也不能加X锁 BEGINE; # 针对主键 id 为 2 的这条记录添加 X 型的记录锁；其他事务就无法对这条记录进修改 SELECT * FROM user WHERE id = 2 FOR UPDATE; 间隙锁\n防止在可重复读的隔离级别下，出现幻读问题。\n比如，事务A开始读取数据, 发现是3条数据。然后，事务B加了一条数据进去。事务A在读去数据,发现是4条数据, 前后数据总数不一致就是幻读。\n临键锁：记录锁 + 间隙锁的组合，既可以锁住记录，也可以防止幻读\n插入意向锁\n意向锁用于快速判断是否可以对某张表加表锁，而无需判断表中具体行的锁定情况。\n插入意向锁的作用：\n标记插入意向图：事务告诉InnoDB，它计划在某个间隙范围内插入新数据。 允许多个事务并发插入不同位置：也就是说如果插入的范围不同，插入意向锁之间互不从突。 【注意】\n一个事务有间隙锁时，另外一个事务不能在相同范围内加插入意向锁 一个事务有插入意向锁是，另外一个事务不能在相同范围内假如间隙锁 23. MySQL 中的 MVCC 是什么？ 【当前读和快照读】\n当前读：select ... lock in share mode、select ... for update、insert/delete/upate 有锁，会阻塞其他事务。当前读不会生成ReadView， 只会加上临键锁next-key lock (记录锁+间隙锁) 快照读：直接 select，普通的查询操作，不加任何锁，不会阻塞其他事务。会生成ReadView，不会有幻行 【隔离级别】\n不同的隔离级别分别解决了脏读、不可重复读、幻读的问题。\n隔离性 读未提交 RU 读已提交 RC 可重复读 RR 串行读 脏读 ❌ ✅ ✅ ✅ 不可重复读 ❌ ❌ ✅ ✅ 幻读 ❌ ❌ ❌ ✅ 【注意】只有读已提交 RC 和可重复读 RR 才会用到快照读\n可重复读 RR，快照会在事务开始时生成，对数据进行更改才修改快照 读已提交 RC ，每次读取都会重新生成快照，总是读取行的最新版本，所以不可重复读 【MVCC】\nMVCC多版本控制并发主要是用来解决 读-写并发 所引起的问题的\n隐藏字段： db_row_id: 如果没有创建主键，就用这个字段来创建聚簇索引 db_trx_id：对该记录左最新一次修改的事务的ID db_roll_ptr: 回滚指针，指向这条记录的上一个版本。其实是只想undo log当中上一个版本的快找地址 Read View: 隐藏字段和 undo log版本决定的是返回的数据，但是具体返回哪个版本，由read view 和版本链返回规则可见性算法控制\ntrx_ids : 表示生成readview是,当前系统中活跃的读写事务的事务ID列表 low_limit_id：应该分配给下一个事务的id值 (最大事务id + 1) up_limit_id: 未提交的事务中最小的事务id (最小事务id) creator_trx_id: 创建该readview的事务id 什么情况是可以看见的? trx_id == creator_trx_id (当前事务修改的)、trx_id \u0026lt; up_limit_id (事务已提交)，up_limit_id \u0026lt; trx_id \u0026lt; low_limit_id (如果trx_id 不在 trx_ids 里面，说明不是这条数据不是存活的事务掌控的，数据已经提交了) 都是可见的。 trx_id \u0026gt; low_limit_id 是不可以访问的\n如果发现当前的记录是不可见的，那么就需要找undo log日志的历史快照了，如果找不到，则返回空。\n【不同隔离版本ReadView的产生时机】\n读已提交 RC，每次select 都会获取一次Read View 读未提交 RR， 只有第一次select才会获取Read View 【二级索引在索引覆盖通过的时候可以用MVCC吗？】\n已知如果查询字段包含了所有的二级索引，那么就会走索引覆盖，而不会回表用主键或row_id去读主键索引的页记录。但是，版本链的头节点在主键索引当中 ( 版本链包含row_id ), 通过二级索引的记录没法儿直接找到版本链。这种情况如何用MVCC？\n二级索引中，用一个额外的page_max_trx_id 来记录修改过该页的最大事务id\n如果查询到的readview 的最小未提交的事务id \u0026gt; page_max_trx_id， 说明在创建该readview时，最后一次更新二级索引的事务已经提交了，也就是说对当前查询是可见的，如果二级索引的记录没有被删除，就直接走索引覆盖。 如果最小未提交的事务id \u0026lt;= page_max_trx_id， 意味着数据可能被修改了。不能直接查询，需要回表，用聚簇索引进行查询。聚簇索引中，叶子结点行记录包含了版本链，可以用MVCC。 【可重复读RR隔离级别是否可以解决幻读】\nRR隔离机制不能完全解决幻读的现象，虽然它用了间隙锁，在一定程度上可以解决幻度。\n但是，如果存在下面这种情况就不行。\n事务A进行快照读, 然后事务B插入了一条记录并提交。此时，事务A是可以update 这条语句的，这样就出现了幻读。 当事务中先执行快照读，再执行当前读时，可能因读取最新数据而触发幻读 -- 事务A（RR隔离级别） BEGIN; SELECT * FROM users WHERE age \u0026gt; 20; -- 快照读，返回空结果 -- 事务B插入 age=25 的记录并提交 SELECT * FROM users WHERE age \u0026gt; 20 FOR UPDATE; -- 当前读，返回事务B插入的记录 24. MySQL 中的日志类型有哪些？binlog、redo log 和 undo log 的作用和区别是什么？ binlog 二进制日志: binlog是MySQL的二进制文件，用于记录所有的增删改操作 (包括表结构和数据的操作)。binlog是在事务提交后生成的，可以用于恢复数据库和备份数据库。(一般MySQL都有主库+从库两个数据库，防止单台故障，binlog就是为了同步主库和从库的) redo log 重做日志: redo log使用来恢复数据的，保证数据的一致性和持久性。当MySQL发生修改是，redolog会将这些操作记录下来，并写入磁盘。当数据库宕机时，可以通过重放redo log恢复数据 undo log 回滚日志: undo log是用于回滚操作的。当MySQL开始事务的时候，undo log会记录这些操作的反向操作。当需要回滚的时候，通过执行相反的操作，就可以回滚事务。 【区别】\n日志名称 作用层级 作用 内容 写入方式 写入时间点 binlog Server层 记录所有操作，支持备份恢复和主从复制 记录逻辑操作 (SQL语句 / 行的变化) 追加写入，写满之后创建新文件，再写 事务提交完成后，写入一次 redo log InnoDB存储引擎层 保证数据的一致性和持久性，用于故障恢复(断电宕机) 记录物理修改 (数据页的修改) 循环写入，固定大小，写完之后从头开始写 事务进行中，不断写入 undo log InnoDB存储引擎层 保证事务的原子性，用于回滚数据 记录事务修改钱的数据，用于回滚和MVCC 随事务变化生成，形成版本链 事务进行中，不断写入 【undo log 结构图】 【Redo Log + Undo log 结构图】\n25. MySQL隔离级别有哪些? MySQL的隔离级别包括四类: 读未提交 RU、读已提交 RC、可重复读 RR、串行化\n读未提交 RU : 顾名思义，如果有两个事务，事务A会在执行过程中读取,事务B还没有提交的修改数据。会出现脏读的情况， 就是读取了其他事务还没提交的数据。 读已提交 RC: 顾名思义，如果有两个事务，事务A会在执行过程中，读取事务B提交之后的数据，若未提交不会读取。但是会出现不可重复读的现象，过程如下。 事务A第一次select name where id = 1读取的数据为 小邓 事务B update user set name = '小刘' 并提交 事务A再次select name where id = 1读取的数据为 小刘 ，结果发生了变化 (你**的究竟是谁) 可重复读 RR: 为了解决不可重复读的现象，RR 隔离级别下，事务A会只用第一次 select (快照读)的时候，生成read view。如果事务B修改同一行的数据并提交。事务A第二次select (快照读)的时候，会用第一次的查询结果。但是，它会出现幻读的现象，过程如下。 事务A第一次select count(*) 读取的数据为 10， 采用的快照读 事务B insert xxx 新增了一条数据并提交 事务A第二次用select count(*) for update，采用当前读。读出来的数据为11条 串行化： 可以理解成把RR隔离级别下，所有的快照读都替换成当前读。当前读的状态下，其他事务不能修改正在读取的数据，实现了读的一致性，避免了幻读。 但是并发性能很低。 【不同隔离级别的特性】\n特性 读未提交 RU 读已提交 RC 可重复读 RR 串行读 脏读 ❌ ✅ ✅ ✅ 不可重复读 ❌ ❌ ✅ ✅ 幻读 ❌ ❌ ❌ ✅ 并发量 高 较高 较低 低 【RR 隔离级别幻读的解决方案】\n只采用下面的某一种方式进行读，就不会出现幻读\n快照读 (MVCC机制)：利用MVCC多版本控制，不会出现幻读。 当前读 (加锁查询)：通过临键锁Next-key Lock (记录锁 + 间隙锁)，避免其他事务修改数据，防止幻读。其实就是串行化隔离级别。 26. 数据库的脏读、不可重复读和幻读分别是什么？ 名称 定义 定义(整活版) 脏读 事务A读取到了事务B还没提交的数据 骗子啊!!! 不可重复读 事务A第一次读取的数据和后面读取到的数据不一致 谁**动我东西了? 幻读 事务A第一次读取的数据总数和第二次读取的数据总数不一样 闹鬼了，进去前3个人，出来了4个人 整活版解释参见ID为 小明 的天才选手\n27. MySQL 默认的事务隔离级别是什么？为什么选择这个级别？ MySQL默认的事务隔离级别是可重复读 RR 。\n【为什么选 RR 隔离级别】\n因为MySQL当中一般是有主库 + 从库两个数据库，为了避免一个库突然g了，数据库就全g了。主库和从库之间是采用binlog进行备份的，如果binlog是statement格式，在RU和RC的隔离级别下，主库和从库就会出现数据不一致的问题。\n【binlog 格式】\n格式名称 内容 优点 缺点 statement 记录执行的SQL语句，发送到从库执行 日志量少，传输率高，简单操作 limit 这种依赖环境的函数，可能出现数据不一致情况 row 记录每行数据变化，发送到从库应用 准确复制数据，避免主从不一致的情况 日志量大，占用带宽和空间 mixed 结合语句和行复制，自动切换 日志量一般，主从一致性较高 自动切换操作复杂 【RU 和 RC 导致主从不一致】\nsession1 session2 事务A开始 delete from user where age \u0026lt; 10 事务B开始 insert into user value(5,...) 事务B提交 事务A提交 此时，binlog里面记录的如下，执行顺序显然和原始的不一样，从库里面age = 5 这条数据肯定没了\ninsert into user value(10,...) delete from user where age \u0026lt; 10 【为什么 RR 不会出现主从数据不一致】\n因为 RR 隔离级别不仅会对更新的数据行添加行级的记录锁， 还会添加间隙锁和临键锁。如果有这两个锁的话，在事务B执行insert的时候，会被阻塞的。\n【为什么大厂一般用 RC 】\n先来对比一下RC 和 RR 隔离级别的区别\n特性 RC RR binlog格式 只能用row, 用mixed也会自动切换未row statement、row、mixed 锁机制 只有行级的记录锁 记录锁、间隙锁、临键锁 读机制 当前读：每次都生成新的快照，读取行的最新版本 同时支持当前读和快照读，默认select是快照读 并发性 并发性高 并发性低：因为有间隙锁、临键锁，会导致锁竞争加剧，降低系统的并发性能。 用RC的原因有两个:\n提高并发：因为相较于RR，RC 的并发率更高 减少死锁：因为RR 当中的间隙锁和临键锁会使得锁的粒度变大，死锁的几率会变大。 【 RC 如何解决不可重复读问题】\n如果只是单纯的不可重复读，其实还好，只要后面修改数据不基于这个值。所以，在修改核心表的时候，增加乐观锁的标记。更新的时候带上乐观锁进行版本判断之后，再更新。\n28. MySQL 事务的二阶段提交是什么？/ MySQL里面的 Redolog 和 BinLog 怎么保持一致? 首先，事务的二阶段提交就是为了让MySQL中的 binlog 和 redo log 保持一致。\n【为什么需要两阶段提交】\n如果没有两阶段提交，可能会导致binlog和redo log不一致，可以参考下面两种情况\n**情况一：**先写完 redo log，再写binlog：如果写完redo log后，MySQL突然宕机了，binlog还没写入数据。此时，MySQL重启后，根据 redo log 恢复事务的修改，但是binlog没有本次事务提交的数据。所以通过binlog恢复的时候，这次事务的修改就丢了。\n**情况二：**先写完binlog，再写redo log：如果写完binlog之后，突然MySQL宕机了，redo log还没写入数据。重启后因为redo log里面没有记录，所以没法儿恢复事务的修改。但是binlog记录了本次事务提交的数据，后续用binlog恢复数据的时候，就导致和原库不一样了。(binlog是用来给从库复制的)\n为了避免上面的两种情况发生，就把单个事务的提交拆分为2个阶段：准备阶段(prepare) + 提交阶段(commit)\n【事务的二阶段提交过程】\nprepare 准备阶段: InnoDB 将内部事务id XID 写入redo log，并将其标记为 prepare 状态。然后将redo log 持久化到磁盘或者写入redo log buffer，具体取决于 innodb_flush_log_at_trx_commit 参数 commit 提交阶段：将内部事务id XID写入到binlog，调用write()函数写入到文件系统的Page Cache。当binlog写入磁盘成功就认为事务就是执行完成了，就算redo log 还是prepare状态也没事儿。 如何解决的上面提到的两种情况呢？\n情况一： 写完 redo log 之后，还处于prepare状态，还没写入binlog， 突然宕机了。 MySQL重启后，会顺序扫描redo log文件，如果还处于prepare状态，就查看redo log当中的内部事务IDXID在binlog中是否存在 如果binlog不存在内部事务idXID，表明redolog已经刷盘(写入磁盘了)，但是binlog还没有刷盘，直接回滚事务，就当这条事务执行失败 情况二： 写完bin log之后，还处于prepare状态，还没commit， 突然宕机了。 MySQL重启后，会顺序扫描redo log文件，如果还处于prepare状态，就查看redo log当中的内部事务IDXID在binlog中是否存在。 (一般都是先扫描redolog，再看binlog) 如果binlog里面有当前内部事务idXID，说明redolog和binlog都刷盘了，直接提交事务就好了。 【两阶段提交有没有什么问题】\n两阶段提交确实会导致磁盘I/O次数增高和锁的竞争变得激烈\n磁盘I/O的次数增高: 每次事务提交都会进行两次写入磁盘 fsync，一次redolog刷盘，一次binlog刷盘 锁竞争激烈：为了保证单事务的两个日志内容一致，所以需要在提交流程上，添加锁保证两阶段的原子性。确保日志里面的顺序，不受多事务提交的影响。 【优化二阶段提交：组提交】\n为了减少二阶段提交的I/O次数和锁的竞争，MySQL新增了组提交机制，可以让多个事务提交时合并多个binlog，只进行一次刷盘操作。组提交版本的二阶段提交只有commit提交部分有些变化：\nflush阶段：多个事务按照顺序将binlog从Cache写入到文件 (不刷盘)， 为了支撑redo log组提交 sync同步阶段：对binlog进行写入磁盘fsync操作，多个事务的binlog一并写入磁盘，为了支撑binlog的组提交 commit阶段: 所有事务按照顺序进行commit提交操作 每个阶段都有队列维护，锁针对队列进行保护，减小锁的范围的同时，提高效率。\n【binlog刷盘时间】\n事务执行过程中，线写日志到binlog cache (Server层的cache) 事务提交的时候，从binlog cache 写入到 binlog文件。单个事务的binlog不能拆开，只能一次性写入。 ​ MySQL分配了一片内存用于缓冲binlog ，就是binlog cache。可以用binlog_cache_size修改它的大小。\n29. 什么是 Write-Ahead Logging (WAL) 技术？它的优点是什么？MySQL 中是否用到了 WAL？ WAL 是用来确保在修改真正的数据之前，先将修改记录写入日志的技术。为了当系统宕机的时候，通过日志也可以恢复数据，MySQL的redo log就是依靠的 WAL技术。它的核心就是, 先写日志，再写数据\nMySQL事务从开启到提交的过程，大致如下：\n开启事务 -\u0026gt; 查询数据到内存 -\u0026gt; 记录undo log -\u0026gt; 记录redo log(prepare阶段) -\u0026gt; 更新内存 -\u0026gt; 记录binlog -\u0026gt; 记录redo log (commit之后)\n30. MySQL 中如果发生死锁应该如何解决？ 【如何处理MySQL死锁】\n设置MySQL死锁自动检测机制\nMySQL自带死锁检测机制innodb_deadlock_detect，开启即可。如果检查到死锁的发生，数据库会自动回滚一个持有资源较少的事务，然后另一个事务就可以执行了。\n-- 查看主动死锁检测是否开启 show variable like \u0026#39;%innodb_deadlock_detect%\u0026#39; -- 开启主动死锁检测 (默认为ON) set global innodb_deadlock_detect=\u0026#39;ON\u0026#39; 设置锁等待超时参数\n可以设置获取锁的等待时间(默认为50s)，如果超过了这个时间，就会主动释放锁，让事务回滚\n-- 事务等待锁的超时时间 (默认为50s) show variable like \u0026#39;%innodb_lock_wait_timeout%\u0026#39; KILL死锁事务\n如果MySQL已经上线了，且没有设置那些检测，可以直接把死锁的事务kill掉。kill之前，需要查看一下执行的事务和表信息，用show engine innodb status\n-- 查看死锁日志 -- 查看正在执行的事务, 和相关的表信息 SHOW ENGINE INNODB STATUS -- 通过线程ID, 手动KILL死锁事务 kill 线程ID 【如何避免死锁的发生】\n避免大事务: 大事务占用的时间比较长，容易导致死锁发生。可以把大事务拆解成多个小事务，就可以降低死锁的发生概率。 更改数据库的隔离级别：MySQL的默认隔离级别是RR，它包含间隙锁和临键锁。如果改成RC，可以减少死锁的概率。 合理加索引，减少加锁范围：命中索引会对该行加上行锁，没有命中则会对整张表加上表锁。表锁的冲突概率比较大，容易导致死锁。 31. MySQL 中如何解决深度分页的问题？ 深度分页问题定义：深度分页是指当用户需要查询很久以前的数据，比如早年某个范围的订单。 SQL语句当中的 limit 偏移量变得非常大，MySQL性能直线下降的现象。\n为什么会性能下降: 因为MySQL会选择全表扫描，而不用索引扫描，导致效率低下。当 limit 偏移量偏大的时候，查询流程如下：\n扫描偏移量之前的1000000行，丢弃不符合条件的结果 每一次查询都需要用 age 列查到的主键值去回表，效率很低。(MySQL优化器就选择了，全表扫描 + 文件排序) 返回符合条件的最终记录 select * from user where sex = \u0026#39;女\u0026#39; order by age limit 1000000, 10 【如何解决深度分析带来的性能问题】\n记录上一次的最大ID，修改为范围查询 (如果能够保证 id 连续递增)\n查询的过程中，会走主键索引，加快查询速度。但是高并发的情况下，可能出现数据重复或者遗漏的情况。\n# 可以通过记录上次查询结果的最后一条记录进行下一页的查询 SELECT * FROM user WHERE id \u0026gt; 1000000 LIMIT 10; 子查询\n通过子查询来获取 id 的起始值，把 limit 2000000 的条件转移到子查询。 查询过程如下：\n子查询语句利用id的主键索引快速找到这条记录，然后定位到 1000001 这条记录的主键 主查询语句将子查询返回的起始 ID 作为过滤条件，然后使用查询条件过滤掉前面的数据 可以减少全表扫描，提高性能。但是，子查询会生成临时表，复杂场景会导致性能下降。\nSELECT * FROM user WHERE id \u0026gt;= ( SELECT id FROM user order by id limit 1000000,1 ) LIMIT 10; 延迟关联\n和子查询类似，将limit 操作转移到主键索引上，让其减少回表次数来优化查询 (只查询id不用回表)。然后将子查询中的结果合并到主查询当中，避免创建临时表。整体性能比子查询好。查询过程如下:\n子查询语句利用 id 的主键索引来快速找到符合条件的前10条记录的id 通过inner join 内连接将id 和 主表进行关联，获取完整记录 select user.* from user t1 inner join (SELECT id FROM user order by id limit 1000000, 10) t2 on t1.id = t2.id 覆盖索引：\n覆盖索引包含所有需要查询的字段(都是索引的，可以避免回表操作\n-- 覆盖索引查询 SELECT id, name FROM user by id limit 1000000, 10 优化方法 适用场景 优点 缺点 范围查询 主键或索引字段，连续性高 简单高效，减少扫面范围 不适用于非主键字段; 如果有高并发，可能会出现数据重复或者遗漏的情况。 子查询 偏移量大，索引列存在 利用索引快速定位，减少全表扫描 需要创建临时表，增加开销，复杂场景性能下降 延迟关联 主键索引存在，查询字段多 减少回表次数 查询逻辑复杂 覆盖索引 需要查询字段都包含在索引里面 无需回表查询，查询效率高 只能用于简单字段查询，查询的字段有优先 【如果出现表分页怎么办】\n假如出现表分页，比如现在有表1和表2。表1中按score字段排序为100,90,80，表2中按score字段排序为95,85,75。然后适用select score from student_info limit 1, 2 查询出来的是 90 (表1) 和 85 (表2)的合并结果。\n解决方案：将分页条件改写为limit 0, 3，取出所有前两页数据，再结合排序条件计算出正确的数据。如果遇到表分页的情况，必须从offset = 0的地方开始查询，避免漏掉数据。\n32. 什么是 MySQL 的主从同步机制？它是如何实现的？ 主从同步机制: 将主数据库上的数据同步到多个从数据库中的技术 为什么会有主从同步?: 因为如果MySQL只有一个数据库，当数据库文件损坏了，所有的数据都没了。为了防止这种单台故障，就有了主从数据库。主从数据库之间为了保持数据一致，就有了主从同步。 【主从同步的流程】\n从服务器创建线程: 从服务器开启主从复制之后，创建I/O线程和SQL线程 从服器和住服务器建立连接：从服务器的I/O线程和主服务器建立连接，主服务器的binlog dump 线程和从服务器进行交互 从服务器告知同步位置：从服务器的I/O线程会告知住服务器的 dump 线程从哪里开始接受 binlog。 **主服务器更新binlog：**主服务器把所有的更新记录从Page Cache 写入binlog 文件 (有三种格式：statement、row、mixed) dump线程控制binlog传输： 主服务器的dump线程检测到binlog变化，从指定位置读取。从服务器的I/O线程开始拉取binlog 文件，采用拉取模式有利于从库管理同步进度和处理延迟 中继存储到relay log： 从服务器的I/O线程将接收到的来自binlog中的内容，存储到relay log 重放relay log，写入数据：从服务器的SQL线程读取relay log 内容，解析成具体操作之后写入到对应的表中 【主从同步的三种方式】\n同步模式 说明 优点 缺点 异步复制(默认) 主库执行完事务马上给客户端返回，从库异步进行复制操作。 性能高 数据一致性低 同步复制 主库执行完事务等待从库复制完的信息，然后再给客户端返回 数据一致性高 性能较差，延迟大 半同步复制 主库执行完事务等待指定个数的从库复制完信息，然后给客户端返回 数据一致性和性能都居中 仍有丢失数据的可能 下面图片就是半同步复制/同步复制的过程，半同步复制可以设置检查从库的个数\n【从数据库的并行复制】\n从数据库默认是按照顺序逐条执行binlog的日志指令(也就是重放relay log)，但是串行执行可能导致从库的复制数据赶不上主库，所以就出现了下面的几种并行复制模式\n并行复制模式 特点 优缺点 MySQL 5.6 库级别并行 将不同数据库db1和db2的事务同时分开执行 事务都在同一个库时，失效 MySQL 5.7 组提交事务 将组提交的事务当作独立的事务，多线程并行执行 如果事务的last_commited相同，则说明再同一个组提交的，即便不冲突，也不能并发执行 MySQL 5.7 逻辑时钟 给prepare阶段的不存在锁冲突的事务打上时间标记sequece_number，后面直接提交 sequence_number就是last_commited，假如这个值相同，不冲突，也不能并发 MySQL 8.0 WriteSet WriteSet可以通过哈希算法对主键生成标识，来判断事务之间是否冲突，不冲突就可以并行复制 可能实现起来比较复杂 33. 如何处理 MySQL 的主从同步延迟？ 首先，MySQL的主从同步是一定存在延迟的。主从同步延迟是指主库更新完成之后，从库还没来得及更新，导致主从数据不一致。这种延迟对一些实时数据需求高的业务场景(比如金融系统)会造成影响。\n【为什么有主从同步延迟】\n从整体上看，有下面两个原因：\nrelay log赶不上binlog: 从库接受binlog的速度跟不上主库写入binlog的速度，从库的redo log就会比主库的binlog滞后 SQL执行赶不上relay log: 从库SQL线程执行relay log的速度比不上I/O线程接受binlog的速度，导致从库滞后relay log 导致上面两个情况发送的原因可能是：\n从库性能不足：CPU、内存、磁盘I/O比主库差一些，同步速度慢 从库读请求多：要分配一部分资源去满足读请求，影响同步的效率 主库提交太多大事务：从库去同步一个大事务需要较长的时间 从库数量过多：主库推送binlog开销大，导致延迟 网络延迟：主库和从库之间的网络延迟比较大，导致同步速度受限制 复制模式：默认采用异步复制模式，主库不等待从库完成复制，肯定有延迟 【避免延迟的方法】\n强行把写入后的读请求交给主库处理 （不推荐）: 把写入后的读请求给主库处理，可以避免主从延迟，但是主库承受的压力也会增大\n用半同步复制：半同步复制可以保证至少有一个从库复制完成了\nSET GLOBAL rpl_semi_sync_master_enabled = 1; SET GLOBAL rpl_semi_sync_slave_enabled = 1; 优化主从结构\n提升从库性能：配好一点的CPU、内存、磁盘I/O 减少从库数量：减少主库的同步开销 拆分读流量：把读请求负载均衡到多个从库上 sleep方案：假设主从库的延迟为1s，可以每次执行一个 select sleep(1)， 保证拿到最新的数据。\n34. MySQL中的长事务可能会导致哪些问题？ 长时间的锁竞争，阻塞资源：长事务持有的锁时间比较长，容易导致其他事务再获取相同锁的时候，发送阻塞，增加系统的等待时间和降低并发性能。业务线程会因为长时间的数据库请求而被阻塞，部分业务的阻塞会影响到其他的业务，导致产生雪崩。最终可能会让服务全面崩盘，导致严重的线上事故。 死锁风险：长事务更容易产生死锁，因为可能存在多个事务在互相等待对方释放锁，导致系统死锁。 主从延迟：长事务容易导致主从延迟，因为长事务需要主库花更长的时间执行，然后通过binlog传给从库。从库读取relay log的时候，重发操作又需要一长段时间，可能导致一大段时间数据是不同步的。 回滚导致时间浪费：如果事务执行了很长一段时间，突然执行出错，需要事务回滚，之前的执行都浪费了，耗费时间。 版本链过长：假如事务A对某条数据执行了10000次修改操作，在没有提交之前，事务B进行select 操作，会需要耗费很长的时间。 【长事务的SQL如何处理】\n拆分长事务SQL: 把单条SQL拆分为多条短事务SQL\n# 假如需要删除2021年的数据(4.8亿条)，共5亿条数据 delete from yes where create_date \u0026gt; \u0026#34; 2020-12-31\u0026#34; and create_date \u0026lt; \u0026#34;2022-01-01\u0026#34;; # 按照日期进行拆分成多条事务 delete from yes where create_date \u0026gt; \u0026#34; 2020-12-31\u0026#34; and create_date \u0026lt; \u0026#34;2021-02-01\u0026#34;; .... delete from yes where create_date \u0026gt; \u0026#34; 2021-11-31\u0026#34; and create_date \u0026lt; \u0026#34;2022-01-01\u0026#34;; 反向操作减轻事务时间：把需要旧表删除的数据转成新增到新的表，然后用新表替换旧表就可以了。\n","permalink":"https://swimmingliu.cn/posts/job/mysql-interview-questions/","summary":"\u003ch2 id=\"1mysql-中的数据排序是怎么实现的\"\u003e1.MySQL 中的数据排序是怎么实现的？\u003c/h2\u003e\n\u003cp\u003e1.\u003cstrong\u003e排序方法\u003c/strong\u003e：索引排序和文件排序 (filesort)\u003c/p\u003e\n\u003cp\u003e2.\u003cstrong\u003e索引排序\u003c/strong\u003e：如果\u003ccode\u003eorder by xxx\u003c/code\u003e的字段为索引字段，则利用索引进行排序。效率最高，索引默认有序。\u003c/p\u003e\n\u003cp\u003e3.\u003cstrong\u003e文件排序 (filesort)\u003c/strong\u003e：内存排序(单路排序和双路排序)和磁盘排序，具体取决于排序数据的大小。其中，内存排序使用单路排序或双路排序，取决于\u003ccode\u003emax_length_for_sort_data\u003c/code\u003e(默认为4096个字节)\u003c/p\u003e\n\u003cp\u003e4.\u003cstrong\u003e双路排序\u003c/strong\u003e：取\u003ccode\u003erow_id\u003c/code\u003e(如果有主键，则为主键)和\u003ccode\u003eselect a,b,c order by xxx\u003c/code\u003e的\u003ccode\u003exxx\u003c/code\u003e字段放入\u003ccode\u003esort_buffer\u003c/code\u003e(排序缓存)中，将排序后的\u003ccode\u003erow_id\u003c/code\u003e回表查询\u003ccode\u003ea,b,c\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e5.\u003cstrong\u003e单路排序\u003c/strong\u003e: 直接把要查的所有字段放入\u003ccode\u003esort_buffer\u003c/code\u003e里，排序后直接得到结果集合\u003c/p\u003e\n\u003cp\u003e6.\u003cstrong\u003e磁盘排序\u003c/strong\u003e（归并排序）:将数据分为多份文件，单独对文件进行排序，然后合并成一个有序的大文件\u003c/p\u003e\n\u003ch2 id=\"2-mysql-的-change-buffer-是什么它有什么作用\"\u003e2. MySQL 的 Change Buffer 是什么？它有什么作用？\u003c/h2\u003e\n\u003cp\u003e1.ChangeBuffer定义：Change Buffer是InnoDB缓冲当中的一块缓存区，用于暂存二级索引的修改，避免二级索引页修改产生的随机IO\n2.ChangeBuffer注意事项：只能用于二级索引，不能用于其他任何索引，包括主键索引和唯一索引都不行。\n3.如果ChangeBuffer挂了，更改操作未执行，是否会出现脏数据？\n首先，ChangeBuffer也会保存在磁盘空间里面，redo log会记录Change Buffer当中的修改操作，确保数据一致性。\u003c/p\u003e\n\u003cp\u003e知识拓展1：一级索引和二级索引区别\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e一级索引（聚簇索引）\u003c/strong\u003e：数据表的主键索引，数据和索引存储在同一B+树的叶子节点中。每个表只能有一个一级索引。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e二级索引（非聚簇索引）\u003c/strong\u003e：除主键外的其他索引，叶子节点存储索引列的值和对应的主键值。通过二级索引查询时，需要先通过二级索引获取主键值，再通过主键值查询数据，这个过程称为“回表”。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e知识拓展2:  MySQL中有哪些常见索引？都有什么区别？\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e在MySQL中，索引是提高查询效率的关键工具。常见的索引类型包括主键索引、唯一索引、普通索引、全文索引和空间索引。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e1. 主键索引（Primary Key Index）\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e定义\u003c/strong\u003e：主键索引是一种特殊的唯一索引，用于唯一标识表中的每一行数据。每个表只能有一个主键索引，且主键列的值不能为空。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e特点\u003c/strong\u003e：主键索引的叶子节点存储完整的数据行，因此查询效率高。在InnoDB存储引擎中，主键索引是聚簇索引，数据存储与索引结构合并。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e2. 唯一索引（Unique Index）\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e定义\u003c/strong\u003e：唯一索引确保索引列的每个值都是唯一的，但允许有空值。与主键索引类似，不同之处在于唯一索引允许列值为NULL。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e特点\u003c/strong\u003e：唯一索引的叶子节点存储索引列的值和对应的主键值。在InnoDB中，唯一索引是非聚簇索引，数据存储与索引结构分开。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e3. 普通索引（Index）\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e定义\u003c/strong\u003e：普通索引是最基本的索引类型，没有任何限制。索引列的值可以重复，也可以为NULL。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e特点\u003c/strong\u003e：普通索引的叶子节点存储索引列的值和对应的主键值。在InnoDB中，普通索引是非聚簇索引，数据存储与索引结构分开。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e4. 全文索引（Fulltext Index）\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e定义\u003c/strong\u003e：全文索引用于对文本数据进行全文搜索，适用于MyISAM存储引擎。它允许对文本字段进行复杂的搜索，如查找包含特定单词的记录。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e特点\u003c/strong\u003e：全文索引的叶子节点存储文档的词项信息。在MyISAM中，全文索引是非聚簇索引，数据存储与索引结构分开。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e5. 空间索引（Spatial Index）\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e定义\u003c/strong\u003e：空间索引用于对地理空间数据进行索引，支持空间数据类型的快速查询。它适用于存储地理位置、地图等空间数据的表。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e特点\u003c/strong\u003e：空间索引的叶子节点存储空间数据的索引信息。在MyISAM中，空间索引是非聚簇索引，数据存储与索引结构分开。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e主键索引\u003c/strong\u003e：用于唯一标识每一行数据，值不能为空。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e唯一索引\u003c/strong\u003e：确保索引列的值唯一，但允许有空值。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e普通索引\u003c/strong\u003e：最基本的索引类型，允许重复和空值。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e全文索引\u003c/strong\u003e：用于对文本数据进行全文搜索，适用于MyISAM存储引擎。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e空间索引\u003c/strong\u003e：用于对地理空间数据进行索引，支持空间数据类型的快速查询。\u003c/li\u003e\n\u003c/ul\u003e\u003c/blockquote\u003e\n\u003ch2 id=\"3-详细描述一条-sql-语句在-mysql-中的执行过程\"\u003e3. 详细描述一条 SQL 语句在 MySQL 中的执行过程。\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e连接器判断用户是否成功建立连接，数据库连接的权限校验\u003c/li\u003e\n\u003cli\u003e连接器会查询缓存，\u003ccode\u003ekey\u003c/code\u003e 是 SQL 语句，\u003ccode\u003evalue\u003c/code\u003e 是查询结果。如果命中，直接返回查询结果。(MySQL 8.0之后，就移除这个功能了)。\u003c/li\u003e\n\u003cli\u003e分析器分析SQL语法和词法是否有误\u003c/li\u003e\n\u003cli\u003e优化器生成SQL的执行计划，确定使用的索引和调整where的执行顺序（包括连表顺序）\u003c/li\u003e\n\u003cli\u003e执行器判断当前用户是否有权限查询该表，然后执行该SQL语句\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg alt=\"MySQL架构图\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/7457976c-ef5d-11ef-b738-c858c0c1deba\"\u003e\u003c/p\u003e","title":"MySQL面试题笔记"},{"content":"== 和 equals 区别 == 基本类型(int, long, float, char, boolean) 值比较， 引用类型(String，List) 进行地址比较\nequals 默认就是 == ，但是部分引用类型(String，List)重写了该方法，进行值比较\nget 和 post 区别 特性 GET POST 目的 获取资源，查询数据 提交数据，创建或更新资源 请求数据方式 参数通过 URL 查询字符串传递 数据通过请求体传递 数据暴露 数据暴露在 URL 中，较不安全 数据存储在请求体中，相对安全 数据大小限制 URL 长度有限制（约 2048 个字符） 没有数据大小限制 适用场景 获取数据，查询，展示资源 提交表单，上传文件，修改资源，发送敏感数据等 SpringMVC中@ReponseBody、@PathVariable、@RequestParameters在什么情况下使用? @ReponseBody 用于接受请求体数据，一般用于POST请求\n@PathVariable 用于接受路径参数，一般用户接受 id\n@RequestParameters 用于接受请求参数，一般用于GET请求\nJVM堆的结构、GC介绍和作用 JVM堆结构的参考文章 、 GC垃圾回收过程\n区域 主要用途 特点 新生代（Young Generation） 存储新创建的对象，快速垃圾回收 包含 Eden 区和两个 Survivor 区，采用复制算法进行回收 老年代（Old Generation） 存储长期存活的对象 回收频率较低，垃圾回收较耗时 永久代（Permanent Generation) (jdk 1.7） 存储类的元数据、方法字节码等 在 jdk 1.8 被 Metaspace 替代 元空间（jdk 1.8） 存储类的元数据 不再属于堆，使用本地内存，大小由系统限制 GC 是垃圾回收器， 作用是自动内存管理和避免内存泄漏\nInnodb和MYISAM的特点 InnoDB 和 MyISAM 是 MySQL 数据库管理系统中的两种主要存储引擎。 InnoDB 是 MySQL 5.5 版本的默认引擎。\n特性 InnoDB MyISAM 事务支持 支持事务（ACID），提供 COMMIT, ROLLBACK, SAVEPOINT 等语句 不支持事务 存储方式 行级锁（Row-level locking） 表级锁（Table-level locking） 支持外键 支持外键约束（Foreign Key） 不支持外键约束 崩溃恢复 支持崩溃恢复，自动恢复到一致性状态 不支持崩溃恢复，数据可能会丢失 性能特点 适合高并发读写的应用，性能较慢（因为使用行级锁） 适合读多写少的应用，性能较快（因为使用表级锁） 数据完整性 数据完整性和一致性强，支持原子性操作 不支持数据完整性，容易出现数据不一致 缓存机制 使用内存缓冲池来提高性能 使用内存缓存提高查询速度 适用场景 高并发、需要事务和数据一致性的应用，如金融、银行等 读多写少、数据一致性要求较低的应用，如日志记录、数据仓库等 行级锁（Row Lock）：InnoDB使用行级锁，避免了对整张表加锁的性能问题，允许多个事务并发访问不同的行。\n表级锁（Table Lock）：MySQL使用表级锁时，整个表会被锁定，导致其他事务无法访问表中的任何行，性能较低。\n意向锁（Intention Lock）：行锁和表锁之间的一种锁，InnoDB用来处理行锁和表锁之间的兼容性问题。\n如何理解数据库中的MVCC原理? MVCC原理解析\n脏读、幻读、不可重复读区别 快速理解脏读、不可重复读、幻读和MVCC\nMySQL事务 事务特性 (AIDC) 原子性（Atomicity）：事务中的操作要么全部成功，要么全部失败。MySQL会保证即使发生崩溃或中断，未提交的事务会被回滚。\n隔离性（Isolation）：事务的执行不应该被其他事务干扰。隔离级别控制了事务之间的“可见性”。\n持久性（Durability）：一旦事务提交，变更将永久保存，即使系统崩溃，数据也不会丢失。\n一致性（Consistency）：事务必须让数据库从一个一致的状态转换到另一个一致的状态，保证数据完整性。\n事务的隔离级别 读未提交：事务可以读取到其他事务未提交的数据，可能导致脏读。\n读已提交：事务只能读取已提交的事务数据，避免了脏读，但仍然可能出现不可重复读。\n可重复读：事务在其生命周期内读取的数据始终一致，避免了脏读和不可重复读。可能会出现幻读。\n串行化：最高的隔离级别，事务强制串行执行，避免脏读、不可重复读和幻读。但性能差，容易产生资源瓶颈。\n如何优化数据库 SQL优化 1.**避免使用 select ***\n2.索引优化\n索引使用：创建适当的索引，尤其是常用于 WHERE、ORDER BY、JOIN、GROUP BY 中的字段。\n覆盖索引：尽量让查询可以通过索引直接返回结果，避免回表。\n避免过多的索引：索引虽能加速查询，但也会增加插入、更新的成本。\n联合索引：对于多个字段常一起查询的情况，可以考虑创建联合索引。\n3.避免全表扫描\n使用 EXPLAIN 来分析SQL执行计划，检查是否有全表扫描，并优化查询。\n示例：EXPLAIN SELECT * FROM orders WHERE user_id = ? 可以检查是否使用了索引。\n数据库架构优化 1.分库分表：\n当数据量非常大时，可以通过分库分表来提高查询和插入的效率。 例如：按时间范围、ID范围或业务维度进行水平分表，按业务模块进行垂直分库。 2.读写分离 (Redis)：\n使用主从复制，主库处理写操作，从库处理读操作，减轻主库压力，提高系统的并发处理能力。 示例：主库执行 INSERT、UPDATE、DELETE，从库执行 SELECT。 (现在用Redis用来第一步判断，数据库后操作) 3.数据库冗余与备份：\n增加数据库的冗余副本，定期进行备份，确保数据的高可用性。 缓存优化 1.使用缓存来减轻数据库压力：对频繁查询的数据进行缓存（如使用 Redis），比如热门商品信息。\n2.合理的缓存策略：\n缓存穿透 : Redis 和 数据库都不存在，用空对象缓存到Redis\n缓存雪崩 :\n大量key同时过期：设置随机的TLL\nRedis服务宕机 : 设置Redis集群 + 哨兵模式 / 缓存业务降级限流 / 业务添加多级缓存\n缓存击穿：Redis的热点Key过期，互斥锁 / 逻辑过期\n3.避免缓存不一致：使用双写策略（更新数据库同时更新缓存），或通过异步更新缓存来避免缓存与数据库数据不一致。\n数据库连接池 使用连接池（如 HikariCP、Druid）可以有效地减少数据库连接的开销，避免频繁创建和销毁连接。\n数据库并发控制 1.事务与锁机制优化\n通过合理的事务管理和锁策略，避免死锁和性能瓶颈。 控制事务的粒度，避免长时间持有锁，减少锁竞争。 2.乐观锁与悲观锁：\n在适当的场景下使用乐观锁（如使用版本号），避免对数据加锁。 在高并发下，使用悲观锁（如数据库行级锁、悲观锁）确保数据一致性。 Redis一主两从+哨兵模式 Redis 采用一主两从+哨兵的集群方案，主要是为了在高并发和高可用的场景下保证系统的稳定性和可靠性。主节点(master)处理写请求，从节点(slave1 和 slave2)处理读请求，减少主节点的压力；哨兵机制监控主节点和从节点，能够自动进行故障转移，确保 Redis 集群在节点故障时的高可用性。\n普通的主从模式，当主数据库崩溃时，需要手动切换从数据库成为主数据库，这就需要人工干预，费事费力，还会造成一段时间内服务不可用，即存在高可用问题。我们又使用了哨兵。哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送ping命令，等待Redis服务器响应，从而监控运行的多个Redis实例。哨兵可以实现自动故障修复，当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换master。同时那台有问题的旧主节点也会变为新主节点的从节点，也就是说当旧的主即使恢复时，并不会恢复原来的主身份，而是作为新主的一个从。\nOAuth2.0 / 单点登录 (SSO) OAuth2.0 介绍、单点登录SSO介绍\n如何防注入攻击？ 1.使用预编译语句（Mybatis）： 将 SQL 语句与参数分离，防止恶意输入被解释为代码\n2.最小权限原则: 为指定数据库用户分配最小必要的权限，限制其只能执行特定操作，减少潜在的安全风险。\n3.避免动态拼接SQL ( XML里面 # 和 $ 区别): 使用#，而不用 $ 防止直接拼接\n如何设计表的映射关系 有一个订单表，一个产品表，一个产品订单表\n订单表（Order）：存储订单的基本信息，如订单ID、用户ID、订单日期、订单状态等。\n产品表（Product）：存储产品的详细信息，如产品ID、产品名称、产品价格、库存数量等。\n订单项表（Order_Item）：用于表示订单与产品之间的多对多关系，记录每个订单中包含的产品及其数量、价格等信息。\n哪些表需要加索引？对哪些字段加索引? 需要索引的表 对于记录数较多的表，建立索引可以显著提升查询性能。\n需要加索引的字段 1.主键字段：主键字段默认建立唯一索引，确保记录的唯一性和快速定位。\n2.经常作为查询条件的字段：在 WHERE 子句中频繁出现的字段，特别是在大表中，应建立索引，以提高查询效率。\n3.用于表连接的字段：在与其他表进行连接操作时，连接字段应建立索引，以加速连接操作。\n4.用于排序（ORDER BY）和分组（GROUP BY）的字段：这些字段建立索引后，可提高排序和分组操作的性能。\n5.选择性高的字段：选择性高意味着字段值的唯一性较高。在此类字段上建立索引，可以有效过滤数据，提高查询效率。\n下面是不需要加索引的\n避免在频繁更新的字段上建立索引：因为每次更新不仅要修改数据，还需维护索引，可能影响写操作性能。 (商品库存，商品信息)\n避免在低选择性字段上建立索引：如性别字段，只有 \u0026ldquo;男\u0026rdquo; 和 \u0026ldquo;女\u0026rdquo; 两种值，建立索引效果不明显。\n控制索引数量：过多的索引会增加数据库的维护成本，特别是在频繁写操作的场景下，需要在查询性能和写操作开销之间找到平衡点。\n组合索引 / 复合索引 / 联合索引 像组合索引和复合索引你知道吗?比如说我建了一个a,b,c联合索引。我写代码的时候先写的c，b，a可以吗?\n组合索引（也称复合索引或联合索引）是指在多个列上创建的单个索引，用于提高多条件查询的性能。\n当创建了包含列 a、b、c 的组合索引时，查询条件的顺序会影响索引的使用效果。\n这遵循 最左前缀原则，即索引的使用从最左边的列开始匹配，必须按照索引定义的列顺序进行匹配。\n所以不能使用 c，b ，a 查询。\nMySQL的索引在什么条件下会失效? 对索引字段的运算或函数操作\nSELECT * FROM users WHERE YEAR(birthdate) = 1990; 使用了通配符（LIKE '%abc'）\nSELECT * FROM products WHERE name LIKE \u0026#39;%abc\u0026#39;; 在 WHERE 子句中使用了不等于（\u0026lt;\u0026gt;）操作符\nSELECT * FROM orders WHERE status \u0026lt;\u0026gt; 1; 进行 NULL 值查询时未优化\nSELECT * FROM users WHERE phone_number IS NULL; 数据类型不匹配\nSELECT * FROM users WHERE age = \u0026#39;25\u0026#39;; 使用了 OR 操作符，特别是跨字段时\nSELECT * FROM products WHERE price = 100 OR category = \u0026#39;electronics\u0026#39;; 索引列的数据分布不均匀: 当索引列的数据分布极其不均匀时，即使索引可以使用，MySQL 也可能选择不使用索引，因为扫描全表比扫描索引更高效。\n事务放在MVC当中的哪一层？ 事务的管理应放在 Service层，这是因为Service层负责业务逻辑，可以统一控制跨多个DAO操作的事务。Controller层应该尽量避免直接管理事务，以保持系统的解耦性和职责清晰。而DAO层则专注于数据的持久化操作，不应承担事务管理的责任。\n什么时候应该添加事务？ 那我们查询list会加事物吗? 使用delete删除时会加事物吗?\n事务的使用场景：事务通常用于数据修改操作（如插入、更新、删除），确保数据一致性。\n查询操作的事务性：查询操作一般不需要事务，除非有一致性需求，需通过隔离级别来控制。\n增、删、改操作的事务性：增、删、改应该放在事务中进行，确保增、删、改的原子性。\n并发修改请求如何控制? 假设我的银行卡里面只有10块钱，现在过来10个请求都要扣10块钱，是你的话你会怎么控制?\n最直接的方式是保证每个扣款操作具有原子性。可以通过悲观锁或乐观锁来控制并发，确保多个请求不会同时扣款。\n1.悲观锁和乐观锁\n悲观锁通过数据库层面的锁机制（如 SELECT FOR UPDATE）防止并发修改余额。\n乐观锁通过版本号或 CAS 原理进行操作，适用于并发冲突较少的情况。\n2.分布式锁 （Redission）\n在分布式系统中，可以使用分布式锁来保证对共享资源的独占访问。\n3.队列和限流 (RabbitMQ)\n队列和限流 控制请求的处理速度，避免突发的高并发请求。\n分布式事务如何处理？它的作用? 为什么需要分布式事务：分布式事务用于解决分布式系统中不同服务之间的数据一致性问题，确保跨服务操作能够保证最终的一致性。\n分布式事务解决什么问题：主要解决跨服务的一致性，保证多个服务中的操作要么全部成功，要么全部回滚，保持数据一致性。\n分布式事务的解决方案：（后期学习）\n2PC：适合强一致性要求的场景。 TCC：用于操作更复杂的分布式场景。 Saga模式：适合长事务的分布式事务，通常用于最终一致性场景。 开发过程中Git分支管理 1.开发的时候来了一个新需求，你们的分支是怎么管理的?\n我们采用三种不同的前缀来管理 feat 新增、fix 修复、refactor 重构\n2.增加新需求，分支是从哪里新增的?\n每个新需求都会从 main 分支上创建一个 feat 分支进行开发。\n3.建完一个分支之后就开始改代码吗?\n确保你从主分支（main）创建了最新的分支，避免后续合并时的冲突。\n在开发前，应该确认需求的具体内容，并与相关团队成员对接，然后配置好对应环境，再进行开发。\n4.开发完之后测试的话，这个代码放到哪里去?\n我们会commit feat 分支，然后打包上传到测试环境，提交给测试\n5.假如现在又来了两个新需求，一个需求先上线，一个需求过几天上线。你们的分支是怎么管理的?\n当有多个需求时，先满足第一个要上线的 需求A 。然后再拉取代码，编写 需求B 的代码\n6.你们那个测试拉代码是运维拉代码还是测试拉代码？\n测试拉取代码\nSpringboot和Spring区别及理解 Spring：\n核心特性：Spring 提供了控制反转（IoC）和面向切面编程（AOP）的支持，主要用于构建企业级应用程序。 配置方式：Spring的配置是非常灵活但复杂的。通常，开发者需要通过 XML 配置、注解配置或 Java 配置类来配置 Spring 容器和各种模块。 模块化：Spring 框架分为多个模块，如 Spring Core、Spring AOP、Spring Data、Spring MVC 等，开发者需要根据需要集成和配置这些模块。 Spring Boot：\n自动配置：Spring Boot 提供了大量的自动化配置，开发者只需要少量的配置，甚至可以省去 XML 配置，简化了传统 Spring 配置的复杂度。 内嵌服务器：Spring Boot 提供了 Tomcat、Jetty、Undertow 等内嵌服务器，使得应用可以直接打包为可执行 JAR 文件，无需外部容器支持。 开箱即用：Spring Boot 提供了很多开箱即用的功能，例如，默认的应用结构、内置的健康检查、自动化的日志配置等，极大提高了开发效率。 Spring Boot Starter：使用“Starter”可以让开发者方便地引入常见的依赖包，避免手动配置和集成常用组件。 Spring和Springboot区别 特性 Spring Spring Boot 目标 提供企业级应用开发框架。 简化 Spring 应用的配置和启动过程。 配置方式 需要大量的 XML 或 Java 配置。 通过自动配置简化配置，几乎不需要手动配置。 应用启动 需要外部应用服务器（如 Tomcat）。 支持内嵌服务器，应用可以打包为可执行 JAR 文件。 依赖管理 需要手动配置依赖和版本。 提供预设的 Spring Boot Starter，自动管理依赖。 模块集成 需要开发者手动集成各个模块（如 Spring MVC, Spring Data）。 自动化集成各个模块，并提供开箱即用的功能。 开发效率 配置和集成较为繁琐，开发效率较低。 通过自动配置和开箱即用的功能，大大提高开发效率。 启动时间 启动速度较慢，需要等待容器的初始化。 启动速度快，集成化和内嵌式服务减少了初始化时间。 环境依赖 配置较为灵活，环境依赖需要手动管理。 内嵌服务器和自动配置降低了环境依赖问题。 RabbitMQ和Kafka区别和理解 Kafka 和 RabbitMQ 对比 - 原理\n应用场景 RabbitMQ Kafka 消息大小和格式 适合处理中小型消息，支持各种消息格式，包括文本、JSON等 适合处理大型消息和流式数据，支持批量消息传递和日志存储 实时性要求 支持低延迟的消息传递和定时功能，适用于实时消息处理 （微秒级） 延迟较高，主要优化吞吐量，适合高吞吐量数据流处理 （毫秒级） 吞吐量 吞吐量较低，适合低并发场景 吞吐量极高，适用于高并发、大数据场景 数据一致性和可靠性 提供消息确认机制和强大的持久化功能，保证消息不丢失 通过日志存储、分区和副本机制保证数据可靠性和高可用性 分布式系统支持 支持集群模式，但在扩展性上不如 Kafka 原生支持分布式架构，适用于大规模分布式系统 插件支持和生态系统 丰富的插件支持，易与各种技术和工具集成，功能多样化 插件支持较少，但生态系统广泛，主要用于流处理、大数据平台 ","permalink":"https://swimmingliu.cn/posts/job/java-interview-questions-notes/","summary":"\u003ch2 id=\"-和-equals-区别\"\u003e== 和 equals 区别\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003e==\u003c/code\u003e 基本类型(int, long, float, char, boolean) 值比较， 引用类型(String，List) 进行地址比较\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eequals\u003c/code\u003e 默认就是 \u003ccode\u003e==\u003c/code\u003e ，但是部分引用类型(String，List)重写了该方法，进行值比较\u003c/p\u003e\n\u003ch2 id=\"get-和-post-区别\"\u003eget 和 post 区别\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e特性\u003c/th\u003e\n          \u003cth\u003eGET\u003c/th\u003e\n          \u003cth\u003ePOST\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e目的\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e获取资源，查询数据\u003c/td\u003e\n          \u003ctd\u003e提交数据，创建或更新资源\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e请求数据方式\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e参数通过 URL 查询字符串传递\u003c/td\u003e\n          \u003ctd\u003e数据通过请求体传递\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e数据暴露\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e数据暴露在 URL 中，较不安全\u003c/td\u003e\n          \u003ctd\u003e数据存储在请求体中，相对安全\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e数据大小限制\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003eURL 长度有限制（约 2048 个字符）\u003c/td\u003e\n          \u003ctd\u003e没有数据大小限制\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e适用场景\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e获取数据，查询，展示资源\u003c/td\u003e\n          \u003ctd\u003e提交表单，上传文件，修改资源，发送敏感数据等\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"springmvc中reponsebodypathvariablerequestparameters在什么情况下使用\"\u003eSpringMVC中@ReponseBody、@PathVariable、@RequestParameters在什么情况下使用?\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003e@ReponseBody\u003c/code\u003e 用于接受请求体数据，一般用于POST请求\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e@PathVariable\u003c/code\u003e 用于接受路径参数，一般用户接受 \u003ccode\u003eid\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e@RequestParameters\u003c/code\u003e 用于接受请求参数，一般用于GET请求\u003c/p\u003e\n\u003ch2 id=\"jvm堆的结构gc介绍和作用\"\u003eJVM堆的结构、GC介绍和作用\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://www.51cto.com/article/710705.html\"\u003eJVM堆结构的参考文章\u003c/a\u003e 、 \u003ca href=\"https://www.bilibili.com/video/BV1dt411u7wi\"\u003eGC垃圾回收过程\u003c/a\u003e\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e区域\u003c/th\u003e\n          \u003cth\u003e主要用途\u003c/th\u003e\n          \u003cth\u003e特点\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e新生代（Young Generation）\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e存储新创建的对象，快速垃圾回收\u003c/td\u003e\n          \u003ctd\u003e包含 Eden 区和两个 Survivor 区，采用复制算法进行回收\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e老年代（Old Generation）\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e存储长期存活的对象\u003c/td\u003e\n          \u003ctd\u003e回收频率较低，垃圾回收较耗时\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e永久代（Permanent Generation) (jdk 1.7）\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e存储类的元数据、方法字节码等\u003c/td\u003e\n          \u003ctd\u003e在 jdk 1.8 被 Metaspace 替代\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e元空间（jdk 1.8）\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e存储类的元数据\u003c/td\u003e\n          \u003ctd\u003e不再属于堆，使用本地内存，大小由系统限制\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003ccode\u003eGC\u003c/code\u003e 是垃圾回收器， 作用是自动内存管理和避免内存泄漏\u003c/p\u003e","title":"Java面试题-随手记"},{"content":"Abstract 肺癌是全球最致命的癌症之一，早期诊断对于患者的生存至关重要。肺结节是早期肺癌的主要表现，通常通过 CT 扫描进行评估。如今，计算机辅助诊断系统被广泛用于辅助医生进行疾病诊断。肺结节的准确分割受到内部异质性和外部数据因素的影响。为了克服结节的细微、混合、粘附型、良性和不确定类别的分割挑战，提出了一种新的混合手动特征网络，可增强灵敏度和准确性。该方法通过双分支网络框架和多维融合模块集成特征信息。通过使用多个数据源和不同数据质量进行训练和验证，我们的方法在 LUNA16、多厚度切片图像数据集 (Multi-thickness Slice Image dataset)、LIDC 和 UniToChest 上表现出领先的性能，Dice 相似系数达到 86.89%、75.72%、84.12% 和 80.74分别超过了当前大多数肺结节分割方法。我们的方法进一步提高了肺结节分割任务的准确性、可靠性和稳定性，即使是在具有挑战性的 CT 扫描中也是如此。本研究中使用的代码发布在 GitHub 上，可通过以下 URL (https://github.com/BITEWKRER/DBNet) 获取。\nIntroduction 肺癌是全球癌症相关死亡的主要原因[1]。仅在美国，预计 2023 年将有 127,070 人死于肺癌，占所有癌症死亡的 21% [2]。不幸的是，超过 50% 的肺癌病例发生在发展中国家或不发达国家，与发达国家相比，这些国家的医疗资源有限[3]。\n为了增加生存机会，早期诊断和治疗肺癌仍然至关重要。在中国，研究表明，小于1厘米的I期肺癌的5年生存率为92%。然而，晚期肺癌的5年生存率低得多，仅为7.0%[4]。利用计算机断层扫描 (CT) 进行肺癌筛查已显示出可大幅降低死亡率的潜力 [5]、[6]。低剂量CT是目前肺癌筛查最常用的方法。此外，移动CT的引入有助于解决欠发达国家和偏远地区缺乏CT扫描仪的问题[6]。由于可能没有明显的症状，检测早期肺癌的存在可能会带来重大挑战。\n这种医学背景数据可以直接借鉴，Chatgpt润色改写就完事儿\n在 CT 图像上识别肺结节提供了疾病的关键指标 [1], [3]。这些结节代表圆形异常，其大小各异，直径范围为 3 至 30 毫米 [7]。为了进一步研究肺结节，美国国家癌症研究所组装了“肺部图像数据库联盟和图像数据库资源计划（LIDC）”数据集[8]。\n欠发达地区设备不足、人员不足，导致医生的诊断和治疗时间有限[9]。在这种情况下，医生的工作量很大、重复且耗时[10]、[5]。此外，由于与CT切片相比，肺部结节性病变占据相对较小的面积，长时间和密集的CT筛查可能会导致漏检小的、细微的或 GGO (肺磨玻璃结节) [3]，[6]。为了解决这些问题，计算机辅助诊断系统（CAD）出现并得到了快速发展，特别是随着基于深度学习技术的诊断方法的进步。 CAD系统大大减轻了医生的工作量，最大限度地降低了未发现结节的风险，并提高了肺结节诊断的效率和可靠性。然而，当前用于肺结节分割的 CAD 系统仍然面临一些挑战。\n下面详细阐述了肺结节分割的几个现有挑战，可以从这些挑战入手\n首先，放射科医生标记的肺结节包含九个诊断特征[11]，异质性表型阻碍了肺结节分割的发展。如图1所示，实心结节（a，b）具有清晰的形状和边界，而微妙的GGO结节（e）具有低对比度和模糊的边界[4]，使得网络很容易将它们分类为背景区域。空洞（g）结节降低了网络分割的敏感性，并且由于背景和分割目标之间的极度不平衡，小结节很容易被遗漏[12]。\n由于周围多余的组织结构，血管旁或胸膜旁（c、d、f）可能会导致网络分类错误[13]。此外，部分实性结节（h）比纯GGO更致密，产生更复杂的异质纹理，更容易发展成恶性结节[14]。\n其次，肺结节内部因素造成的分割困难在于医生注释、层厚、数据来源和数据质量。数据质量差或不同医生的经验可能会导致不同的注释和注释者数量。由多名医生注释的病变区域通常更可靠，减少了潜在的临床风险。在资源有限的地区，由于 CT 扫描仪短缺和成像设备陈旧，CT 扫描质量差的情况很常见。较厚的切片更有可能产生“体积平均效应”和伪影，使医生难以达成一致的诊断。即使使用移动 CT 扫描仪也可能无法提供完整的诊断详细信息。最后，目前大多数肺结节分割方法都是基于2D图像，但这些方法忽略了空间关系，因此提出一种有效的3D肺结节分割模型来捕获肺结节的空间位置、纹理和其他详细信息变得越来越重要以避免误诊和漏诊。\nChallenge:\n异质性: 肺结节的形状多异 （实心结节、磨玻璃结节 (GGO) 、空洞结节、血管和胸膜旁边的结节）\n数据集缺陷：数据集质量不好、较厚的切片和医生的不同标注都可能影响最后的分割结果\n2D网络缺陷：忽略了CT信息中的空间关系\n背景知识补充：在医学成像，特别是在使用计算机断层扫描（CT）进行诊断时，“体积平均效应”和“伪影”是两个可能影响图像质量和解读准确性的问题。\n体积平均效应：这是一种由于扫描切片厚度较大而引起的现象。在一个较厚的切片中，多个不同密度的结构可能被平均到同一个体素（三维像素）里。这意味着高密度和低密度区域可能会混合在一起，从而降低了图像的对比度和分辨率。这种效应使得较小的结构，如小肺结节，更难以被准确识别和分割，因为它们可能在较厚的切片中“消失”或与周围组织混合。 伪影：伪影是指在成像过程中由各种原因产生的非实际存在于原始对象中的图像特征。在CT扫描中，伪影可能由患者移动、成像设备的限制、软件处理算法或扫描参数设置不当等因素引起。较厚的切片可能加剧这些伪影，因为每个切片覆盖更大的体积，增加了平均和重建过程中出现错误的机会。 这段话中提到，“较厚的切片更有可能产生‘体积平均效应’和伪影”，意味着在使用较厚切片进行CT扫描时，上述两个问题更容易发生，这会降低图像的质量和可解释性。结果，医生在解读这些图像时可能会遇到困难，因为图像的不清晰和伪影可能导致诊断不一致或误诊。这就强调了使用高分辨率、薄层切片扫描和高质量成像设备的重要性，以提高诊断的准确性和一致性。\n针对上述肺结节的异质性特征，我们提出了一种新的混合手动特征，旨在提供额外的边界和病灶信息，显着提高肺结节分割的灵敏度，减少漏诊的发生，降低像素点的可能性错误分类。为了保证分割结果的可靠性，我们采用多位医师标注结果的平均值作为GroundTruth，并对单位医师标注的样本进行二次筛选。为了确保模型在不同数据源和数据质量上的鲁棒性，我们在不同来源、质量和尺度的数据集上训练模型，并在不同数据源和切片厚度上进行验证。为了有效地整合主、辅分支的特征信息，我们设计了多维融合模块，并从空间和通道维度进行学习，以增强网络的表示和泛化能力。最后，所提出的网络能够进行三维分割，有利于病变信息的全面获取。\n下面是 Main Contribution\n（a）提出了一种新的端到端双分支网络和融合模块，有效完成肺结节分割任务，简单易用，泛化性较好能力。\n（b）提出了混合手动特征来同时增强肺结节边界信息和对比度信息。\n（c）我们的方法显示了分割各种类型的肺结节的性能改进，特别是在细微的、混合纹理的、粘连的、良性的和不确定的结节中。\n(d) 研究并总结了不同层厚和尺寸下模型的性能变化和模式。\nRelated work 目前，肺部结节的分割方法有很多，可以分为基于算法的传统分割方法和数据驱动的深度学习分割方法。然而，传统的肺结节分割方法存在明显的缺陷，特别是当肺结节的边缘变得模糊时，导致性能急剧下降[15]。相比之下，数据驱动的方法表现出更好的性能[16]。\n数据驱动算法 \u0026gt; 传统分割算法 ==\u0026gt; 调研数据驱动算法的论文，利用数据驱动来创新\n多分支网络架构引起了广泛的关注和研究。这些结构擅长集成不同规模、视角和维度的不同特征，从而提高性能。为了解决肺结节的异质性以及结节与其周围环境的相似性的挑战，Wang等人[17]引入了中央聚焦卷积神经网络。该网络从 2D 和 3D CT 图像块中提取肺结节信息，并通过中央池化层保留中央位置的基本细节。 Chen等人[18]引入了Fast Multi-crop Guided Attention，一种基于残差的多尺度引导分割网络来解决这个问题。该方法最初将 2D 和 3D 图像输入单独的分支网络，以从多维相邻轴捕获上下文特征信息。随后，采用全局卷积层来感知和融合上下文特征，同时通过中央池化层增强对图像块的中心区域的关注。 Wang等[19]提出了一种提高不规则肺结节分割效率的方法，同时保持简单结节的准确分割。他们利用双分支框架来处理 CT 图像和边界梯度信息，使用密集注意力模块来关注关键结节特征，并使用多尺度选择性注意力模块来连接不同尺度的特征。此外，他们引入了边界上下文增强模块来合并和增强边缘相关的体素特征，从而实现简单型肺结节的准确分割。 Xu等人[20]提出了一种用于分割非典型结节的双编码融合网络。他们首先使用金字塔上采样方法来创建平滑的病变图像，并减少 CT 图像中高粒度像素的干扰。然后，他们使用全局和局部分支对上采样的 CT 图像块和原始图像块进行编码，以捕获全局和局部信息。此外，他们采用了金字塔池化模块来增强本地分支的输出特征。最后，他们融合并解码了来自双分支的特征信息。 Wang等人[21]提出了一种混合深度学习模型（H-DL），用于分割各种大小和形状的肺结节。该模型结合了基于VGG19的浅层U-Net网络和基于密集连接的深层U-Net网络，增强了复杂肺结节分割的学习能力。与独立的 UNet 结构模型相比，将这两个模型集成到混合模型 H-DL 中证明了分割结果得到了改善。\n基本块的设计对于肺结节分割也具有重要意义。研究人员探索了多种设计概念来提高模型性能和效率。 Wang等人[22]设计了一个基于空洞卷积的深度尺度感知模块来聚合上下文。该模块将具有不同扩张率（1、2和3）的并行分支嵌入到瓶颈层中，以捕获更丰富的语义信息。 Agnes等人[23]提出了一种多尺度全卷积3D UNet模型，其中作者设计了一个多尺度基本块，使用 $3×3×3$ 和$5×5×5$ 卷积从各种尺度中提取特征信息。他们使用 Maxout 激活函数优化多尺度特征信息，抑制低贡献特征。 Chen等人[15]提出了一种用于分割GGO的注意力级联残差网络。该网络通过残差结构和扩张的空间金字塔池模块捕获肺结节的特征信息。在后处理阶段，应用基于体素的条件随机场来进一步细化分割结果。 Zhou等[3]介绍了一种级联的2.5D肺结节检测和分割方法。在分割网络中，作者将卷积块注意力模块（CBAM）[24]合并到编码器中，以增强网络的编码能力。在瓶颈层设计了不同的多尺度卷积扩张率，以实现结节区域的精细分割。\n另一种方法是使用对抗性生成网络进行肺结节分割。训练数据稀缺和类别不平衡一直是影响肺结节分割性能的关键因素。数据稀缺会导致过度拟合或模型收敛失败，而类别不平衡则增加了目标区域分割的挑战。为了解决这些问题，Song等人[25]提出了一种基于生成对抗网络对多种类型肺结节进行全自动分割的端到端架构。该模型包括两个分支。第一个分支用于潜在的肺结节分割和结节生成。第二个分支旨在减少第一个分支产生的潜在假阳性结节。此外，Tyagi 等人[26]引入了一种基于条件生成网络的分割方法。该方法利用生成器（基于具有空间和通道挤压和激励模块的 UNet）和判别器进行对抗训练来学习训练数据集的样本分布，从而提高分割性能。在Luna16数据集上，其DSC得分为80.74%，灵敏度为85.46%。这两种方法背后的动机是利用生成对抗网络的特征来学习肺结节内的抽象特征并生成适用于临床环境的训练样本。虽然这种方法在有足够数量的训练样本时是可行的，但由于肺结节数据集中的样本分布不平衡，它面临着挑战。目前，生成高质量和多样化的数据仍然是一个重大挑战。\nMethod A. Pre-processing 肺结节CT图像预处理步骤如下：\n(a) Ground Truth: 同一结节的Mask 根据质心坐标进行聚类，并使用开源Pyldc工具库对不同医生的注释进行平均，级别设置为0.5[27]。然后获得真实值 (GT)，如图 2 所示。\n(b) 重新采样：将裁剪后的肺结节区域重新采样为 1 mm，并将生成的图像块大小调整为 64×64×64 [28]，[29].\n(c) 归一化和混合特征：使用Z-score对原始图像块进行标准化，将CT图像转换为标准正态分布，提高网络训练的稳定性。混合特征通过变换和加权求和，同时保留了切归一化后的对比度信息（Cut-norm，eq（1））和 Sobel算子的边界信息，如图3所示。肺HU值的切归一化范围为**[-1000, 400]** [3]，然后将截断的 CT 图像映射到 [0,1]，从而提高 CT 图像中低对比度组织和细节的可视性，同时增强网络的灵敏度。 Sobel算子是一种简单且稳定的算子，可以有效突出细微、血管旁和胸膜旁结节的边界信息。另外，Prewitt算子的成像结果与Sobel算子相似，因此没有进行进一步的研究。\nB. Overall Design of the Dual-branch network 双分支网络 (DBNet) 的架构如图 4 所示。它代表了一种端到端肺结节分割方法，包括信息编码和解码两个阶段。在编码阶段，我们采用主网络和辅助网络概念。主网络（$En_raw$）以原始CT图像作为输入，而辅助网络（$En_aid$）则利用混合特征图像作为输入。主、辅分支的输入图像块大小为 $Image^{C×H×W×D}{raw}$ , $Image^{C×H×W×D}{help}$ ∈ $R^{1×64×64×64}$，其中 $C$、$H$、$W$、$D$表示输入通道、长度、宽度和深度。编码阶段总共包括5个编码块和4次下采样操作，不同编码阶段的特征图可以表示为 $f^i_r$ , $f^i_a$ , $i$ ∈ [1, 5]，$r$ 和 $a$ 表示主分支和辅助分支，特征图从 $32 × 64 × 64 × 64$ 过渡到 $64 × 32 × 32 × 32$，然后过渡到 $128 × 16 × 16 × 16$、$256 × 8 × 8 × 8$，最后过渡到 $512 × 4 × 4 × 4$\n在解码阶段，采用双分支设计，减少网络参数和计算量，同时提供更多的特征选择和更强的泛化能力。针对双分支特征信息的融合设计，提出了多维融合模块，从多个维度的空间通道中提取特征信息。然后，注意力模块的输出特征图将被上采样并与相应的编码阶段特征图 $ f^i_r $ 和 $f^i_a$ 融合，其中 $i$ ∈ [1,4]，以补偿下采样过程造成的信息损失。该融合过程重复四次，以逐渐预测肺结节区域。经过 $3×3×3$ 卷积的特征提取和优化后，得到预测的肺结节区域为 $Output^{1×64×64×64}$ ∈ [0,1]。设置阈值0.5，如果该值大于阈值，则该像素被认为是肺结节的一部分；否则，它被视为背景的一部分。\n网络的基本单元包括卷积（Conv）、BatchNorm（BN）和Swish激活函数[30]，统称为CBS。 BN 加速网络收敛并增强其表达能力，而 Swish 激活函数可以减轻与更深网络相关的梯度消失问题。可训练参数 $beta$ = 1.0 动态调整 Swish 激活函数的形状，以更好地适应肺结节分割任务，如（2）所示，其中 $σ$ 表示 sigmoid 激活函数。将基本块的数量增加到2，并添加残差连接，得到残差基本块RCBS。\nC. Design of the Multi-Dimensional Fusion Module 多维融合模块（MDFM）由两部分组成：通道挤压洗牌注意力模块（CESA）和轴向多尺度空间注意力模块（AMSA），模块设计和内部注意力变化[31]如图5所示，整个过程可以表示为方程3至方程5。\n1) Channel Extrusion Shuffle Attention Module 通道挤压洗牌注意力模块 (CESA) 的输入来自双分支编码器的级联输出特征图。在优化通道特征之前，首先使用自适应均值池化和自适应最大池化将特征图聚合为 $C×1×1×1$，并使用CBS基本块来融合两类特征信息。多尺度设计可以扩大网络的感受野，获得更丰富的局部细节和全局信息。受这一思想的启发，在通道维度上对通道特征进行多尺度采样，在不改变融合特征图大小的情况下优化特征信息。通道多尺度涉及通道维度上的降维和扩展操作，深度依次为 $C/2$、$C/4$、$C/8$、$C/16$。此外，通过密集连接设计，网络的表达和泛化能力得到进一步增强，该过程称为“挤出”。通道混洗操作将通道分为8组，并通过混洗通道内的特征信息引入一定程度的随机性和多样性。然后将打乱后的特征添加到挤压操作后的特征图上，最后通过点积操作恢复特征图。利用Sigmoid（σ）方法，将特征图转换为[0,1]之间的概率分布，并将注意力权重映射到原始特征图。\n2) Axial Multiscale Spatial Attention Module 准确捕获肺结节的空间位置、纹理和形状信息对于分割任务至关重要。因此，提出了轴向多尺度空间注意力模块。首先，我们使用 $7 × 7 × 7 $ 窗口大小的 CBS 块来感知全局上下文信息，同时以 8、16、32 和 64 的压缩比 (r) 压缩特征图通道。压缩后的特征信息不仅更加关注空间维度特征，而且减少了网络参数和计算量。然后，我们利用窗口大小 $H×3×3$ 、$3×W×3$ 和 $3×3×D$ 的基本块来感知 Coronal、Sagittal 和 Axis 方向的特征图，其中 H、W 和 D 分别是特征图尺寸，从而捕获不同平面**（冠状矢状、矢状轴、冠状矢状）**的局部信息以及不同轴向的全局信息。这种设计有助于强调和突出肺结节的关键特征，使模型能够更好地理解和表达多维数据中的特征。对多维特征信息进行汇总，并利用残差连接补充梯度信息。最后利用 $7×7×7$ 的卷积核来恢复特征图，完成空间特征信息的提取。\nD. Loss Function Dice相似系数[32]（DSC）是一种相似性测量函数，通常用于计算两个样本的相似性。 DSC ∈ [0,1]，值越小表明**模型预测结果 **与 真实标签差距越大。\n其中 $P$ 表示二进制预测结果像素的集合，$G$ 表示二进制真实标签结果的集合。 $| P ∩ G |$ 表示 $P $ 和 $G$ 的交集。\nExperiments A. Datasets 本文在其实验设置中介绍了四个数据集：\n（1）LIDC： 肺部图像数据库联盟和图像数据库资源倡议 (LIDC) 数据集是全球最大的公开肺癌数据集。它包括来自多家医院的 1, 018 个研究病例，包含 11 种不同厚度类型的数据，最多有四名医生在 CT 图像中注释病变信息 [8]，如图 6 所示。首先，直径为 3mm 或 3mm 的结节由至少两名医生注释的较大的被保留[21]。然后，对由一名医生注释的结节进行二次筛查，以去除不确定或注释错误的样本，总共得到 2, 615 个肺结节样本。\n2）Luna16： Luna16 数据集是 LIDC 数据集的子集，旨在解决 LIDC 数据集中 CT 切片厚度变化和数据质量等问题。 Luna16数据集总共包括1186个肺结节样本，这些样本由三名或更多医生注释，直径为3毫米或更大，切片厚度为2.5毫米或更小[33]。\n(3) 多厚度切片图像数据集(mThickSImg)： 剔除Luna16肺结节样本后，共获得1429个多层结节，主要用于内模型性能测试，实验数据的样本分布如图7所示。\n(4) UniToChest： UniToChest [34] 数据集包括 306,440 个匿名胸部 CT 扫描切片和相应的肺结节分割掩模。这些数据来自623名不同的患者，经过处理和筛选后，总共获得了211张结节大小从3到35mm的多层CT图像用于外部测试集。\nB. Lung nodule characteristic attributes classification LIDC 数据集总共包含由医生注释的 9 个视觉特征。在该实验中，去除了内部结构和钙化特性，并重新定义了良性和恶性的分类[35]，同时还纳入了肺结节的大小[24]。为了保证多个医师对同一肺结节标注的一致性，肺结节属性分类采用两种策略：（1）良恶性肺结节的定义是多个医师对结节标注结果的中位数 [35]。 (2)其他特征属性通过投票过程获得。肺结节属性分类如表1所示。\nC. Evaluation Metrics 在本文中，我们使用精度（PRE）、灵敏度（SEN）、骰子相似系数（DSC）和并集平均交集（mIoU）作为评估指标，如方程（7）至（10）所示。 True Positive（TP）表示正确分割的焦点区域，True Negative（TN）表示正确分割的正常组织区域，False Positive（FP）表示正常组织区域被错误地分割为焦点区域，False Negative（FN）表示焦点区域被错误地分割为正常组织区域。\nD. Training Details 本实验使用Ubuntu 18.04.3 LTS操作系统作为实验基础平台。 CPU型号为Intel(R)Xeon(R)-Gold 6140，内存大小为187.4G，软件环境为Python 3.8、Conda 10.1、Pytorch 1.8.1在Tesla V100-SXM2-32GB显卡上实验。\n实验遵循所有 CAD 方法的一致设置。在训练阶段，数据集被分为5个子集，每个子集循环用作验证集，其余4个子集作为训练数据。应用数据增强技术，包括水平和垂直翻转、旋转和平移，来增强训练样本并增强模型的鲁棒性。最终的性能评估基于5倍交叉验证获得的平均结果。 Adam 优化器 [37] 的初始学习率为 3e-4，批量大小为 12，最多 500 次训练迭代。使用的损失函数是 Dice 损失。另外，我们使用提前停止机制来防止过拟合。在 50 轮训练中，如果没有达到较小的损失，模型训练将结束。\nResult A. CAD model performance comparison 如表2所示，所提出的方法与一些最近优秀的CAD模型进行了比较。根据样本数量和选择策略，这些方法分为小样本肺结节分割方法和一般样本数量肺结节分割方法。这些方法的筛选标准列于表中。在使用小样本量的肺结节分割方法中，我们提出的模型在包含 1,186 个结节的 Luna16 数据集上实现了最先进的性能，通过 5 folder 交叉验证实现了最高 DSC 87.68%（最佳）和 86.89%（平均）。就整体 DSC 而言，这比当前顶级小样本方法 DS-CMSF 领先 0.93%。这证明了我们的方法在相对较小的训练样本量下的有效性。此外，为了研究大样本量的性能，我们的方法在 LIDC 数据集中的 2,618 个节点集上进行了训练。我们取得了最佳 DSC 分数和平均 DSC 分数分别为 85.42% 和 84.12%，显着优于当前领先的 LNHG 模型（82.05%）和其他主流算法。\n总体而言，不同数据量下的测试结果表明本文方法具有较强的稳定性和泛化能力。\nB. Ablation studies 在本节中，我们对所提出的 CAD 模型的不同部分进行了消融研究，以评估它们对性能的贡献。消融研究中使用的模型是基于 Luna16 数据集进行训练的。\n在影响模型性能的因素中，研究人员普遍认为模型规模是关键因素。目前，大多数学者倾向于使用 $64×64×64$ 的 patch大小作为神经网络的输入。按照此设置，模型的初始通道数设置为32，考虑到输入大小的约束，模型的最大下采样次数设置为4。此时，瓶颈层的输入大小为 $4 × 4 × 4$ ，512 个通道。基于此，我们设计了四种双分支分割模型（称为模型A、B、C和D），深度分别为2、3、4和5层。这些模型均使用CBAM模块作为双分支模型的融合模块。实验结果表明，随着网络深度和通道数的增加，模型性能呈现出不断增加的趋势，DSC从80.61%上升到85.8%，如表3所示。因此，得出结论：在输入尺寸为64×64×64的情况下，本研究模型的最佳深度为5，瓶颈层有512个通道。\n实验中主要探索了两类辅助特征。一种是利用Cut-norm来突出病变的特征信息，另一种方法主要利用Sobel梯度算子来增强边界信息。在最佳模型规模的讨论中，所有模型均使用Z-score标准方法进行训练。训练这两个手动特征并与模型 D 进行比较后，发现使用 Cut-norm 的模型 E 和使用 Sobel 算子的模型 F 在 DSC 中分别与模型 D 相差 0.61% 和 0.78%。这说明了该辅助分支策略的有效性。此外，进一步验证了Sobel算子在不同数据尺度下的有效性，发现模型D和模型F在LIDC数据集上的DSC性能分别达到83.56%和83.82%，相差0.26%。这表明，即使在更大规模的测试集中，Sobel算子仍然有效，因此，暂时将Sobel算子用作辅助特征。\n进一步基于Sobel算子作为辅助特征，提出了通道挤压洗牌注意力模块和轴向多尺度空间注意力模块，即模型G和模型H，模型性能最优达到86.63%。最后，为了同时保留高对比度病变区域和突出显示的边界细节以方便学习，我们使用变换操作和加权求和来整合这两个特征。通过这种策略，本文提出的方法获得了 86.89% DSC 的最佳结果，超过了单独使用 Sobel 滤波器特征的性能。直接的性能提升验证了我们辅助功能的有效性。\n虽然模型 H 和我们的整体性能差距并不显着，但模型 H 在内部数据集中的 DSC 性能为 63.03%，对于 GGO 类型评估的灵敏度为 62.42%。然而，使用混合特征的进一步替代导致灵敏度和 DSC 性能显着提高，分别达到 65.27% 和 65.08%。观察模型G、H和Ours的收敛速度，随着注意力模块数量的增加和混合特征的替换，模型拟合所需的epoch逐渐增加，但综合考虑，总体费用是值得的。\nC. Comparison experiments of different datasets and segmentation CADs 本节将我们的方法与开源医学分割模型 UNet [38]、UNet++ [28]、ReconNet [39]、Unetr [40] 和 Asa [41] 在不同数据集上的测试结果进行比较。结果如表IV所示。总体而言，该方法在 Luna16 数据集上实现了 86.89% 的 DSC，分别领先 UNet 和 ReconNet 模型 1.38% 和 0.77%。在基于Transformer的方法中，在DSC方面，它以4.01%和2.66%的优势超过了Unetr和ASA。整体性能超过了经典和现有的优秀分割模型。具体而言，该方法的精度为87.13%，灵敏度为87.02%。更高的灵敏度可以更好地识别结节，防止漏诊；而更高的精度为医生提供了更可靠的分割区域，减少误诊。这对于肺结节分割任务至关重要。此外，该方法实现了高 mIoU，表明预测与真实情况之间有更大的重叠。可以很好地分割大部分肺部病变区域，辅助合理诊断，有利于临床使用。\n随后，所有方法都在内部 mThickImgs 数据集和外部 UniToChest 数据集上进行了验证。在这两个数据集上，UNet++ 达到了最高的精度，但灵敏度较低。这表明 UNet++ 在真阳性区域中假阴性的比例较大，丢失了更多样本并最终影响了灵敏度指标。这种不平衡对于临床目的是有害的。此外，ReconNet在mThickImgs数据集中具有较高的灵敏度。我们的方法在两个数据集中实现了 75.32% 和 80.64% DSC，分别超过次优方法 0.57% 和 0.59%，实验结果再次证明了我们方法强大的泛化能力。\n总体而言，我们的方法在不同数据集的指标上比其他最先进的3D CAD模型具有明显的优势，特别是在灵敏度和DSC这两个最关键的分割性能指标方面，验证了我们方法的分割能力在多源医学图像中。\nAnalysis of lung nodule performance A. Effect of different layer thicknesses on model performance 我们分析了 mThickSImg 数据集中肺结节的分布，并检查了不同 CT 切片厚度和尺寸的结节性能变化。我们将数据分为六组，数据样本分布如表六所示。然后对不同的CAD模型进行测试，并将不同模型的平均测试结果作为最终的性能趋势，如表5所示。\n我们的方法是基于2.5mm层厚度以下的样本进行训练的，通过观察精度，我们发现在1.5mm和1.5mm ~ 2.5mm的比较中，网络的灵敏度随着层厚度的减小而增加。\n另外，在观察DSC性能时，注意到DSC性能随着层厚度的增加而增加。然而，似乎存在随着层厚度减小灵敏度增加而DSC降低的现象。为什么会出现这种现象呢？一方面，这种趋势可能会受到数据分布、样本数量和样本标签的影响而有些偏差。一般来说，随着 CT 层厚度的增加，图像分辨率会降低，可能导致神经网络难以捕获更精细的特征和结构。\n因此，由于较厚的 CT 层中详细信息的丢失，网络随着层厚度的增加而表现出较低的灵敏度。另一方面，虽然层厚度的减少提高了 CT 图像的层内分辨率，并能够更准确地呈现解剖结构和病变，但同时也减少了接收到的光子数量。与较厚的图像相比，光子计数的减少可能会导致噪声增加和对比度降低。这些因素会对肺结节（尤其是 GGO）的分割产生负面影响，可能导致验证集的性能下降。\n我们还发现，在基于薄层图像进行训练然后在厚层图像上进行验证后，网络表现出更好的性能。我们相信，更薄的 CT 图像由于具有更高的分辨率和更详细的信息，使网络能够学习更微妙的特征。这些细微的特征在2.5mm以上的层厚图像中具有更强的泛化能力，这是基于厚层数据所不具备的。因此，这种现象可能表明关于层厚度效应的更好的性能。\nB. Heterogeneity analysis of lung nodules 本节演示不同分割模型在Luna16数据集和mThickSImg数据集上的测试性能。总的来说，我们的方法在两个数据集上的大多数肺结节分割属性上都取得了领先的结果\n1) Subtle feature 肺结节的早期诊断和治疗对于疾病的诊断具有重要意义。\n可以看出，在Luna16数据集中，我们的方法和UNet在 “Extremely Subtle” 属性和“Moderately Subtle”属性的分割上表现更好，并且我们的方法仅次于UNet的方法，达到了70.99%和76.69%。在mThickImgs测试集中，我们的方法在所有Subtlety特征属性上都达到了最佳性能，“Extremely Subtle”和“Moderately Subtle”属性分别超过UNet和ReconNet 2.75％、1.03％和2.33％、0.94％ 。 UNet网络在两个数据集中表现出不同的性能变化，这并不排除数据分布和数据质量的影响。由于双分支和混合特征的设计，我们的方法在 mThickImgs 测试集上对“Extremely Subtle”属性和“Moderately Subtle”属性分割有较大的性能提升，这证明了我们的方法具有很强的泛化能力和鲁棒性，并提高了临床使用的可靠性。 Extremely Subtle GGO 的分割结果如图 10-(1) 所示。\n2) Texture feature 观察两个数据集中“Texture”特征的测试结果可以发现，在Luna16数据集中，我们的方法在“Solid/Mixed”和“NonSolid/Mixed”类别上表现出了很大的进步，分别为2.73%与次优方法相比，分别提高了 1.62% 和 1.62%。在 mThickSImg 数据集中，我们的方法在 GGO 类和“NonSolid/Mixed”类中达到了 65.08% 和 70.2%，分别领先次优 0.35% 和 1.33%。\n虽然对于 GGO 样肺结节，我们的方法没有显着改进，但对于具有混合纹理的结节，我们的方法进一步减轻了分割挑战。固体/混合分割结果如图10-（3至7）所示。\n3) Maligancy feature 良性和恶性的区分是肺结节分割任务的关键特征。良性结节常呈圆形或椭圆形，而恶性结节往往体积较大，并有明显的针状或分叶状特征。两个数据集的测试结果表明，不确定属性的分割结果最差，其次是良性结节。我们的方法改进了这三类属性的分割，与次优方法、不确定和恶性分割相比，在 Luna16 数据集中增加了 0.73%（良性）、0.28%（不确定）和 0.87%（恶性）如图10（1、2～7）所示。在mThickSImg测试集中，该方法的性能提升更为显着，分别领先1%（良性）、0.83%（不确定）和0.61%（恶性）。提高肺结节良性和不确定性的分割性能对于临床诊断至关重要。采用相同的CAD方法对这两类结节进行分割可以有效观察其发展趋势。与医生手工勾画相比，该方法提高了诊断的准确性和可靠性。\n4) Other features 除了上述三种常见且具有挑战性的分割特征外，肺结节的“球形”、“边缘”、“分叶”和“毛刺”特征对临床诊断具有一定的指导意义。观察“球形”特征，可以发现当前方法在常见的“卵形或圆形”属性上表现出更好的性能。一方面它有更多的训练样本，另一方面也更简单地分割该类的样本。我们的方法在 mThickSImg 数据集中的“线性”和“卵形/线性”病变形状属性中表现出显着优势，导致“线性”和“卵形/线性”属性中的 DSC 次优，分别为 2.74% 和 1.81% 。线性分割结果如图10-(6)所示。还值得注意的是，我们的方法在 Luna16 数据集的 Margin 特征中的五个属性上显示出巨大的改进，特别是“Poorly Defined”属性。\n在 mThickImgs 测试集中，我们的方法在五个属性上分别与次优值相差 0.65%、0.93%、0.7%、0.94% 和 1.02%，这也表明辅助特征可以减轻图像边界的复杂性。病变区域。分叶和毛刺是判断恶性程度的重要指标。这些特征可以帮助医生区分结节边缘的规律性，并有助于对结节进行初步分类和观察。\n可以看出，与次优相比，我们的方法在 mThickImgs 数据集的性能方面表现出了显着的改进。然而，“标记分叶”和“标记毛刺”特征属性的分割仍然具有挑战性。在不同尺寸的结节中，我们的方法在分割3到6mm范围内的实性结节方面也表现出了一定的性能改进。\n与次优方法相比，我们的方法在两个测试集中分别提高了 0.73% 和 1.39%。然而，在“SubSolid”中，大多数方法没有表现出显着差异。\nCONCLUSION 我们提出了一种简单有效的双分支网络分割方法。五折交叉验证的结果表明，该方法能够有效、稳定地执行分割任务。此外，我们的方法对大多数肺结节的特征特征和复杂数据样本的分割具有一定的适用性，特别是对于细微的、纹理混合的、边界模糊的、良性的和不确定的结节，可以大大降低临床应用的难度，并提供为医生提供更可靠的参考。\n这种方法也有一些局限性。首先，虽然混合特征设计保留了边界和对比度信息，但它间接引入了额外的噪声，这可能会干扰网络的特征学习。其次，我们的方法在“Subsolid”小结节的分割方面没有表现出显着的性能改进，未来可能会尝试更深或更详细的多尺度设计来缓解这个问题。另外，由于实验整体采用多位医师标注的平均值作为最终的GT，一定程度上保证了结果的准确性。但也可能导致最终的GT与实际情况存在差异，导致区域不完整或有刺状等详细信息丢失，如图10-(7)所示，对“Marked Lobulation”的分割提出挑战”和“标记毛刺”属性。未来，可能会开发多置信区域方法来缓解这个问题。\n读完的第一感觉： 太长了\u0026hellip;.\n","permalink":"https://swimmingliu.cn/posts/papernotes/2023-dbnet/","summary":"\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e肺癌是全球最致命的癌症之一，早期诊断对于患者的生存至关重要。\u003cstrong\u003e肺结节\u003c/strong\u003e是\u003cstrong\u003e早期肺癌的主要表现\u003c/strong\u003e，通常通过 \u003cstrong\u003eCT 扫描\u003c/strong\u003e进行评估。如今，计算机辅助诊断系统被广泛用于辅助医生进行疾病诊断。\u003cstrong\u003e肺结节的准确分割\u003c/strong\u003e受到\u003cstrong\u003e内部异质性和外部数据\u003c/strong\u003e因素的影响。为了克服\u003cstrong\u003e结节的细微、混合、粘附型、良性和不确定类别\u003c/strong\u003e的分割挑战，提出了一种新的\u003cstrong\u003e混合手动特征网络\u003c/strong\u003e，可\u003cstrong\u003e增强灵敏度和准确性\u003c/strong\u003e。该方法通过\u003cstrong\u003e双分支网络框架和多维融合模块\u003c/strong\u003e集成\u003cstrong\u003e特征信息\u003c/strong\u003e。通过使用\u003cstrong\u003e多个数据源和不同数据质量\u003c/strong\u003e进行训练和验证，我们的方法在 \u003cstrong\u003eLUNA16\u003c/strong\u003e、\u003cstrong\u003e多厚度切片图像数据集 (Multi-thickness Slice Image dataset)\u003c/strong\u003e、\u003cstrong\u003eLIDC\u003c/strong\u003e 和 \u003cstrong\u003eUniToChest\u003c/strong\u003e 上表现出领先的性能，Dice 相似系数达到 86.89%、75.72%、84.12% 和 80.74分别超过了当前大多数肺结节分割方法。我们的方法进一步提高了肺结节分割任务的\u003cstrong\u003e准确性、可靠性和稳定性\u003c/strong\u003e，即使是在具有挑战性的 CT 扫描中也是如此。本研究中使用的代码发布在 GitHub 上，可通过以下 URL (\u003ca href=\"https://github.com/BITEWKRER/DBNet\"\u003ehttps://github.com/BITEWKRER/DBNet\u003c/a\u003e) 获取。\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e肺癌是全球癌症相关死亡的主要原因[1]。仅在美国，预计 2023 年将有 127,070 人死于肺癌，占所有癌症死亡的 21% [2]。不幸的是，超过 50% 的肺癌病例发生在发展中国家或不发达国家，与发达国家相比，这些国家的医疗资源有限[3]。\u003c/p\u003e\n\u003cp\u003e为了增加生存机会，早期诊断和治疗肺癌仍然至关重要。在中国，研究表明，\u003cstrong\u003e小于1厘米的I期肺癌的5年生存率为92%\u003c/strong\u003e。然而，\u003cstrong\u003e晚期肺癌的5年生存率低得多\u003c/strong\u003e，仅为\u003cstrong\u003e7.0%\u003c/strong\u003e[4]。\u003cstrong\u003e利用计算机断层扫描 (CT) 进行肺癌筛查已显示出可大幅降低死亡率的潜力\u003c/strong\u003e [5]、[6]。低剂量CT是目前肺癌筛查最常用的方法。此外，移动CT的引入有助于解决欠发达国家和偏远地区缺乏CT扫描仪的问题[6]。由于可能没有明显的症状，检测早期肺癌的存在可能会带来重大挑战。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e这种医学背景数据可以直接借鉴，Chatgpt润色改写就完事儿\u003c/strong\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e在 \u003cstrong\u003eCT 图像上识别肺结节提供了疾病的关键指标\u003c/strong\u003e [1], [3]。这些结节代表\u003cstrong\u003e圆形异常\u003c/strong\u003e，其\u003cstrong\u003e大小各异\u003c/strong\u003e，直径范围为 \u003cstrong\u003e3 至 30 毫米\u003c/strong\u003e [7]。为了进一步研究肺结节，美国国家癌症研究所组装了“肺部图像数据库联盟和图像数据库资源计划（LIDC）”数据集[8]。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e欠发达地区设备不足、人员不足，导致医生的诊断和治疗时间有限\u003c/strong\u003e[9]。在这种情况下，\u003cstrong\u003e医生的工作量很大、重复且耗时\u003c/strong\u003e[10]、[5]。此外，由于与CT切片相比，\u003cstrong\u003e肺部结节性病变\u003c/strong\u003e占据相对\u003cstrong\u003e较小的面积\u003c/strong\u003e，\u003cstrong\u003e长时间和密集的CT筛查\u003c/strong\u003e可能会导致\u003cstrong\u003e漏检小的、细微的或 GGO\u003c/strong\u003e (肺磨玻璃结节) [3]，[6]。为了解决这些问题，计算机辅助诊断系统（CAD）出现并得到了快速发展，特别是随着基于深度学习技术的诊断方法的进步。 \u003cstrong\u003eCAD系统大大减轻了医生的工作量，最大限度地降低了未发现结节的风险，并提高了肺结节诊断的效率和可靠性\u003c/strong\u003e。然而，当前用于肺结节分割的 CAD 系统仍然面临一些挑战。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e下面详细阐述了肺结节分割的几个现有挑战，可以从这些挑战入手\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e首先，\u003cstrong\u003e放射科医生标记的肺结节\u003c/strong\u003e包含\u003cstrong\u003e九个诊断特征\u003c/strong\u003e[11]，\u003cstrong\u003e异质性表型\u003c/strong\u003e阻碍了\u003cstrong\u003e肺结节分割的发展\u003c/strong\u003e。如图1所示，\u003cstrong\u003e实心结节（a，b）具有清晰的形状和边界\u003c/strong\u003e，而\u003cstrong\u003e微妙的GGO结节（e）具有低对比度和模糊的边界\u003c/strong\u003e[4]，使得网络很容易将\u003cstrong\u003e它们分类为背景区域\u003c/strong\u003e。\u003cstrong\u003e空洞（g）结节降低了网络分割的敏感性\u003c/strong\u003e，并且由于\u003cstrong\u003e背景和分割目标之间的极度不平衡，小结节很容易被遗漏\u003c/strong\u003e[12]。\u003c/p\u003e\n\u003cp\u003e由于周围多余的组织结构，\u003cstrong\u003e血管旁或胸膜旁（c、d、f）可能会导致网络分类错误\u003c/strong\u003e[13]。此外，\u003cstrong\u003e部分实性结节（h）比纯GGO更致密\u003c/strong\u003e，产生更\u003cstrong\u003e复杂的异质纹理，更容易发展成恶性结节\u003c/strong\u003e[14]。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e\u003cimg alt=\"image-20240303102609243\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/262f8e71-d931-11ee-b68c-c858c0c1debd\"\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e其次，肺结节内部因素造成的分割困难在于\u003cstrong\u003e医生注释、层厚、数据来源和数据质量\u003c/strong\u003e。\u003cstrong\u003e数据质量差\u003c/strong\u003e或\u003cstrong\u003e不同医生的经验\u003c/strong\u003e可能会导致\u003cstrong\u003e不同的注释和注释者数量\u003c/strong\u003e。由\u003cstrong\u003e多名医生注释的病变区域\u003c/strong\u003e通常更\u003cstrong\u003e可靠\u003c/strong\u003e，减少了潜在的临床风险。\u003cstrong\u003e在资源有限的地区\u003c/strong\u003e，由于 \u003cstrong\u003eCT 扫描仪短缺和成像设备陈旧\u003c/strong\u003e，\u003cstrong\u003eCT 扫描质量差的情况很常见\u003c/strong\u003e。\u003cstrong\u003e较厚的切片\u003c/strong\u003e更有可能产生“\u003cstrong\u003e体积平均效应”和伪影\u003c/strong\u003e，使医生\u003cstrong\u003e难以达成一致的诊断\u003c/strong\u003e。即使使用\u003cstrong\u003e移动 CT 扫描仪\u003c/strong\u003e也可能\u003cstrong\u003e无法提供完整的诊断详细信息\u003c/strong\u003e。最后，目前\u003cstrong\u003e大多数肺结节分割方法\u003c/strong\u003e都是基于\u003cstrong\u003e2D图像\u003c/strong\u003e，但这些方法忽略了\u003cstrong\u003e空间关系\u003c/strong\u003e，因此提出一种有效的\u003cstrong\u003e3D肺结节分割模型\u003c/strong\u003e来\u003cstrong\u003e捕获肺结节的空间位置\u003c/strong\u003e、\u003cstrong\u003e纹理和其他详细信息变得越来越重要以避免误诊和漏诊\u003c/strong\u003e。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003eChallenge\u003c/strong\u003e:\u003c/p\u003e","title":"A Dual-Branch Framework with Prior Knowledge for Precise Segmentation of Lung Nodules in Challenging CT Scans"},{"content":"Abstract 如今的深度学习方法主要关注如何设计最合适的目标函数，使模型的预测结果能够最接近真实情况。同时，必须设计一个适当的架构，可以帮助获取足够的信息进行预测。现有方法忽略了一个事实，即当输入数据经过逐层特征提取和空间变换时，大量信息将会丢失。本文将深入研究数据通过深度网络传输时数据丢失的重要问题，即信息瓶颈和可逆函数。我们提出了可编程梯度信息（PGI）的概念来应对深度网络实现多个目标所需的各种变化。 PGI可以为目标任务计算目标函数提供完整的输入信息，从而获得可靠的梯度信息来更新网络权值。此外，还设计了一种基于梯度路径规划的新型轻量级网络架构——通用高效层聚合网络（GELAN）。GELAN的架构证实了PGI在轻量级模型上取得了优异的结果。我们在基于 MS COCO 数据集的目标检测上验证了所提出的 GELAN 和 PGI。结果表明，与基于深度卷积开发的最先进方法相比，GELAN 仅使用传统的卷积算子即可实现更好的参数利用率。 PGI 可用于从轻型到大型的各种模型。它可以用来获取完整的信息，使得train-from-scratch (从零开始训练) 模型能够比使用大数据集预训练的state-of-theart模型获得更好的结果，对比结果如图1所示。源代码位于：https： //github.com/WongKinYiu/yolov9。\n核心创新点: 依然是网络结构的创新\nProgrammable Gradient Information (PGI) Generalized Efficient Layer Aggregation Network（GELAN） Introduction 基于深度学习的模型在计算机视觉、语言处理和语音识别等各个领域都表现出了比过去的人工智能系统更好的性能。近年来，深度学习领域的研究人员主要关注如何开发更强大的系统架构和学习方法，例如CNN，Transformers[8,9,40] 、41、60、69、70]，Perceivers[26、26、32、52、56、81、81]和Mambas[17、38、80]。此外，一些研究人员尝试开发更通用的目标函数，例如损失函数[5,45,46,50,77,78]，标签分配[10,12,33,67,79]和辅助监督[18] 、20、24、28、29、51、54、68、76]。上述研究都试图精确地找到输入和目标任务之间的映射。然而，大多数过去的方法都忽略了输入数据在前馈过程中可能会产生不可忽略的信息丢失量。这种信息丢失可能会导致有偏差的梯度流，随后用于更新模型。上述问题可能导致深度网络在目标和输入之间建立不正确的关联，导致训练后的模型产生不正确的预测。\n在深度网络中，输入数据在前馈过程中丢失信息的现象俗称信息瓶颈[59]，其示意图如图2所示。目前可以缓解这种现象的主要方法有：（1）可逆架构的使用[3,16,19]：该方法主要使用重复的输入数据，并以显式的方式维护输入数据的信息； （2）使用Masked建模[1,6,9,27,71,73]：主要利用重构损失，采用隐式方式最大化提取特征并保留输入信息； （3）引入深度监督概念[28,51,54,68]：它利用没有丢失太多重要信息的浅层特征来预先建立从特征到目标的映射，以确保重要信息能够被传递到更深的层次。然而，上述方法在训练过程和推理过程中都存在不同的缺点。例如，可逆架构需要额外的层来组合重复馈送的输入数据，这将显着增加推理成本。另外，由于输入数据层到输出层不能有太深的路径，这种限制将导致在训练过程中难以对高阶语义信息进行建模。对于 Masked 建模，其重建损失有时与目标损失相冲突。此外，大多数掩码机制还会产生与数据的不正确关联。 对于深层监督机制来说，会产生误差累积，如果浅层监督在训练过程中丢失信息，后续层将无法检索到所需信息。上述现象在困难任务和小模型上会更加显着。\n针对上述问题，我们提出了一个新的概念，即可编程梯度信息（PGI）。其概念是通过辅助可逆分支生成可靠的梯度，使得深层特征仍然能够保持执行目标任务的关键特征。\n辅助可逆分支的设计可以避免传统的融合多路径特征的深度监督过程可能造成的语义损失。换句话说，我们在不同语义层面上编程梯度信息传播，从而达到最佳的训练结果。 PGI的可逆架构建立在辅助分支上，因此没有额外的成本。由于PGI可以自由选择适合目标任务的损失函数，因此也克服了Masked建模遇到的问题。所提出的PGI机制可以应用于各种规模的深度神经网络，并且比仅适用于非常深的神经网络的深度监督机制更通用。\n在本文中，我们还基于ELAN[65]设计了广义ELAN（GELAN），GELAN的设计同时考虑了参数量、计算复杂度、准确性和推理速度。这种设计允许用户针对不同的推理设备任意选择合适的计算块。我们将提出的PGI和GELAN结合起来，然后设计了新一代YOLO系列物体检测系统，我们称之为YOLOv9。我们使用MS COCO数据集进行实验，实验结果验证了我们提出的YOLOv9在所有比较中都取得了顶尖的性能。\n我们总结本文的贡献如下：\n我们从可逆函数的角度对现有的深度神经网络架构进行了理论分析，通过这个过程我们成功地解释了许多过去难以解释的现象。我们还基于此分析设计了PGI和辅助可逆分支，并取得了优异的结果。\n我们设计的PGI解决了深度监督只能用于极深的神经网络架构的问题，从而让新的轻量级架构真正应用于日常生活中。\n我们设计的GELAN仅使用常规卷积来实现比基于最先进技术的深度卷积设计更高的参数利用率，同时表现出轻、快速、准确的巨大优势。\n结合所提出的PGI和GELAN，YOLOv9在MS COCO数据集上的目标检测性能在各个方面都大大超过了现有的实时目标检测器。\nProgrammable Gradient Information (PGI)：\n自由选择适合目标任务的损失函数\n可逆结构建立辅助分支，不增加推理成本\n适用于各种规模的深度神经网络\nGELAN：\n轻、快速、准确 采用常规卷积吊打其他新颖卷积 Related work 2.1 Real-time Object Detectors 目前主流的实时目标检测器是YOLO系列[2,7,13–15,25,30,31,47–49,61–63,74,75]，这些模型大多数使用CSPNet[64]或 ELAN [65] 及其变体作为主要计算单元。在特征集成方面，通常使用改进的PAN[37]或FPN[35]作为工具，然后使用改进的YOLOv3头[49]或FCOS头[57, 58]作为预测头。最近也提出了一些实时目标检测器，例如 RT DETR [43]，其基础是 DETR [4]。然而，由于DETR系列目标检测器在没有相应领域预训练模型的情况下很难应用于新领域，因此目前应用最广泛的实时目标检测器仍然是YOLO系列。本文选择 YOLOv7 [63] 作为开发该方法的基础，该方法已在各种计算机视觉任务和各种场景中被证明有效。\n我们使用 GELAN 来改进所提出的 PGI 的架构和训练过程。上述新颖方法使所提出的 YOLOv9 成为新一代顶级实时目标检测器。\n2.2 Reversible Architectures 可逆架构[3,16,19]的运算单元必须保持可逆转换的特性，因此可以保证每层运算单元的输出特征图都能保留完整的原始信息。之前，RevCol[3]将传统的可逆单元推广到多个层次，这样做可以扩展不同层单元表达的语义层次。通过对各种神经网络架构的文献回顾，我们发现有许多高性能架构具有不同程度的可逆特性。例如，Res2Net模块[11]以分层方式将不同的输入分区与下一个分区组合起来，并在向后传递之前连接所有转换后的分区。 CBNet [34, 39]通过复合主干网重新引入原始输入数据以获得完整的原始信息，并通过各种组合方法获得不同级别的多级可逆信息。这些网络架构通常具有出色的参数利用率，但额外的复合层导致推理速度缓慢。 DynamicDet [36]结合了CBNet [34]和高效实时目标检测器YOLOv7 [63]，在速度、参数数量和精度之间实现了非常好的权衡。本文介绍了 DynamicDet 架构作为设计可逆分支的基础。此外，可逆信息被进一步引入到所提出的PGI中。所提出的新架构在推理过程中不需要额外的连接，因此可以充分保留速度、参数量和准确性的优势。\n2.3 Auxiliary Supervision 深度监督[28,54,68]是最常见的辅助监督方法，它通过在中间层插入额外的预测层来进行训练。尤其是基于Transformer的方法中引入的多层解码器的应用是最常见的一种。\n另一种常见的辅助监督方法是利用相关元信息来指导中间层产生的特征图，并使它们具有目标任务所需的属性[18,20,24,29,76]。这种类型的示例包括使用分割损失或深度损失来提高对象检测器的准确性。\n最近，文献[53,67,82]中有许多报告使用不同的标签分配方法来生成不同的辅助监督机制，以加快模型的收敛速度，同时提高鲁棒性。然而，辅助监督机制通常只适用于大型模型，因此当其应用于轻量级模型时，很容易造成欠参数化现象，从而使性能变差。我们提出的PGI设计了一种重新编程多级语义信息的方法，这种设计让轻量级模型也受益于辅助监督机制。\nProblem Statement 通常，人们将深度神经网络收敛问题的困难归因于梯度消失或梯度饱和等因素，而这些现象在传统深度神经网络中确实存在。然而，现代深度神经网络已经通过设计各种归一化和激活函数从根本上解决了上述问题。尽管如此，深度神经网络仍然存在收敛速度慢或收敛结果差的问题。\n在本文中，我们进一步探讨上述问题的本质。通过对信息瓶颈的深入分析，我们推断出这个问题的根本原因是原本来自很深网络的初始梯度在传输后很快就丢失了实现目标所需的大量信息。为了证实这一推论，我们将不同架构的深度网络前馈了初始权重，然后将其可视化并在图2中进行说明。显然，PlainNet丢失了深层物体检测所需的大量重要信息。至于ResNet、CSPNet、GELAN能够保留重要信息的比例，确实与训练后能够获得的准确率呈正相关。我们进一步设计了基于可逆网络的方法来解决上述问题的原因。本节我们将详细阐述对信息瓶颈原理和可逆函数的分析。\n3.1. Information Bottleneck Principle 根据信息瓶颈原理，我们知道数据X在进行变换时可能会造成信息丢失，如式(1)所示。\n其中 $I$ 表示相互信息，$f$ 和 $g$ 是变换函数，$θ$ 和 $ϕ$ 分别是 $f$ 和 $g$ 的参数。\n在深度神经网络中，$f_θ (·)$ 和 $g_ψ (·)$ 分别表示深度神经网络中两个连续层的操作。从方程（1）我们可以预测**，随着网络层数越深，原始数据丢失的可能性就越大**。然而深度神经网络的参数是基于网络的输出以及给定的目标，然后通过计算损失函数生成新的梯度后更新网络。\n可以想象**，更深的神经网络的输出不太能够保留有关预测目标的完整信息**。这将使得在网络训练期间使用不完整的信息成为可能，从而导致梯度不可靠和收敛性差。\n解决上述问题的一种方法是直接增加模型的尺寸。当我们使用大量的参数来构建模型时，它更有能力对数据进行更完整的转换。上述方法使得即使在数据前馈过程中信息丢失，仍然有机会保留足够的信息来执行到目标的映射。上述现象解释了为什么在大多数现代模型中宽度比深度更重要。然而，上述结论并不能从根本上解决非常深的神经网络中梯度不可靠的问题。\n下面，我们将介绍如何利用可逆函数来解决问题并进行相关分析。\n3.2. Reversible Functions 当函数 $r$ 有一个逆变换函数 $v$ 时，我们称该函数为可逆函数，如式(2)所示。\n其中 $ψ$ 和 $ζ$ 分别是 $r$ 和 $v$ 的参数。数据 $X$ 通过可逆函数转换而不会丢失信息，如式(3)所示。\n当网络的变换函数由可逆函数组成时，可以获得更可靠的梯度来更新模型。当今流行的深度学习方法几乎都是符合可逆性质的架构，例如式（4）。\n其中 $l$ 表示 PreAct ResNet 的第 $l$ 层，$f$ 是第 $l$ 层的变换函数。 PreAct ResNet [22] 以显式方式重复将原始数据 X 传递到后续层。这样的设计虽然可以让一千多层的深度神经网络收敛得很好，但却破坏了我们需要深度神经网络的一个重要原因。也就是说，对于困难的问题，我们很难直接找到简单的映射函数将数据映射到目标。这也解释了为什么当层数较少时，PreAct ResNet 的性能比 ResNet [21] 差。\n【Remind】PreAct ResNet 和 ResNet 结构图比较一下\n此外，我们尝试使用Masked建模，使 Transformer 模型取得重大突破。我们使用近似方法，例如方程 (5) 尝试求 $r$ 的逆变换 $v$，使得变换后的特征能够利用稀疏特征保留足够的信息。方程(5) 如下：\n其中 $M$ 是动态二进制掩码。其他常用于执行上述任务的方法是扩散模型和可变化自动编码器，它们都具有查找反函数的功能。然而，当我们将上述方法应用于轻量级模型时，就会存在缺陷，因为轻量级模型对大量原始数据的参数化不足。由于上述原因，将数据 $X$ 映射到目标 $Y$ 的重要信息 $I(Y，X)$ 也会面临同样的问题。对于这个问题，我们将使用信息瓶颈的概念来探讨它[59]。信息瓶颈的计算公式如下：\n一般来说，$I(Y,X)$ 只会占据 $I(X,X)$ 的很小一部分。然而，这对于目标任务至关重要。因此，即使前馈阶段丢失的信息量并不大，只要覆盖了 $I(Y,X)$，训练效果就会受到很大影响。轻量级模型本身处于欠参数化状态，因此在前馈阶段很容易丢失很多重要信息。因此，我们轻量级模型的目标是如何从 $I(X, X)$ 中准确过滤出 $I(Y, X)$。至于完全保留 $X$ 的信息，这是很难做到的。基于上述分析，我们希望提出一种新的深度神经网络训练方法，不仅能够生成可靠的梯度来更新模型，而且适用于浅层和轻量级神经网络。\nMethodology 4.1 Programmable Gradient Information 为了解决上述问题，我们提出了一种新的辅助监督框架，称为可编程梯度信息（PGI），如图3（d）所示。 PGI主要包括三个组成部分，即（1）主分支，（2）辅助可逆分支，（3）多级辅助信息。从图3(d)中我们可以看出，PGI的推理过程仅使用主分支，因此不需要任何额外的推理成本。\n至于其他两个组件，它们用于解决或减缓深度学习方法中的几个重要问题。其中，辅助可逆分支是为了处理神经网络加深带来的问题而设计的。网络加深会造成信息瓶颈，导致损失函数无法生成可靠的梯度。对于多级辅助信息，旨在处理深度监督带来的误差累积问题，特别是针对多个预测分支的架构和轻量级模型。接下来我们将逐步介绍这两个组件。\n4.1.1 Auxiliary Reversible Branch 在PGI中，我们提出了辅助可逆分支来生成可靠的梯度并更新网络参数。通过提供从数据映射到目标的信息，损失函数可以提供指导并避免从与目标不太相关的不完整前馈特征中发现错误相关性的可能性。我们提出通过引入可逆架构来维护完整信息，但是在可逆架构中添加主分支会消耗大量的推理成本。\n我们分析了图3(b)的架构，发现当添加从深层到浅层的额外连接时，推理时间将增加20%。当我们反复将输入数据添加到网络的**高分辨率计算层（黄色框）**时，推理时间甚至超过了两倍。\n由于我们的目标是使用可逆架构来获得可靠的梯度，因此**“可逆”并不是推理阶段的唯一必要条件**。鉴于此，我们将可逆分支视为深度监督分支的扩展，然后设计辅助可逆分支，如图3(d)所示。对于由于信息瓶颈而丢失重要信息的主分支深度特征，它们将能够从辅助可逆分支接收可靠的梯度信息。\n这些梯度信息将驱动参数学习来协助提取正确且重要的信息，上述动作可以使主分支获得对目标任务更有效的特征。此外，可逆架构在浅层网络上的表现比在一般网络上差，因为复杂的任务需要在更深的网络中进行转换。我们提出的方法并不强迫主分支保留完整的原始信息，而是通过辅助监督机制生成有用的梯度来更新它。这种设计的优点是所提出的方法也可以应用于较浅的网络。\n最后，由于在推理阶段可以去除辅助可逆分支，因此可以保留原始网络的推理能力。我们也可以选择PGI中的任意可逆架构来起到辅助可逆分支的作用。\n4.1.2 Multi-level Auxiliary Information 在本节中，我们将讨论多级辅助信息如何工作。包括多个预测分支的深度监督架构如图 3 (c) 所示。对于目标检测，不同的特征金字塔可用于执行不同的任务，例如它们一起可以检测不同大小的目标。因此，连接到深度监督分支后，会引导浅层特征学习小物体检测所需的特征，此时系统会将其他尺寸的物体的位置视为背景。然而，上述行为会导致深层特征金字塔丢失大量预测目标对象所需的信息。关于这个问题，我们认为每个特征金字塔都需要接收所有目标对象的信息，以便后续的主分支可以保留完整的信息来学习对各种目标的预测。\n辅助可逆分支： (1) 可以还原所有的特征信息 （2）推理的时候，不会额外增加计算量\n多级辅助信息： 不分大、中、小目标，把所有物体的特征都汇聚在一起\n4.2. Generalized ELAN 在本节中，我们将描述所提出的新网络架构——GELAN。通过结合采用梯度路径规划设计的两种神经网络架构CSPNet [64]和ELAN [65]，我们设计了兼顾轻量级、推理速度和准确性的广义高效层聚合网络（GELAN）。其整体架构如图 4 所示。我们将最初仅使用卷积层堆叠的 ELAN [65] 的功能推广到可以使用任何计算块的新架构。\nELAN 和 GELAN 的区别：\nELAN使用的是常规的卷积操作\nGELAN是把卷积换成了任意的模块，最后转到相同的通道数、相同维度大小即可\nExperiments 实验是一篇论文，审稿人看的比较仔细的地方。学习一下别人的写法\n附录可以给审稿人和读者，更直观的看到实现的细节\n5.1. Experimental Setup 我们使用 MS COCO 数据集验证了所提出的方法。\n所有实验设置均遵循 YOLOv7 AF [63]，而数据集为 MS COCO 2017 分割。我们提到的所有模型都是使用从头开始训练策略进行训练的，总训练次数为 500 epoch。在设置学习率时，我们在前三个epoch中使用线性预热，随后的epoch根据模型规模设置相应的衰减方式。至于最后 15 个时期，我们关闭马赛克数据增强。更多设置请参考附录。\n5.2 Implementation Details 我们分别基于 YOLOv7 [63] 和 Dynamic YOLOv7 [36] 构建了 YOLOv9 的通用版本和扩展版本。\n在网络架构的设计中，我们使用 CSPNet 块 [64] 和计划的 RepConv [63] 作为计算块，用 GELAN 替换了 ELAN [65]。我们还简化了下采样模块并优化了无锚预测头。至于PGI的辅助损失部分，我们完全遵循YOLOv7的辅助头设置。详情请参阅附录。\n5.3 Comparison with state-of-the-arts 表 1 列出了我们提出的 YOLOv9 与其他从头开始训练的实时目标检测器的比较。总体而言，现有方法中性能最好的方法是用于轻量级模型的 YOLO MS-S [7]、用于中型模型的 YOLO MS [7]、用于通用模型的 YOLOv7 AF [63] 和用于大型模型的 YOLOv8-X [15]。与轻量级和中型模型YOLO MS[7]相比，YOLOv9的参数减少了约10%，计算量减少了5∼15%，但AP仍然有0.4∼0.6%的提升。与YOLOv7 AF相比，YOLOv9-C的参数减少了42%，计算量减少了21%，但达到了相同的AP（53%）。与YOLOv8-X相比，YOLOv9-X参数减少15%，计算量减少25%，AP显着提升1.7%。上述对比结果表明，我们提出的YOLOv9与现有方法相比在各方面都有显着改进。\n另一方面，我们也将ImageNet预训练模型纳入对比，结果如图5所示。我们分别根据参数和计算量进行比较。就参数数量而言，性能最好的大型模型是 RT DETR [43]。从图5中我们可以看到，使用传统卷积的YOLOv9在参数利用率上甚至比使用深度卷积的YOLO MS还要好。至于大型模型的参数利用率，也大大超过了使用ImageNet预训练模型的RT DETR。更棒的是，在深度模型中，YOLOv9展示了使用PGI的巨大优势。通过准确保留和提取将数据映射到目标所需的信息，我们的方法仅需要 64% 的参数，同时保持 RT DETR-X 的精度。\n至于计算量，现有最好的模型从最小到最大依次是YOLO MS [7]、PP YOLOE [74]和RT DETR [43]。从图5中我们可以看到，YOLOv9在计算复杂度方面远远优于从头开始训练的方法。另外，如果与基于深度卷积和基于ImageNet的预训练模型相比，YOLOv9也很有竞争力。\n5.4 Ablation Studies 5.4.1 Generalized ELAN 对于 GELAN，我们首先对计算模块进行消融研究。我们分别使用Res块[21]、Dark块[49]和CSP块[64]进行实验。表2表明，用不同的计算块替换ELAN中的卷积层后，系统可以保持良好的性能。用户确实可以自由更换计算块并在各自的推理设备上使用它们。在不同的计算块替换中，CSP 块的性能特别好。它们不仅减少了参数量和计算量，而且将 AP 提高了 0.7%。因此，我们选择CSPELAN作为YOLOv9中GELAN的组成单元。\n接下来，我们对不同尺寸的GELAN进行ELAN块深度和CSP块深度实验，并将结果显示在表3中。我们可以看到，当ELAN的深度从1增加到2时，精度显着提高。但当深度大于等于2时，无论是提高ELAN深度还是CSP深度，参数数量、计算量和精度总是呈现线性关系。这意味着 GELAN 对深度不敏感。\n也就是说，用户可以任意组合GELAN中的组件来设计网络架构，无需特殊设计即可拥有性能稳定的模型。在表3中，对于YOLOv9-{S,M,C}，我们将ELAN深度和CSP深度的配对设置为{{2, 3}, {2, 1}, {2, 1}}。\n5.4.2 Programmable Gradient Information 在PGI方面，我们分别对backbone和neck的辅助可逆分支和多级辅助信息进行了消融研究。我们设计了辅助可逆分支ICN来使用DHLC[34]链接来获取多级可逆信息。对于多级辅助信息，我们使用FPN和PAN进行消融研究，PFH的作用相当于传统的深度监督。所有实验的结果列于表4中。从表4中我们可以看出，PFH仅在深度模型中有效，而我们提出的PGI可以在不同组合下提高精度。尤其是使用ICN时，我们得到了稳定且更好的结果。我们还尝试将YOLOv7[63]中提出的lead-head指导分配应用于PGI的辅助监督，并取得了更好的性能。\n我们进一步将PGI和深度监督的概念应用到不同规模的模型上，并比较结果，结果如表5所示。正如一开始分析的那样，深度监督的引入会导致浅层模型精度的损失。对于一般模型来说，引入深度监督会导致性能不稳定，而深度监督的设计理念只能在极深的模型中带来收益。所提出的PGI可以有效处理信息瓶颈和信息破碎等问题，并且可以全面提高不同规模模型的准确性。 PGI 的概念带来了两个宝贵的贡献。第一个是让辅助监督方法适用于浅层模型，第二个是让深层模型训练过程获得更可靠的梯度。这些梯度使深度模型能够使用更准确的信息来建立数据和目标之间的正确相关性\n最后，我们在表中显示了从基线 YOLOv7 到 YOLOv9E 逐渐增加组件的结果。我们提出的GELAN和PGI给模型带来了全面的改进。\n5.5 Visualization 本节将探讨信息瓶颈问题并将其可视化。此外，我们还将可视化所提出的 PGI 如何使用可靠的梯度来找到数据和目标之间的正确相关性。在图6中，我们展示了在不同架构下使用随机初始权重作为前馈获得的特征图的可视化结果。我们可以看到，随着层数的增加，所有架构的原始信息逐渐减少。例如，在PlainNet的第50层，很难看到物体的位置，并且所有可区分的特征将在第100层丢失。对于ResNet，虽然在第50层仍然可以看到物体的位置，但边界信息已经丢失。当深度达到第100层时，整个图像变得模糊。 CSPNet 和提出的 GELAN 都表现得非常好，并且它们都可以保持支持清晰识别对象的特征直到第 200 层。对比中，GELAN结果更稳定，边界信息更清晰\n图7用于展示PGI是否可以在训练过程中提供更可靠的梯度，使得用于更新的参数能够有效捕获输入数据与目标之间的关系。图7显示了GELAN和YOLOv9（GELAN + PGI）的特征图在PAN偏置预热中的可视化结果。从图7（b）和（c）的比较中，我们可以清楚地看到PGI准确而简洁地捕获了包含对象的区域**。对于不使用PGI的GELAN，我们发现它在检测物体边界时存在发散**，并且在某些背景区域也产生了意想不到的响应。这个实验证实了PGI确实可以提供更好的梯度来更新参数，并使主分支的前馈阶段能够保留更重要的特征。\nConclusions 在本文中，我们提出使用PGI来解决信息瓶颈问题以及深度监督机制不适合轻量级神经网络的问题。我们设计了 GELAN，一个高效、轻量级的神经网络。在物体检测方面，GELAN在不同的计算块和深度设置下都具有强大且稳定的性能。它确实可以广泛扩展为适合各种推理设备的模型。针对以上两个问题，PGI的引入使得轻量级模型和深度模型都获得了精度的显着提升。 PGI和GELAN相结合设计的YOLOv9已经展现出强大的竞争力。其出色的设计使得深度模型相比YOLOv8减少了49%的参数数量和43%的计算量，但在MS COCO数据集上仍然有0.6%的AP提升。\n","permalink":"https://swimmingliu.cn/posts/papernotes/2024-yolov9/","summary":"\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e如今的深度学习方法主要关注如何设计\u003cstrong\u003e最合适的目标函数\u003c/strong\u003e，使模型的预测结果能够最接近真实情况。同时，必须设计一个\u003cstrong\u003e适当的架构\u003c/strong\u003e，可以帮助\u003cstrong\u003e获取足够的信息进行预测\u003c/strong\u003e。现有方法忽略了一个事实，即\u003cstrong\u003e当输入数据经过逐层特征提取和空间变换时\u003c/strong\u003e，\u003cstrong\u003e大量信息将会丢失\u003c/strong\u003e。本文将深入研究数据通过\u003cstrong\u003e深度网络传输时数据丢失的重要问题\u003c/strong\u003e，即\u003cstrong\u003e信息瓶颈和可逆函数\u003c/strong\u003e。我们提出了\u003cstrong\u003e可编程梯度信息（PGI）\u003cstrong\u003e的概念来应对深度网络实现\u003c/strong\u003e多个目标所需的各种变化\u003c/strong\u003e。\nPGI可以为\u003cstrong\u003e目标任务计算目标函数\u003c/strong\u003e提供\u003cstrong\u003e完整的输入信息\u003c/strong\u003e，从而获得\u003cstrong\u003e可靠的梯度信息来更新网络权值\u003c/strong\u003e。此外，还设计了一种基于\u003cstrong\u003e梯度路径规划的新型轻量级网络架构\u003c/strong\u003e——\u003cstrong\u003e通用高效层聚合网络（GELAN）\u003c/strong\u003e。GELAN的架构证实了PGI在轻量级模型上取得了优异的结果。我们在基于 MS COCO 数据集的目标检测上验证了所提出的 GELAN 和 PGI。结果表明，与基于深度卷积开发的最先进方法相比，GELAN 仅使用\u003cstrong\u003e传统的卷积算子\u003c/strong\u003e即可实现更好的参数利用率。 PGI 可用于从轻型到大型的各种模型。它可以用来获取完整的信息，使得\u003cstrong\u003etrain-from-scratch (从零开始训练) 模型能够比使用大数据集预训练\u003c/strong\u003e的state-of-theart模型获得更好的结果，对比结果如图1所示。源代码位于：https： //github.com/WongKinYiu/yolov9。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e核心创新点:  依然是网络结构的创新\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eProgrammable Gradient Information (PGI)\u003c/li\u003e\n\u003cli\u003eGeneralized Efficient Layer Aggregation Network（GELAN）\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg alt=\"image-20240301113226341\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/f6b3ea45-d79d-11ee-a66b-c858c0c1debd\"\u003e\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e基于深度学习的模型在计算机视觉、语言处理和语音识别等各个领域都表现出了比过去的人工智能系统更好的性能。近年来，深度学习领域的研究人员主要关注如何开发更强大的系统架构和学习方法，例如CNN，Transformers[8,9,40] 、41、60、69、70]，Perceivers[26、26、32、52、56、81、81]和Mambas[17、38、80]。此外，一些研究人员尝试开发更通用的目标函数，例如损失函数[5,45,46,50,77,78]，标签分配[10,12,33,67,79]和辅助监督[18] 、20、24、28、29、51、54、68、76]。上述研究都试图精确地找到\u003cstrong\u003e输入和目标任务之间的映射\u003c/strong\u003e。然而，大多数过去的方法都忽略了\u003cstrong\u003e输入数据在前馈过程中可能会产生不可忽略的信息丢失量\u003c/strong\u003e。这种\u003cstrong\u003e信息丢失\u003c/strong\u003e可能会导致\u003cstrong\u003e有偏差的梯度流\u003c/strong\u003e，随后用于更新模型。上述问题可能导致深度网络\u003cstrong\u003e在目标和输入之间建立不正确的关联\u003c/strong\u003e，导致训练后的模型产生不正确的预测。\u003c/p\u003e\n\u003cp\u003e在深度网络中，\u003cstrong\u003e输入数据在前馈过程中丢失信息的现象\u003c/strong\u003e俗称\u003cstrong\u003e信息瓶颈\u003c/strong\u003e[59]，其示意图如图2所示。目前可以缓解这种现象的主要方法有：（1）\u003cstrong\u003e可逆架构\u003c/strong\u003e的使用[3,16,19]：该方法主要\u003cstrong\u003e使用重复的输入数据，并以显式的方式维护输入数据的信息\u003c/strong\u003e； （2）使用\u003cstrong\u003eMasked建模\u003c/strong\u003e[1,6,9,27,71,73]：主要利用重构损失，采用\u003cstrong\u003e隐式方式最大化提取特征并保留输入信息\u003c/strong\u003e； （3）引入\u003cstrong\u003e深度监督\u003c/strong\u003e概念[28,51,54,68]：它利用\u003cstrong\u003e没有丢失太多重要信息的浅层特征来预先建立从特征到目标的映射\u003c/strong\u003e，以确保\u003cstrong\u003e重要信息能够被传递到更深的层次\u003c/strong\u003e。然而，上述方法在训练过程和推理过程中都存在不同的缺点。例如，\u003cstrong\u003e可逆架构需要额外的层来组合重复馈送的输入数据\u003c/strong\u003e，这将显着增加推理成本。另外，由于\u003cstrong\u003e输入数据层到输出层不能有太深的路径\u003c/strong\u003e，这种限制将导致\u003cstrong\u003e在训练过程中难以对高阶语义信息进行建模\u003c/strong\u003e。对于 \u003cstrong\u003eMasked 建模\u003c/strong\u003e，其\u003cstrong\u003e重建损失有时与目标损失相冲突\u003c/strong\u003e。此外，大多数\u003cstrong\u003e掩码机制还会产生与数据的不正确关联\u003c/strong\u003e。 对于\u003cstrong\u003e深层监督\u003c/strong\u003e机制来说，会产生\u003cstrong\u003e误差累积\u003c/strong\u003e，如果\u003cstrong\u003e浅层监督在训练过程中丢失信息\u003c/strong\u003e，\u003cstrong\u003e后续层将无法检索到所需信息\u003c/strong\u003e。上述现象在\u003cstrong\u003e困难任务\u003c/strong\u003e和\u003cstrong\u003e小模型上\u003c/strong\u003e会更加\u003cstrong\u003e显着\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e针对上述问题，我们提出了一个新的概念，即\u003cstrong\u003e可编程梯度信息（PGI）\u003c/strong\u003e。其概念是通过\u003cstrong\u003e辅助可逆分支生成可靠的梯度\u003c/strong\u003e，使得\u003cstrong\u003e深层特征仍然能够保持执行目标任务的关键特征\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e辅助可逆分支的设计\u003c/strong\u003e可以避免传统的\u003cstrong\u003e融合多路径特征的深度监督过程\u003c/strong\u003e可能造成的\u003cstrong\u003e语义损失\u003c/strong\u003e。换句话说，我们在\u003cstrong\u003e不同语义层面上编程梯度信息传播\u003c/strong\u003e，从而达到最佳的训练结果。 PGI的\u003cstrong\u003e可逆架构建立在辅助分支上\u003c/strong\u003e，因此\u003cstrong\u003e没有额外的成本\u003c/strong\u003e。由于PGI可以\u003cstrong\u003e自由选择适合目标任务的损失函数\u003c/strong\u003e，因此也克服了\u003cstrong\u003eMasked建模\u003c/strong\u003e遇到的问题。所提出的\u003cstrong\u003ePGI机制\u003c/strong\u003e可以应用于各种规模的\u003cstrong\u003e深度神经网络\u003c/strong\u003e，并且比仅适用于\u003cstrong\u003e非常深的神经网络\u003c/strong\u003e的\u003cstrong\u003e深度监督机制更通用\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e在本文中，我们还基于ELAN[65]设计了\u003cstrong\u003e广义ELAN（GELAN）\u003c/strong\u003e，GELAN的设计同时\u003cstrong\u003e考虑了参数量、计算复杂度、准确性和推理速度\u003c/strong\u003e。这种设计允许用户\u003cstrong\u003e针对不同的推理设备任意选择合适的计算块\u003c/strong\u003e。我们将提出的PGI和GELAN结合起来，然后设计了新一代YOLO系列物体检测系统，我们称之为YOLOv9。我们使用MS COCO数据集进行实验，实验结果验证了我们提出的YOLOv9在所有比较中都取得了顶尖的性能。\u003c/p\u003e\n\u003cp\u003e我们总结本文的贡献如下：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e我们从\u003cstrong\u003e可逆函数的角度\u003c/strong\u003e对\u003cstrong\u003e现有的深度神经网络架构进行了理论分析\u003c/strong\u003e，通过这个过程\u003cstrong\u003e我们成功地解释了许多过去难以解释的现象\u003c/strong\u003e。我们还基于此分析\u003cstrong\u003e设计了PGI和辅助可逆分支\u003c/strong\u003e，并取得了优异的结果。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e我们设计的PGI解决了\u003cstrong\u003e深度监督\u003c/strong\u003e只能用于\u003cstrong\u003e极深的神经网络架构的问题\u003c/strong\u003e，从而让\u003cstrong\u003e新的轻量级架构真正应用于日常生活中\u003c/strong\u003e。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e我们设计的GELAN仅使用\u003cstrong\u003e常规卷积\u003c/strong\u003e来实现比基于最先进技术的\u003cstrong\u003e深度卷积设计更高的参数利用率\u003c/strong\u003e，同时表现出\u003cstrong\u003e轻、快速、准确\u003c/strong\u003e的巨大优势。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e结合所提出的PGI和GELAN，YOLOv9在MS COCO数据集上的目标检测性能在各个方面都大大超过了现有的实时目标检测器。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\u003c/blockquote\u003e\n\u003cp\u003eProgrammable Gradient Information (PGI)：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e自由选择适合目标任务的损失函数\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e可逆结构建立辅助分支，不增加推理成本\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e适用于各种规模的深度神经网络\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eGELAN：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e轻、快速、准确\u003c/li\u003e\n\u003cli\u003e采用常规卷积吊打其他新颖卷积\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"related-work\"\u003eRelated work\u003c/h2\u003e\n\u003ch3 id=\"21-real-time-object-detectors\"\u003e2.1 Real-time Object Detectors\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e目前主流的实时目标检测器是YOLO系列[2,7,13–15,25,30,31,47–49,61–63,74,75]，这些模型大多数使用CSPNet[64]或 ELAN [65] 及其变体作为主要计算单元。在特征集成方面，通常使用改进的PAN[37]或FPN[35]作为工具，然后使用改进的YOLOv3头[49]或FCOS头[57, 58]作为预测头。最近也提出了一些实时目标检测器，例如 RT DETR [43]，其基础是 DETR [4]。然而，由于DETR系列目标检测器在没有相应领域预训练模型的情况下很难应用于新领域，因此目前应用最广泛的实时目标检测器仍然是YOLO系列。本文选择 YOLOv7 [63] 作为开发该方法的基础，该方法已在各种计算机视觉任务和各种场景中被证明有效。\u003c/p\u003e","title":"YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information"},{"content":"Introduction YOLOSHOW is a graphical user interface (GUI) application embed with YOLOv5 YOLOv7 YOLOv8 YOLOv9 YOLOv10 YOLOv11 RT-DETR SAM MobileSAM FastSAM algorithm.\nEnglish \u0026nbsp; | \u0026nbsp; 简体中文 Demo Video YOLOSHOW v1.x : YOLOSHOW-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI\nYOLOSHOW v2.x : YOLOSHOWv2.0-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI\nTodo List Add YOLOv9 YOLOv10 RT-DETR YOLOv11 SAM MobileSAM FastSAM Algorithm Support Instance Segmentation （ YOLOv5 YOLOv8 YOLOv11 SAM MobileSAM FastSAM） Support Pose Estimation （ YOLOv8 YOLOv11） Support Oriented Bounding Boxes ( YOLOv8 YOLOv11 ) Support Http Protocol in RTSP Function ( Single Mode ) Add Model Comparison Mode（VS Mode） Support Dragging File Input Tracking \u0026amp; Counting ( Industrialization ) Functions 1. Support Image / Video / Webcam / Folder (Batch) / IPCam Object Detection Choose Image / Video / Webcam / Folder (Batch) / IPCam in the menu bar on the left to detect objects.\n2. Change Models / Hyper Parameters dynamically When the program is running to detect targets, you can change models / hyper Parameters\nSupport changing model in YOLOv5 / YOLOv7 / YOLOv8 / YOLOv9 / YOLOv10 / YOLOv11 / RTDETR / YOLOv5-seg / YOLOv8-seg YOLOv11-seg / YOLOv8-pose / YOLOv11-pose / YOLOv8-obb / YOLOv11-obb / SAM / MobileSAM / FastSAM dynamically Support changing IOU / Confidence / Delay time / line thickness dynamically 3. Loading Model Automatically Our program will automatically detect pt files including YOLOv5 Models / YOLOv7 Models / YOLOv8 Models / YOLOv9 Models / YOLOv10 Models / YOLOv11 Models / RT-DETR Models / SAM Models / MobileSAM Models / FastSAM Models that were previously added to the ptfiles folder.\nIf you need add the new pt file, please click Import Model button in Settings box to select your pt file. Then our program will put it into ptfiles folder.\nNotice :\nAll pt files are named including yolov5 / yolov7 / yolov8 / yolov9 / yolov10 / yolo11 / rtdetr / sam / samv2 / mobilesam / fastsam. (e.g. yolov8-test.pt) If it is a pt file of segmentation mode, please name it including yolov5n-seg / yolov8s-seg / yolo11-seg . (e.g. yolov8n-seg-test.pt) If it is a pt file of pose estimation mode, please name it including yolov8n-pose / yolo11n-pose . (e.g. yolov8n-pose-test.pt) If it is a pt file of oriented bounding box mode, please name it including yolov8n-obb / yolo11n-obb . (e.g. yolov8n-obb-test.pt) 4. Loading Configures After startup, the program will automatically loading the last configure parameters. After closedown, the program will save the changed configure parameters. 5. Save Results If you need Save results, please click Save Mode before detection. Then you can save your detection results in selected path.\n6. Support Object Detection, Instance Segmentation and Pose Estimation From YOLOSHOW v3.0，our work supports both Object Detection , Instance Segmentation, Pose Estimation and Oriented Bounding Box. Meanwhile, it also supports task switching between different versions，such as switching from YOLOv5 Object Detection task to YOLOv8 Instance Segmentation task.\n7. Support Model Comparison among Object Detection, Instance Segmentation, Pose Estimation and Oriented Bounding Box From YOLOSHOW v3.0，our work supports compare model performance among Object Detection, Instance Segmentation, Pose Estimation and Oriented Bounding Box.\nPreparation Experimental environment OS : Windows 11 CPU : Intel(R) Core(TM) i7-10750H CPU @2.60GHz 2.59 GHz GPU : NVIDIA GeForce GTX 1660Ti 6GB 1. Create virtual environment create a virtual environment equipped with python version 3.9, then activate environment.\nconda create -n yoloshow python=3.9 conda activate yoloshow 2. Install Pytorch frame Windows: pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 Linux: pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 Change other pytorch version in 3. Install dependency package Switch the path to the location of the program\ncd {the location of the program} Install dependency package of program\npip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple 4. Add Font Windows User Copy all font files *.ttf in fonts folder into C:\\Windows\\Fonts\nLinux User mkdir -p ~/.local/share/fonts sudo cp fonts/Shojumaru-Regular.ttf ~/.local/share/fonts/ sudo fc-cache -fv MacOS User The MacBook is so expensive that I cannot afford it, please install .ttf by yourself. 😂\n5. Run Program python main.py Frames Reference YOLO Algorithm YOLOv5 YOLOv7 YOLOv8 / YOLOv11 / RT-DETR / SAM / MobileSAM / FastSAM YOLOv9 YOLOv10\nYOLO Graphical User Interface YOLOSIDE\tPyQt-Fluent-Widgets\n","permalink":"https://swimmingliu.cn/posts/diary/yoloshow/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003eYOLOSHOW\u003c/strong\u003e\u003c/em\u003e is a graphical user interface (GUI) application embed with \u003ccode\u003eYOLOv5\u003c/code\u003e \u003ccode\u003eYOLOv7\u003c/code\u003e \u003ccode\u003eYOLOv8\u003c/code\u003e \u003ccode\u003eYOLOv9\u003c/code\u003e \u003ccode\u003eYOLOv10\u003c/code\u003e \u003ccode\u003eYOLOv11\u003c/code\u003e  \u003ccode\u003eRT-DETR\u003c/code\u003e \u003ccode\u003eSAM\u003c/code\u003e \u003ccode\u003eMobileSAM\u003c/code\u003e \u003ccode\u003eFastSAM\u003c/code\u003e algorithm.\u003c/p\u003e\n \u003cp align=\"center\"\u003e \n  English \u0026nbsp; | \u0026nbsp; \u003ca href=\"https://github.com/SwimmingLiu/YOLOSHOW/blob/master/README_cn.md\"\u003e简体中文\u003c/a\u003e\n \u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"YOLOSHOW-Screen\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/YOLOSHOW-SNAPSHOT.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"demo-video\"\u003eDemo Video\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eYOLOSHOW v1.x\u003c/code\u003e : \u003ca href=\"https://www.bilibili.com/video/BV1BC411x7fW\"\u003eYOLOSHOW-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eYOLOSHOW v2.x\u003c/code\u003e : \u003ca href=\"https://www.bilibili.com/video/BV1ZD421E7m3\"\u003eYOLOSHOWv2.0-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"todo-list\"\u003eTodo List\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e Add \u003ccode\u003eYOLOv9\u003c/code\u003e \u003ccode\u003eYOLOv10\u003c/code\u003e  \u003ccode\u003eRT-DETR\u003c/code\u003e  \u003ccode\u003eYOLOv11\u003c/code\u003e  \u003ccode\u003eSAM\u003c/code\u003e  \u003ccode\u003eMobileSAM\u003c/code\u003e  \u003ccode\u003eFastSAM\u003c/code\u003e Algorithm\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e Support Instance Segmentation （ \u003ccode\u003eYOLOv5\u003c/code\u003e  \u003ccode\u003eYOLOv8\u003c/code\u003e  \u003ccode\u003eYOLOv11\u003c/code\u003e \u003ccode\u003eSAM\u003c/code\u003e  \u003ccode\u003eMobileSAM\u003c/code\u003e  \u003ccode\u003eFastSAM\u003c/code\u003e）\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e Support Pose Estimation （ \u003ccode\u003eYOLOv8\u003c/code\u003e  \u003ccode\u003eYOLOv11\u003c/code\u003e）\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e Support Oriented Bounding Boxes ( \u003ccode\u003eYOLOv8\u003c/code\u003e  \u003ccode\u003eYOLOv11\u003c/code\u003e )\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e Support Http Protocol in \u003ccode\u003eRTSP\u003c/code\u003e Function ( \u003ccode\u003eSingle\u003c/code\u003e Mode )\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e Add Model Comparison Mode（VS Mode）\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e Support Dragging File Input\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Tracking \u0026amp; Counting ( \u003ccode\u003eIndustrialization\u003c/code\u003e )\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"functions\"\u003eFunctions\u003c/h2\u003e\n\u003ch3 id=\"1-support-image--video--webcam--folder-batch--ipcam-object-detection\"\u003e1. Support Image / Video / Webcam / Folder (Batch) / IPCam Object Detection\u003c/h3\u003e\n\u003cp\u003eChoose Image / Video / Webcam / Folder (Batch) / IPCam in the menu bar on the left to detect objects.\u003c/p\u003e","title":"YOLOSHOW - YOLOv5/YOLOv7/YOLOv8/YOLOv9/RTDETR GUI based on Pyside6"},{"content":"介绍 YOLOSHOW 是一款集合了 YOLOv5 YOLOv7 YOLOv8 YOLOv9 YOLOv10 YOLOv11 RT-DETR SAM MobileSAM FastSAM 的图形化界面程序\nEnglish \u0026nbsp; | \u0026nbsp; 简体中文 演示视频 YOLOSHOW v1.x : YOLOSHOW-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI\nYOLOSHOW v2.x : YOLOSHOWv2.0-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI\n待做清单 加入 YOLOv9 YOLOv10 RT-DETR YOLOv11 SAM MobileSAM FastSAM算法 支持实例分割 （ YOLOv5 YOLOv8 YOLOv11 SAM MobileSAM FastSAM） 支持姿态估计 （YOLOv8 YOLOv11） 支持旋转框 (YOLOv8 YOLOv11) RTSP 功能 支持 Http 协议 ( Single Mode ) 支持模型对比模式（VS Mode） 支持拖拽文件输入 追踪和计数模型 ( 工业化 ) 功能 1. 支持 图片 / 视频 / 摄像头 / 文件夹（批量）/ 网络摄像头 目标检测 选择左侧菜单栏的图片 / 视频 / 摄像头 / 文件夹（批量）/ 网络摄像头 进行目标检测\n2. 动态切换模型 / 调整超参数 程序开始检测时，支持动态切换模型 / 调整超参数\n支持动态切换 YOLOv5 / YOLOv7 / YOLOv8 / YOLOv9 / YOLOv10 / YOLOv11 / RTDETR / YOLOv5-seg / YOLOv8-seg YOLOv11-seg / YOLOv8-pose / YOLOv11-pose / YOLOv8-obb / YOLOv11-obb / SAM / MobileSAM / FastSAM 模型 支持动态修改 IOU / Confidence / Delay time / line thickness 超参数 3. 动态加载模型 程序可以自动检测ptfiles 文件夹中包含 YOLOv5 Models / YOLOv7 Models / YOLOv8 Models / YOLOv9 Models / YOLOv10 Models / YOLOv11 Models / RT-DETR Models / SAM Models / MobileSAM Models / FastSAM Models pt 模型.\n如果你需要导入新的 pt 文件, 请点击 Settings 框中的 Import Model 按钮 来选择需要导入的 pt 文件. 然后程序会把该文件复制到 ptfiles 文件夹下.\nNotice :\n所有的 pt 模型文件命名必须包含 yolov5 / yolov7 / yolov8 / yolov9 / yolov10 / yolo11 / rtdetr / sam / samv2 / mobilesam / fastsam 中的任意一个版本. (如 yolov8-test.pt) 如果是分割类型的 pt 文件, 命名中应包含 yolov5n-seg / yolov8s-seg / yolo11-seg 中的任意一个版本. (如 yolov8n-seg-test.pt) 如果是姿态检测类型的 pt 文件, 命名中应包含 yolov8n-pose / yolo11n-pose 中的任意一个版本. (如 yolov8n-pose-test.pt) 如果是旋转框类型的 pt 文件, 命名中应包含 yolov8n-obb / yolo11n-obb 中的任意一个版本. (e.g. yolov8n-obb-test.pt) 4. 加载超参数配置 程序启动后, 自动加载最近保存的超参数配置. 程序关闭后, 自动保存最近修改的超参数配置. 5. 保存检测结果 如果需要保存检测结果，请在检测前点击 Save Mode . 然后等待检测完毕，选择需要保存的路径进行结果保存.\n6. 同时支持目标检测、实例分割和姿态估计 从 YOLOSHOW v3.0 起 ，支持目标检测、实例分割、姿态估计和旋转框多种任务。同时支持不同版本的任务切换，如从YOLOv5 目标检测任务 切换到 YOLOv8 实例分割任务。\n7. 支持目标检测、实例分割、姿态估计和旋转框模型对比模式 从 YOLOSHOW v3.0 起，支持目标检测、实例分割、姿态估计和旋转框模型对比模式。\n运行准备工作 实验环境 OS : Windows 11 CPU : Intel(R) Core(TM) i7-10750H CPU @2.60GHz 2.59 GHz GPU : NVIDIA GeForce GTX 1660Ti 6GB 1. 创建虚拟环境 创建内置Python 3.9的conda虚拟环境, 然后激活该环境.\nconda create -n yoloshow python=3.9 conda activate yoloshow 2. 安装Pytorch框架 Windows: pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 Linux: pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 安装其他版本的 Pytorch : 3. 安装依赖包 切换到YOLOSHOW程序所在的路径\ncd {YOLOSHOW程序所在的路径} 安装程序所需要的依赖包\npip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple 4. 添加字体 Windows 用户 把所有的fonts 文件夹中的字体文件 *.ttf 复制到 C:\\Windows\\Fonts\nLinux 用户 mkdir -p ~/.local/share/fonts sudo cp fonts/Shojumaru-Regular.ttf ~/.local/share/fonts/ sudo fc-cache -fv MacOS 用户 MacBook实在太贵了，我买不起。你们自己想办法安装吧~😂\n5. 运行程序 python main.py 使用框架 参考文献 YOLO 算法 YOLOv5 YOLOv7 YOLOv8 / YOLOv11 / RT-DETR / SAM / MobileSAM / FastSAM YOLOv9 YOLOv10\nYOLO 图形化界面 YOLOSIDE\tPyQt-Fluent-Widgets\n","permalink":"https://swimmingliu.cn/posts/diary/yoloshow-cn/","summary":"\u003ch2 id=\"介绍\"\u003e介绍\u003c/h2\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003eYOLOSHOW\u003c/strong\u003e\u003c/em\u003e 是一款集合了 \u003ccode\u003eYOLOv5\u003c/code\u003e \u003ccode\u003eYOLOv7\u003c/code\u003e \u003ccode\u003eYOLOv8\u003c/code\u003e \u003ccode\u003eYOLOv9\u003c/code\u003e \u003ccode\u003eYOLOv10\u003c/code\u003e \u003ccode\u003eYOLOv11\u003c/code\u003e  \u003ccode\u003eRT-DETR\u003c/code\u003e \u003ccode\u003eSAM\u003c/code\u003e \u003ccode\u003eMobileSAM\u003c/code\u003e \u003ccode\u003eFastSAM\u003c/code\u003e 的图形化界面程序\u003c/p\u003e\n\u003cp align=\"center\"\u003e \n  \u003ca href=\"https://github.com/SwimmingLiu/YOLOSHOW/blob/master/README.md\"\u003e English\u003c/a\u003e \u0026nbsp; | \u0026nbsp; 简体中文\u003c/a\u003e\n \u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"YOLOSHOW-Screen\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/YOLOSHOW-SNAPSHOT.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"演示视频\"\u003e演示视频\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eYOLOSHOW v1.x\u003c/code\u003e : \u003ca href=\"https://www.bilibili.com/video/BV1BC411x7fW\"\u003eYOLOSHOW-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eYOLOSHOW v2.x\u003c/code\u003e : \u003ca href=\"https://www.bilibili.com/video/BV1ZD421E7m3\"\u003eYOLOSHOWv2.0-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"待做清单\"\u003e待做清单\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e 加入 \u003ccode\u003eYOLOv9\u003c/code\u003e \u003ccode\u003eYOLOv10\u003c/code\u003e  \u003ccode\u003eRT-DETR\u003c/code\u003e  \u003ccode\u003eYOLOv11\u003c/code\u003e  \u003ccode\u003eSAM\u003c/code\u003e  \u003ccode\u003eMobileSAM\u003c/code\u003e  \u003ccode\u003eFastSAM\u003c/code\u003e算法\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e 支持实例分割 （ \u003ccode\u003eYOLOv5\u003c/code\u003e  \u003ccode\u003eYOLOv8\u003c/code\u003e  \u003ccode\u003eYOLOv11\u003c/code\u003e \u003ccode\u003eSAM\u003c/code\u003e  \u003ccode\u003eMobileSAM\u003c/code\u003e  \u003ccode\u003eFastSAM\u003c/code\u003e）\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e 支持姿态估计 （\u003ccode\u003eYOLOv8\u003c/code\u003e \u003ccode\u003eYOLOv11\u003c/code\u003e）\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e 支持旋转框 (\u003ccode\u003eYOLOv8\u003c/code\u003e \u003ccode\u003eYOLOv11\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e \u003ccode\u003eRTSP\u003c/code\u003e 功能 支持 Http 协议 ( Single Mode )\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e 支持模型对比模式（VS Mode）\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e 支持拖拽文件输入\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e 追踪和计数模型 ( \u003ccode\u003e工业化\u003c/code\u003e )\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"功能\"\u003e功能\u003c/h2\u003e\n\u003ch3 id=\"1-支持-图片--视频--摄像头--文件夹批量-网络摄像头-目标检测\"\u003e1. 支持 图片 / 视频 / 摄像头 / 文件夹（批量）/ 网络摄像头 目标检测\u003c/h3\u003e\n\u003cp\u003e选择左侧菜单栏的图片 / 视频 / 摄像头 / 文件夹（批量）/ 网络摄像头 进行目标检测\u003c/p\u003e","title":"YOLOSHOW 中文版 - YOLOv5/YOLOv7/YOLOv8/YOLOv9/RTDETR GUI based on Pyside6"},{"content":"安装 Xshell 和 Xftp https://www.netsarang.com/en/xshell-download/ # Xshell下载连接 https://blog.csdn.net/m0_67400972/article/details/125346023 # 安装教程 添加Xshell连接 其中 server.ip 为服务器公网ip地址，端口为 6969\n安装Anaconda3 每个用户均被分配 AnacondaAnaconda3-2023.07-1-Linux-x86_64.sh 于主目录\nbash AnacondaAnaconda3-2023.07-1-Linux-x86_64.sh # 安装anaconda3 输入 yes 后， 再按回车键 即可\n初始化Anaconda3 conda init bash\t# 初始化conda 然后重新使用Xshell 连接即可\nMagic Network 下载外网文件、克隆Github项目等操作，必须使用Magic Network\nexport http_proxy=http://127.0.0.1:7890 export https_proxy=http://127.0.0.1:7890 取消Magic Network\nunset http_proxy unset https_proxy 如果使用上面的命令，不能连接Google. 需要远程桌面连接，打开CFW (默认是打开的)\nnohup bash /home/dell/LYJ/Clash/cfw \u0026gt; cfw.out 国内镜像下载 pip 清华源下载\npip install -i https://pypi.tuna.tsinghua.edu.cn/simple packge # packge为包名 conda 配置镜像\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ # 以上两条是Anaconda官方库的镜像 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ # 以上是Anaconda第三方库 Conda Forge的镜像 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ # 以上是Pytorch的Anaconda第三方镜像 远程桌面连接 远程连接直接找师兄问 向日葵 和 Teamviewer 密码，连接即可\n注意事项 建议非必要不使用远程连接（由于在同一时间段内，远程连接只能单用户使用） 使用远程连接，请先阅读服务器壁纸上的注意事项 如需上传文件，尽量使用移动硬盘，到918实验室拷贝至服务器上 ","permalink":"https://swimmingliu.cn/posts/diary/zstu_server_manuscript/","summary":"\u003ch2 id=\"安装-xshell-和-xftp\"\u003e安装 Xshell 和 Xftp\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ehttps://www.netsarang.com/en/xshell-download/ \u003cspan class=\"c1\"\u003e# Xshell下载连接\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ehttps://blog.csdn.net/m0_67400972/article/details/125346023 \u003cspan class=\"c1\"\u003e# 安装教程\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"添加xshell连接\"\u003e添加Xshell连接\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"image-20240105113129928\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/B6xRW.png\"\u003e\u003c/p\u003e\n\u003cp\u003e其中 \u003ccode\u003eserver.ip\u003c/code\u003e 为服务器公网ip地址，端口为 \u003ccode\u003e6969\u003c/code\u003e\u003c/p\u003e\n\u003ch2 id=\"安装anaconda3\"\u003e安装Anaconda3\u003c/h2\u003e\n\u003cp\u003e每个用户均被分配 \u003ccode\u003eAnacondaAnaconda3-2023.07-1-Linux-x86_64.sh \u003c/code\u003e 于主目录\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ebash AnacondaAnaconda3-2023.07-1-Linux-x86_64.sh \u003cspan class=\"c1\"\u003e# 安装anaconda3\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cimg alt=\"image-20240105113942737\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/B6KTv.png\"\u003e\u003c/p\u003e\n\u003cp\u003e输入 \u003ccode\u003eyes\u003c/code\u003e 后， 再按回车键 即可\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20240105114146047\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/B6one.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"初始化anaconda3\"\u003e初始化Anaconda3\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003econda init bash\t\u003cspan class=\"c1\"\u003e# 初始化conda\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e然后重新使用Xshell 连接即可\u003c/p\u003e\n\u003ch2 id=\"magic-network\"\u003eMagic Network\u003c/h2\u003e\n\u003cp\u003e下载外网文件、克隆Github项目等操作，必须使用Magic Network\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eexport\u003c/span\u003e \u003cspan class=\"nv\"\u003ehttp_proxy\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003ehttp://127.0.0.1:7890\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eexport\u003c/span\u003e \u003cspan class=\"nv\"\u003ehttps_proxy\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003ehttp://127.0.0.1:7890\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e取消Magic Network\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eunset\u003c/span\u003e http_proxy\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eunset\u003c/span\u003e https_proxy\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e如果使用上面的命令，不能连接Google. 需要远程桌面连接，打开CFW (默认是打开的)\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003enohup bash /home/dell/LYJ/Clash/cfw \u0026gt; cfw.out\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cimg alt=\"image-20240105115600487\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/B6So3.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"国内镜像下载\"\u003e国内镜像下载\u003c/h2\u003e\n\u003cp\u003epip 清华源下载\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003epip install -i https://pypi.tuna.tsinghua.edu.cn/simple packge      \u003cspan class=\"c1\"\u003e# packge为包名\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003econda 配置镜像\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003econda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003econda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 以上两条是Anaconda官方库的镜像\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003econda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 以上是Anaconda第三方库 Conda Forge的镜像\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003econda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 以上是Pytorch的Anaconda第三方镜像\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"远程桌面连接\"\u003e远程桌面连接\u003c/h2\u003e\n\u003cp\u003e远程连接直接找师兄问 向日葵 和 Teamviewer 密码，连接即可\u003c/p\u003e","title":"ZSTU服务器使用教程 (Yang Li Lab)"},{"content":"FRP配置 跳板机 # frps.ini 配置 [common] bind_port = 7000 #frps服务监听的端口 token = 123 # 链接口令 ./frps -c frps.ini # 启动frps 服务器 # frpc.ini [common] server_addr = x.x.x.x # 此处为 跳板机 的公网ip server_port = 7000 # 跳板机上frps服务监听的端口 token = 123 # 链接口令 [ssh] type = tcp local_ip = 127.0.0.1 local_port = 22 # 需要暴露的内网机器的端口 remote_port = 6000 # 暴露的内网机器的端口在vps上的端口 SSH连接 ssh -p 6000 swimmingliu@server.ip # 普通ssh 连接 ssh swimmingliu@server.ip 6000\t# xshell ssh连接 用户管理 添加用户 sudo adduser xxx 删除用户 sudo deluser xxx Magic Network export http_proxy=http://127.0.0.1:7890 export https_proxy=http://127.0.0.1:7890 Anaconda3 安装和配置 安装Anaconda3 wget --user-agent=\u0026#34;Mozilla\u0026#34; https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2023.07-1-Linux-x86_64.sh bash Anaconda3-2023.07-1-Linux-x86_64.sh # https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive 清华源 配置之前的envs cp -r old_envs_path anaconda/envs/\t#迁移之前的envs环境 完结撒花❀❀❀ ","permalink":"https://swimmingliu.cn/posts/diary/zstu_server_management/","summary":"\u003ch2 id=\"frp配置\"\u003eFRP配置\u003c/h2\u003e\n\u003ch3 id=\"跳板机\"\u003e跳板机\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# frps.ini 配置\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e[\u003c/span\u003ecommon\u003cspan class=\"o\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003ebind_port\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"m\"\u003e7000\u003c/span\u003e \u003cspan class=\"c1\"\u003e#frps服务监听的端口\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003etoken\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"m\"\u003e123\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 链接口令\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e./frps -c frps.ini \u003cspan class=\"c1\"\u003e# 启动frps\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"服务器\"\u003e服务器\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# frpc.ini\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e[\u003c/span\u003ecommon\u003cspan class=\"o\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003eserver_addr\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e x.x.x.x \u003cspan class=\"c1\"\u003e# 此处为 跳板机 的公网ip\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003eserver_port\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"m\"\u003e7000\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 跳板机上frps服务监听的端口\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003etoken\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"m\"\u003e123\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 链接口令\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e[\u003c/span\u003essh\u003cspan class=\"o\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003etype\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e tcp\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003elocal_ip\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e 127.0.0.1 \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003elocal_port\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"m\"\u003e22\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 需要暴露的内网机器的端口\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003eremote_port\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"m\"\u003e6000\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 暴露的内网机器的端口在vps上的端口\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"ssh连接\"\u003eSSH连接\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003essh -p \u003cspan class=\"m\"\u003e6000\u003c/span\u003e swimmingliu@server.ip \u003cspan class=\"c1\"\u003e# 普通ssh 连接\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003essh swimmingliu@server.ip 6000\t  \u003cspan class=\"c1\"\u003e# xshell ssh连接\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"用户管理\"\u003e用户管理\u003c/h2\u003e\n\u003ch3 id=\"添加用户\"\u003e添加用户\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo adduser xxx\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"删除用户\"\u003e删除用户\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo deluser xxx\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"magic-network\"\u003eMagic Network\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eexport\u003c/span\u003e \u003cspan class=\"nv\"\u003ehttp_proxy\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003ehttp://127.0.0.1:7890\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eexport\u003c/span\u003e \u003cspan class=\"nv\"\u003ehttps_proxy\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003ehttp://127.0.0.1:7890\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"anaconda3-安装和配置\"\u003eAnaconda3 安装和配置\u003c/h2\u003e\n\u003ch3 id=\"安装anaconda3\"\u003e安装Anaconda3\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ewget --user-agent\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;Mozilla\u0026#34;\u003c/span\u003e https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2023.07-1-Linux-x86_64.sh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ebash Anaconda3-2023.07-1-Linux-x86_64.sh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive 清华源\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"配置之前的envs\"\u003e配置之前的envs\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecp -r old_envs_path anaconda/envs/\t\t\u003cspan class=\"c1\"\u003e#迁移之前的envs环境\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"完结撒花\"\u003e完结撒花❀❀❀\u003c/h2\u003e","title":"ZSTU Server Management"},{"content":"Introduction 基于知识图谱和neo4j图数据库的电影知识问答系统\nWorkflow DataBase 爬取豆瓣TOP1000电影信息数据\nFrontend 获取用户输入的信息 （语音输入 / 文本输入） 向电影知识问答后端服务器发送请求 获取返回结果 (成功 -\u0026gt; 4 / 失败 -\u0026gt; 5) 如果返回结果包含image信息，则显示图片和文字，否则只显示文字 请求基于gpt的AI模型服务器，并显示返回结果 Backend ​\t[准备工作] 训练 TF-IDF 向量算法和朴素贝叶斯分类器，用于预测用户文本所属的问题类别\n接受前端请求，获取用户输入信息 使用分词库解析用户输入的文本词性，提取关键词 根据贝叶斯分类器，分类出用户文本的问题类型 结合关键词与问题类别，在 Neo4j 中查询问题的答案 返回查询结果 （若问题类型为 演员信息 / 电影介绍，则附加图片url） WorkFlow Graph Frame DataBase Frontend Backend Reference Frontend 微信小程序：微信聊天机器人\nBackEnd 基于知识图谱的电影知识问答系统\n电影知识库问答机器人\n","permalink":"https://swimmingliu.cn/posts/diary/2023-moviekgqa/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003e基于知识图谱和neo4j图数据库的电影知识问答系统\u003c/p\u003e\n\u003cdiv style=\"display:flex; justify-content: space-around; \"\u003e\r\n\u003cimg src=\"https://i.imgs.ovh/2023/12/12/mM4uR.png\" alt=\"image-20231212102658908\" style=\"box-shadow: 0 0 10px rgba(200, 200, 200);\" width=30% height:300px/\u003e\r\n\u003cimg src=\"https://i.imgs.ovh/2023/12/12/mM58p.png\" alt=\"image-20231212102738360\" style=\"box-shadow: 0 0 10px rgba(200, 200, 200);\" width=30% height:300px/\u003e\r\n\u003cimg src=\"https://i.imgs.ovh/2023/12/12/mMdFT.png\" alt=\"image-20231212103113278\" style=\"\" width=30% height:300px/\u003e\r\n\u003c/div\u003e\r\n\u003ch2 id=\"workflow\"\u003eWorkflow\u003c/h2\u003e\n\u003ch3 id=\"database\"\u003eDataBase\u003c/h3\u003e\n\u003cp\u003e爬取豆瓣TOP1000电影信息数据\u003c/p\u003e\n\u003ch3 id=\"frontend\"\u003eFrontend\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e获取用户输入的信息 （语音输入 / 文本输入）\u003c/li\u003e\n\u003cli\u003e向电影知识问答后端服务器发送请求\u003c/li\u003e\n\u003cli\u003e获取返回结果  (成功 -\u0026gt; 4 / 失败 -\u0026gt; 5)\u003c/li\u003e\n\u003cli\u003e如果返回结果包含image信息，则显示图片和文字，否则只显示文字\u003c/li\u003e\n\u003cli\u003e请求基于gpt的AI模型服务器，并显示返回结果\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"backend\"\u003eBackend\u003c/h3\u003e\n\u003cp\u003e​\t[准备工作]  训练 TF-IDF 向量算法和朴素贝叶斯分类器，用于预测用户文本所属的问题类别\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e接受前端请求，获取用户输入信息\u003c/li\u003e\n\u003cli\u003e使用分词库解析用户输入的文本词性，提取关键词\u003c/li\u003e\n\u003cli\u003e根据贝叶斯分类器，分类出用户文本的问题类型\u003c/li\u003e\n\u003cli\u003e结合关键词与问题类别，在 Neo4j 中查询问题的答案\u003c/li\u003e\n\u003cli\u003e返回查询结果 （若问题类型为 演员信息 / 电影介绍，则附加图片url）\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"workflow-graph\"\u003eWorkFlow Graph\u003c/h3\u003e\n\u003cp\u003e\u003cimg alt=\"workflow graph\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/0IEuW.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"frame\"\u003eFrame\u003c/h2\u003e\n\u003ch3 id=\"database-1\"\u003eDataBase\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://neo4j.com/\"\u003e\u003cimg alt=\"Neo4j\" loading=\"lazy\" src=\"https://img.shields.io/badge/neo4j-test?style=for-the-badge\u0026logo=neo4j\u0026logoColor=white\u0026color=blue\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"frontend-1\"\u003eFrontend\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://developers.weixin.qq.com/\"\u003e\u003cimg alt=\"wechat mini programs\" loading=\"lazy\" src=\"https://img.shields.io/badge/wechat%20mini%20programs-test?style=for-the-badge\u0026logo=wechat\u0026logoColor=white\u0026color=%2320B2AA\"\u003e\u003c/a\u003e\u003c/p\u003e","title":"MovieKGQA: 基于知识图谱和neo4j图数据库的电影知识问答系统"},{"content":"Abstract 在本文中，我们介绍了 U-Net v2，这是一种用于医学图像分割的新的稳健且高效的 U-Net 变体。它的目的是增强语义信息在低级特征中的注入，同时用更精细的细节来细化高级特征。对于输入图像，我们首先使用深度神经网络编码器提取多级特征。接下来，我们通过注入来自更高级别特征的语义信息并通过 Hadamard 乘积集成来自较低级别特征的更精细的细节来增强每个级别的特征图。我们新颖的跳跃连接赋予所有级别的功能以丰富的语义特征和复杂的细节。改进后的特征随后被传输到解码器以进行进一步处理和分割。我们的方法可以无缝集成到任何编码器-解码器网络中。我们在几个公共医学图像分割数据集上评估了我们的方法，用于皮肤病变分割和息肉分割，实验结果证明了我们的新方法相对于最先进的方法的分割准确性，同时保留了内存和计算效率。代码位于：https://github.com/yaoppeng/U-Net_v2。\n主要工作就在于中间的skip-connection\nIntroduction 随着现代深度神经网络的进步，语义图像分割取得了重大进展。语义图像分割的典型范例涉及具有跳跃连接的编码器-解码器网络[1]。在此框架中，编码器从输入图像中提取层次和抽象特征，而解码器获取编码器生成的特征图并重建像素级分割掩模或图，为输入图像中的每个像素分配类标签。人们进行了一系列研究[2, 3]，将全局信息纳入特征图中并增强多尺度特征，从而大大提高了分割性能。 在医学图像分析领域，精确的图像分割在计算机辅助诊断和分析中起着至关重要的作用。 U-Net [4] 最初是为了医学图像分割而引入的，利用跳跃连接来连接每个级别的编码器和解码器阶段。跳跃连接使解码器能够访问早期编码器阶段的特征，从而保留高级语义信息和细粒度空间细节。这种方法有助于精确描绘对象边界并提取医学图像中的小结构。此外，还应用了密集连接机制，通过连接所有级别和所有阶段的特征来减少编码器和解码器中特征之间的差异[5]。设计了一种机制来通过连接较高和较低级别的不同尺度的特征来增强特征[6]。 然而，基于 U-Net 的模型中的这些连接在集成低级和高级特征方面可能不够有效。例如，在 ResNet [7] 中，深度神经网络是作为多个浅层网络的集合而形成的，并且显式添加的残差连接表明，即使在百万规模的训练中，网络也很难学习恒等映射函数图像数据集。\n对于编码器提取的特征，低级特征通常保留更多细节，但缺乏足够的语义信息，并且可能包含不需要的噪声。相反，高级特征包含更多语义信息，但由于分辨率显着降低而缺乏精确的细节（例如对象边界）。通过串联简单地融合特征将在很大程度上依赖于网络的学习能力，这通常与训练数据集的大小成正比。这是一个具有挑战性的问题，特别是在医学成像领域，通常受到有限数据的限制。这种信息融合是通过密集连接跨多个级别连接低级和高级特征来实现的，可能会限制来自不同级别的信息的贡献并可能引入噪声。另一方面，尽管引入的额外卷积并没有显着增加参数数量，但 GPU 内存消耗将会增加，因为必须存储所有中间特征图和相应的梯度以进行前向传递和后向梯度计算。这会导致 GPU 内存使用量和浮点运算 (FLOP) 增加。\n(a) U-Net v2 模型的整体架构，由编码器、SDI（语义和细节注入）模块和解码器组成。 (b) SDI模块的架构。为简单起见，我们仅显示第三级特征的细化（l = 3）。 SmoothConv 表示用于特征平滑的 3 × 3 卷积。$\\bigotimes$ 表示哈达玛积。\n在[8]中，利用反向注意力来明确地建立多尺度特征之间的联系。在[9]中，ReLU激活应用于较高级别的特征，并将激活的特征与较低级别的特征相乘。此外，在[10]中，作者提出分别从 CNN 和 Transformer 模型中提取特征，在多个级别上组合来自 CNN 和 Transformer 分支的特征来增强特征图。然而，这些方法都很复杂，而且它们的性能仍然不是很令人满意，因此需要进一步改进。\n在本文中，我们提出了 U-Net v2，这是一种基于 U-Net 的新分割框架，具有简单且高效的跳跃连接。我们的模型首先使用 CNN 或 Transformer 编码器提取多级特征图。接下来，对于第 i 层的特征图，我们通过简单的哈达玛乘积操作显式地注入高层特征（包含更多语义信息）和低层特征（捕获更精细的细节），从而增强语义和细节第 i 级特征。随后，细化的特征被传输到解码器进行分辨率重建和分割。我们的方法可以无缝集成到任何编码器-解码器网络中。\n我们使用公开的数据集在两个医学图像分割任务（皮肤病变分割和息肉分割）上评估我们的新方法。实验结果表明，我们的 U-Net v2 在这些分割任务中始终优于最先进的方法，同时保持 FLOP 和 GPU 内存效率。\nMethod 2.1 Overall Architecture 我们的 U-Net v2 的整体架构如图 1（a）所示。它包括三个主要模块：编码器、SDI（语义和细节注入）模块和解码器。给定输入图像 I，其中 I ∈ $R^{H×W×C}$ ，编码器产生 M 个级别的特征。我们将第 i 级特征表示为$ f^0_i$ , 1 ≤ i ≤ M。这些收集到的特征，{$ f^0_1$ ,$ f^0_2$,… , $ f^0_M$}，然后传输到 SDI 模块进行进一步细化。\n2.2 Semantics and Detail Infusion (SDI) Module 利用编码器生成的分层特征图，我们首先将空间和通道注意机制[11]应用于每个级别 i 的特征 $ f^0_i$。此过程使特征能够集成局部空间信息和全局通道信息，如下所示：\n其中$f^1_i$表示第 i 层处理后的特征图，$φ^s_i$ 和 $\\phi^c_i$ 分别表示第 i 层空间注意力和通道注意力的参数。此外，我们应用 1 × 1 卷积将$f^1_i$的通道减少到 c，其中 c 是超参数。得到的特征图表示为$f^2_i$，其中 $f^2_i$ ∈ $R^{H_i × W_i × c}$ ，其中$H_i$、$W_i$ 和 c 分别表示 $f^2_i$ 的宽度、高度和通道。\n接下来，我们需要将精炼后的特征图发送到解码器。在每个解码器级别 i，我们使用 $f^2_i$ 作为目标参考。然后，我们调整每个第 j 层的特征图的大小，以匹配与 $f^2_i$ 相同的分辨率，公式为：\n其中 D 、 I 和 U 分别表示自适应平均池化、恒等映射和双线性插值 $f^2_i$ 到 $H_i$、$W_i$ 的分辨率，其中 1 ≤ i，j ≤ M。\n然后，应用 3 × 3 卷积来平滑每个调整大小的特征图 $f^3_{ij}$ ，公式为：\n其中$θ_{ij}$表示平滑卷积的参数， $f^4_{ij}$ 是第i层的第j个平滑特征图。\n将所有第 i 级特征图调整为相同的分辨率后，我们将元素级哈达玛积应用于所有调整大小的特征图，以通过更多语义信息和更精细的细节来增强第 i 级特征，如下所示：\n其中$H(·)$表示哈达玛积 (见图1(b))。然后，$f^5_i$ 被分派到第i级解码器以进行进一步的分辨率重建和分割。\nExperiments 3.1 Datasets 我们使用以下数据集评估新的 U-Net v2。 ISIC 数据集：使用两个皮肤病变分割数据集：ISIC 2017 [15, 16]，其中包含 2050 个皮肤镜图像，ISIC 2018 [15]，其中包含 2694 个皮肤镜图像。为了公平比较，我们遵循[13]中概述的训练/测试分割策略。 息肉分割数据集：使用五个数据集：Kvasir-SEG [17]、ClinicDB [18]、ColonDB [19]、Endoscene [20] 和 ETIS [21]。为了公平比较，我们使用[8]中的训练/测试分割策略。具体来说，使用来自 ClinicDB 的 900 张图像和来自 Kvasir-SEG 的 548 张图像作为训练集，其余图像作为测试集。\n3.2 Experimental Setup 我们使用 PyTorch 在 NVIDIA P100 GPU 上进行实验。我们的网络使用 Adam 优化器进行优化，初始学习率 = 0.001，β1 = 0.9，β2 = 0.999。\n我们采用幂为 0.9 的多项式学习率衰减。训练时期的最大数量设置为 300。超参数 c 设置为 32。按照[13]中的方法，我们报告 ISIC 数据集的 DSC（骰子相似系数）和 IoU（并集交集）分数。对于息肉数据集，我们报告 DSC、IoU 和 MAE（平均绝对误差）分数。每个实验运行 5 次，并报告平均结果。我们使用金字塔视觉变换器（PVT）[22]作为特征提取的编码器。\n3.3 Results and Analysis 表 1 列出了 ISIC 数据集上最先进方法的比较结果。如图所示，我们提出的 UNet v2 将 DSC 分数提高了 1.44% 和 2.48%，IoU 分数提高了 2.36% 和 3.90%。分别是 ISIC 2017 和 ISIC 2018 数据集。这些改进证明了我们提出的将语义信息和更精细的细节注入每个特征图的方法的有效性。\n表 2 列出了息肉分割数据集上最先进方法的比较结果。如图所示，我们提出的 U-Net v2 在 Kavasir-SEG、ClinicDB、ColonDB 和 ETIS 上优于 Poly-PVT [14]数据集，DSC 得分分别提高了 1.1%、0.7%、0.4% 和 0.3%。这强调了我们提出的方法在将语义信息和更精细的细节注入每个级别的特征图中的一致有效性。\n3.4 Ablation Study 我们使用 ISIC 2017 和 ColonDB 数据集进行消融研究，以检查 U-Net v2 的有效性，如表 3 所示。具体来说，我们使用 PVT [22] 模型作为 UNet++ [5] 的编码器。请注意，当我们的 SDI 模块被移除时，U-Net v2 将恢复为具有 PVT 主干的普通 U-Net。 **SC 表示 SDI 模块内的空间和通道关注点。**从表 3 可以看出，与不带 SDI 的 U-Net v2（即带 PVT 编码器的 U-Net）相比，UNet++ 的性能略有下降。\n这种下降可能归因于密集连接生成的多级特征的简单串联，这可能会混淆模型并引入噪声。表 3 表明 SDI 模块对整体性能贡献最大，突出显示我们提出的跳跃连接（即 SDI）持续带来性能改进。\n3.5 Qualitative Results 图 2 给出了 ISIC 2017 数据集的一些定性示例，这表明我们的 U-Net v2 能够将语义信息和更精细的细节合并到每个级别的特征图中。因此，我们的分割模型可以捕获对象边界的更精细的细节。\n3.6 Computation, GPU Memory, and Inference Time 为了检查 U-Net v2 的计算复杂性、GPU 内存使用情况和推理时间，我们报告了我们的方法 U-Net [4] 的参数、GPU 内存使用情况、FLOP 和 FPS（每秒帧数），以及表 4 中的 UNet++ [5]。实验使用 float32 作为数据类型，这导致每个变量使用 4B 的内存。 GPU内存使用记录了前向/后向传递过程中存储的参数和中间变量的大小。\n(1, 3, 256, 256) 表示输入图像的大小。所有测试均在 NVIDIA P100 GPU 上进行。\n从表4中可以看出，UNet++引入了更多的参数，并且由于在密集前向过程中存储中间变量（例如特征图），其GPU内存使用量更大。通常，此类中间变量比参数消耗更多的 GPU 内存。\n此外，U-Net v2 的 FLOPs 和 FPS 也优于 UNet++。与 U-Net (PVT) 相比，我们的 U-Net v2 的 FPS 降低是有限的。\nConclusion 引入了新的 U-Net 变体 U-Net v2，它采用新颖且简单的跳跃连接设计，以改进医学图像分割。该设计明确地将来自较高级别特征的语义信息和来自较低级别特征的更精细细节集成到编码器使用 Hadamard 乘积生成的每个级别的特征映射中。在皮肤病变和息肉分割数据集上进行的实验验证了我们的 UNet v2 的有效性。复杂性分析表明 U-Net v2 在 FLOP 和 GPU 内存使用方面也很高效\n这篇文章比较简单，整体的行文风格一看就是会议论文。核心创新点就一个SDI（Semantic and Detail Infusion）模块。SDI模块作用就是 连接高级特征的语义信息和低级特征的细节信息。首先通过通道和特征注意力机制，分别关注不同级别的通道和空间信息。然后将所有的通道都 padding / scaling 到和第i级别相同的通道数，然后通过双线性插值 / 自适应平均池化到相同大小的尺寸。最后，使用哈达码乘积进行特征融合。 对，没错就这么简单！！！\n（思考: 能不能用减法单元来融合差异性？？？）\n","permalink":"https://swimmingliu.cn/posts/papernotes/2023-unet_v2/","summary":"\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e在本文中，我们介绍了 U-Net v2，这是一种用于医学图像分割的新的稳健且高效的 U-Net 变体。它的目的是\u003cstrong\u003e增强语义信息在低级特征中的注入\u003c/strong\u003e，同时\u003cstrong\u003e用更精细的细节来细化高级特征\u003c/strong\u003e。对于输入图像，我们首先使用\u003cstrong\u003e深度神经网络编码器提取多级特征\u003c/strong\u003e。接下来，我们通过\u003cstrong\u003e注入来自更高级别特征的语义信息\u003c/strong\u003e并通过 \u003cstrong\u003eHadamard 乘积\u003c/strong\u003e集成来自\u003cstrong\u003e较低级别特征的更精细的细节\u003c/strong\u003e来\u003cstrong\u003e增强每个级别的特征图\u003c/strong\u003e。我们新颖的\u003cstrong\u003e跳跃连接\u003c/strong\u003e赋予\u003cstrong\u003e所有级别的功能\u003c/strong\u003e以\u003cstrong\u003e丰富的语义特征和复杂的细节\u003c/strong\u003e。\u003cstrong\u003e改进后的特征随后被传输到解码器\u003c/strong\u003e以进行\u003cstrong\u003e进一步处理和分割\u003c/strong\u003e。我们的方法可以\u003cstrong\u003e无缝集成到任何编码器-解码器网络中\u003c/strong\u003e。我们在几个公共医学图像分割数据集上评估了我们的方法，用于皮肤病变分割和息肉分割，实验结果证明了我们的新方法相对于最先进的方法的分割准确性，同时\u003cstrong\u003e保留了内存和计算效率\u003c/strong\u003e。代码位于：https://github.com/yaoppeng/U-Net_v2。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e主要工作就在于中间的skip-connection\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e随着现代深度神经网络的进步，语义图像分割取得了重大进展。语义图像分割的典型范例涉及具有\u003cstrong\u003e跳跃连接的编码器-解码器网络[\u003cstrong\u003e1]。在此框架中，编码器从\u003c/strong\u003e输入图像中提取层次和抽象特征\u003c/strong\u003e，而解码器获取\u003cstrong\u003e编码器生成的特征图并重建像素级分割掩模或图\u003c/strong\u003e，\u003cstrong\u003e为输入图像中的每个像素分配类标签\u003c/strong\u003e。人们进行了一系列研究[2, 3]，\u003cstrong\u003e将全局信息纳入特征图\u003c/strong\u003e中并增强多尺度特征，从而大大提高了分割性能。\n在医学图像分析领域，\u003cstrong\u003e精确的图像分割\u003c/strong\u003e在计算机辅助诊断和分析中起着至关重要的作用。 U-Net [4] 最初是为了\u003cstrong\u003e医学图像分割\u003c/strong\u003e而引入的，利用\u003cstrong\u003e跳跃连接\u003c/strong\u003e来连接每个级别的\u003cstrong\u003e编码器和解码器阶段\u003c/strong\u003e。\u003cstrong\u003e跳跃连接\u003c/strong\u003e使解码器能够访问\u003cstrong\u003e早期编码器阶段\u003c/strong\u003e的特征，从而保留\u003cstrong\u003e高级语义信息\u003c/strong\u003e和\u003cstrong\u003e细粒度空间细节\u003c/strong\u003e。这种方法有助于\u003cstrong\u003e精确描绘对象边界\u003c/strong\u003e并提取\u003cstrong\u003e医学图像中的小结构\u003c/strong\u003e。此外，还应用了\u003cstrong\u003e密集连接机制\u003c/strong\u003e，通过\u003cstrong\u003e连接所有级别\u003c/strong\u003e和\u003cstrong\u003e所有阶段的特征\u003c/strong\u003e来减少\u003cstrong\u003e编码器和解码器中特征之间的差异\u003c/strong\u003e[5]。设计了一种机制来\u003cstrong\u003e通过连接较高和较低级别\u003c/strong\u003e的\u003cstrong\u003e不同尺度的特征\u003c/strong\u003e来\u003cstrong\u003e增强特征\u003c/strong\u003e[6]。\n然而，基于 U-Net 的模型中的这些连接在\u003cstrong\u003e集成低级和高级特征方面\u003c/strong\u003e可能\u003cstrong\u003e不够有效\u003c/strong\u003e。例如，在 ResNet [7] 中，深度神经网络是作为\u003cstrong\u003e多个浅层网络的集合\u003c/strong\u003e而形成的，并且\u003cstrong\u003e显式添加的残差连接\u003c/strong\u003e表明，即使在百万规模的训练中，网络也很难学习\u003cstrong\u003e恒等映射函数图像\u003c/strong\u003e数据集。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e对于编码器提取的特征，低级特征通常保留更多细节，但缺乏足够的语义信息，并且可能包含不需要的噪声\u003c/strong\u003e。相反，\u003cstrong\u003e高级特征包含更多语义信息，但由于分辨率显着降低而缺乏精确的细节（例如对象边界）\u003c/strong\u003e。通过\u003cstrong\u003e串联简单地融合特征\u003c/strong\u003e将在\u003cstrong\u003e很大程度上依赖于网络的学习能力\u003c/strong\u003e，这\u003cstrong\u003e通常与训练数据集的大小成正比\u003c/strong\u003e。这是一个具有挑战性的问题，特别是在医学成像领域，\u003cstrong\u003e通常受到有限数据的限制\u003c/strong\u003e。这种信息融合是\u003cstrong\u003e通过密集连接跨多个级别连接低级和高级特征\u003c/strong\u003e来实现的，可能会限制来自\u003cstrong\u003e不同级别的信息的贡献\u003c/strong\u003e并可能引入噪声。另一方面，尽管\u003cstrong\u003e引入的额外卷积并没有显着增加参数数量\u003c/strong\u003e，但 \u003cstrong\u003eGPU 内存消耗将会增加\u003c/strong\u003e，因为必须\u003cstrong\u003e存储所有中间特征图和相应的梯度\u003c/strong\u003e以进行前向传递和后向梯度计算。这会导致 \u003cstrong\u003eGPU 内存使用量\u003c/strong\u003e和\u003cstrong\u003e浮点运算 (FLOP) 增加\u003c/strong\u003e。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e\u003cimg alt=\"image-20231211193109745\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/mCdvu.png\"\u003e\u003c/p\u003e\n\u003cp\u003e(a) U-Net v2 模型的整体架构，由\u003cstrong\u003e编码器、SDI（语义和细节注入）模块和解码器\u003c/strong\u003e组成。 (b) SDI模块的架构。为简单起见，我们仅显示第三级特征的细化（l = 3）。 \u003cstrong\u003eSmoothConv 表示用于特征平滑的 3 × 3 卷积\u003c/strong\u003e。$\\bigotimes$ 表示哈达玛积。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e在[8]中，利用\u003cstrong\u003e反向注意力\u003c/strong\u003e来明确地建立\u003cstrong\u003e多尺度特征之间\u003c/strong\u003e的联系。在[9]中，ReLU激活应用于\u003cstrong\u003e较高级别\u003c/strong\u003e的特征，并\u003cstrong\u003e将激活的特征与较低级别的特征相乘\u003c/strong\u003e。此外，在[10]中，作者提出分别从 \u003cstrong\u003eCNN 和 Transformer 模型\u003c/strong\u003e中提取特征，在多个级别上组合\u003cstrong\u003e来自 CNN 和 Transformer 分支\u003c/strong\u003e的特征来\u003cstrong\u003e增强特征图\u003c/strong\u003e。然而，这些方法\u003cstrong\u003e都很复杂\u003c/strong\u003e，而且它们的\u003cstrong\u003e性能仍然不是很令人满意\u003c/strong\u003e，因此需要进一步改进。\u003c/p\u003e\n\u003cp\u003e在本文中，我们提出了 U-Net v2，这是一种基于 U-Net 的新分割框架，具有\u003cstrong\u003e简单且高效的跳跃连接\u003c/strong\u003e。我们的模型首先\u003cstrong\u003e使用 CNN 或 Transformer 编码器\u003c/strong\u003e提取\u003cstrong\u003e多级特征图\u003c/strong\u003e。接下来，\u003cstrong\u003e对于第 i 层的特征图\u003c/strong\u003e，我们通过\u003cstrong\u003e简单的哈达玛乘积操作\u003c/strong\u003e显式地注入\u003cstrong\u003e高层特征（包含更多语义信息）\u003cstrong\u003e和\u003c/strong\u003e低层特征（捕获更精细的细节）\u003c/strong\u003e，从而\u003cstrong\u003e增强语义和细节第 i 级特征\u003c/strong\u003e。随后，\u003cstrong\u003e细化的特征\u003c/strong\u003e被传输到解码器进行\u003cstrong\u003e分辨率重建和分割\u003c/strong\u003e。我们的方法可以无缝集成到任何编码器-解码器网络中。\u003c/p\u003e\n\u003cp\u003e我们使用公开的数据集在两个医学图像分割任务（皮肤病变分割和息肉分割）上评估我们的新方法。实验结果表明，我们的 U-Net v2 在这些分割任务中始终优于最先进的方法，\u003cstrong\u003e同时保持 FLOP 和 GPU 内存效率\u003c/strong\u003e。\u003c/p\u003e","title":"U-NET V2: RETHINKING THE SKIP CONNECTIONS OF U-NET FOR MEDICAL IMAGE SEGMENTATION"},{"content":"Abstract 放射科医生拥有不同的培训和临床经验，导致肺结节的分割注释存在差异，从而导致分割的不确定性。传统方法通常选择单个注释作为学习目标或尝试学习包含多个注释的潜在空间。\n然而，这些方法无法利用多个注释之间的共识和分歧所固有的有价值的信息。在本文中，我们提出了一种不确定性感知注意机制（UAAM），它利用多个注释之间的共识和分歧来促进更好的分割。为此，我们引入了多置信度掩模（MCM），它结合了低置信度（LC）掩模和高置信度（HC）掩模。 LC 掩模表示分割置信度较低的区域，放射科医生可能有不同的分割选择。继UAAM之后，我们进一步设计了一个不确定性引导多置信分割网络（UGMCS-Net），它包含三个模块：一个捕获肺结节一般特征的特征提取模块，一个为肺结节产生三个特征的不确定性感知模块。注释的并集、交集和注释集，以及一个交集并集约束模块，该模块使用三个特征之间的距离来平衡最终分割和 MCM 的预测。为了全面展示我们方法的性能，我们提出了 LIDC-IDRI 上的复杂结节验证，它测试了 UGMCS-Net 对使用常规方法难以分割的肺结节的分割性能。实验结果表明，我们的方法可以显着提高传统方法难以分割的结节的分割性能。\nINTRODUCTION 肺结节分割在肺癌计算机辅助诊断 (CAD) 系统中至关重要 [1]，可提供结节大小、形状和其他重要医学特征等关键信息。然而，对于深度学习方法的一般训练和测试范例，每个结节图像数据只有一个由一名放射科医生描绘的注释掩模[2]-[6]。因此，网络每次只能提供结节区域的单个预测。\n然而，在临床实践中，不同的放射科医生由于其不同的培训和临床经验可能会为肺结节提供不同的分割注释[7]-[9]。\n因此，基于单一注释的传统方法无法反映临床经验的多样性，限制了深度学习方法的应用。\n解决放射科医生之间注释不同问题的一个直接解决方案是为每个肺结节图像合并多个注释。这导致了另一个问题：多个注释不可避免地会带来不确定性和冲突，因为放射科医生可能会对同一区域进行不同的注释。为了克服这个问题，Kohl 等人在 2018 年提出了一种概率 U-Net，它利用条件变分自动编码器将多个分割变体编码到低维潜在空间中 [8]、[10]。通过从该空间采样，网络可以影响相应的分割图。基于这项研究，Hu等人提出将真实不确定性与概率UNet相结合，这可以提高预测不确定性估计、样本准确性和样本多样性[7]。这些方法依赖于潜在空间和该空间中的随机样本。因此，这些方法只能通过多次预测来提供不确定区域。\n在本文中，我们提出了一个论点，即多个注释之间的不确定性遵循特定的模式。\n为了演示这种现象，我们引入了多重置信掩码 (MCM)，它结合了高置信度 (HC) 掩码和低置信度 (LC) 掩码，如图 1 所示。 A. 交叉掩码等于 HC mask，代表所有注释的交集。\n联合掩码是所有注释的联合。 LC掩模是交集掩模和并集掩模之间的差异。当在 LIDC-IDRI 数据集 [11] 上计算 HC 和 LC 的 Hounsfield 单位 (HU) 核估计时，如图 1.B 所示，我们可以观察到 LC 和 HC 掩模之间的 HU 分布存在明显区别。具体地，LC区域具有比HC区域更低的HU值。从像素分布来看，HU值越低，对应区域的密度越低。就CT图像特征而言，LC区域主要由结节边缘、毛刺和磨玻璃特征等边界相关特征组成，而HC区域主要分布在结节核心内。因此，我们提出了这样的假设：导致放射科医生之间差异的区域主要与低密度组织和边界相关特征有关。\n与其他方法不同，我们建议利用 MCM (多重置信掩码) ** 和注释集作为具有不同分割确定性的特征的学习指导**，有助于更好的分割性能。我们将这种训练称为UncertaintyAware Attention Mechanism，如图2所示。按照这种机制，我们进一步设计了用于肺结节分割的Uncertainty-Guide Multi-Confidence Segmentation Network（UGMCS-Net）。\nUGMCS-Net 包含三个模块：基于 U-Net 的特征提取模块、不确定性感知模块和交集并集约束模块。\n首先，标签分为交集标签( $L_\\cap$ )、并集标签 ( $L_\\cup$ )、原始标签 (L)。\n其次，HC (consensus) 表示 $L_\\cap$ 、 LC（disagreement）表示 $L_\\cup$ - $L_\\cap$。\nMCM (Multi Confidence Mask) 表示 HC 和 LC的统称\n首先，特征提取模块从输入的CT图像中提取通用特征图R。其次，不确定性感知模块在标签的交集、并集、和原标签的指导下，将通用特征图R转换为三个独立的特征图$R_{LC}$、$R_{HC}$和$R_{Uni}$。 $R_{LC}$、$R_{HC}$用于预测并集掩码和交集掩码，并将结果组合为MCM。$R_{Uni}$用于预测初步分割结果。我们稍后使用 $\\cup(X)$, $\\cap(X)$, $X_{Uni}$ 来表示预测的并集掩码、交集掩码和初步分割结果。第三，约束模块使用来自$R_{LC}$、$R_{HC}$ 和 $R_{Uni}$的特征感知注意块捕获首选特征，然后用特征距离约束最终预测$X_S$，确保分割结果以合理的方式受到约束。为了更好地利用多个注释，我们还引入了多注释融合损失来优化 $X_{Uni}$和 $X_S$，它计算预测和所有注释之间的平均 BCE 损失。\n该方法具有两个明显的优点： （1）与学习潜在空间的传统基于 VAE 的方法相比，该方法具有特定的学习目标，使其能够提供不确定结节区域的稳定预测。 （2）该方法利用所有注释来优化预测，以确保最终预测平衡不同条件，充分利用可用信息。\n我们在之前的出版物中报告了这项工作的初步版本[12]。本文的新贡献可概括如下: （1）一种称为不确定性感知注意机制（UAAM）的新颖机制：UAAM 最大限度地利用多个注释，并采用多重置信掩码（MCM）来指导低置信度和高置信度特征的学习。\n（2）升级后的Uncertainty-Guide Multi-Confidence Segmentation Network (UGMCS-Net)：基于该机制，我们将UGS-Net更新为UGMCSNet，其中包含特征提取模块、不确定性感知模块和新的交并集约束模块。为了充分利用多个注释，我们还引入了多注释融合损失。所提出的模块是即插即用的，可以应用于不同情况下的其他分割网络。\n（3）全面验证：我们提出了ComplexNodule Validation，测试UGMCS-Net对U-Net难以分割的肺结节的分割性能。实验表明，对于UNet上DSC分数低于60％的结节，我们网络的DSC分数可以提高11.03％，我们网络的IoU分数可以提高11.88％。我们还为不同的模块、主干和模型设置提供足够的消融研究。\nRelated Work 2.1 Lung Nodule Segmentation 肺结节分割对于肺结节计算机辅助检测 (CAD) 系统至关重要。其主要目标是准确地描绘目标结节的边界，以提供其直径、大小和语义特征等细节[13]-[16]。这项任务的主要挑战是肺结节具有各种形状、大小和微妙的特征。早年，研究人员提供了多种肺结节分割方法，例如基于形态学的方法和基于区域生长的方法[17]，[18]。近年来，深度学习已成为该领域最流行的方法。\n2017年，Wang等人提出了一种用于肺结节分割的多视图卷积网络。所提出的网络同时从 CT 图像的轴向、冠状和矢状视图中捕获了一组不同的结节敏感特征。使用多分支 CNN 网络对这些特征进行分析，平均 DSC 相似系数 (DSC) 为 77.67% [19]。此外，Wang 等人在 2017 年提出了一种具有中心池层的中心聚焦卷积神经网络，可以彻底分析 2D 和 3D 结节 [1]。 2020年，Cao等人设计了带有强度池层的双分支残差网络，增强了强度信息的学习，并将DSC提高到82.74％[20]。 2021年，Pezzano等人推出了一种CNN网络，可以通过生成两个代表CT中所有背景和次要重要元素的掩模来学习结节的背景，从而使网络可以更好地区分结节特征[15]。后来在2022年，Shariaty等人进一步提出了纹理特征提取和特征选择算法来改进分割，实现了84.75%的DSC[2]。\n根据上述研究的观察结果，显然现有方法主要优先考虑实现更精确的分割，而忽略了不同放射科医生对如何分割同一肺结节可能持有不同意见的事实。在这项研究中，我们认为注释之间的分歧也具有诊断价值。因此，我们的方法旨在生成一个分割，通过从注释集学习并识别具有不同分割确定性的区域来有效地平衡所有注释。\n2.2 Uncertainty in Lung Nodule Segmentation 许多医学图像视觉问题都存在模糊性。在临床情况下，仅通过 CT 扫描可能无法明确哪个特定区域是癌组织 [10]、[21]。因此，即使是经验丰富的医生和放射科医生也可能对相同的组织或肿瘤提供不同的分割。\n2018 年，Kohl 等人提出将此任务建模为学习肺结节多样化但合理的分割上的分布。基于 U-Net [5]，他们引入了概率 U-Net，它是 UNet 和条件 VAE 的组合，可以产生无限数量的合理分割。 2019年晚些时候，Kohl等人进一步提出了一种分层概率U-Net，它使用分层潜在空间分解来制定高保真度分割的采样和重建[8]。同样在 2019 年，Hu 等人分析了两种类型的不确定性：任意的和认知的 [7]。他们利用多个注释的可变性作为“ground truth”任意不确定性的来源，将这种不确定性与概率 UNet 结合起来，并尝试定量分析分割不确定性。 2021年，Long等人将[7]中的概念扩展到V-Net和3D肺结节CT图像。作为包含 1000 多个肺结节的多个注释的理想数据集，所有这些研究 [7]-[10] 都分析了 LIDC-IDRI。\n与基于VAE的网络不同，我们的工作更关注导致各种标注的原因，表现为分割分歧。我们引入了一种专门针对不确定性区域的替代方法，使我们能够对不确定的结节区域和整体肺结节分割做出稳定的预测。这种方法使我们能够深入了解分割差异的根本原因，并在不确定的肺结节区域中产生更可靠的结果。\n在医学图像处理中，\u0026ldquo;条件变分自编码器（Conditional Variational Autoencoder, CVAE）\u0026ldquo;是一种生成模型，它结合了变分自编码器（VAE）的特性和条件生成的能力。VAE是一种深度学习模型，能够学习输入数据的潜在表示，然后从这些表示中生成新的数据实例。CVAE在此基础上增加了条件变量，使得生成的过程可以依赖于某些条件或标签。\n对于医学图像，CVAE可以用于多种任务，如生成特定类型的医学图像（例如，根据特定疾病状态生成CT或MRI图像），数据增强（生成新的训练样本），以及特征提取和表示学习等。通过将条件信息（如疾病标签、图像类型或患者信息）融入到生成过程中，CVAE能够生成更符合特定条件的图像，从而在特定医学应用中发挥作用。\nMethod 3.1 Uncertainty-Guided Multi-Confidence Segmentation Network 在图 3 中，我们展示了 UncertaintyGuided Multi-Confidence Segmentation Network (UGMCSNet) 的架构。该网络以肺结节 CT 图像作为输入，并产生两个输出：预测的多置信度掩模（MCM）和最终的分割 $X_S$。 MCM 结合了预测的并集 $\\cup(X)$ 和交集 $\\cap(X)$。网络的学习目标是注释集 GT，以及它们的 Union Mask $\\cup(GT)$ 和 Intersection Mask $\\cap(GT)$。输入图像及其相应的掩模的尺寸为 50 × 50 像素，通过从带有官方注释的 LIDC-IDRI 数据集裁剪获得。在输入网络之前，输入图像和掩模的大小被调整为 3 × 64 × 64 像素的尺寸。\nUGMCS-Net 包含三个模块：(1) 特征提取模块，(2) 不确定性感知模块，(3) 交并并约束模块。特征提取模块可以使用任何基于UNet结构的分割网络，初步获得形状为32×64×64的特征图R。本文使用具有五个下采样和上采样层的Attention U-Net [4] 。每个上采样层由两个卷积层和一个注意力块组成。不确定性感知模块分析 R 并生成$R_{LC}$、$R_{HC}$和$R_{Uni}$。然后将这些特征图输入 MCM BCE Loss Block 和 Multiple Annotation Loss Block，生成初始的 $\\cup(X)$、$\\cap(X)$ 和合理的分割 $X_{Uni}$。计算并集以 $\\cup(X)$、$\\cap(X)$获得 MCM。 Intersection-Union Constraining Module 学习 $R_{LC}$、$R_{HC}$和$R_{Uni}$的不同特征，并将这三个特征融合到$R_{final}$ 中。然后该模块通过分析RF ianl提供更合理的最终分割$X_S$。\n3.2 Uncertainty-Aware Module 引入不确定性感知模块（UAM），通过学习$\\cup(GT)$、$\\cap(GT)$ 和 GT来充分合理地利用所有注释信息。该模块有两个任务：（1）从低置信度（LC）区域、高置信度（HC）区域和所有注释中捕获不同的特征； (2) 生成多重置信掩模 (MCM) 的初始预测和一般分割。\n如图3所示，UAM采用三分支CNN网络作为骨干。它以 R (32 × 64 × 64) 作为输入，并使用内核大小为 1×1 的三个不同卷积层提取 $R_{LC}$、$R_{HC}$和$R_{Uni}$。 $R_{LC}$、$R_{HC}$和$R_{Uni}$的大小相同，均为 32 × 64 × 64。 MCM BCE Loss Block 接收 $R_{LC}$、$R_{HC}$ ，用三个不同的卷积层生成 $\\cup(X)$ 和 $\\cap(X)$ ，内核大小为 3× 3. BCE损失计算$\\cup(X)$ 和 $\\cup(GT)$的损失以及$\\cap(X)$ 和 $\\cap(GT)$。 $\\cup(X)$和$\\cap(X)$通过归一化操作Normal($\\cup(X)$+$\\cap(X)$)组合为MCM\u0026rsquo;，反映了不同区域的不确定性程度。与我们之前的工作 [12] 不同，$R_{Uni}$ 的分支是通过多重注释损失块进行优化的，这将在稍后讨论。此外，具有相同形状的 1 × 64 × 64 的特征图 $R_{LC}$、$R_{HC}$和$R_{Uni}$ 将被输入到下一个模块中进行进一步分析。\n主要还是用来生成一个MCM\n3.3 Intersection-Union Constraining Module 如上所述，$\\cup(GT)$和$\\cap(GT)$ 是UAM的学习目标。具体地，$\\cup(GT)$表示所有可能是结节组织的区域，表示置$\\cap(GT)$信度最高的结节区域。为了在极端情况之间实现平衡，我们进一步开发了一个新模块，称为交集并集约束模块（IUCM）。\n该模块旨在捕获所有三个学习目标的特征，并产生更合理的分割预测，可以在极端情况之间取得平衡。\n如图 4 所示，IUCM 将 $R_{LC}$、$R_{HC}$和$R_{Uni}$作为输入，并将对应的 $R_{LC}^{\\prime}$、$R_{HC}^{\\prime}$和$R_{Uni}^{\\prime}$与特征感知注意块 (FAAB) 对应。 $R_{LC}^{\\prime}$、$R_{HC}^{\\prime}$和$R_{Uni}^{\\prime}$的尺寸相同，均为 32 × 32 × 32。FAAB 是基于自注意力块 [22] 和特征感知滤波器构建的。\n这些注意力块使用不同的特征感知滤波器处理$R_{LC}$、$R_{HC}$和$R_{Uni}$，使网络能够针对不同的学习目标制定不同的学习偏好，并获得更多有助于分割的图像特征[23]、[24]。更具体地说，假设输入$R_z$，FAAB的过程可以总结为：\n其中 z ∈ {Uni, LC, HC},A表示自注意力架构。 Г是一个特征感知滤波器，在本研究中，$R_{Uni}$和$R_{LC}$的Г是Gabor[25]，$R_{HC}$的Г是Otsu[26]。 Γ(A($R_z$)) 与$R_z$逐像素相加，以便网络可以从输入中保留更多信息。\n通过对数据集和Hounsfield Unit Kernel Estimations的观察，我们可以看到，$R_{HC}$主要是密度较高的实性结节，而$R_{LC}$则包括更多的低密度组织（如毛刺），主要分布在结节的边缘。 Otsu对密度特征敏感，可以帮助网络更准确地识别高密度组织。因此，我们应用 Otsu 从 $R_{HC}$ 中提取 $R_{HC}^{\\prime}$。同时，Gabor对图像边缘敏感，能够提供良好的方向选择和尺度选择特征，从而能够捕获图像局部区域多个方向的局部结构特征。因此，我们选择Gabor从$R_{LC}$和$R_{Uni}$中提取$R_{LC}^{\\prime}$和$R_{Uni}^{\\prime}$。关于过滤器选择的消融研究将在第四节中提供。\n得到 $R_{LC}^{\\prime}$、$R_{HC}^{\\prime}$和$R_{Uni}^{\\prime}$后，IUCM 得到 $S_z$ = d{$R_Z$,$R$},d是计算余弦相似度的运算。\nIUCM 的输出为 $R_{Aug}$ = Concat($S_{Uni}$× $R_{Uni}^{\\prime}$ ; $S_{LC}$× $R_{LC}^{\\prime}$; $S_{HC}$× $R_{HC}^{\\prime}$ )。$R_{Aug}$将与来自特征提取模块的 R 连接，输入到卷积层，并生成最终的分割预测 $X_S$。 R 和 $R_{Aug}$ 的串联保留了来自 CT 输入的更多信息。\n3.4 Loss Function 在图 3 中，UGMCS-Net 包含两个优化：MCM BCE 损失块和多注释损失块。\nMCM BCE Loss Block 计算$\\cup(X)$ 和 $\\cup(GT)$之间; $\\cap(X)$ 和$\\cap{(GT)}$之间的 BCE 损失可表示为：\n我们使用多注释融合损失来优化多注释损失块中的$X_{Uni}$和$X_S$，表示为Φ。在我们之前的工作中，只选择了一组注释来优化$X_{Uni}$和$X_S$，这导致其他注释中有价值的信息丢失。\n本研究引入了多重注释融合损失，它将预测与所有可能的注释进行比较。\n首先，$R_{Uni}$和$R_F$最终产生$X_{Uni}$和$X_S$。其次，如图 5 所示，多注释融合损失函数计算优化对象（$X_{Uni}$和$X_S$）与注释集之间的 BCE 损失，并合并这些损失的平均值。根据我们的设计，$X_{Uni}$应该倾向于整个注释集，XS应该从注释集中学习足够的信息并产生平衡所有注释的分割，因此我们选择使用多注释融合损失来优化$X_{Uni}$和$X_S$。我们有：\n网络的损失融合可以定义为：\n其中 α1、α2 和 α3 是预定义参数。根据经验，本文中α1设置为0.5，α2设置为0.5，α3设置为1。重量选择的消融研究将在第四节中显示。\nEXPERIMENT 4.1 Dataset and Experimental Settings 在本研究中，我们使用 LIDC-IDRI 数据集 [11] 评估所提出的网络，该数据集由 1018 个研究实例和超过 2600 个结节组成。在本研究中，我们选择了 1860 个直径为 3-30mm 且具有多个注释的肺结节。每个结节数据至少有两个注释，以便我们可以获得其CT图像、多个注释集GT、它们的并集$\\cup(GT)$和交集$\\cap(GT)$。输入图像及其掩模均为 50 × 50 像素，根据官方注释从 LIDC-IDRI 数据集中裁剪。每个像素反映 CT 图像的亨斯菲尔德单位。\n在训练之前，我们将 CT 图像的强度值裁剪到范围 [1000,1000] 并将所有强度值归一化到范围 [0, 1]。数据处理的代码在网站 https://github.com/qiuliwang/LIDCIDRI-Toolbox-python 上提供。\n我们在运行 Ubuntu 18.04、Tesla V100 GPU 的服务器上进行实验，使用 CUDA 11.2，GPU 内存约为 16G。该网络使用PyTorch-v1.0.1和Python3.7实现。我们使用五重验证来评估网络的有效性，确保数据分割的稳健性。我们使用热重启随机梯度下降（SGDR）作为优化器，初始学习率（LR）为0.00001，批量大小为32，动量为0.9，权重衰减率为0.0001。每个网络都训练 200 个 epoch，学习率每 50 个 epoch 更新一次。 UGMCS-Net的源代码、原始USGNet以及所有实验设置将上传到https://github.com/yanghan-yh/UGS-Net。\n4.2 Performance of Lung Nodule Segmentation 每个结节的相关注释Label1，它是注释集中的第一个。 Probabilistic U-Net是一种基于VAE的模糊分割方法，因此我们取其四个样本的平均值作为最终的分割结果。本研究使用三个指标来评估网络对病变区域的预测能力：平均 Dice 相似系数（DSC）、交集交集（IoU）和归一化表面 Dice（NSD）[35]。在表 I 中，所有方法均使用 Label1 进行评估。\n这实验数据太丰富了把！！！\n表I显示UGMCS-Net在DSC、IoU和NSD方面取得了最高分数，分别为87.65%（±0.56%）、78.78%（±0.83%）和95.62%（±0.59%）。与 U-Net 相比，UGMCS-Net 在三个指标上分别提高了 1.39%、1.99% 和 1.16%。同样，与 Attention U-Net 相比，UGMCS-Net 在各个指标上实现了 0.98%、1.45% 和 0.68% 的增强。这些结果凸显了 UGMCS-Net 卓越的分割性能，特别是 NSD 分数的大幅提高，表明其强大的边界特征分割能力。此外，与 UGSNet 相比，UGMCS-Net 在所有指标上都表现出了相当大的进步，DSC 分数提高了 0.49%，IoU 分数提高了 0.74%，NSD 分数提高了 0.34%。此外，从 UGMCS-Net 的五重交叉验证中获得的三个指标的方差始终小于 UGS-Net 的方差，表明通过集成多重注释融合损失和约束操作增强了网络稳定性。 nnU-Net 是用于分割任务的流行网络。然而，它在 DSC 中仅达到 84.60%，在 IoU 中仅达到 74.45%。这是因为nnU-Net的训练需要很大的数据集。然而，我们在此任务中只有 1860 个结节图像。\n图6显示了上述方法的部分分割结果。输入列中的红色框表示感兴趣的区域或结节容易出错的分割位置。结节(a)-(c)包含许多低密度区域，结节(d)-(f)在其边界处具有不规则形状，例如毛刺迹象，并且结节(g)-(h)具有空腔。 UGMCS-Net 对这些区域的分割明显比其他方法更符合病灶的实际形状。\n对比实验结果的套话 （可以学习一下）\n（U-Net、Attention U-Net、R2U-Net、Channel U-Net、Nested U-Net、UGS-Net 和 UGMCS-Net 的分割结果。输入列对应的红色框表示分割时应注意的特征或结节容易出错的位置。 UGMCS-Net 列中的红色框表示 UGMCS-Net 在这些位置的分割细节。绿色框表示次优分割结果的不足之处。最后一栏是相应结节的直径，单位为毫米）\n这个定性结果的对比方法，值得学习。\n图 6 和表 I 表明：（1）从注释集及其并集和交集中学习，为分割任务提供了更丰富的视觉信息。\n(2)从LC区域学习提高了网络识别低密度区域的能力。\n值得注意的是，图6（g）-（h）中，标注中没有空洞，但UGMCS-Net得到的分割结果反映了空洞特征。我们选择保留这些特征有两个原因：（1）常见结节组织的密度高于肺实质。但肺结节内的空腔密度极低，甚至是空的。\n我们可以将它们视为结节的一部分，也可以不视为结节的一部分。 (2) 分割图应提供更多有关结节特征的信息。空腔是重要的特征，因此保留这些空腔是更好的选择。如果需要，可以使用 cv2.findContours 等方法轻松去除预测中的空洞。\n表II，UGMCS-Net对于U-Net、Attention UNet、UGS-Net在Dice和IoU分数中的p值远小于0.05，并且t值的绝对值较大，表明UGMCS-Net在性能上明显优于U-Net、Attention U-Net和UGS-Net。\nP值 (P-value)：在统计分析中，P值用于量化结果发生的概率，假设零假设（通常是无效假设，如两组之间无差异）为真。在医学图像分析的研究中，如果涉及到统计检验（例如，比较两种分割方法的性能），P值可以用来表示这种比较的显著性水平。 V值：这个术语在医学图像分析中不常见，可能指的是特定研究或技术中使用的一个特定参数或度量。例如，它可能代表体积（Volume）的度量，特别是在分析器官大小或肿瘤体积时。在不同的上下文中，它可能有不同的含义。 上面的实验是基于注释集中的第一个注释Label1 。为了消除掩码选择的影响，我们还提供了 U-Net、Attention U-Net、UGS-Net 和 UGMCS-Net 在标注集中的第二个标签 Label2 上的性能。表III中列出的实验结果表明UGMCS-Net在Label2上保持了其优越的性能。这意味着所提出的方法可以在不同的掩模选择上保持稳定的性能。在传统的训练方法中，每个结节都被分配一个单一的掩模，无法为具有复杂结构特征的结节提供足够的信息。\n在我们的网络中，每个结节与 2-4 个掩模相关联。通过整合多重注释融合损失，我们将更全面的信息注入到学习过程中。它对于分割具有复杂结构和低密度纹理的结节特别有益。因此，多重注释融合损失显着提高了性能，特别是对于具有复杂结构的结节。\n4.3 Uncertain Region Prediction 除了能够分割结节之外，UGMCS-Net 还可以预测更有可能是结节组织的区域和可能性较低的区域。图 7 说明了预测结果 $\\cup(X)$和$\\cap(X)$、最终分割结果 $X_S$ 以及生成的 MCM’。在MCM’和MCM+UGSNet中，红色表示高置信度区域，蓝色表示低置信度区域，绿色对应于最终分割$X_S$。在理想情况下，$X_S$应有效地在高置信度和低置信度区域之间取得平衡。\n（预测交集$\\cap(X)$、预测并集$\\cup(X)$、最终分割$X_S$ 和 MCM 由 UGMCS-Net 生成。 MCM 中的颜色用于更好的可视化，红色表示$\\cap(X)$，蓝色表示$\\cup(X)$。此外，最终的分割在 MCM 中表示并标记为绿色以方便比较。红色框表示不易区分的结节区域或特征。最后一栏是相应结节的直径（以毫米为单位）)\n根据图 7，我们的最终分割结果位于高置信度区域和低置信度区域这两种极端情况之间。这些中间结果表明（1）我们的预测认识到所有潜在的注释，并且（2）预测被限制在$\\cap(X)$和$\\cup(X)$之间。\n具体来说，在肺结节特征分割中使用MCM具有以下几个优点，可以更好地显示结节的语义特征：（1）MCM可以更好地突出结节的显着空腔特征（图7.（g）（h））。与其他方法相比，UGMCS-Net 的预测掩模上的结节腔特征更加明显。这是由于UGMCS-Net能够在交叉掩模$\\cap(GT)$和联合掩模$\\cup(GT)$的指导下捕获结节组织的密度差异，这有助于保留结节腔的更多特征。\n(2)MCM可以更好地分割毛刺征象，这是诊断良恶性肺结节的重要特征(图7.(a)-(f))。针状结构是由结节侵入周围组织引起的星状变形，通常是低密度的并分布在结节边缘周围。这一特征是传统深度学习方法难以分割的。 UGMCS-Net在union mask $\\cup(GT)$的指导下可以更加关注结节边界特征，从而对分布在结节边界的毛刺有更好的分割性能。\n（3）MCM可以更好地分割结节的低密度组织（图7.（i）-（l）），该区域常见于磨玻璃结节，是造成专家标记差异的主要区域。 UGMCSNet通过对注释集GT和union mask $\\cup(GT)$的研究，可以最大程度地识别低密度组织，这对于磨玻璃结节的诊断很有帮助。\n由于LC掩模尺寸较小，传统的定量评估指标如DSC和IoU不足以衡量MCM的预测质量。为了解决这个问题，我们将预测的 HC 和 LC 掩模的 HU 分布与实际的 HC 和 LC 掩模进行比较。我们假设UGMCS-Net能够合理地预测不同区域的不确定性程度。因此，预测的 HC 和 LC 掩模的 HU 值分布应与实际分布相似。图8显示预测曲线与实际曲线吻合较好，表明我们预测的区域不确定性水平在统计上是可靠的。\n4.4 Ablation Study 我真的要被这个工作量给吓鼠了，太能做实验了把\n模块的消融研究：如果不指出实用性，我们会在每个部分进行五倍验证。为了更好地利用多个注释的信息并增强 $R_{LC}$ 、 $R_{HC}$ 和 $R{final}$ 之间的关系，我们用多注释融合损失和交叉联合约束模块更新了 UGMCS-Net。为了进一步证明这两个模块的贡献，我们基于 UGMCS-Net 构建了 UGMCS-$Φ_a$、UGMCS-$Φ_b$、UGMCS-$Φ_a$+$Φ_b$ 和 UGMCS-IUCM 进行消融实验。在UGMCS-$Φ_a$中，多注释融合损失仅应用于$\\cup(X)$;在UGMCS-$Φ_b$中，Multiple Annotation Fusion Loss仅应用于网络XS的最终输出；在UGMCS-$Φ_a$+$Φ_b$ 中，多重注释融合损失应用于$\\cup(X)$和$X_S$；在UGMCS-IUCM中，我们使用USG-Net中的Intersection-Union约束模块，但没有多重注释融合损失。\n我们的 UGMCS-Net 及其四种变体的性能列于表 IV，“-”表示 Attention U-Net。 V1是指没有IUCM和多重注释融合损失的UGS-Net，它作为其他变体的基础网络。\n结果表明：（1）UGMCS-$Φ_a$、UGMCS-$Φ_b$网络相对于UGMCS-Net的性能改进表明，所有标注信息的融合可以使网络更准确地捕获结节区域并获得更好的分割性能。 (2) UGMCS-$Φ_a$+$Φ_b$ 网络的 DSC、IoU 和 NSD 高于 UGMCS-$Φ_a$、UGMCS-$Φ_b$网络，表明同时对 UAM 和最终输出使用多重注释融合损失优于单独使用其中之一。 (3) 我们的 UGMCS-Net 优于UGMCS-$Φ_a$+$Φ_b$和 UGMCS-IUCM，证明了交集并集约束模块的有效性。尽管仅添加交集-并集约束模块（UGMCS-IUCM）时网络的定量性能略有下降，但观察到了显着的定性改进，这将在后面讨论。此外，UGMCS-Net的优越性能表明，多重注释融合损失和交叉联合约束模块可以相互增强，约束不确定性并促进更好的分割性能。\n为了进一步验证多注释融合损失和交叉联合约束模块的有效性，我们在图 9 中使用 Grad-CAM [36]、[37] 演示了特征图可视化。每种情况下的结果代表了网络的最终预测。 M3、M2和M1分别表示不同网络配置下倒数第三个、第二个和第一个卷积层的视觉特征图。基于图9，我们观察到：（1）当将多重注释融合损失应用于$\\cup(X)$或$X_S$时，网络对低密度组织的识别能力显着提高（UGMCS-$Φ_a$和UGMCS-$Φ_b$，结节A-D)； （2）$\\cup(X)$或$X_S$中同时使用Multiple Annotation Fusion Loss，可以在提高对低密度组织的敏感性的基础上，使网络勾勒出结节边界更加清晰（UGMCS-$Φ_a$+$Φ_b$网络，结节A-D）。 (3) IntersectionUnion Constraining Module使网络能够学习更多的边界特征，例如spiculation（毛刺）（UGMCS-IUCM网络，Nodule A-C）。 （4）当同时使用Multiple Annotation Fusion Loss和Intersection-Union Constraining Module时，网络注意力转移到结节边界，勾画出更加合理完整的结节区域（UGMCS-Net，Nodule A-E）。\n如图9所示，在IUCM的帮助下，网络可以针对复杂结节获得更语义化、更合理的分割结果。然而，如表IV所示，与UGMCS-$Φ_a$+$Φ_b$相比，UGMCS-Net在DSC、IoU和NSD上的性能增益较弱。我们认为造成这种现象的原因有3个：（1）IUCM专注于提高复杂结节的分割性能，与测量上的改进相比，IUCM使得模型对分割结果的性能提升更加显着（进一步验证在第 IV-E 节）。\n（2）复杂结节仅占结节总数的一小部分，因此IUCM无法显着提高模型在各项指标上的得分。 (3)数据集中仍然存在一些失败案例。如图10所示，在这些情况下，UGMCS-IUCM和UGMCS-Net获得的分割掩模包含更多的结节组织并且是更准确的病变区域，但它们的DSC分数较低。\n由于不同医生领域的知识偏差会影响groundtruth，因此对于分割任务来说，获得更准确、更合理的分割掩模通常比更高的度量分数更有意义。\n表V显示了加入UAM和IUCM后模型复杂度的增加。显然，UAM 和 IUCM 可以使模型以很少的计算成本获得更好的性能。\nBackbone 的消融研究：我们测试 U-Net 和 R2U-Net 作为三个模块的骨干。如表六所示，以U-Net为骨干的模型在DSC、IoU和NSD上分别获得了87.04%、78.07%和94.50%的分数。\n以R2U-Net为骨干的模型在DSC、IoU和NSD上分别获得了86.20%、76.82%和93.75%的结果。实验结果表明，所提出的特征提取模块、不确定性感知模块和交集并集约束模块是即插即用的。\n我们之前的工作评估了 nnU-Net [22] 作为骨干网络。\n这个网络在这个任务中有两个缺点：（1）它占用了太多的计算资源，（2）我们只有 1860 个结节，这可能会导致过度拟合。为了平衡计算资源和性能增益，我们在本工作中选择 Attention U-Net。\n交叉点联合约束模块中滤波器的消融研究：在第 III-C 节中，我们讨论了 Otsu 对密度特征的敏感性，使模型能够准确识别高密度组织。因此，我们利用 Otsu 的方法来提取 $R_{HC}$ 的特征。相反，Gabor对图像边缘敏感并提供有效的方向和尺度选择特征，被选择用于 $R_{LC}$的特征提取。在这些部分中，我们进行了涉及 Fold1 上 IntersectionUnion 约束模块内的五个过滤器设置的实验。表 VII 概述了这些设置。如表 VII 所示，我们的最终配置产生了最高的 DSC 分数。\n我们在图 11 中提供了 $R_{LC}^{\\prime}$ 和 $R_{HC}^{\\prime}$ 的特征可视化。可以看出， $R_{LC}^{\\prime}$ 的可视化更多地集中在结节的边缘，其中包含更多的低置信度区域。相比之下， $R_{HC}^{\\prime}$ 的可视化更关注结节的核心，具有更高的分割置信度。这些可视化结果重新证明了我们过滤器设计的有效性。\n参数消融研究：在方程 4 中，存在三个手动设置的参数：α1 指定为 0.5，α2 指定为 0.5，α3 指定为 1。在本节中，我们进行五重验证并说明这些参数选择背后的基本原理。\n如表VIII所示，当α1设置为0.5，α2设置为0.5，α3设置为1时，所提出的方法达到其峰值性能。值得注意的是，α3代表最终分割的权重，这意味着XS在训练过程中发挥着重要作用。\n此外，我们对三个分支的概率图加权平均融合进行了实验，希望网络能够为IUCM中的每个分支选择合适的权重。然而，我们观察到与 $R_{Uni}$ 对应的分支可以为结节分割提供更通用的特征，并且比其他两个分支显得“更强”。因此，其他两个分支的权重往往会减少到 0。根据这些观察结果，我们选择直接融合概率图。\n4.5 Complex-Nodule Validation UGMCS-Net 从可能导致分割不确定性的区域学习特征。因此，它可以更好地分割具有大的低密度区域或复杂结构的结节。为了更好地证明其对 U-Net 难以分割的结节的改进，我们设计了一个 Complex Nodule Validation。基于五重验证U-Net，我们进一步选择了DSC分数低于60％、70％和80％的三组结节。然后使用相同的数据设置训练 Attention U-Net、UGMCS-$Φ_a$+$Φ_b$、UGMCS-IUCM 和 UGMCS-Net，以再次测试这些结节并比较 DSC 和 IoU 分数。\nUGMCS-Net 在复杂结节上的性能提升是显而易见的。与Attention U-Net相比，对于U-Net上DSC分数低于60%的结节，UGMCS-$Φ_a$+$Φ_b$导致平均DSC分数提高1.58%，UGMCS-IUCM使平均DSC分数提高5.12%，UGMCS-平均 DSC 得分净产量增加了 5.45%。对于 U-Net 上 DSC 得分在 60% 到 70% 之间的结节，UGMCS-$Φ_a$+$Φ_b$、UGMCS-IUCM 和 UGMCS-Net 的平均 DSC 得分分别提高了 0.69%、3.11% 和 5.07%。同样，对于 U-Net 上 DSC 分数在 70% 至 80% 之间的结节，UGMCS-$Φ_a$+$Φ_b$、UGMCS-IUCM 和 UGMCS-Net 的平均 DSC 分数相应提高了 0.14%、1.52% 和 1.64%。从上述差异可以看出，UGMCS-IUCM对于复杂结节有很大程度的性能提升。根据表一，我们的网络在整个数据集上仅将 DSC 提高了 0.89%，但相对于 U-Net 上 DSC 分数低于 60% 的结节而言，相对于 Attention U-Net 具有很大的性能提升。这是因为具有复杂结构的结节仅占所有数据的一小部分。\n图12显示了一些复杂结节的分割结果。红色下标是UGMCS-Net的分段DSC，黑色下标是UNet的DSC。可以看出，U-Net分割DSC得分低于60%的结节是一些低密度或毛玻璃组织。 UGMCS-Net在这些结节中的显着改进表明UGMCS-Net可以更好地学习结节低密度组织的特征并更准确地分割低密度结节病变区域。当U-Net分割DSC得分低于70%时，可以观察到除了一些低密度结节外，一些结节还存在不规则空洞、毛刺、组织内突然出现亮点或肺壁过亮。 UGMCS-Net在这些结节上令人信服的分割性能反映了UGMCS-Net对边界特征、密度差异的学习能力以及良好的抗噪声能力。当U-Net分割DSC得分低于80%时，我们观察到许多新结节具有更多的实体组织。在这种情况下，UGMCS-Net可以准确地确定结节区域。此外，对于大多数结节，UGMCS-Net的分割结果反映了更多的语义特征，具有更强的可解释性。\n复杂结节验证中的分割性能分析。 UGMCS-$Φ_a$+$Φ_b$、UGMCS-IUCM 和 UGMCS-Net 平均 DSC 和 IoU 后面是与 Attention U-Net 相应度量的差值（绿色数字）。所有指标均以百分比表示。\n（复杂结节验证：该验证测试了 UGMCS-Net 对 U-Net 难以分割的肺结节进行三个级别的分割性能。每张CT图像的最后两个掩模分别是UGMCS-Net和U-Net的分割结果。U-Net的分割结果以黑色显示，UGMCS-Net以红色显示。所有指标均以百分比表示。）\nDISCUSSIONS 长期以来，肺结节分割的任务一直致力于实现高精度，其中 DSC 或 IoU 是主要目标。然而，考虑到肺结节尺寸小且结构复杂，如果分割结果以不同置信度突出显示区域，可能对放射科医生更有帮助。高置信度区域提供了结节或肿瘤组织的主要部分，而低置信度区域则包含重要的低密度特征，例如毛玻璃状和毛刺征，放射科医生也应注意这些特征。\n所提出的方法旨在提供对临床诊断更有用的信息，而不是简单地改进 DSC。它并不寻求取代医生的临床作用，而是通过允许他们利用人工智能方法的优势来补充医生的临床作用。我们相信，这是将人工智能融入临床实践的更好方法。\n5.1 Data Requirement 我们的方法并不需要每个放射科医生都对所有结节进行注释。如 [11] 所示，项目期间共有 12 名放射科医生参与了所有五个站点的图像注释程序。鉴于大多数结节由 1-4 名放射科医生进行注释，可以想象结节可能由不同的放射科医生进行注释。\n尽管如此，不同放射科医生参与注释结节不会妨碍我们方法的适用性。尽管不同放射科医生之间的注释风格可能存在差异，但值得注意的是，训练有素的放射科医生遵循既定的结节注释标准，例如[38]。这些标准确保不同组的放射科医生提供多样化但基本一致的注释。\n5.2 Limitation 我们研究的一个局限性是我们仅在 LIDC-IDRI 数据集上测试我们提出的方法，该数据集是目前唯一公开可用的肺结节完整注释数据集。尽管已有十多年的历史，该数据集仍然提供了许多研究机会。然而，对多个注释的需求可能会限制我们的方法在现实临床环境中的实用性，其中获得多个注释可能并不总是可行。为了解决这个限制，我们计划探索能够基于单个注释自动识别高置信度和低置信度区域的技术，从而提高我们方法的可行性和适用性。\nCONCLUSIONS 多个注释之间的协议，以改进分割并识别分割置信度较低的区域。UAAM 从多置信度模板 (MCM) 中捕获特征，多置信度模板是低置信度 (LC) 模板和高置信度 (HC) 模板的组合。基于UAAM，我们进一步设计了不确定性引导分割网络（UGMCS-Net），其中包含特征提取模块、不确定性感知模块和交集并集约束模块。这些模块共同从多个注释之间的共识或分歧中学习有价值的信息，提供具有高和低分割置信度的区域，以及可以平衡所有可能性的分割结果。除了传统的验证方法之外，我们还提出了 LIDC-IDRI 上的复杂结节验证，测试 UGMCS-Net 对 U-Net 难以分割的肺结节的分割性能。\n实验结果表明，我们的方法可以显着提高 U-Net 分割效果不佳的结节的分割性能。\n总结：牛逼牛逼牛逼！！！ 确实牛逼！ 不愧是一区顶刊\n","permalink":"https://swimmingliu.cn/posts/papernotes/2023-uncertainty-aware-attentionmechanism/","summary":"\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e放射科医生拥有不同的培训和临床经验，导致\u003cstrong\u003e肺结节的分割注释\u003c/strong\u003e存在\u003cstrong\u003e差异\u003c/strong\u003e，从而导\u003cstrong\u003e致分割的不确定性\u003c/strong\u003e。传统方法通常选择\u003cstrong\u003e单个注释\u003c/strong\u003e作为学习目标或尝试学习包含\u003cstrong\u003e多个注释\u003c/strong\u003e的\u003cstrong\u003e潜在空间\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e然而，这些方法无法\u003cstrong\u003e利用多个注释之间的共识和分歧所固有的有价值的信息\u003c/strong\u003e。在本文中，我们提出了一种\u003cstrong\u003e不确定性感知注意机制\u003c/strong\u003e（UAAM），它利用多个\u003cstrong\u003e注释之间的共识\u003c/strong\u003e和分歧来促进更好的分割。为此，我们引入了\u003cstrong\u003e多置信度掩模\u003c/strong\u003e（MCM），它结合了\u003cstrong\u003e低置信度（LC）掩模\u003c/strong\u003e和高置信度（HC）掩模。 \u003cstrong\u003eLC 掩模\u003c/strong\u003e表示\u003cstrong\u003e分割置信度较低的区域\u003c/strong\u003e，\u003cstrong\u003e放射科医生可能有不同的分割选择\u003c/strong\u003e。继\u003cstrong\u003eUAAM\u003c/strong\u003e之后，我们进一步设计了一个\u003cstrong\u003e不确定性引导多置信分割网络\u003c/strong\u003e（UGMCS-Net），它包含三个模块：\u003cstrong\u003e一个捕获肺结节一般特征的特征提取模块\u003c/strong\u003e，\u003cstrong\u003e一个为肺结节产生三个特征的不确定性感知模块\u003c/strong\u003e。\u003cstrong\u003e注释的并集、交集和注释集，以及一个交集并集约束模块\u003c/strong\u003e，该模块使用\u003cstrong\u003e三个特征之间的距离来平衡最终分割和 MCM 的预测\u003c/strong\u003e。为了全面展示我们方法的性能，我们提出了 LIDC-IDRI 上的复杂结节验证，它测试了 UGMCS-Net 对使用常规方法难以分割的肺结节的分割性能。实验结果表明，我们的方法可以显着提高传统方法难以分割的结节的分割性能。\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch2 id=\"introduction\"\u003eINTRODUCTION\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e肺结节分割\u003c/strong\u003e在\u003cstrong\u003e肺癌计算机辅助诊断 (CAD)\u003c/strong\u003e 系统中至关重要 [1]，可提供\u003cstrong\u003e结节大小、形状和其他重要医学特征\u003c/strong\u003e等关键信息。然而，对于深度学习方法的\u003cstrong\u003e一般训练和测试范例\u003c/strong\u003e，每个结节图像数据只有一个由\u003cstrong\u003e一名放射科医生\u003c/strong\u003e描绘的注释掩模[2]-[6]。因此，\u003cstrong\u003e网络每次只能提供结节区域\u003c/strong\u003e的单个预测。\u003c/p\u003e\n\u003cp\u003e然而，在临床实践中，不同的放射科医生\u003cstrong\u003e由于其不同的培训和临床经验\u003c/strong\u003e可能会为肺结节提供\u003cstrong\u003e不同的分割注释\u003c/strong\u003e[7]-[9]。\u003c/p\u003e\n\u003cp\u003e因此，基于\u003cstrong\u003e单一注释的传统方法\u003c/strong\u003e无法反映\u003cstrong\u003e临床经验的多样性\u003c/strong\u003e，限制了深度学习方法的应用。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e解决放射科医生之间注释不同问题\u003c/strong\u003e的一个直接解决方案是为\u003cstrong\u003e每个肺结节图像合并多个注释\u003c/strong\u003e。这导致了另一个问题：\u003cstrong\u003e多个注释不可避免地会带来不确定性和冲突\u003c/strong\u003e，因为放射科医生\u003cstrong\u003e可能会对同一区域进行不同的注释\u003c/strong\u003e。为了克服这个问题，Kohl 等人在 2018 年提出了一种概率 U-Net，它\u003cstrong\u003e利用条件变分自动编码器\u003c/strong\u003e将\u003cstrong\u003e多个分割变体编码\u003c/strong\u003e到\u003cstrong\u003e低维潜在空间\u003c/strong\u003e中 [8]、[10]。通过从该空间采样，网络可以影响相应的分割图。基于这项研究，Hu等人提出将\u003cstrong\u003e真实不确定性\u003c/strong\u003e与\u003cstrong\u003e概率UNet\u003c/strong\u003e相结合，这可以\u003cstrong\u003e提高预测不确定性估计\u003c/strong\u003e、\u003cstrong\u003e样本准确性和样本多样性\u003c/strong\u003e[7]。这些方法依赖于\u003cstrong\u003e潜在空间和该空间中的随机样本\u003c/strong\u003e。因此，这些方法只能通过多次预测来提供不确定区域。\u003c/p\u003e\n\u003cp\u003e在本文中，我们提出了一个论点，即\u003cstrong\u003e多个注释之间的不确定性遵循特定的模式\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e为了演示这种现象，我们引入了\u003cstrong\u003e多重置信掩码\u003c/strong\u003e (MCM)，它结合了\u003cstrong\u003e高置信度 (HC) 掩码\u003c/strong\u003e和低置信度 (LC) 掩码，如图 1 所示。 A. 交叉掩码等于 \u003cstrong\u003eHC mask\u003c/strong\u003e，代表\u003cstrong\u003e所有注释的交集\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e联合掩码是所有注释的联合\u003c/strong\u003e。 \u003cstrong\u003eLC掩模是交集掩模和并集掩模之间的差异\u003c/strong\u003e。当在 LIDC-IDRI 数据集 [11] 上计算 HC 和 LC 的 Hounsfield 单位 (HU) 核估计时，\u003cstrong\u003e如图 1.B 所示，我们可以观察到 LC 和 HC 掩模之间的 HU 分布存在明显区别\u003c/strong\u003e。具体地，LC区域具有比HC区域更低的HU值。从像素分布来看，\u003cstrong\u003eHU值越低，对应区域的密度越低\u003c/strong\u003e。就CT图像特征而言，LC区域\u003cstrong\u003e主要由结节边缘、毛刺和磨玻璃特征等边界相关特征组成\u003c/strong\u003e，而\u003cstrong\u003eHC区域主要分布在结节核心内\u003c/strong\u003e。因此，我们提出了这样的假设：导致放射科医生之间差异的区域主要与\u003cstrong\u003e低密度组织和边界相关特征\u003c/strong\u003e有关。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e\u003cimg alt=\"image-20231130203343980\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/327b2.png\"\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e与其他方法不同，我们建议利用 \u003cstrong\u003eMCM (多重置信掩码) ** 和注释集作为具有\u003c/strong\u003e不同分割确定性的特征的学习指导**，有助于更好的分割性能。我们将这种训练称为\u003cstrong\u003eUncertaintyAware Attention Mechanism\u003c/strong\u003e，如图2所示。按照这种机制，我们进一步设计了用于肺结节分割的\u003cstrong\u003eUncertainty-Guide Multi-Confidence Segmentation Network\u003c/strong\u003e（UGMCS-Net）。\u003c/p\u003e","title":"Uncertainty-Aware Attention Mechanism:利用不确定性感知注意机制进行肺结节分割和不确定区域预测"},{"content":"程序设计作业接口文档 统一返回格式\n{ code: ...,\t# 状态码 msg: ...,\t# 描述信息 data: { # 数据 ... } } code = { 200 == 成功, 500 == 失败, } msg = { success == 成功 fail == 失败 ... } data = { key : value } 前端 虚拟换衣功能 @请求格式 （请求后端） # 前后端需统一样例图片id { userId: ...\u0026lt;int\u0026gt;,\t# 标识哪个用户的请求 isUploadCloth: ...\u0026lt;bool\u0026gt;, # 若上传衣服图片使用base64，否则用id isUploadPerson: ...\u0026lt;bool\u0026gt;, # 若上传人物图片使用base64，否则用id clothData: ...\u0026lt;base64||null\u0026gt;, # 衣服图片base64编码 personData: ...\u0026lt;base64||null\u0026gt;,\t# 人物图片base64编码 exampleClothId: ...\u0026lt;int\u0026gt;,\t# 衣服样例图片id examplePersonId: ...\u0026lt;int\u0026gt;\t# 任务样例图片id } 动漫头像功能 @请求格式 （请求后端） { userId: ...\u0026lt;int\u0026gt;, # 标识哪个用户的请求 imgData: ...\u0026lt;base64\u0026gt; # 需要动漫化的图片 } 后端 虚拟换衣功能 前端请求API: https://talented-civet-separately.ngrok-free.app/tryon/ @返回格式 (返回前端) { code: ...\u0026lt;int\u0026gt;, # 状态码 (200表示成功, 500表示失败) msg: ...\u0026lt;string\u0026gt;,\t# 消息 (success / fail) data: { tryon_result : ...\u0026lt;url\u0026gt;, # 处理后的图片url } } 动漫头像功能 前端请求API: https://talented-civet-separately.ngrok-free.app/anime/ @返回格式 (返回前端) { code: ...\u0026lt;int\u0026gt;, # 状态码 (200表示成功, 500表示失败) msg : ...\u0026lt;string\u0026gt;, # 消息 (success / fail) data: { anime_result : ...\u0026lt;url\u0026gt;, # 处理后的图片url } } 模型端 虚拟换衣功能 后端请求API: https://certain-ideally-foal.ngrok-free.app/tryon/predict/ @请求格式\t(后端发出请求) { userid : ...\u0026lt;int\u0026gt;, # 用户id cloth : ...\u0026lt;url\u0026gt;, # 衣服图片url链接 person : ...\u0026lt;url\u0026gt;\t# 人物图片url链接 } @返回格式\t（返回后端） { code: ...\u0026lt;int\u0026gt;, # 状态码 (200表示成功, 500表示失败) msg: ...\u0026lt;string\u0026gt;,\t# 消息 (success / fail) data: { image_value : ...\u0026lt;base64\u0026gt;, # 处理后的图片base64编码 } } 动漫头像功能 后端请求API: https://certain-ideally-foal.ngrok-free.app/anime/predict/ @请求格式 { userid : ...\u0026lt;int\u0026gt;, # 用户id origin_image : ...\u0026lt;url\u0026gt;, # 原图片url链接 } @返回格式 { code: ...\u0026lt;int\u0026gt;, # 状态码 (200表示成功, 500表示失败) msg: ...\u0026lt;string\u0026gt;,\t# 消息 (success / fail) data: { image_value : ...\u0026lt;base64\u0026gt;, # 处理后的图片base64编码 } } ","permalink":"https://swimmingliu.cn/posts/diary/2023-%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E4%BD%9C%E4%B8%9A%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/","summary":"\u003ch1 id=\"程序设计作业接口文档\"\u003e程序设计作业接口文档\u003c/h1\u003e\n\u003cp\u003e统一返回格式\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003ecode:\u003c/span\u003e \u003cspan class=\"err\"\u003e...,\u003c/span\u003e\t\u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e状态码\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003emsg:\u003c/span\u003e \u003cspan class=\"err\"\u003e...,\u003c/span\u003e\t\u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e描述信息\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003edata:\u003c/span\u003e \u003cspan class=\"err\"\u003e{\u003c/span\u003e     \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e数据\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \t\u003cspan class=\"err\"\u003e...\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003ecode\u003c/span\u003e \u003cspan class=\"err\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003e200\u003c/span\u003e \u003cspan class=\"err\"\u003e==\u003c/span\u003e \u003cspan class=\"err\"\u003e成功,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003e500\u003c/span\u003e \u003cspan class=\"err\"\u003e==\u003c/span\u003e \u003cspan class=\"err\"\u003e失败,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003emsg\u003c/span\u003e \u003cspan class=\"err\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003esuccess\u003c/span\u003e \u003cspan class=\"err\"\u003e==\u003c/span\u003e \u003cspan class=\"err\"\u003e成功\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003efail\u003c/span\u003e    \u003cspan class=\"err\"\u003e==\u003c/span\u003e \u003cspan class=\"err\"\u003e失败\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003e...\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003edata\u003c/span\u003e \u003cspan class=\"err\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003ekey\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003evalue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"前端\"\u003e前端\u003c/h2\u003e\n\u003ch3 id=\"虚拟换衣功能\"\u003e虚拟换衣功能\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e@请求格式\u003c/span\u003e  \u003cspan class=\"err\"\u003e（请求后端）\u003c/span\u003e  \t \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e前后端需统一样例图片id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003euserId:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;,\u003c/span\u003e\t\t\t\u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e标识哪个用户的请求\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003eisUploadCloth:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;bool\u0026gt;,\u003c/span\u003e           \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e若上传衣服图片使用base64，否则用id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003eisUploadPerson:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;bool\u0026gt;,\u003c/span\u003e          \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e若上传人物图片使用base64，否则用id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003eclothData:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;base64||null\u0026gt;,\u003c/span\u003e \t\u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e衣服图片base64编码\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003epersonData:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;base64||null\u0026gt;,\u003c/span\u003e\t\u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e人物图片base64编码\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003eexampleClothId:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;,\u003c/span\u003e\t\t\u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e衣服样例图片id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003eexamplePersonId:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;\u003c/span\u003e\t\t\u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e任务样例图片id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"动漫头像功能\"\u003e动漫头像功能\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e@请求格式\u003c/span\u003e \u003cspan class=\"err\"\u003e（请求后端）\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003euserId:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;,\u003c/span\u003e    \t        \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e标识哪个用户的请求\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003eimgData:\u003c/span\u003e  \u003cspan class=\"err\"\u003e...\u0026lt;base64\u0026gt;\u003c/span\u003e \t        \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e需要动漫化的图片\u003c/span\u003e \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"后端\"\u003e后端\u003c/h2\u003e\n\u003ch3 id=\"虚拟换衣功能-1\"\u003e虚拟换衣功能\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e前端请求API:\u003c/span\u003e \u003cspan class=\"err\"\u003ehttps:\u003c/span\u003e\u003cspan class=\"c1\"\u003e//talented-civet-separately.ngrok-free.app/tryon/\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"err\"\u003e@返回格式\u003c/span\u003e \u003cspan class=\"err\"\u003e(返回前端)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003ecode:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;,\u003c/span\u003e \t                \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e状态码\u003c/span\u003e \u003cspan class=\"err\"\u003e(200表示成功,\u003c/span\u003e \u003cspan class=\"err\"\u003e500表示失败)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003emsg:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;string\u0026gt;,\u003c/span\u003e\t                \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e消息\u003c/span\u003e \u003cspan class=\"err\"\u003e(success\u003c/span\u003e \u003cspan class=\"err\"\u003e/\u003c/span\u003e \u003cspan class=\"err\"\u003efail)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003edata:\u003c/span\u003e \u003cspan class=\"err\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"err\"\u003etryon_result\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;url\u0026gt;,\u003c/span\u003e  \t\u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e处理后的图片url\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"动漫头像功能-1\"\u003e动漫头像功能\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e前端请求API:\u003c/span\u003e \u003cspan class=\"err\"\u003ehttps:\u003c/span\u003e\u003cspan class=\"c1\"\u003e//talented-civet-separately.ngrok-free.app/anime/\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"err\"\u003e@返回格式\u003c/span\u003e \u003cspan class=\"err\"\u003e(返回前端)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003ecode:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;,\u003c/span\u003e  \t                \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e状态码\u003c/span\u003e \u003cspan class=\"err\"\u003e(200表示成功,\u003c/span\u003e \u003cspan class=\"err\"\u003e500表示失败)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003emsg\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;string\u0026gt;,\u003c/span\u003e \t                \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e消息\u003c/span\u003e \u003cspan class=\"err\"\u003e(success\u003c/span\u003e \u003cspan class=\"err\"\u003e/\u003c/span\u003e \u003cspan class=\"err\"\u003efail)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003edata:\u003c/span\u003e \u003cspan class=\"err\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \t\u003cspan class=\"err\"\u003eanime_result\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e  \u003cspan class=\"err\"\u003e...\u0026lt;url\u0026gt;,\u003c/span\u003e \t\u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e处理后的图片url\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"模型端\"\u003e模型端\u003c/h2\u003e\n\u003ch3 id=\"虚拟换衣功能-2\"\u003e虚拟换衣功能\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e后端请求API:\u003c/span\u003e \u003cspan class=\"err\"\u003ehttps:\u003c/span\u003e\u003cspan class=\"c1\"\u003e//certain-ideally-foal.ngrok-free.app/tryon/predict/\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"err\"\u003e@请求格式\u003c/span\u003e\t\u003cspan class=\"err\"\u003e(后端发出请求)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003euserid\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;,\u003c/span\u003e              \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e用户id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003ecloth\u003c/span\u003e  \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;url\u0026gt;,\u003c/span\u003e \t            \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e衣服图片url链接\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003eperson\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;url\u0026gt;\u003c/span\u003e\t            \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e人物图片url链接\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e@返回格式\u003c/span\u003e\t\u003cspan class=\"err\"\u003e（返回后端）\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003ecode:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;,\u003c/span\u003e \t            \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e状态码\u003c/span\u003e \u003cspan class=\"err\"\u003e(200表示成功,\u003c/span\u003e \u003cspan class=\"err\"\u003e500表示失败)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003emsg:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;string\u0026gt;,\u003c/span\u003e\t            \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e消息\u003c/span\u003e \u003cspan class=\"err\"\u003e(success\u003c/span\u003e \u003cspan class=\"err\"\u003e/\u003c/span\u003e \u003cspan class=\"err\"\u003efail)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003edata:\u003c/span\u003e \u003cspan class=\"err\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"err\"\u003eimage_value\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;base64\u0026gt;,\u003c/span\u003e  \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e处理后的图片base64编码\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"动漫头像功能-2\"\u003e动漫头像功能\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e后端请求API:\u003c/span\u003e \u003cspan class=\"err\"\u003ehttps:\u003c/span\u003e\u003cspan class=\"c1\"\u003e//certain-ideally-foal.ngrok-free.app/anime/predict/\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"err\"\u003e@请求格式\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003euserid\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;,\u003c/span\u003e  \t   \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e用户id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003eorigin_image\u003c/span\u003e  \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;url\u0026gt;,\u003c/span\u003e \t   \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e原图片url链接\u003c/span\u003e \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e@返回格式\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003ecode:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;,\u003c/span\u003e \t            \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e状态码\u003c/span\u003e \u003cspan class=\"err\"\u003e(200表示成功,\u003c/span\u003e \u003cspan class=\"err\"\u003e500表示失败)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003emsg:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;string\u0026gt;,\u003c/span\u003e\t            \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e消息\u003c/span\u003e \u003cspan class=\"err\"\u003e(success\u003c/span\u003e \u003cspan class=\"err\"\u003e/\u003c/span\u003e \u003cspan class=\"err\"\u003efail)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003edata:\u003c/span\u003e \u003cspan class=\"err\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"err\"\u003eimage_value\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;base64\u0026gt;,\u003c/span\u003e  \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e处理后的图片base64编码\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"程序设计作业接口文档"},{"content":"Prior Attention Network: 用于医学图像中多病灶分割的预先注意网络 Abstract 医学图像中邻近组织的多种类型病变的准确分割在临床实践中具有重要意义。基于从粗到精策略的卷积神经网络（CNN）已广泛应用于该领域。然而，由于组织的大小、对比度和高类间相似性的不确定性，多病灶分割仍然具有挑战性。此外，普遍采用的级联策略对硬件要求较高，限制了临床部署的潜力。为了解决上述问题，我们提出了一种新颖的先验注意网络（PANet），它遵循从粗到细的策略来在医学图像中执行多病灶分割。所提出的网络通过在网络中插入与病变相关的空间注意机制，在单个网络中实现了两个步骤的分割。此外，我们还提出了中间监督策略，用于生成与病变相关的注意力来获取感兴趣区域（ROI），这加速了收敛并明显提高了分割性能。我们在两个应用中研究了所提出的分割框架：肺部 CT 切片中多发性肺部感染的 2D 分割和脑 MRI 中多发性病变的 3D 分割。实验结果表明，与级联网络相比，在 2D 和 3D 分割任务中，我们提出的网络以更少的计算成本实现了更好的性能。所提出的网络可以被视为 2D 和 3D 任务中多病灶分割的通用解决方案。源代码可在 https://github.com/hsiangyuzhao/PANet 获取\n问题导向：\n①组织的大小、对比度和高类间相似性的不确定性\n②多类别病灶分割\n③普遍采用的级联策略对硬件要求较高\nIntroduction 医学图像分割对于疾病的准确筛查和患者的预后具有重要意义。基于病灶分割的病灶评估提供了疾病进展的信息，帮助医生提高临床诊断和治疗的质量。然而，手动病变分割相当主观且费力，这限制了其潜在的临床应用。近年来，随着人工智能的快速发展，基于深度学习的算法得到了广泛的应用，并在医学图像分割方面取得了最先进的性能[1]。卷积神经网络（CNN）由于其高分割质量而在医学图像中的病变分割中很受欢迎。此类算法通常具有深度编码器，可从输入图像中自动提取特征，并通过以下操作生成密集预测。例如，Long等人[2]提出了一种用于图像语义分割的全卷积网络，该网络颇具影响力，并启发了后来的医学分割中的端到端框架。 Ronneberger等人[3]提出了一种用于医学图像分割的U形网络（U-Net），该网络在医学分割的许多领域都显示出了可喜的结果，并已成为许多医学分割任务的虚拟基准。\n这一段都可以当成经典医学图像分割的背景引入\n然而，尽管医学分割取得了这些突破，但目前的医学分割方法主要集中在病灶的二元分割上，即区分病灶（前景）和其他一切（背景）。尽管二元分割确实有助于隔离某些感兴趣区域并允许对医学图像进行精确分析，但在某些需要对病变进行多类分割的场景中，二元分割还不够。与二元分割相比，由于组织的类间相似性，这种情况要困难得多，因为不同类型的病变在纹理、大小和形状上可能相似。具有从粗到细策略的级联网络已广泛应用于此类场景，例如肝脏和病变的分割、脑肿瘤分割[4]、[5][6]、[7]。\n此类网络通常由两个独立的网络组成，其中第一个网络执行粗分割，第二个网络基于从第一个网络分割的 ROI 细化分割。然而，尽管级联网络已广泛应用于医学图像的多病灶分割，但级联策略也有其缺点。由于级联网络由两个独立的网络组成，参数量和显存占用通常是单个网络的两倍，这对硬件要求较高，限制了其在临床使用的潜力。更重要的是，由于级联网络中的两个网络通常是独立的，因此级联网络的训练过程有时比单个网络更困难，这可能导致欠拟合。\n级联网络：参数量大、容易欠拟合。\n在本文中，我们提出了一种名为先验注意网络（PANet）的新型网络结构，用于在医学图像中执行多病灶分割。所提出的网络由一个用于特征提取的编码器和两个分别生成病变区域注意力和最终预测的解码器组成。该网络与注意力机制结合在一起。为了减少参数大小和硬件占用，我们使用网络编码器的深层、语义丰富的特征来生成病变区域的空间注意力。\n然后，编码器生成的特征表示通过空间注意力进行细化，并将其发送到解码器以进行最终的多类预测。为了提高分割性能并加速收敛，我们还在网络结构中引入了中间监督和深度监督。通过这些改进，与传统的级联网络相比，所提出的网络以显着降低的参数大小和计算成本实现了有竞争力的结果。\n利用网络编码器的深层、特征信息来生成空间注意力（WTF ???）\n中间监督、深度监督 （不错不错， 好多一区和顶会的文章都用深度监督）\n这项工作的贡献体现在三个方面。首先，我们提出了一种新颖的网络架构，通过将传统级联网络中的两个分割步骤结合在单个网络中，遵循 2D 和 3D 医学图像中多病灶分割的从粗到细的策略。与级联网络相比，所提出的架构以更少的额外计算成本实现了有竞争力的分割性能，更容易训练和部署到生产环境。其次，我们提出了一种监督空间注意力机制，将病变区域的注意力与网络提取的特征相结合，将多病变分割分解为两个更容易的阶段，并且与当前基于注意力的方法相比具有更好的可解释性。第三，所提出的网络已在两个实际应用中得到验证，包括肺部 CT 切片中的 COVID-19 病变的 2D 分割和多模态 MRI 中的脑肿瘤的 3D 分割。所提出的网络在 2D 和 3D 任务中都优于前沿方法，并且在参数和计算成本方面比当前网络更高效。\n一个网络、监督空间注意力机制、参数和计算成本方面比当前网络更高效。\nRelated Work 1）图像分割的网络结构：用于图像分割的典型卷积神经网络通常由一个卷积特征提取器组成，其拓扑类似于常见的分类网络，自动从输入图像中提取特征，并进行基于卷积的操作以生成最终的密集预测。在自然图像分割领域，FCN [2]、DeepLab [8]、PSPNet [9] 和 SegNet [10] 因其性能和效率而颇受欢迎。对于医学分割，U-Net [3] 在许多任务中相当流行，并且已被修改为许多改进版本，例如 Attention U-Net [11]、U-Net++ [12]、V-Net [13] 和H-DenseUNet [14]在某些领域获得更好的性能。\n2）级联网络在医学分割中的应用：级联网络已广泛应用于正常组织和病变的分割以及不同类型病变的分割，包括肝脏病变、脑肿瘤、硬化病变和前列腺癌的分割[4] ，[15][5]，[16]。例如，Awad 等人[17]提出了一个名为 CU-Net 的级联框架，用于在 CT 扫描中对肝脏和病变进行自动分割。他们还提供了可以指导临床治疗的有用信息和解释。 Xi等人[18]提出了一种级联U-ResNets，它遵循一种新颖的垂直级联策略，并在他们的工作中评估了不同类型的损失函数。除了肝脏病灶分割之外，级联策略在 BraTS 挑战中也很流行。例如，BraTS 2019挑战赛的Top-2解决方案[6]、[7]都是具有不同级联策略的级联网络。\n3）神经网络中的注意力：注意力机制受到人类感知和视觉认知的启发，并已普遍应用于计算机视觉任务中[19]，[20][11]，[21]。计算机视觉任务中的注意力机制是在神经网络提取的特征表示上生成空间或通道权重图。例如，Woo等人[20]开发了一个卷积块注意力模块（CBAM）来引入一种融合注意力机制，其中包括通道注意力和空间注意力。这种注意力模块可以插入到常用的分类或分割网络中。Oktay等人[11]在Attention U-Net中提出了一种新颖的注意力门，用于细化网络编码器提取的特征表示，以促进网络专注于ROI。最近，首先在自然语言处理任务中提出的变压器[22]已被引入到医学分割任务中。例如，Wang 等人 [23] 提出了一种 TransBTS，用于从多模态脑 MRI 中执行脑肿瘤分割。\n综上所述，注意力机制已被广泛用于突出ROI并抑制不相关信息，但目前基于注意力的方法的研究并没有对注意力如何产生以及网络为何关注某些区域提供清晰的解释，这使得限制了注意力机制的可解释性。\nMethod 在本节中，我们将详细介绍所提出的先验注意网络架构。在第一部分中，我们将概述所提议的网络。然后，我们相应地提供有关具有中间监督、参数化跳跃连接和具有深度监督的多类解码器的所提出的注意引导解码器的详细信息。\n3.1 . Overview of Network Architecture 基本上，我们提出的网络是基于 U-Net [3] 架构进行修改的，该架构具有 U 形拓扑以及编码器和解码器之间的跳跃连接。在提出的先验注意网络中，一种新颖的注意引导解码器模块被集成到网络的跳跃连接中，以通过空间注意来细化特征表示。网络中还引入了一种新颖的参数化跳跃连接，以指导网络学习普通特征图和精炼特征图之间的比率。注意力引导解码器从编码器获取丰富的语义特征并生成空间注意力图来指导接下来的多类分割。为了产生与投资回报率相关的注意力，框架中使用了中间监督策略。然后将细化的特征图发送到多类解码器以进行最终的密集预测。\n多类解码器采用深度监督策略以获得更好的收敛性并提高分割性能。这种网络拓扑通过注意力引导解码器生成的注意力图在单个网络中实现了传统级联网络的两个步骤。组网方案如图2所示。\n3.2 Attention Guiding Decoder 在典型的级联网络中，分割的第一步是执行粗分割并找到输入图像中的 ROI。在提出的先验注意网络中，我们提出了一个注意引导解码器来执行该过程。所提出的注意力引导解码器被集成到网络中以生成与 ROI 相关的注意力图，然后利用这些图来细化特征表示并提高多类分割性能。\n1）模块拓扑：所提出的注意力引导解码器的基本拓扑基于FCN [2]中提出的特征融合。从网络解码器最深三层提取的特征表示被馈送到该模块。由于特征图的空间大小不同，因此首先执行线性插值以对特征图进行上采样。然后对特征进行压缩，抑制通道维度中的不相关信息，降低计算成本。然后将压缩后的特征分别在通道维度上连接起来以进行特征融合。(torch.cat) 最后，融合三个特征图以获得最终的预测。\n为了简单起见，我们使用 2D 分割来说明注意力图的计算。我们使用 Xi ∈ R Ci × Hi × Wi,i ∈ (3, 4, 5) 表示从网络编码器提取的特征图，其中 X5 表示最深的特征。特征压缩和融合计算如下：\n其中Z5 ∈ R C4 × H4 × W4表示X5和X4的融合特征，Z4 ∈ R C3 × H3 × W3表示X4和X3的融合特征，Wc5 ∈RC5×C4和Wc4 ∈RC4×C3表示相应的压缩卷积， W4 ∈ RC4×C4 表示融合 X5 和 X4 的融合卷积，⊕ 表示特征串联。\n注意力引导解码器的输出计算如下：\n其中 W3 ∈ R C3×C3 表示融合 X4 和 X3 的融合卷积，Wout ∈ R C3 × 1 表示输出卷积，σ 分别表示 Sigmoid 激活。\n2）中间监督：计算机视觉中的传统注意力机制自动生成注意力图，但注意力生成的过程通常是人类无法解释的，并且网络关注的区域可能与人类关注的区域不同。\n这种差距会限制注意力机制的性能和可解释性，有时还会导致网络容量的恶化。为了解决这些问题，我们在网络中引入了中间监督策略。在遵循从粗到细的方式的多病灶分割任务中，我们首先生成一个二元Ground Truth，其中前景表示所有类型的病灶，背景表示其他一切。在具有 C 种病变的多病变分割任务中，我们使用 Gi,i ∈ (1,\u0026hellip;,C) 表示第 i 类病变的二元基本事实，其中前景表示特定病变背景代表其他一切。二进制真实值 Gb 计算如下：\n然后利用二元损失函数来计算二元真实值 yb 和注意力引导解码器生成的注意力图 Y 之间的二元损失 l：\n其中 Lb 表示二元损失函数。然后利用计算出的损失 l 来监督注意力引导解码器的参数更新。\n这个地方的中间监督主要是 要让中间的注意力机制起作用，不能随便生成。\n通过引入中间监督，生成的注意力由输入图像的二元真实值进行监督。这样，网络被迫学习多病灶分割任务的分解，即首先提取病灶区域，然后对病灶区域进行细粒度分类。这种分解降低了多病灶分割的难度，并且与当前在“黑匣子”中生成注意力的基于注意力的医学分割方法相比，具有更好的可解释性。\n3.3 Parameterized Skip Connections 跳跃连接已广泛应用于流行的卷积网络中，包括U-Net [3]、ResNet [24]等。受[11]的启发，我们建议将注意力图集成到连接网络编码器和多网络的跳跃连接中，形成多级解码器。在跳跃连接中，我们还引入了额外的残差路径来恢复普通特征图并进一步提高分割性能。与传统的残差路径相比，残差路径的幅值因子αi,i ∈ (1, 2,…, 5)被设置为网络的可学习参数，并在反向传播过程中更新。我们相信这样的设置可以为网络增加额外的非线性能力并增强跳过连接的有效性。\n我们使用 Fi,i ∈ (1, 2,\u0026hellip;, 5) 表示来自网络编码器的普通特征图，Y 表示注意力图，精炼后的特征图 Fri,i ∈ (1, 2,. .., 5) 多类解码器接收的信息计算如下：\n然后将细化的特征图发送到多类解码器以进行最终的多类预测。\n3.4 Multi-Class Decoder With Deep Supervision U形分割网络中的解码器用于接收编码器发送的特征图，随着解码器中的特征通道数量的减少和空间分辨率的增加，分割性能逐步细化。然而，随着网络变深，最深的解码器块变得难以训练，这可能会限制最终的分割性能。深度监督策略已经被提出来训练深度卷积网络[25]、[26]。在所提出的先验注意网络中，辅助预测是从不同级别的解码器块中提取的，并使用相同的基本事实进行监督。我们使用 Pi,i ∈ (1, 2, 3) 表示来自多类解码器的辅助预测，Pm 表示最终的多类预测，g 表示真实值，Lm 表示多类损失函数。最终的多类损失计算如下：\n所提出的多类解码器的解码器块也与当前网络设置具有共同的设置，即卷积层、归一化层和非线性激活单元的堆栈。\n总结一下：\n① 注意力机制 + 中间监督：最后三层特征融合 + 这一部分做深度监督（原来这样也叫创新）\n② 跳跃连接的部分加了一个α因子 （感觉像权重一样的东西 ）\n③ 多阶段的深度监督 （这个就算一个trick吧，大家都在用）， 不过这里变成了多类别\nExperiments 4.1 Strong Baselines and Evaluation Metrics 为了研究网络架构的性能差异，我们将所提出的先验注意网络与医学分割中最流行的方法进行了比较，包括 U-Net [3]、Attention U-Net [11] 和级联 U-Net，在两个 2D 中和 3D 分割任务。值得注意的是，与他们论文中提出的原始版本相比，基线方法根据网络拓扑方面的某些任务进行了修改和优化，以获得性能提升。我们将残差连接[24]、批量归一化[30]和来自 ImageNet 的预训练编码器引入到 2D COVIDlesion 分割任务的基线方法中，并且我们还将残差连接、实例归一化和 PReLU 激活引入到 3D 脑肿瘤分割任务中。除了网络拓扑之外，基线方法与所提出的先验注意网络共享相同的数据增强和训练配置。\n对于 COVID-19 病变的 2D 分割，我们使用 Dice 指数、精度分数和召回分数来评估所提出的网络的性能。 Dice指数是一种用来衡量两个样本相似度的统计量，已广泛用于分割算法的评估。精确率衡量的是实际正确的阳性识别的比例，召回率衡量的是算法对阳性样本的敏感度。对于 BraTS 2020 挑战赛的 3D 分割，在在线门户上进行评估，并根据 Dice 指数和 95% Hausdorff 距离（HD）对算法进行排名。\n我们使用 G 表示ground truth，P 表示密集预测，TP 表示正确预测的正样本，FP 表示错误预测的正样本，TN 表示正确预测的副样本，FN 表示错误预测的副样本。这些指标的计算方式如下：\n这个HD（Hausdorff ）也是一种评估分割结果的方式 （alright 又多了一种指标）\n4.2 肺部 CT 切片中的 COVID-19 病灶的 2D 多病灶分割 1）数据：由于可用的开源COVID-19 CT分割数据集通常很小，因此利用两个独立的公开可用数据集，即COVID-19 CT分割数据集[27]和CC-CCII数据集[28]来验证所提出的方法二维分割任务中的方法。第一个数据集包含来自 40 多名患者的 100 个轴向 CT 切片，这些切片已重新缩放至 512 × 512 像素并进行灰度化。所有切片均由放射科医生用不同的标签进行分割，以识别不同类型的肺部感染。第二个数据集由 150 名 COVID-19 患者的 750 张 CT 切片组成，这些切片被手动分割为背景、肺野、毛玻璃混浊和实变。由于并非所有 750 个切片都包含病变，我们最终使用了 150 名患者的 549 个带注释的切片。对于这两个数据集，利用 5 倍交叉验证来评估所提出模型的性能。\n折叠之间的数据根据患者进行分割，以避免潜在的数据泄漏。最终的标签和分割图包含 3 个类别，包括背景、毛玻璃不透明度 (GGO) 和合并 (CON.)。\n2）实现细节：a）模型设置和损失函数：对于预训练网络编码器，我们采用来自ImageNet的预训练ResNeXt-50（32 × 4d）[31]作为基线方法和所提出的先验注意网络的编码器。对于解码器中的上采样，采用双线性插值，比例因子为2。对于中间监督和级联U-Net第一阶段的二元损失函数，我们采用Dice Loss [13]和Focal的线性组合损失[32]作为损失函数。对于最终输出的多类损失函数，我们采用Focal Tversky Loss [33]作为损失函数。\nb) 训练细节：我们的模型是在 Ubuntu 16.04 服务器上使用 PyTorch 1.7.1 框架实现的。我们使用 NVIDIA RTX 2080 Ti GPU 来加速我们的训练过程。在我们的训练过程中使用Albumentations [34] 进行数据增强，以减少过度拟合并提高泛化能力。首先，将所有输入图像重新缩放为 560 × 560，然后进行随机亮度和对比度偏移以及随机仿射变换。然后将图像随机裁剪为 512 × 512，然后进行随机弹性变换，最后输入网络。该模型由 Adam 优化器优化，β1 = 0.9、β2 = 0.999、γ = 1e − 8。L2 正则化也用于减少过度拟合。我们将模型权重衰减设置为 1e − 5。初始学习率设置为 1e −4 并降低，然后采用余弦退火策略。批量大小设置为 4，模型训练 40 轮。该模型使用 5 倍交叉验证进行评估。\n3）定量结果：我们在两个数据集上的实验中不同模型的详细比较分别如表一和表二所示。如图所示，我们提出的网络在毛玻璃不透明度和固结的 Dice 分数方面优于 U-Net、Attention U-Net。所提出的 PANet 以更少的参数和计算成本实现了与级联 U-Net 竞争的结果。由于这些模型在模型主干和训练策略上是相同的，很明显，所提出的注意力引导解码器、中间监督和深度监督的组合对分割性能有很大贡献。注意力引导解码器的利用有助于模型更准确地检测感染组织并生成与感染相关的注意力图，从而有利于解码器中的多类分割。\n此外，中间监督和深度监督的引入促进了网络的收敛，这也有助于提高性能。\n好好好，这哥们儿，睁着眼睛说瞎话是吧（这Unet明明比你低啊，精度也没差多少啊）\n4）定性结果：不同模型在 2D COVID-19 切片上的视觉比较如图 4 所示。由于模型在 Dice 分数方面非常接近，因此乍一看这些模型的表现相似。但与 U-Net 和 Attention U-Net 相比，所提出的 PANet 在实变和微小病变的分割上表现更好。\n与 U-Net 和 Attention U-Net 相比，PANet 产生更准确的分割掩模，并且与 Cascaded U-Net 相比，所提出的网络以更少的计算成本实现了有竞争力的结果。\n额 只要定量结果上去了，好像定性结果都是挑好的说吧？\n) 消融实验：进行了几次消融实验来评估我们模型中组件的性能，如表 III 所示。 a）具有深度监督的多类解码器的有效性：为了探索深度监督策略的贡献，我们建立了两个实验：No.1（U-Net）和No.2（U-Net + DS）。表三的结果表明，深度监督在一定程度上对绩效有所贡献。\nb）注意力引导解码器的有效性：我们通过构建实验 3（U-Net + AGD w/o IS）来研究所提出的网络中所提出的注意力引导解码器的有效性。如表III所示，与实验1相比，注意力引导解码器的引入提供了显着的性能提升。这表明注意力引导解码器在所提出的网络中提供了有效的注意力图，从而指导解码器中的多类分割。\nc）参数化跳跃连接的有效性：为了探索所提出的参数化跳跃连接的有效性，我们建立了两个实验4（U-Net + AGD*）和5（U-Net + AGD）。引入参数化跳跃连接后，分割性能得到了提高，几乎没有额外的参数或计算成本。\nd）中间监督的有效性：为了研究所提出的 PANet 中中间监督策略的有效性，我们比较了第 3 号（U-Net + AGD w/o IS）和第 5 号（U-Net + AGD）。如表 III 所示，与第 3 种相比，具有中间监督的网络获得了额外的改进。此外，在比较第 6 种（U-Net + DS + AGD w/o IS）和第 7 种（PANet）时也可以观察到改进。 ）尽管改进相对较小。可以看出，深度监管的引入也对绩效产生了提升，因此中级监管对绩效的提升并不像以前那么显着。\n4.3 3D Multi-Lesion Segmentation of Brain Tumor From Multi-Modality Brain MRIs 1）数据：我们使用来自 BraTS 2020 挑战赛的开源多模态 MRI 数据集 [29]、[36] [37]。训练集由 369 个多对比 MRI 扫描组成，其中每个扫描包含四种模式，即原生 T1 加权、对比后 T1 加权 (T1Gd)、T2 加权 (T2) 和 T2 流体衰减反转恢复 (FLAIR) ）。\n每次扫描都有相应的 4 类标签：背景（标签 0）、GD 增强肿瘤（ET，标签 4）、瘤周水肿（ED，标签 2）以及坏死和非增强肿瘤核心（NET/ NCR，标签 1)。验证集由 125 个多重对比 MRI 扫描组成，其模式与训练集和隐藏的基本事实相同。所有 MRI 扫描均去除颅骨，与相同的大脑模板 (SRI24) 对齐，并插值至 1mm3 分辨率。验证阶段通过在线门户进行，算法根据 3 个重叠肿瘤区域的性能进行排名，即增强肿瘤 (ET)、肿瘤核心 (ET + NET/NCR) 和整个肿瘤 (ET) + NET/NCR + ED）\n2）实现细节：a）模型设置和损失函数：对于3D分割，由于缺乏开源预训练编码器，所有模型都是从头开始训练的。下采样通过跨步 3 × 3 × 3 填充卷积执行，上采样通过三线性插值实现。为了进一步提高在BraTS数据集上的性能，我们采用基于区域的训练策略（直接在重叠区域而不是独立标签上优化）并增强肿瘤抑制（如果增强肿瘤的预测体积为，则用坏死替换预测的增强肿瘤）小于某个阈值）在训练过程中。对于损失函数，我们采用 Dice Loss [13] 和 Cross Entropy Loss 的线性组合作为网络中二分类和多分类阶段的损失函数。\nb) 训练细节：我们的模型是在 Ubuntu 服务器上使用 PyTorch 1.7.1 框架实现的。由于3D分割的训练，尤其是级联U-Net对显存的要求较高，因此我们使用NVIDIA RTX 2080 Ti GPU和NVIDIA RTX 3090 GPU分别训练单个模型和级联模型。\n由于训练过程的显存占用大于11Gb，我们采用PyTorch框架提供的原生混合精度训练程序来节省显存使用并加速训练过程。人工智能医学开放网络（MONAI）项目[38]和TorchIO[39]分别用于训练和推理阶段的数据加载过程。数据增强是在训练过程中通过 MONAI 项目进行的。\n首先，分别使用 z 分数标准化对所有模态进行标准化。然后通过随机翻转、随机强度偏移、随机强度缩放和弹性变换来增强图像。最后，我们将图像块随机裁剪为 128 × 128 × 128 并将其输入网络。对于推理，我们还采用基于补丁的推理管道来生成 BraTS 2020 验证集的预测。面片大小设置为 128 × 128 × 128，面片之间的重叠设置为 75%。重叠区域中的预测是重叠块的平均值。这种重叠配置可以被视为自集成并产生更好的分割性能。对于模型评估，我们进行了 2 个单独的评估程序来比较分割模型的性能。首先，我们对 BraTS 2020 训练集进行 5 倍交叉验证，以比较离散区域（增强肿瘤、瘤周水肿和非增强肿瘤核心）上的分割性能。然后，我们对 BraTS 2020 验证集进行评估，以比较重叠区域（增强肿瘤、肿瘤核心和整个肿瘤）的分割性能，其中我们可以将所提出的方法与最先进的方法进行比较BraTS 挑战。\n3）定量结果：BraTS 2020 训练集的交叉验证性能已在表 IV 中报告。\n所提出的 PANet 在 Dice 分数和 Hausdorff 距离方面优于所有其他网络。此外，我们还在 BraTS 2020 验证集上对训练后的模型进行了验证。通过这种方式，我们还将所提出的网络与模态配对学习（BraTS 2020 中的 Top-2 解决方案）[35] 和研究中的 Transformer TransBTS [23] 进行了比较，除了基于 U 的常用网络之外-网。\n性能列于表五中。我们提出的 PANet 在 BraTS 2020 验证集上优于 U-Net、Attention U-Net、级联 U-Net 和 TransBTS。此外，所提出的 PANet 在 BraTS 2020 上实现了与 Top2 解决方案类似的 Dice 分数，并且具有更好的 Hausdorff 距离。另外，值得注意的是，与 U-Net 相比，所提出的 PANet 仅增加了 3.9% 的额外 GFlops，并且以更少的计算成本实现了比级联 U-Net 更好的性能。这些结果表明，所提出的先验注意网络在 BraTS 2020 数据集上的分割性能和计算效率之间取得了复杂的平衡。\n4）定性结果：我们可视化具有不同分割难度的 3 幅 MRI 图像，以展示不同模型的性能。对于最简单的情况（BraTS20_Validation_077），所有模型都能够分割病变，而所提出的 PANet 获得最高的分割 Dice 分数。对于有一定难度的病例（BraTS20_Validation_028），Attention U-Net和级联U-Net在水肿分割方面都产生了严重的误报，导致整个肿瘤的Dice评分较低。对于最难的情况（BraTS20_Validation_076），由于增强肿瘤的假阳性分割，U-Net、Attention U-Net 和级联 U-Net 的性能并不乐观，而所提出的 PANet 产生了最好的分割性能。所提出的 PANet 的成功归功于具有中间监督的注意力引导解码器，特征图通过空间注意力图进行细化，这可以防止潜在的误报预测。\n关于医学影像中的轴位面（横断面）、冠状面、矢状面的解释\n1.冠状面 （Coronal），又称额状面。即从左右方向，沿人体的长轴将人体纵切为前、后两部分的切面。这种提法只是为了在临床中将器官位置描述的更具体，英文名称是：Coronal section；\n2.矢状面 (Sagittal)就是把人体分成左右两面的解剖面，于这个面平行的也是矢状面。出于这个位置的叫矢状位。矢状位的英文名称是：Median sagittal section；\n3.水平位 (Axial)又称横断位，即左右、前后构成的面为水平位，英文名称是:Transverse section。\n5）消融分析：在 BraTS 2020 验证数据集上也进行了与 2D 分割类似的消融实验，以评估我们模型中呈现的组件的有效性，如表六所示。\na）具有深度监督的多类解码器的有效性：我们通过向网络解码器引入深度监督来构建实验2（U-Net + DS）。与基线（No.1）相比，实验No.2在增强肿瘤、肿瘤核心和整个肿瘤的分割性能方面提供了一定程度的性能提升。此外，当引入注意力引导解码器时，可以观察到性能的提高（第3和第6）。\nb) 注意力引导解码器的有效性：我们构建实验 3（U-Net + AGD w/o IS）来研究所提出的网络中注意力引导解码器的有效性。与基线相比，注意力引导解码器在增强肿瘤和肿瘤核心的分割性能方面产生了显着的改善。这表明注意力引导解码器对从编码器提取的特征图产生有效的注意力，从而更容易区分病变。\nc）参数化跳跃连接的有效性：我们建立了两个实验No.4（U-Net + AGD*）和No.5（UNet + AGD）来探索所提出的参数化跳跃连接的有效性。引入参数化跳跃连接后，在增强肿瘤和肿瘤核心方面分割性能有所提高，但整个肿瘤的分割性能略有下降。\nd）中间监督的有效性：我们通过比较表六中的第3号和第5号来调查中间监督策略的有效性。在No.5（U-Net + AGD）中，通过引入中间监督，增强肿瘤和肿瘤核心的Dice得分显着提高。但是当引入深度监督时，中间监督的性能提升并不像以前那么显着（第6和第7），这与2D分割情况类似。\nDISCUSSION AND CONCLUSION 多病灶分割在临床场景中具有重要意义，因为某种疾病可能同时发生多种类型的感染，不同感染阶段的患者可能会出现不同类型的病灶。例如，磨玻璃样混浊（GGO）和实变（CON.）是COVID-19患者典型的肺部病变，前者通常发生在早期患者，而后者的增加可能表明病情恶化。胶质瘤可分为低级别胶质瘤（LGG）和胶质母细胞瘤，即高级别胶质瘤（GBM/HGG），并且在发生HGG的患者中更有可能发现强化肿瘤。因此，多病灶分割在患者的筛查和预后方面具有巨大的潜力。\n多病灶分割问题可以分解为粗分割和细分割，粗分割是对病灶进行粗略分割，而细分割则基于前一分割，以产生最终的分割图。级联网络广泛用于多病变分割任务，因为这些算法背后的逻辑非常自然。然而，级联网络在潜在的临床部署中受到限制，因为它们缺乏灵活性并且对计算资源的要求很高。与现有的级联网络相比，我们开发了一种先验注意网络，它将粗分割和细分割集成到一个网络中。我们提出的网络架构的优点是分割性能和计算效率的平衡。通过将分割的两个步骤结合在一个网络中，所提出的先验注意网络能够实现多病灶分割的端到端训练，在训练和推理方面都具有更大的灵活性，并且在临床部署中具有更大的潜力。此外，我们设法保持所提出的先验注意网络的性能，在分割性能和运行效率之间实现复杂的平衡。\n与级联 U-Net 相比，我们提出的先验注意力网络在 2D 和 3D 任务中都实现了更好的性能和效率，如图 6 所示。\n总之，我们提出了一种新颖的分割网络，即先验注意网络，用于医学图像中的多病灶分割。受流行的从粗到细策略的启发，我们通过空间注意机制将级联网络的两个步骤聚合成一个网络。此外，我们引入了一种新颖的中间监督机制来指导与病变相关的注意图的生成，这可以指导解码器中的后续多类分割。所提出的网络在 2D 和 3D 医学图像（包括 CT 扫描和多模态 MRI）上进行评估。对于 2D 分割，与级联 U-Net 相比，所提出的先验注意力网络以更少的计算成本获得了有竞争力的结果。对于 3D 脑肿瘤分割，所提出的先验注意网络在 BraTS 2020 验证数据集上产生了最先进的性能，并且优于基于 U-Net 的其他基线方法。实验结果表明，该方法在医学影像中的许多多病灶分割任务中具有巨大的应用潜力，与二元分割相比可以提供更多信息，并有助于医生未来的临床诊断。\n","permalink":"https://swimmingliu.cn/posts/papernotes/2022-priorattentionnetwork/","summary":"\u003ch1 id=\"prior-attention-network-用于医学图像中多病灶分割的预先注意网络\"\u003ePrior Attention Network: 用于医学图像中多病灶分割的预先注意网络\u003c/h1\u003e\n\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e医学图像中邻近组织的多种类型病变的准确分割在临床实践中具有重要意义。基于从\u003cstrong\u003e粗到精策略的卷积神经网络（CNN）\u003cstrong\u003e已广泛应用于该领域。然而，由于\u003c/strong\u003e组织的大小、对比度和高类间相似性的不确定性\u003c/strong\u003e，多病灶分割仍然具有挑战性。此外，\u003cstrong\u003e普遍采用的级联策略\u003c/strong\u003e对\u003cstrong\u003e硬件要求较高\u003c/strong\u003e，限制了临床部署的潜力。为了解决上述问题，我们提出了一种新颖的先验注意网络（PANet），它\u003cstrong\u003e遵循从粗到细的策略\u003c/strong\u003e来在医学图像中执行多病灶分割。所提出的网络通过在网络中\u003cstrong\u003e插入与病变相关的空间注意机制\u003c/strong\u003e，在单个网络中实现了\u003cstrong\u003e两个步骤的分割\u003c/strong\u003e。此外，我们还提出了\u003cstrong\u003e中间监督策略\u003c/strong\u003e，用于\u003cstrong\u003e生成与病变相关的注意力\u003c/strong\u003e来获取\u003cstrong\u003e感兴趣区域（ROI）\u003c/strong\u003e，这加速了收敛并明显提高了分割性能。我们在两个应用中研究了所提出的分割框架：\u003cstrong\u003e肺部 CT 切片\u003c/strong\u003e中多发性\u003cstrong\u003e肺部感染的 2D 分割\u003c/strong\u003e和\u003cstrong\u003e脑 MRI 中多发性病变的 3D 分割\u003c/strong\u003e。实验结果表明，与级联网络相比，在 2D 和 3D 分割任务中，我们提出的网络以更少的计算成本实现了更好的性能。所提出的网络可以被视为 2D 和 3D 任务中多病灶分割的通用解决方案。源代码可在 \u003ca href=\"https://github.com/hsiangyuzhao/PANet\"\u003ehttps://github.com/hsiangyuzhao/PANet\u003c/a\u003e 获取\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e问题导向：\u003c/p\u003e\n\u003cp\u003e①\u003cstrong\u003e组织的大小、对比度和高类间相似性的不确定性\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e②多类别病灶分割\u003c/p\u003e\n\u003cp\u003e③\u003cstrong\u003e普遍采用的级联策略\u003c/strong\u003e对\u003cstrong\u003e硬件要求较高\u003c/strong\u003e\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e医学图像分割对于疾病的准确筛查和患者的预后具有重要意义。基于病灶分割的病灶评估提供了疾病进展的信息，帮助医生提高临床诊断和治疗的质量。然而，手动病变分割相当主观且费力，这限制了其潜在的临床应用。近年来，随着人工智能的快速发展，基于深度学习的算法得到了广泛的应用，并在医学图像分割方面取得了最先进的性能[1]\u003c/strong\u003e。卷积神经网络（CNN）由于其高分割质量而在医学图像中的病变分割中很受欢迎。此类算法通常具有\u003cstrong\u003e深度编码器\u003c/strong\u003e，可从输入图像中自动提取特征，并通过以下操作\u003cstrong\u003e生成密集预测\u003c/strong\u003e。例如，Long等人[2]提出了一种用于图像语义分割的全卷积网络，该网络颇具影响力，并启发了后来的医学分割中的端到端框架。 Ronneberger等人[3]提出了一种用于医学图像分割的U形网络（U-Net），该网络在医学分割的许多领域都显示出了可喜的结果，并已成为许多医学分割任务的虚拟基准。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e这一段都可以当成经典医学图像分割的背景引入\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e然而，尽管医学分割取得了这些突破，但目前的\u003cstrong\u003e医学分割方法主要集中在病灶的二元分割上\u003c/strong\u003e，即\u003cstrong\u003e区分病灶（前景）和其他一切（背景）\u003c/strong\u003e。尽管二元分割确实有助于\u003cstrong\u003e隔离某些感兴趣区域\u003c/strong\u003e并允许对\u003cstrong\u003e医学图像进行精确分析\u003c/strong\u003e，但在某些需要\u003cstrong\u003e对病变进行多类分割的场景中，二元分割还不够\u003c/strong\u003e。与二元分割相比，由于\u003cstrong\u003e组织的类间相似性，这种情况要困难得多\u003c/strong\u003e，因为\u003cstrong\u003e不同类型的病变在纹理、大小和形状上可能相似\u003c/strong\u003e。具有从粗到细策略的级联网络已广泛应用于此类场景，例如\u003cstrong\u003e肝脏和病变的分割、脑肿瘤分割\u003c/strong\u003e[4]、[5][6]、[7]。\u003c/p\u003e\n\u003cp\u003e此类网络通常由两个独立的网络组成，其中第一个\u003cstrong\u003e网络执行粗分割，第二个网络基于从第一个网络分割的 ROI 细化分割\u003c/strong\u003e。然而，尽管\u003cstrong\u003e级联网络\u003c/strong\u003e已广泛应用于医学图像的\u003cstrong\u003e多病灶分割\u003c/strong\u003e，但级联策略也有其缺点。由于\u003cstrong\u003e级联网络由两个独立的网络组成\u003c/strong\u003e，\u003cstrong\u003e参数量和显存占用通常是单个网络的两倍\u003c/strong\u003e，这对硬件要求较高，限制了其在临床使用的潜力。更重要的是，由于级联网络中的两个网络通常是独立的，因此\u003cstrong\u003e级联网络的训练过程有时比单个网络更困难\u003c/strong\u003e，这可能导致欠拟合。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e级联网络：参数量大、容易欠拟合。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e在本文中，我们提出了一种名为先验注意网络（PANet）的新型网络结构，用于在医学图像中执行\u003cstrong\u003e多病灶分割\u003c/strong\u003e。所提出的网络由\u003cstrong\u003e一个\u003c/strong\u003e用于\u003cstrong\u003e特征提取的编码器\u003c/strong\u003e和\u003cstrong\u003e两个分别生成病变区域注意力和最终预测的解码器组成\u003c/strong\u003e。该网络与\u003cstrong\u003e注意力机制\u003c/strong\u003e结合在一起。为了\u003cstrong\u003e减少参数大小和硬件\u003c/strong\u003e占用，我们使用\u003cstrong\u003e网络编码器的深层、语义丰富的特征\u003c/strong\u003e来\u003cstrong\u003e生成病变区域的空间注意力\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e然后，\u003cstrong\u003e编码器生成的特征\u003c/strong\u003e表示通过\u003cstrong\u003e空间注意力\u003c/strong\u003e进行细化，并将其发送到解码器以进行\u003cstrong\u003e最终的多类预测\u003c/strong\u003e。为了\u003cstrong\u003e提高分割性能并加速收敛\u003c/strong\u003e，我们还在网络结构中引入了\u003cstrong\u003e中间监督和深度监督\u003c/strong\u003e。通过这些改进，与传统的级联网络相比，所提出的网络以\u003cstrong\u003e显着降低的参数大小和计算成本\u003c/strong\u003e实现了有竞争力的结果。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e利用网络编码器的深层、特征信息来生成空间注意力（WTF ???）\u003c/p\u003e\n\u003cp\u003e中间监督、深度监督 （不错不错， 好多一区和顶会的文章都用深度监督）\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e这项工作的贡献体现在三个方面。\u003cstrong\u003e首先\u003c/strong\u003e，我们提出了一种新颖的网络架构，通过将传统级联网络中的两个分割步骤结合在\u003cstrong\u003e单个网络\u003c/strong\u003e中，遵循 2D 和 3D 医学图像中多病灶分割的\u003cstrong\u003e从粗到细的策略\u003c/strong\u003e。与级联网络相比，所提出的架构以更少的额外计算成本实现了有竞争力的分割性能，更容易训练和部署到生产环境。\u003cstrong\u003e其次\u003c/strong\u003e，我们提出了一种\u003cstrong\u003e监督空间注意力机制\u003c/strong\u003e，将\u003cstrong\u003e病变区域的注意力与网络提取的特征相结合\u003c/strong\u003e，将多病变分割分解为\u003cstrong\u003e两个更容易的阶段\u003c/strong\u003e，并且与当前\u003cstrong\u003e基于注意力的方法相比具有更好的可解释性\u003c/strong\u003e。\u003cstrong\u003e第三\u003c/strong\u003e，所提出的网络已在两个实际应用中得到验证，\u003cstrong\u003e包括肺部 CT 切片中的 COVID-19 病变的 2D 分割和多模态 MRI 中的脑肿瘤的 3D 分割\u003c/strong\u003e。所提出的网络在 2D 和 3D 任务中都优于前沿方法，并且在参数和计算成本方面比当前网络更高效。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e一个网络、监督空间注意力机制、参数和计算成本方面比当前网络更高效。\u003c/p\u003e\n\u003ch2 id=\"related-work\"\u003eRelated Work\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e1）图像分割的网络结构：用于图像分割的典型卷积神经网络通常由一个卷积特征提取器组成，其拓扑类似于常见的分类网络，自动从输入图像中提取特征，并进行基于卷积的操作以生成最终的密集预测。在自然图像分割领域，FCN [2]、DeepLab [8]、PSPNet [9] 和 SegNet [10] 因其性能和效率而颇受欢迎。对于医学分割，U-Net [3] 在许多任务中相当流行，并且已被修改为许多改进版本，例如 Attention U-Net [11]、U-Net++ [12]、V-Net [13] 和H-DenseUNet [14]在某些领域获得更好的性能。\u003c/p\u003e","title":"Prior Attention Network: 用于医学图像中多病灶分割的预先注意网络"},{"content":"地大服务器使用教程 1. 服务器环境介绍 NVIDIA RTX 3090 (24GB) NVIDIA RTX 2080 Ti (11GB) 2. 配置实验环境 2.1 Conda环境安装 每位同学都会分配个人用户，大家在自己的用户上使用Conda进行环境配置。\nConda安装教程：https://blog.csdn.net/JineD/article/details/129507719\n大家按照教程步骤安装即可, 由于安装时间较长, 视频中暂不进行演示。\n2.2 Conda环境配置 （以YOLOv8为例） # 创建conda环境 名为yolov8_lyj python版本为3.9 conda create -n yolov8_lyj python=3.9 # 激活环境 conda activate yolov8_lyj # 选择合适的路径，克隆github项目代码 git clone https://github.com/ultralytics/ultralytics # 进入到项目路径下 cd ultralytics/ # 安装相关依赖包 pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple 2.3 准备数据集 下载需要训练的数据集 （最好找顶刊/顶会论文中的公开数据集）\n按照算法指定的数据集格式，对数据集格式进行调整。\n​\t目标检测中数据集格式之间的相互转换：（VOC、COCO、YOLO格式）\n​\thttps://zhuanlan.zhihu.com/p/461488682\n2.4 开始实验 在算法中指定数据集的存放路径 （相对/绝对路径均可）\n初始化算法的参数\nbatch-size 批处理大小：每一次处理图片的个数，根据显卡内存进行调整\repochs\t迭代次数：算法总共需要训练的轮次\rworkers 载入数据进程数：每一次调用多少个进程来载入数据\rdevice 选择显卡设备： \u0026#39;0\u0026#39;使用3090，\u0026#39;1\u0026#39;使用2080ti，\u0026#39;0,1\u0026#39;使用两张卡 开始训练 # 运行训练代码 python mian.py (注：使用向日葵的同学，可以直接在Pycharm当中运行)\n3. 注意事项 1. 查看显卡使用情况 两种办法：\n# 第一种 使用nivida驱动直接查看\rnvidia-smi\r# 第二种 使用第三方库 gpustat动态查看\r# 先安装第三方库\rpip install gpustat -i https://pypi.tuna.tsinghua.edu.cn/simple\r# 每两秒刷新一次 动态查看显存使用情况\rwatch -n2 gpustat 2. Magic Network 使用向日葵的同学，可以使用Magic Network进行github仓库克隆、google网盘数据集下载等\n使用方法：\nexport http_proxy=http://127.0.0.1:7890\rexport https_proxy=http://127.0.0.1:7890 预祝大家科研顺利，硕果累累，offer拿到手软！！！\n博客地址： SwimmingLiu.cn\n","permalink":"https://swimmingliu.cn/posts/diary/2023-%E5%9C%B0%E5%A4%A7%E6%9C%8D%E5%8A%A1%E5%99%A8/","summary":"\u003ch1 id=\"地大服务器使用教程\"\u003e地大服务器使用教程\u003c/h1\u003e\n\u003ch2 id=\"1-服务器环境介绍\"\u003e1. 服务器环境介绍\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eNVIDIA RTX \u003cspan class=\"m\"\u003e3090\u003c/span\u003e \u003cspan class=\"o\"\u003e(\u003c/span\u003e24GB\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eNVIDIA RTX \u003cspan class=\"m\"\u003e2080\u003c/span\u003e Ti \u003cspan class=\"o\"\u003e(\u003c/span\u003e11GB\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cimg alt=\"image-20231120113601423\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/HoBnO.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"2-配置实验环境\"\u003e2. 配置实验环境\u003c/h2\u003e\n\u003ch3 id=\"21-conda环境安装\"\u003e2.1 Conda环境安装\u003c/h3\u003e\n\u003cp\u003e每位同学都会分配个人用户，大家在自己的用户上使用Conda进行环境配置。\u003c/p\u003e\n\u003cp\u003eConda安装教程：https://blog.csdn.net/JineD/article/details/129507719\u003c/p\u003e\n\u003cp\u003e大家按照教程步骤安装即可, 由于安装时间较长, 视频中暂不进行演示。\u003c/p\u003e\n\u003ch3 id=\"22-conda环境配置-以yolov8为例\"\u003e2.2 Conda环境配置 （以YOLOv8为例）\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 创建conda环境 名为yolov8_lyj python版本为3.9\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003econda create -n yolov8_lyj \u003cspan class=\"nv\"\u003epython\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e3.9\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 激活环境\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003econda activate yolov8_lyj\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 选择合适的路径，克隆github项目代码\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003egit clone https://github.com/ultralytics/ultralytics\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 进入到项目路径下\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003ecd\u003c/span\u003e ultralytics/\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 安装相关依赖包\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003epip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"23-准备数据集\"\u003e2.3 准备数据集\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e下载需要训练的数据集 （最好找顶刊/顶会论文中的公开数据集）\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e按照算法指定的数据集格式，对数据集格式进行调整。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e​\t\t目标检测中数据集格式之间的相互转换：（VOC、COCO、YOLO格式）\u003c/p\u003e\n\u003cp\u003e​\t\thttps://zhuanlan.zhihu.com/p/461488682\u003c/p\u003e\n\u003ch3 id=\"24-开始实验\"\u003e2.4 开始实验\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e在算法中指定数据集的存放路径 （相对/绝对路径均可）\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e初始化算法的参数\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ebatch-size  批处理大小：每一次处理图片的个数，根据显卡内存进行调整\r\nepochs\t   迭代次数：算法总共需要训练的轮次\r\nworkers     载入数据进程数：每一次调用多少个进程来载入数据\r\ndevice      选择显卡设备： \u0026#39;0\u0026#39;使用3090，\u0026#39;1\u0026#39;使用2080ti，\u0026#39;0,1\u0026#39;使用两张卡\n\u003c/code\u003e\u003c/pre\u003e\u003col start=\"3\"\u003e\n\u003cli\u003e开始训练\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 运行训练代码\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003epython mian.py\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e(注：使用向日葵的同学，可以直接在Pycharm当中运行)\u003c/p\u003e","title":"地大服务器使用教程"},{"content":"ACC-UNet: A Completely Convolutional UNet model for the 2020s (MICCAI2023) 1. Abstract 由于ViT （Vision Transformer）的引入，UNet和Transformer融合已成为大趋势。最近，又有很多研究人员开始重新思考卷积模型，比如将ConvNext嵌入到ResNet，能够达到Swin Transformer的水平。受此启发，作者提出了一个纯粹的卷积UNET模型 （ACC-UNet），并且超越基于Transfomer的模型(如Swin-UNET或UCTransNet)。 作者研究了基于Transfomer的UNET模型优点：长范围依赖关系和跨级别跳过连接。 ACC-UNet结合了卷积神经网络（ConvNets）的内在归纳偏差和Transformer的设计决策 卷积神经网络（ConvNets）的内在归纳偏差：卷积神经网络具有天生的归纳偏差，这意味着它们在处理图像等数据时具有一些固有的假设和特点。例如，卷积神经网络擅长处理局部特征、平移不变性等，这些特点使它们在图像处理任务中表现出色。 Transformer的设计决策：Transformer是一种不同的神经网络架构，它采用了一些独特的设计决策，例如自注意力机制和位置编码等。这些设计决策使得Transformer在处理长距离依赖性、全局关系等方面表现出色，适合处理序列数据和具有远程依赖的任务。 ACC-UNet 在 5 个不同的医学图像分割基准上进行了评估，并且始终优于卷积网络、Transfomer及其混合网络。\n2.Introduction 语义分割是计算机辅助医学图像分析的重要组成部分，可识别并突出显示各种诊断任务中感兴趣的区域。然而，由于涉及图像模态和采集以及病理和生物变化的各种因素，这通常变得复杂[18]。深度学习在这一领域的应用无疑在这方面受益匪浅。最值得注意的是，自推出以来，UNet 模型 [19] 在医学图像分割方面表现出了惊人的功效。结果，UNet 及其衍生品已成为事实上的标准[25]。\n学习一下这里的背景描述\n原始的 UNet 模型包含对称的编码器-解码器架构（图 1a）并采用跳跃连接，这为解码器提供了在编码器的池化操作期间可能丢失的空间信息。尽管通过简单串联的信息传播提高了性能，但编码器-解码器特征图之间可能存在语义差距。这导致了第二类 UNet 的发展（图 1b）。 U-Net++ [26] 利用密集连接，而 MultiResUNet [11] 在跳过连接上添加了额外的卷积块作为潜在的补救措施。到目前为止，UNet 的历史上所有创新都是使用 CNN 进行的。然而，2020 年的十年给计算机视觉领域带来了根本性的变化。 CNN 在视觉领域的长期主导地位被视觉转换器打破了 [7]。 Swin Transformers [15] 进一步针对一般视觉应用调整了变压器。因此，UNet 模型开始采用 Transformer [5]。 Swin-Unet [9] 用 Swin Transformer 块取代了卷积块，从而开创了一类新的模型（图 1c）。尽管如此，CNN 在图像分割方面仍然具有各种优点，导致了融合这两者的发展[2]。这种混合类 UNet 模型（图 1d）在编码器-解码器中采用卷积块，并沿跳跃连接使用变换器层。 UCTransNet [22]和MCTrans[24]是此类的两个代表性模型。最后，还尝试开发全变压器 UNet 架构（图 1e），例如，SMESwin Unet [27] 在编码器-解码器块和跳跃连接中都使用变压器。\n从 UNet出发，然后逐步介绍他的变体（UNet++等）。随后介绍Transformer和UNet的各种结合体，为后续对比实验做铺垫。最后结合一张发展图，简明扼要描述UNet的创新历程。\n最近，鉴于 Transformer 带来的进步，研究开始重新发现 CNN 的潜力。这方面的开创性工作是“A ConvNet for the 2020s”[16]，它探讨了 Transformer 引入的各种想法及其在卷积网络中的适用性。通过逐渐融合训练协议和微观-宏观设计选择的思想，这项工作使 ResNet 模型的性能优于 Swin Transformer 模型。\n在本文中，我们在 UNet 模型的背景下提出了同样的问题。我们研究仅基于卷积的 UNet 模型是否可以与基于 Transformer 的 UNet 竞争。在此过程中，我们从 Transformer 架构中获得动力并开发了纯卷积 UNet 模型。我们提出了一种基于补丁的上下文聚合，与基于窗口的自注意力相反。此外，我们通过融合来自多个级别编码器的特征图来创新跳跃连接。对 5 个基准数据集的广泛实验表明，我们提出的修改有可能改进 UNet 模型。\n通过介绍CONvNet的重要性，引入本文重点 （纯卷积模块的UNet）。\n3. Method 3.1 A high-level view of transformers in UNet Transformers 显然在两个不同方面改进了 UNet 模型:\n1.利用自注意力的远程依赖性: Transformer 可以通过使用（窗口式）自注意力，从更大的上下文视图中计算特征。此外，他们还通过采用反向瓶颈（即增加 MLP 层中的神经元）来提高表达能力。此外，它们包含快捷连接，这有助于学习。 2.通过通道注意力的自适应多级特征组合: 基于 Transformer 的 UNet 使用通道注意力自适应地融合来自多个编码器级别的特征图。与受当前级别信息限制的简单跳跃连接相比，由于来自不同级别的各种感兴趣区域的组合，这会生成丰富的特征。\n主要就两个点：\n自主注意力在UNet的编码和解码阶段都能够快速、准确地根据上下文信息提取特征。\n自注意力机制可以用来连接encoder阶段不同stage的特征图。\n猜想：把新出的自注意力机制加在ACC-Unet是不是也会有提升呢？\n3.2 Hierarchical Aggregation of Neighborhood Context (HANC) 我们首先探索引入远程依赖性并提高卷积块的表达能力的可能性。我们仅使用逐点和深度卷积来降低计算复杂度。为了增加表达能力，我们建议在卷积块中包含反向瓶颈[16]，这可以通过使用逐点卷积将通道数从 cin 增加到 cinv = cin * inv_f ctr 来实现。由于这些额外的通道会增加模型复杂度，因此我们使用3×3深度卷积来补偿。输入特征图 xin ∈ R cin,n,m 被转换为 x1 ∈ R cinv,n,m （图 2b）\n接下来，我们希望在卷积块中模拟自注意力，其核心是将一个像素与其邻域中的其他像素进行比较[15]。通过将像素值与其邻域的平均值和最大值进行比较可以简化这种比较。因此，我们可以通过附加相邻像素特征的平均值和最大值来提供邻域比较的近似概念。因此，连续逐点卷积可以考虑这些并捕获对比视图。\n由于分层分析对图像有益[23]，我们不是在单个大窗口中计算这种聚合，而是在多个级别中分层计算，例如 2 × 2, 2 ^2 × 2^ 2 , · · · , 2^(k− 1) × 2^(k−1) 个补丁。当 k = 1 时，这将是普通的卷积运算，但是当我们增加 k 的值时，将提供更多的上下文信息，从而绕过对更大卷积核的需要。因此，我们提出的分层邻域上下文聚合通过上下文信息丰富了特征图 x1 ∈ R cinv,n,m 作为 x2 ∈ R cinv*(2k−1),n,m （图 2b），其中 ||对应于沿通道维度的串联。\n下面与Transfomer类似，我们在卷积块中包含一个快捷连接，以实现更好的梯度传播。因此，我们执行另一个逐点卷积以减少 cin 的通道数并与输入特征图相加。因此，x2 ∈ R cinv*(2k−1),n,m 变为 x3 ∈ R cin,n,m （图 2b）\n最后，我们使用逐点卷积将滤波器的数量更改为cout作为输出\n\u0026ldquo;inverted bottlenecks\u0026rdquo;（反向瓶颈） ：将Bottleneck放在卷积块的开始，而不是结束。它先使用1x1卷积来减少通道数，然后才是较大的卷积层。\n3.3 Multi Level Feature Compilation (MLFC) 接下来，我们研究多级特征组合的可行性，这是使用基于 Transformer 的 UNet 的另一个优点。\n基于 Transformer 的跳跃连接已经证明了所有编码器级别的有效特征融合以及各个解码器从编译的特征图中进行的适当过滤[24,22,27]。这是通过连接不同级别的投影令牌来执行的[22]。按照这种方法，我们调整从不同编码器级别获得的卷积特征图的大小，以使它们均衡并连接它们。这为我们提供了跨不同语义级别的特征图的概述。我们应用逐点卷积运算来总结这种表示并与相应的编码器特征图合并。整体信息和个体信息的融合通过另一个卷积传递，我们假设它用来自其他级别特征的信息丰富了当前级别特征。\n对于来自 4 个不同级别的特征 x1、x2、x3、x4，特征图可以通过多级信息来丰富（图 2d）\n这里， resizei(xj ) 是将 xj 的大小调整为 xi 的大小且 ctot = c1 + c2 + c3 + c4 的操作。此操作针对所有不同级别单独完成。因此，我们提出了另一个名为多级特征编译（MLFC）的新颖块，它聚合来自多个编码器级别的信息并丰富各个编码器特征图。该块如图 2d 所示。\n总结： 把各stage的特征联合起来进行逐点卷积，然后各stage得到新的特征信息\n3.4 ACC-UNet 因此，我们提出全卷积ACC-UNet（图2a）。我们从普通的 UNet 模型开始，并将滤波器的数量减少了一半。然后，我们用我们提出的 HANC 块替换了编码器和解码器中的卷积块。我们考虑 inv_f ctr = 3，而不是第 3 级的最后一个解码器块 (inv_f ctr = 34)，以模拟 Swin Transformer 第 3 阶段的扩展。 k = 3，最多考虑 4 × 4 个补丁，被选择用于除瓶颈级别 (k = 1) 及其旁边的级别 (k = 2) 之外的所有级别。接下来，我们通过使用残差块（图 2c）来修改跳跃连接以减少语义间隙 [11] 并堆叠 3 个 MLFC 块。所有卷积层均经过批量归一化 [12]，由 Leaky-RELU [17] 激活，并通过挤压和激励 [10] 重新校准。\n总而言之，在 UNet 模型中，我们用我们提出的 HANC 块替换了经典的卷积块，该 HANC 块执行近似版本的自注意力，并修改了与 MLFC 块的跳跃连接，MLFC 块考虑来自不同编码器级别的特征图。所提出的模型有 16.77 M 个参数，比普通 UNet 模型大约增加了 2M。\n4.Experiments 4.1 Datasets 为了评估 ACC-UNet，我们在 5 个跨不同任务和模式的公共数据集上进行了实验。我们使用 ISIC-2018 [6,21]（皮肤镜检查，2594 张图像）、BUSI [3]（乳腺超声，使用类似于 [13] 的 437 张良性图像和 210 张恶性图像）、CVC-ClinicDB [4]（结肠镜检查，612 张图像） ）、COVID [1]（肺炎病灶分割，100 张图像）和 GlaS [20]（腺体分割，85 张训练图像和 80 张测试图像）。所有图像和掩模的大小都调整为224×224。对于GlaS数据集，我们将原始测试分割作为测试数据，对于其他数据集，我们随机选择20％的图像作为测试数据。\n剩余的 60% 和 20% 图像用于训练和验证，并使用不同的随机改组重复实验 3 次。\nISIC-2018、BUSI、 CVC-ClinicDB、COVID、GlaS 五个数据集\n4.2 Comparison Experiments 4.3 Ablation Study 4.4 Qualitative Results ","permalink":"https://swimmingliu.cn/posts/papernotes/2023-acc-unet/","summary":"\u003ch1 id=\"acc-unet-a-completely-convolutional-unet-model-for-the-2020s-miccai2023\"\u003eACC-UNet: A Completely Convolutional UNet model for the 2020s (MICCAI2023)\u003c/h1\u003e\n\u003ch2 id=\"1-abstract\"\u003e1. Abstract\u003c/h2\u003e\n\u003cp\u003e由于ViT （Vision Transformer）的引入，UNet和Transformer融合已成为大趋势。最近，又有很多研究人员开始重新思考卷积模型，比如将ConvNext嵌入到ResNet，能够达到Swin Transformer的水平。受此启发，作者提出了一个纯粹的卷积UNET模型 （ACC-UNet），并且超越基于Transfomer的模型(如Swin-UNET或UCTransNet)。\n作者研究了基于Transfomer的UNET模型优点：长范围依赖关系和跨级别跳过连接。\nACC-UNet结合了\u003cstrong\u003e卷积神经网络（ConvNets）的内在归纳偏差\u003c/strong\u003e和\u003cstrong\u003eTransformer的设计决策\u003c/strong\u003e\n\u003cstrong\u003e卷积神经网络（ConvNets）的内在归纳偏差\u003c/strong\u003e：卷积神经网络具有天生的归纳偏差，这意味着它们在处理图像等数据时具有一些固有的假设和特点。例如，卷积神经网络擅长处理局部特征、平移不变性等，这些特点使它们在图像处理任务中表现出色。\n\u003cstrong\u003eTransformer的设计决策\u003c/strong\u003e：Transformer是一种不同的神经网络架构，它采用了一些独特的设计决策，例如自注意力机制和位置编码等。这些设计决策使得Transformer在处理长距离依赖性、全局关系等方面表现出色，适合处理序列数据和具有远程依赖的任务。\nACC-UNet 在 5 个不同的医学图像分割基准上进行了评估，并且始终优于卷积网络、Transfomer及其混合网络。\u003c/p\u003e\n\u003ch2 id=\"2introduction\"\u003e2.Introduction\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e语义分割是计算机辅助医学图像分析的重要组成部分，可识别并突出显示各种诊断任务中感兴趣的区域。然而，由于涉及图像模态和采集以及病理和生物变化的各种因素，这通常变得复杂[18]。深度学习在这一领域的应用无疑在这方面受益匪浅。最值得注意的是，自推出以来，UNet 模型 [19] 在医学图像分割方面表现出了惊人的功效。结果，UNet 及其衍生品已成为事实上的标准[25]。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e学习一下这里的背景描述\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e原始的 UNet 模型包含对称的编码器-解码器架构（图 1a）并采用跳跃连接，这为解码器提供了在编码器的池化操作期间可能丢失的空间信息。尽管通过简单串联的信息传播提高了性能，但编码器-解码器特征图之间可能存在语义差距。这导致了第二类 UNet 的发展（图 1b）。 U-Net++ [26] 利用密集连接，而 MultiResUNet [11] 在跳过连接上添加了额外的卷积块作为潜在的补救措施。到目前为止，UNet 的历史上所有创新都是使用 CNN 进行的。然而，2020 年的十年给计算机视觉领域带来了根本性的变化。 CNN 在视觉领域的长期主导地位被视觉转换器打破了 [7]。 Swin Transformers [15] 进一步针对一般视觉应用调整了变压器。因此，UNet 模型开始采用 Transformer [5]。 Swin-Unet [9] 用 Swin Transformer 块取代了卷积块，从而开创了一类新的模型（图 1c）。尽管如此，CNN 在图像分割方面仍然具有各种优点，导致了融合这两者的发展[2]。这种混合类 UNet 模型（图 1d）在编码器-解码器中采用卷积块，并沿跳跃连接使用变换器层。 UCTransNet [22]和MCTrans[24]是此类的两个代表性模型。最后，还尝试开发全变压器 UNet 架构（图 1e），例如，SMESwin Unet [27] 在编码器-解码器块和跳跃连接中都使用变压器。\u003c/p\u003e","title":"ACC-UNet: A Completely Convolutional UNet model for the 2020s (MICCAI2023)"},{"content":"(2023) M2SNet: 新颖多尺度模块 + 智能损失函数 = 通用图像分割SOTA网络 Abstract 准确的医学图像分割对于早期医学诊断至关重要。大多数现有方法基于U形结构，并使用逐元素加法或串联在解码器中逐步融合不同级别的特征。然而，这两种操作都容易产生大量冗余信息，从而削弱不同级别特征之间的互补性，导致病灶定位不准确和边缘模糊。为了应对这一挑战，我们提出了一种通用的多尺度减法网络（M2SNet）来完成医学图像的多样化分割。具体来说，我们首先设计一个基本减法单元（SU）来产生编码器中相邻级别之间的差异特征。接下来，我们将单尺度 SU 扩展到层内多尺度 SU，它可以为解码器提供像素级和结构级差异信息。\n然后，我们金字塔式地为不同层次的多尺度SU配备不同的感受野，从而实现层间多尺度特征聚合并获得丰富的多尺度差异信息。此外，我们构建了一个免训练网络“LossNet”来全面监督从底层到顶层的任务感知特征，这驱动我们的多尺度减法网络同时捕获细节和结构线索。\n没有花里胡哨的东西，我们的方法在不同的评估指标下，在不同图像模态的四种不同医学图像分割任务的 11 个数据集上表现优于大多数最先进的方法，包括彩色结肠镜成像、超声成像、计算机断层扫描 (CT) ）和光学相干断层扫描（OCT）。\n两个主要创新点：多尺度金字塔减法单元 （确实牛逼）+ LossNet（为了创新而创新的损失函数）\nIntroduction 作为计算机辅助诊断系统中的重要作用，精确的医学图像分割技术可以为医生做出临床决策提供重要指导。精确分割存在三个普遍的挑战：首先，U形结构[1]、[2]由于其利用多级信息重建高分辨率特征图的能力而受到了相当多的关注。在UNet [2]中，上采样的特征图与从编码器跳过的特征图连接在一起，并在上采样步骤之间添加卷积和非线性，如图1（a）所示。后续基于UNet的方法通过注意力机制[3]、[4]、门机制[5]、[6]、变压器技术[7]、[8]设计不同的特征增强模块，如图1（b）所示。 UNet++[9]使用嵌套和密集的跳跃连接来减少编码器和解码器的特征图之间的语义差距，如图1（c）所示。\n先说医学分割在医学领域重要\u0026hellip;(balabala) 然后当前领域存在xxx挑战\u0026hellip;(balabala)\n这里是以医学图像分割挑战的视角，介绍UNet发展的情况。然后在描述不同UNet变体发展过程中解决的不同问题（感觉可以借鉴）\n一般来说，编码器中不同级别的特征有不同的特征。高级别具有更多的语义信息，有助于定位对象，而低级别具有更详细的信息，可以捕捉对象的微妙边界。解码器利用特定级别和跨级别特征来生成最终的高分辨率预测。然而，上述方法直接使用逐元素加法或串联来融合来自编码器的任意两级特征并将它们传输到解码器。这些简单的操作并没有更多地关注不同层次之间的差异信息。这一缺点不仅会产生冗余信息来稀释真正有用的特征，还会削弱特定于级别的特征的特性，从而导致网络无法平衡精确定位和微妙的边界细化。其次，由于感受野有限，单尺度卷积核很难捕获大小变化物体的上下文信息。一些方法[1]、[2]、[9]-[11]依赖于层间多尺度特征，并逐步整合来自不同尺度表示的语义上下文和纹理细节。其他人[6]、[12]-[15]专注于基于网络中的空洞空间金字塔池化模块[16]（ASPP）或DenseASPP [17]提取层内多尺度信息。然而，类似ASPP的多尺度卷积模块会产生许多额外的参数和计算。许多方法[5]、[18]-[21]通常将多个ASPP模块安装到不同级别的编码器/解码器块中，而有些方法[13]、[14]、[22]、[23]将其安装在不同级别的编码器/解码器块中。最高级别的编码器块。第三，损失函数的形式直接为网络的梯度优化提供了方向。在分割领域，提出了许多损失函数来监督不同级别的预测，例如像素级别的L1损失、交叉熵损失和加权交叉熵损失[24]，SSIM[25]损失区域层面的不确定性损失[26]，全局层面的IoU损失、Dice损失和一致性增强损失[11]。尽管这些基本损失函数及其变体具有不同的优化特性，但复杂的手动数学形式的设计对于许多研究来说确实非常耗时。为了获得综合性能，模型通常会集成多种损失函数，这对研究人员的训练技能提出了很高的要求。因此，我们认为有必要引入一种无需复杂人工设计的智能损失函数来全面监督分割预测。\n在本文中，我们提出了一种用于一般医学图像分割的新型多尺度减法网络（M2SNet）。首先，我们设计一个减法单元（SU）并将其应用于每对相邻的级别特征。 SU突出了特征之间有用的差异信息，并消除了冗余部分的干扰。其次，我们借助所提出的多尺度减法模块收集极端多尺度信息。\n对于层间多尺度信息，我们以金字塔方式连接多个减法单元来捕获大跨度的跨层信息。然后，我们聚合特定于级别的特征和多路径跨级别差分特征，然后在解码器中生成最终预测。对于层内多尺度信息，我们通过一组不同内核大小的full one滤波器将单尺度减法单元改进为多尺度减法单元，可以自然地实现多尺度减法聚合，而无需引入额外的参数。如图1所示，MSNet配备了层间多尺度减法模块，M2SNet同时具有层间和层内多尺度减法结构。第三，我们提出了一个LossNet来自动监督从底层到顶层提取的特征图，它可以通过简单的L2损失函数优化从细节到结构的分割。\n多尺度减法单元可以去特征之间的差异信息，消除冗余干扰。\n（也就是说可以用这种办法替换注意力机制）\nRELATED WORK Medical Image Segmentation Network 根据不同器官或病变的特点，我们将现有的医学图像分割方法分为两类：医学通用的和医学专用的。随着U-Net[2]在医学图像分割领域取得稳定的性能，带有编码器-解码器的U形结构已成为基本的分割基线。 U-Net++[9]集成了长连接和短连接，可以减少编码器和解码器子网络的特征图之间的语义差距。对于注意力 U-Net [28]，注意力门嵌入在编码器和解码器块之间的每个过渡层中，它可以自动学习关注不同形状和大小的目标结构。最近，Transformer [29]架构在许多自然语言处理任务中取得了成功。一些作品[7]、[8]探讨了其对医学视觉任务的有效性。 UTNet [7] 是一种简单但功能强大的混合变压器架构，它在编码器和解码器中应用自注意力模块，以最小的开销捕获不同规模的远程依赖关系。另一个具有代表性的基于 Transformer 的模型是 TransUNet [8]，它通过将图像特征视为序列来编码强全局上下文，并通过 U 形混合架构设计利用低级 CNN 特征。\n医学特定方法。在息肉分割任务中，SFA [30]和PraNet [4]专注于恢复息肉与其周围粘膜之间的清晰边界。前者提出了共享编码器和两个相互约束的解码器下的选择性特征聚合结构和边界敏感损失函数。后者利用反向注意模块来建立区域和边界线索之间的关系。此外，Ji等人[31]利用时空信息构建视频息肉分割模型。在COVID-19肺部感染任务中，Paluru等人[32]提出了一种基于变形深度嵌入的轻量级CNN来分割COVID-19胸部CT图像中的异常。 Inf-Net [33] 构建隐式反向注意力和显式边缘注意力来对边界进行建模。 BCS-Net [34]具有三个渐进边界上下文语义重建块，可以帮助解码器捕获肺部感染的零散区域。在乳腺分割任务中，Byra等人[35]通过注意力机制开发了选择性核来调整U-Net的感受野，可以进一步提高乳腺肿瘤的分割精度。 Chen 等人 [36] 提出了一种嵌套 U 网，通过利用不同的深度和共享权重来实现乳腺肿瘤的稳健表示。\n我们可以看到，医学通用方法通常针对通用挑战（即丰富的特征表示、多尺度信息提取和跨级别特征聚合）。并且，医学特异性方法根据当前器官或病变的特征提出有针对性的解决方案，例如设计一系列注意力机制、边缘增强模块、不确定性估计等。然而，通用医学模型和医学特异性模型都依赖于通过大量的加法或串联操作来实现特征融合，削弱了互补特征之间的特殊性部分。我们提出的多尺度减法模块自然专注于提取差异信息，从而为解码器提供有效的目标特征。\n主要是说大部分特征融合都是用加法/乘法/串联实现的，但是减法可以削弱互补特征之间的特殊性部分。所以多尺度减法模块提取差异信息，然后再用加法进行特征融合。\nMulti-scale Feature Extraction 尺度线索在捕捉对象的上下文信息中发挥着重要作用。受到被广泛验证为有效且理论上合理的框架的尺度空间理论的启发，越来越多的多尺度方法被提出。与单尺度特征相比，多尺度特征有利于解决自然发生的尺度变化。这一特性可以帮助医学分割模型感知不同尺度的病变。根据形式，当前基于多尺度的方法可以大致分为两类，即层间多尺度结构和层内多尺度结构。前者基于特征编码器提取的不同尺度的特征，并在解码器中逐步聚合它们，例如U形[1]、[2]、[4]、[9]-[11]、[37] ，[38]架构。后者通常配备多尺度可插拔模块，如ASPP [16]、DenseASPP [17]、FoldASPP [6]和PAFEM [12]，构建具有不同扩张率的并行多分支卷积层，以获得丰富的组合感受野。与它们不同的是，我们通过同时引入层间和层内多尺度，提出了具有极端多尺度信息的多尺度减法模块中的多尺度。并且，层内多尺度减法单元专注于挖掘从像素到像素到区域到区域的特征对的自差分性质。与单尺度操作相比，整个过程非常高效，不需要额外的参数。\n多尺度减法模块可以超越其他卷积类办法的多尺度特征信息提取办法\nLoss Method 图像分割中的大多数损失函数都是基于交叉熵或重合度量。传统的交叉熵损失对类别信息一视同仁。 Long等人[24]提出了每个类别的加权交叉熵损失（WCE），以抵消数据中的类别不平衡。 Lin等人[39]引入了困难样本和简单样本的权重来提出焦点损失。 Dice loss[40]被提出作为V-Net中重合测量的损失函数，可以有效抑制类别不平衡带来的问题。 Tversky 损失[41]是 Dice 损失的正则化版本，用于控制准确率和召回率对损失函数的贡献。 Wong等人[42]通过Dice损失和WCE损失的加权求和提出指数对数损失（EL Loss）来提高小结构物体的分割精度。\nTaghanaki等人[43]发现单独使用基于重叠的损失函数存在风险，并提出comomoloss将Dice损失作为正则化项与WCE损失相结合来处理输入输出不平衡的问题。\n虽然这些各种各样的损失函数在不同层次上有不同的效果，但手动设计这些复杂的函数确实费时费力。为此，我们提出了自动且全面的分割损失结构，称为LossNet。\nLossNet权重就0.1 （ 感觉这个是为了创新而创新）\nMETHOD Encoder: Res2Net + Connection: MMSB + Decoder: Plus\nMulti-scale in Multi-scale Subtraction Module 我们使用 FA 和 FB 来表示相邻级别的特征图。\n它们都已被 ReLU 操作激活。我们定义一个基本减法单位（SU）：\n其中是逐元素减法运算，然后计算绝对值，Conv(·) 表示卷积层。直接对元素位置特征进行单尺度减法只是为了建立孤立像素级别上的差异关系，没有考虑病灶可能具有区域聚类的特征。与带有单尺度减法单元的MSNet MICCAI版本[27]相比，我们设计了一个强大的层内多尺度减法单元（MSU），并将MSNet改进为M2SNet。如图3所示，我们利用大小为1×1、3×3和5×5的固定全一权重的多尺度卷积滤波器根据像素-像素和区域区域模式计算细节和结构差异值。使用具有固定参数的多尺度滤波器不仅可以直接捕获匹配空间位置处的初始特征对之间的多尺度差异线索，而且可以在不引入额外参数负担的情况下实现高效训练。因此，M2SNet可以保持与MSNet相同的低计算量，并获得更高精度的性能。整个多尺度减法过程可以表述为：\n其中 Filter(·) n×n 表示大小为 n × n 的完整滤波器（卷积）。 MSU可以捕获FA和FB的互补信息，并突出它们从纹理到结构的差异，从而为解码器提供更丰富的信息。\n为了获得跨多个特征级别的高阶互补信息，我们水平和垂直连接多个MSU来计算一系列具有不同阶数和感受野的差分特征。多尺度减法模块中多尺度的细节可以在图2中找到。我们聚合了相应级别和任意级别之间的特定尺度特征（MSi 1 ）和跨尺度差分特征（MSi n6=1）。其他级别生成互补增强特征（CEi）。这个过程可以表述如下：\n最后，所有CEi参与解码，然后对息肉区域进行分割。\n这里就是介绍一下MSU\nLossNet 在所提出的模型中，总训练损失可以写为：\n其中L w IoU和L w BCE表示加权IoU损失和二元交叉熵（BCE）损失，它们已在分割任务中广泛采用。我们使用与[4]、[44]、[45]中相同的定义，它们的有效性已在这些工作中得到验证。与它们不同的是，我们额外使用LossNet来进一步优化从细节到结构的分割。\n具体来说，我们使用 ImageNet 预训练分类网络，例如 VGG-16，分别提取预测和地面实况的多尺度特征。然后，它们的特征差异计算为损失 Lf ：\n令 F i P 和 F i G 分别表示从预测和地面实况中提取的第 i 层特征图。 l i f 计算为其欧几里德距离（L2-Loss），该距离在像素级别进行监督：\n从图4中可以看出，低层特征图包含丰富的边界信息，高层特征图描述位置信息。因此，LossNet可以在特征层面产生全面的监督。\n","permalink":"https://swimmingliu.cn/posts/papernotes/2023-m2snet/","summary":"\u003ch1 id=\"2023-m2snet-新颖多尺度模块--智能损失函数--通用图像分割sota网络\"\u003e(2023) M2SNet: 新颖多尺度模块 + 智能损失函数 = 通用图像分割SOTA网络\u003c/h1\u003e\n\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e准确的医学图像分割对于早期医学诊断至关重要。大多数现有方法基于U形结构，并使用\u003cstrong\u003e逐元素加法或串联在解码器中逐步融合不同级别的特征\u003c/strong\u003e。然而，这两种操作都\u003cstrong\u003e容易产生大量冗余信息\u003c/strong\u003e，从而\u003cstrong\u003e削弱不同级别特征之间的互补性\u003c/strong\u003e，导致\u003cstrong\u003e病灶定位不准确和边缘模糊\u003c/strong\u003e。为了应对这一挑战，我们提出了一种通用的多尺度减法网络（M2SNet）来完成医学图像的多样化分割。具体来说，我们首先设计一个基本\u003cstrong\u003e减法单元（SU）\u003cstrong\u003e来产生编码器中相邻级别之间的差异特征。接下来，我们将单尺度 SU 扩展到层内多尺度 SU，它可以为解码器\u003c/strong\u003e提供像素级和结构级差异信息\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e然后，我们金字塔式地为不同层次的多尺度SU配备不同的感受野，从而实现层间多尺度特征聚合并获得丰富的多尺度差异信息。此外，我们构建了一个免训练网络“LossNet”来全面监督从底层到顶层的任务感知特征，这驱动我们的多尺度减法网络同时捕获细节和结构线索。\u003c/p\u003e\n\u003cp\u003e没有花里胡哨的东西，我们的方法在不同的评估指标下，在不同图像模态的四种不同医学图像分割任务的 11 个数据集上表现优于大多数最先进的方法，包括彩色结肠镜成像、超声成像、计算机断层扫描 (CT) ）和光学相干断层扫描（OCT）。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e两个主要创新点：多尺度金字塔减法单元 （确实牛逼）+ LossNet（为了创新而创新的损失函数）\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e作为计算机辅助诊断系统中的重要作用，精确的医学图像分割技术可以为医生做出临床决策提供重要指导。精确分割存在三个普遍的挑战：首先，U形结构[1]、[2]由于其利用多级信息重建高分辨率特征图的能力而受到了相当多的关注。在UNet [2]中，上采样的特征图与从编码器跳过的特征图连接在一起，并在上采样步骤之间添加卷积和非线性，如图1（a）所示。后续基于UNet的方法通过注意力机制[3]、[4]、门机制[5]、[6]、变压器技术[7]、[8]设计不同的特征增强模块，如图1（b）所示。 UNet++[9]使用嵌套和密集的跳跃连接来减少编码器和解码器的特征图之间的语义差距，如图1（c）所示。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e先说医学分割在医学领域重要\u0026hellip;(balabala)  然后当前领域存在xxx挑战\u0026hellip;(balabala)\u003c/p\u003e\n\u003cp\u003e这里是以医学图像分割挑战的视角，介绍UNet发展的情况。然后在描述不同UNet变体发展过程中解决的不同问题（感觉可以借鉴）\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e一般来说，编码器中不同级别的特征有不同的特征。\u003cstrong\u003e高级别具有更多的语义信息\u003c/strong\u003e，有助于定位对象，而低级别具有\u003cstrong\u003e更详细的信息\u003c/strong\u003e，可以捕捉对象的\u003cstrong\u003e微妙边界\u003c/strong\u003e。解码器利用特定级别和跨级别特征来生成最终的\u003cstrong\u003e高分辨率预测\u003c/strong\u003e。然而，上述方法\u003cstrong\u003e直接使用逐元素加法或串联来融合来自编码器的任意两级特征\u003c/strong\u003e并将它们传输到解码器。这些简单的操作并没有更多地关注\u003cstrong\u003e不同层次之间的差异信息。\u003cstrong\u003e这一缺点不仅会产生\u003c/strong\u003e冗余信息来稀释真正有用的特征\u003c/strong\u003e，还会\u003cstrong\u003e削弱特定于级别的特征的特性\u003c/strong\u003e，从而导致网络无法平衡精确定位和微妙的边界细化。其次，由于\u003cstrong\u003e感受野有限\u003c/strong\u003e，单尺度卷积核很难捕获大小变化物体的\u003cstrong\u003e上下文信息\u003c/strong\u003e。一些方法[1]、[2]、[9]-[11]依赖于层间多尺度特征，并逐步整合来自不同尺度表示的\u003cstrong\u003e语义上下文和纹理细节\u003c/strong\u003e。其他人[6]、[12]-[15]专注于基于网络中的空洞空间金字塔池化模块[16]（ASPP）或DenseASPP [17]提取\u003cstrong\u003e层内多尺度信息\u003c/strong\u003e。然而，类似ASPP的多尺度卷积模块会产生\u003cstrong\u003e许多额外的参数和计算\u003c/strong\u003e。许多方法[5]、[18]-[21]通常将多个ASPP模块安装到不同级别的编码器/解码器块中，而有些方法[13]、[14]、[22]、[23]将其安装在不同级别的编码器/解码器块中。最高级别的编码器块。第三，损失函数的形式直接为网络的梯度优化提供了方向。在分割领域，提出了许多损失函数来监督不同级别的预测，例如像素级别的L1损失、交叉熵损失和加权交叉熵损失[24]，SSIM[25]损失区域层面的不确定性损失[26]，全局层面的IoU损失、Dice损失和一致性增强损失[11]。尽管这些基本损失函数及其变体具有不同的优化特性，但复杂的手动数学形式的设计对于许多研究来说确实非常耗时。为了获得综合性能，模型通常会集成多种损失函数，这对研究人员的训练技能提出了很高的要求。因此，我们认为有必要引入一种无需复杂人工设计的智能损失函数来全面监督分割预测。\u003c/p\u003e\n\u003cp\u003e在本文中，我们提出了一种用于一般医学图像分割的新型多尺度减法网络（M2SNet）。首先，我们设计一个减法单元（SU）并将其应用于\u003cstrong\u003e每对相邻的级别特征\u003c/strong\u003e。 SU突出了\u003cstrong\u003e特征之间有用的差异信息，并消除了冗余部分的干扰\u003c/strong\u003e。其次，我们借助所提出的\u003cstrong\u003e多尺度减法模块\u003c/strong\u003e收集\u003cstrong\u003e极端多尺度信息\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e对于层间多尺度信息，我们以金字塔方式连接多个减法单元来捕获大跨度的跨层信息。然后，我们\u003cstrong\u003e聚合特定于级别的特征\u003c/strong\u003e和\u003cstrong\u003e多路径跨级别差分特征\u003c/strong\u003e，然后在解码器中生成最终预测。对于层内多尺度信息，我们通过一组不同内核大小的full one滤波器将单尺度减法单元\u003cstrong\u003e改进为多尺度减法单元，可以自然地实现多尺度减法聚合，而无需引入额外的参数\u003c/strong\u003e。如图1所示，MSNet配备了层间多尺度减法模块，M2SNet同时具有层间和层内多尺度减法结构。第三，我们提出了一个LossNet来自动监督从底层到顶层提取的特征图，它可以通过简单的L2损失函数优化从细节到结构的分割。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e多尺度减法单元可以去特征之间的差异信息，消除冗余干扰。\u003c/p\u003e\n\u003cp\u003e（也就是说可以用这种办法替换注意力机制）\u003c/p\u003e\n\u003ch2 id=\"related-work\"\u003eRELATED WORK\u003c/h2\u003e\n\u003ch3 id=\"medical-image-segmentation-network\"\u003eMedical Image Segmentation Network\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e根据不同器官或病变的特点，我们将现有的医学图像分割方法分为两类：医学通用的和医学专用的。随着U-Net[2]在医学图像分割领域取得稳定的性能，带有编码器-解码器的U形结构已成为基本的分割基线。 U-Net++[9]集成了\u003cstrong\u003e长连接和短连接\u003c/strong\u003e，可以减少编码器和解码器子网络的特征图之间的语义差距。对于注意力 U-Net [28]，\u003cstrong\u003e注意力门\u003c/strong\u003e嵌入在编码器和解码器块之间的每个过渡层中，它可以自动学习关注不\u003cstrong\u003e同形状和大小的目标结构\u003c/strong\u003e。最近，Transformer [29]架构在许多自然语言处理任务中取得了成功。一些作品[7]、[8]探讨了其对医学视觉任务的有效性。 UTNet [7] 是一种简单但功能强大的混合变压器架构，它在编码器和解码器中应用自注意力模块，以最小的开销捕获不同规模的远程依赖关系。另一个具有代表性的基于 Transformer 的模型是 TransUNet [8]，它通过将图像特征视为序列来编码强全局上下文，并通过 U 形混合架构设计利用低级 CNN 特征。\u003c/p\u003e\n\u003cp\u003e医学特定方法。在息肉分割任务中，SFA [30]和PraNet [4]专注于恢复息肉与其周围粘膜之间的清晰边界。前者提出了共享编码器和两个相互约束的解码器下的选择性特征聚合结构和边界敏感损失函数。后者利用反向注意模块来建立区域和边界线索之间的关系。此外，Ji等人[31]利用时空信息构建视频息肉分割模型。在COVID-19肺部感染任务中，Paluru等人[32]提出了一种基于变形深度嵌入的轻量级CNN来分割COVID-19胸部CT图像中的异常。 Inf-Net [33] 构建隐式反向注意力和显式边缘注意力来对边界进行建模。 BCS-Net [34]具有三个渐进边界上下文语义重建块，可以帮助解码器捕获肺部感染的零散区域。在乳腺分割任务中，Byra等人[35]通过注意力机制开发了选择性核来调整U-Net的感受野，可以进一步提高乳腺肿瘤的分割精度。 Chen 等人 [36] 提出了一种嵌套 U 网，通过利用不同的深度和共享权重来实现乳腺肿瘤的稳健表示。\u003c/p\u003e","title":"M2SNet: Multi-scale in Multi-scale Subtraction Network for Medical Image Segmentation"},{"content":"EGE-UNet: an Efficient Group Enhanced UNet for skin lesion segmentation 1. Abstract 目前的医学图像分割模型大多是 Transformer + Unet，这些模型的大量参数和计算负载使得它们不适合移动健康应用。\n作者提出的EGE-UNet 模型轻量、高效。（与 TransFuse 相比，参数和计算成本分别降低了 494 倍和 160 倍，模型参数量只有50KB）\n创新点：组多轴哈达玛产品注意力模块（GHPA）和组聚合桥模块（GAB）。\n1.GHPA 对输入特征进行分组，并在不同轴上执行哈达玛产品注意力机制（HPA），以从不同角度提取病理信息。\n2.GAB 通过对低级特征、高级特征以及解码器在每个阶段生成的掩码进行分组，有效地融合了多尺度信息。\n2. Introduction 背景: 恶性黑色素瘤是世界上增长最快的癌症之一。据美国癌症协会估计，2020 年约有 100,350 例新发病例，超过 6,500 例死亡。因此，自动化皮肤病变分割系统势在必行，因为它可以帮助医疗专业人员快速识别病变区域并促进后续治疗过程。\n相同方式可引入脑瘤、肺癌。\n为了提高分割性能，最近的研究倾向于采用具有更大参数和计算复杂度的模块，例如结合视觉变换器（ViT）的自注意力机制[7]。例如，Swin-UNet [4]，基于Swin Transformer [11]，利用自注意力机制的特征提取能力来提高分割性能。 TransUNet [5] 开创了用于医学图像分割的 CNN 和 ViT 的串行融合。 TransFuse [26]采用双路径结构，利用 CNN 和 ViT 分别捕获局部和全局信息。UTNetV2[8]利用混合分层架构、高效的双向注意力和语义图来实现全局多尺度特征融合，结合了CNN和ViT的优点。 TransBTS [23] 将自注意力引入脑肿瘤分割任务中，并用它来聚合高级信息。\nAbstract提到当前医学分割模型大部分是Transformer + Unet，这里做出具体阐述。\n先前的工作通过引入复杂的模块来提高性能，但忽略了实际医疗环境中计算资源的限制。因此，迫切需要为移动医疗中的分割任务设计一种低参数、低计算负载的模型。最近，UNeXt [22] 结合了 UNet [18] 和 MLP [21] 开发了一种轻量级模型，该模型可以获得优异的性能，同时减少参数和计算量。此外，MALUNet [19]通过减少模型通道数并引入多个注意力模块来减小模型大小，从而比 UNeXt 具有更好的皮肤病变分割性能。然而，尽管MALUNet大大减少了参数数量和计算量，但其分割性能仍然低于一些大型模型，例如TransFuse。因此，在本研究中，我们提出了 EGE-UNet，这是一种轻量级皮肤病变分割模型，可实现最先进的效果，同时显着降低参数和计算成本。此外，据我们所知，这是第一个将参数减少到大约 50KB 的工作。\n提出问题：医疗环境中计算资源的限制，复杂模块难以落地 \u0026mdash;\u0026gt; 解决办法：轻量化模型\n当前轻量化发展历程 \u0026mdash;\u0026gt; 轻量化的模型分割效果不好 \u0026mdash;\u0026gt; EGE-Unet 轻量+分割能力强\n具体来说，EGE-UNet 利用两个关键模块：群组多轴 Hadamard 产品注意力模块（GHPA）和群组聚合桥模块（GAB）。\n一方面，由于多头自注意力机制（MHSA），最近基于 ViT [7] 的模型已经显示出前景。 MHSA将输入划分为多个head，并在每个head中计算self-attention，这使得模型能够从不同的角度获取信息，整合不同的知识，提高性能。尽管如此，MHSA 的二次复杂度极大地增加了模型的大小。因此，我们提出了具有线性复杂度的哈达玛产品注意力机制（HPA）。HPA 采用可学习的权重，并使用输入执行哈达玛乘积运算以获得输出。随后，受到 MHSA 中多头模式的启发，我们提出了 GHPA，它将输入分为不同的组，并在每个组中执行 HPA。然而，值得注意的是，我们在不同组的不同轴上进行HPA，这有助于进一步从不同的角度获取信息。\n另一方面，对于GAB，由于医学图像中分割目标的大小和形状不一致，因此获得多尺度信息至关重要[19]。因此，GAB基于组聚合融合不同大小的高层和低层特征，并额外引入掩模信息来辅助特征融合。通过将上述两个模块与UNet相结合，我们提出了EGE-UNet，它以极低的参数和计算量实现了出色的分割性能。与以前仅注重提高性能的方法不同，我们的模型还优先考虑现实环境中的可用性。图 1 显示了 EGEUNet 与其他网络的清晰比较。\n具体介绍为什么引入两个创新模块（GHPA、GAB）、以及模块是基于什么论文。（模块背景+创新方法）\n(1)提出了GHPA和GAB，前者有效地获取和集成多视角信息，后者接受不同尺度的特征，以及用于高效多尺度特征融合的辅助掩模。\n(2)我们提出了EGEUNet，这是一种专为皮肤病变分割而设计的极其轻量级的模型。\n(3) 我们进行了广泛的实验，证明了我们的方法在以显着降低的资源需求实现最先进性能方面的有效性。\n主要贡献：（1）写模块作用 （2）写整体网络优势 （3）实验效果\n3. Method 3.1EGE-Unet网络结构 EGE-UNet由对称编码器-解码器部分组成的 U 形架构之上。\n编码器由六级组成，每级通道数为{8,16,24,32,48,64}。解码器同理\n前三个阶段采用内核大小为 3 的普通卷积，后三个阶段利用提出的 GHPA 从不同的角度提取表示信息。\n与 UNet 中的简单跳跃连接相比，EGE-UNet 在编码器和解码器之间的每个阶段都采用了 GAB。\n利用深度监督生成不同规模的掩模预测，这些预测用于损失函数并作为 GAB 的输入之一。\n通过集成这些高级模块，EGE-UNet 显着减少了参数和计算负载，同时与之前的方法相比增强了分割性能。\n3.2 GHPA (Group multi-axis Hadamard Product Attention module) 为了克服 MHSA 带来的二次复杂度问题，我们提出了具有线性复杂度的 HPA。给定输入 x 和随机初始化的可学习张量 p，首先使用双线性插值来调整 p 的大小以匹配 x 的大小。然后，我们在 p 上采用深度可分离卷积（DW）[10][20]，然后在 x 和 p 之间进行哈达玛乘积运算以获得输出。然而，仅利用简单的HPA不足以从多个角度提取信息，导致结果不理想。受 MHSA 中多头模式的启发，我们引入了基于 HPA 的 GHPA，如算法 1 所示。我们将输入沿通道维度平均分为四组，并在高度-宽度、通道-高度和通道上执行 HPA - 分别为前三组的宽度轴。对于最后一组，我们只在特征图上使用DW。最后，我们沿着通道维度连接四组，并应用另一个数据仓库来整合不同角度的信息。请注意，DW 中使用的所有内核大小均为 3。\n首先对输入的特征分为四组进行处理：高度-宽度、通道-高度、通道-宽度、深度可分离卷积\n然后连接4组特征，进行可分离卷积融合特征。\n具体过程：\n第一步，按通道数将输入张量分为四组。（x1, x2, x3, x4）\n设置初始化三个全一张量，分别为高度-宽度、通道-高度、通道-宽度（Pxy, Pzx, Pzy）。\n第二步，将 x1, x2, x3 的对应切片分别使用双线插值法（bilinear）在Pxy, Pzx, Pzy中进行插值。\n第三步，对插值后的Pxy, Pzx, Pzy，进行深度可分离卷积，然后分别和x1, x2, x3进行哈达玛乘积\n第四步，连接4组特征信息，然后经过深度可分离卷积融合特征。\n3.3 GAB (Group Aggregation Bridge module) 多尺度信息的获取被认为对于密集预测任务（例如医学图像分割）至关重要。因此，如图 3 所示，我们引入了 GAB，它接受三个输入：低级特征、高级特征和掩码。首先，采用深度可分离卷积（DW）和双线性插值来调整高层特征的大小，以匹配低层特征的大小。其次，我们沿通道维度将两个特征映射分为四组，并将一组低级特征与一组高级特征连接起来，以获得四组融合特征。对于每组融合特征，掩码被连接起来。接下来，将内核大小为3和不同扩张率{1,2,5,7}的扩张卷积[25]应用于不同的组，以提取不同尺度的信息。最后，将四组沿通道维度连接起来，然后应用内核大小为 1 的普通卷积，以实现不同尺度的特征之间的交互。\nGAB模块作用： 将高级特征、低级特征、低级特征的预测掩码进行特征融合，作为新的输入特征进行解码。\n具体过程： 高级特征、低级特征、低级特征的预测掩码 (xh、xl 、Mask)\n首先，采用深度可分离卷积（DW）和双线性插值来调整高层特征 (xh) 的大小，以匹配低层特征 (xl) 的大小。\n其次，沿通道维度将两个特征映射分为四组。（对应不同空洞卷积的扩张率：d1 = 1, d2 = 2, d3 = 5, d4 = 7）\n并将每一组的低级特、高级特征和掩码连接起来，总共四组融合特征。\n最后，将四组特征进行连接，并进行1x1卷积得到输出。\n3.4 Loss Function 在本研究中，由于不同的GAB需要不同尺度的掩模信息，因此采用深度监督来计算不同阶段的损失函数，以生成更准确的掩模信息。我们的损失函数可以表示为方程（1）和（2）。其中 Bce 和 Dice 表示二元交叉熵和dice损失。 λi是不同阶段的权重。在本文中，我们默认将i=0到i=5之间的λi设置为1、0.5、0.4、0.3、0.2、0.1。\n分为6个阶段，逐一计算每个阶段的损失。然后按照权重对损失进行求和。\n4.Experiments 4.1 Datasets and Implementation details 为了评估我们模型的有效性，我们选择了两个公共皮肤病变分割数据集，即 ISIC2017 [1][3] 和 ISIC2018 [2][6]，分别包含 2150 个和 2694 个皮肤镜图像。与之前的研究[19]一致，我们以 7:3 的比例将数据集随机划分为训练集和测试集。\nEGE-UNet是由Pytorch[17]框架开发的。所有实验均在单个 NVIDIA RTX A6000 GPU 上执行。图像被归一化并调整大小为 256×256。我们应用各种数据增强，包括水平翻转、垂直翻转和随机旋转。 AdamW [13] 用作优化器，以 0.001 的学习率初始化，CosineAnnealingLR [12] 用作调度器，最大迭代次数为 50，最小学习率为 1e-5。总共训练了 300 个 epoch，批量大小为 8。为了评估我们的方法，我们采用并集平均交集 (mIoU)、Dice 相似度得分 (DSC) 作为指标，并进行 5 次训练\n​\t在公共皮肤病变分割数据集（ISIC2017 和 ISIC2018 ）进行对比实验，在ISIC2018进行消融实验\n采用并集平均交集 (mIoU)、Dice 相似度得分 (DSC) 作为评估指标\n4.2 Comparison Experiments 4.3 Ablation Experiments 4.4 Qualitative Comparisons 5. ConClusions 在本文中，我们提出了两个高级模块。我们的 GHPA 使用一种新颖的 HPA 机制将自注意力的二次复杂度简化为线性复杂度。它还利用分组来充分捕获来自不同角度的信息。我们的 GAB 融合了低级和高级特征，并引入了一个掩模来集成多尺度信息。基于这些模块，我们提出了用于皮肤病变分割任务的 EGE-UNet。实验结果证明了我们的方法在显着降低资源需求的情况下实现最先进的性能的有效性。我们希望我们的工作能够激发医学图像界对轻量级模型的进一步研究。\n作者提出的EGE-UNet实现了轻量、准确的皮肤病变分割任务\n","permalink":"https://swimmingliu.cn/posts/papernotes/2023-ege-unet%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/","summary":"\u003ch1 id=\"ege-unet-an-efficient-group-enhanced-unet-for-skin-lesion-segmentation\"\u003eEGE-UNet: an Efficient Group Enhanced UNet for skin lesion segmentation\u003c/h1\u003e\n\u003ch2 id=\"1-abstract\"\u003e1. Abstract\u003c/h2\u003e\n\u003cp\u003e目前的医学图像分割模型大多是 Transformer + Unet，这些模型的大量参数和计算负载使得它们不适合移动健康应用。\u003c/p\u003e\n\u003cp\u003e作者提出的EGE-UNet 模型轻量、高效。（与 TransFuse 相比，参数和计算成本分别降低了 494 倍和 160 倍，模型参数量只有50KB）\u003c/p\u003e\n\u003cp\u003e创新点：组多轴哈达玛产品注意力模块（GHPA）和组聚合桥模块（GAB）。\u003c/p\u003e\n\u003cp\u003e1.GHPA 对输入特征进行分组，并在不同轴上执行哈达玛产品注意力机制（HPA），以从不同角度提取病理信息。\u003c/p\u003e\n\u003cp\u003e2.GAB 通过对低级特征、高级特征以及解码器在每个阶段生成的掩码进行分组，有效地融合了多尺度信息。\u003c/p\u003e\n\u003ch2 id=\"2-introduction\"\u003e2. Introduction\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e背景: 恶性黑色素瘤是世界上增长最快的癌症之一。据美国癌症协会估计，2020 年约有 100,350 例新发病例，超过 6,500 例死亡。因此，自动化皮肤病变分割系统势在必行，因为它可以帮助医疗专业人员快速识别病变区域并促进后续治疗过程。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e相同方式可引入脑瘤、肺癌。\u003c/strong\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e为了提高分割性能，最近的研究倾向于采用具有更大参数和计算复杂度的模块，例如结合视觉变换器（ViT）的自注意力机制[7]。例如，Swin-UNet [4]，基于Swin Transformer [11]，利用自注意力机制的特征提取能力来提高分割性能。 TransUNet [5] 开创了用于医学图像分割的 CNN 和 ViT 的串行融合。 TransFuse [26]采用双路径结构，利用 CNN 和 ViT 分别捕获局部和全局信息。UTNetV2[8]利用混合分层架构、高效的双向注意力和语义图来实现全局多尺度特征融合，结合了CNN和ViT的优点。 TransBTS [23] 将自注意力引入脑肿瘤分割任务中，并用它来聚合高级信息。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003eAbstract提到当前医学分割模型大部分是Transformer + Unet，这里做出具体阐述。\u003c/strong\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e先前的工作通过引入复杂的模块来提高性能，但忽略了实际医疗环境中计算资源的限制。因此，迫切需要为移动医疗中的分割任务设计一种低参数、低计算负载的模型。最近，UNeXt [22] 结合了 UNet [18] 和 MLP [21] 开发了一种轻量级模型，该模型可以获得优异的性能，同时减少参数和计算量。此外，MALUNet [19]通过减少模型通道数并引入多个注意力模块来减小模型大小，从而比 UNeXt 具有更好的皮肤病变分割性能。然而，尽管MALUNet大大减少了参数数量和计算量，但其分割性能仍然低于一些大型模型，例如TransFuse。因此，在本研究中，我们提出了 EGE-UNet，这是一种轻量级皮肤病变分割模型，可实现最先进的效果，同时显着降低参数和计算成本。此外，据我们所知，这是第一个将参数减少到大约 50KB 的工作。\u003c/p\u003e","title":"EGE-UNet: an Efficient Group Enhanced UNet for skin lesion segmentation"}]