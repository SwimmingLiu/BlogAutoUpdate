[{"content":"1. 什么是 Java 内存模型（JMM）？ JMM 是 Java内存模型 ， 它是Java虚拟机 JVM 定义的一种规范，用于描述多线程程序中的变量，像实例字段、静态字段和数组元素，他们如何在内存中存储和传递的规则。也就是规定线程啥时候从住内存里面读数据，啥时候把数据写回到住内存。JMM 的核心目标是确保多线程环境下的可见性、有序性和原子性, 避免硬件和编译器优化带来的不一致问题。\n【可见性、有序性、原子性定义】\n可见性：确保一个线程对共享变量的修改，能够及时被另外一个线程看到。 volatile就是用来保证可见性的，强制线程每次读写的时候，直接从主内存当中获取最新值。 有序性：指线程执行操作的顺序。JMM允许某些指令重排序之后再提高性能，但会保证线程内的操作顺序不会被破坏。通过happens-before (线程A发生在线程B之前)的关系来保证跨线程的有序性。 原子性：操作不可分割，线程不会在执行的过程当中被打断。例如, synchronize 关键字能确保方法或代码块的原子性 【JMM作用】\n因为不同的操作系统都有一套独立的内存模型，但是Java为了满足跨平台的特性，它需要定义一套内存模型屏蔽个操作系统之间的差异。我们可以利用JMM当中定义好的从Java源码到CPU指令的执行规范，也就是使用synchronized 、volatile 等关键字，还有happens-before原则，就可以写出并发安全的代码了。 比如说，线程A和线程B同时操作 变量-1，假如最开始变量-1 是 0\n首先，线程A和线程B都读取了变量-1 然后，线程B对取到的变量-1自增为1，并写回主内存 此时，线程A对读取到的变量-1也自增1，并写回主内存。这就会导致线程B的操作失效了，出现并发安全问题。 如果有JMM，我们就可以在线程A要修改数据之前,让它采用CAS乐观锁的方式进行修改。再次去读主内存当中的值，然后修改之后，再判断一下主内存的值是否发生变化。如果没有发生变化，就写回主内存。如果发生变化，就要进行自旋。\n【注意】 工作内存是每个线程独立的内存空间，其他线程都是看不到的。主内存是Java堆内存的一部分，所有的实例变量、静态变量和数组元素都存储在主内存当中。\n【内存间交互操作类型 (8种原子操作)】\nlock 上锁：把一个变量表示为一条线程独占的状态 unlock 解锁： 把一个变量从独占状态中释放出来，释放后的变量才能被其他线程锁定 read 读取： 从主内存当中读取一个变量到工作内存中 load 载入：把read操作从主内存中得到的变量值放入工作内存的变量副本当中 use 使用：把工作内存当中的一个变量值传递给执行引擎 assign 赋值：把一个从执行引擎接收到的值赋给工作内存中的变量 store 存储：把工作内存中的一个变量的值传送给主内存中 write 写入：把store操作从工作内存中得到的变量值放入主内存的变量中 【volatile 特殊规则】\n可见性：对于 volatile 修饰的变量的写操作会立即刷新到内存中，任何线程对这个volatile 变量的读操作都能立即看到最新的值。 禁止指令重排序： 在对 volatile 变量进行读/写操作的时候，会插入内存屏障，禁止指令重排序。也就是该变量的写操作不能与之前的读/写操作重排序，它的都操作不能与之后的读/写操作重排序。 【Happens-Before 原则】\n见下一个问题\n2. 什么是Java的 happens-before 规则? happens-before 原则就是 JMM 当中定义操作间顺序的规则，确保操作的有序性和可见性。\n程序次序规则：线程当中所有操作都是按程序代码的顺序发生 监视器锁规则：解锁操作发生在同一个锁的随后的加锁操作之前，说白了，先解锁，后上锁 volatile 变量规则： volatile 变量的写操作发生在对改变量随后的读操作之前，先写后读 线程启动规则：线程A对线程B的Thread.start() 调用发生在这个新线程的每一个操作之前 线程终止规则：线程A所有的操作都发生在其他线程检测到线程A终止之前 线程中断规则：对线程的中断操作 (Thread.interrupt()) 发生在被中断线程检测到的中断时间之前 (通过Thread.interrupted() 或 Thread.isInterrupted() 进行检测) 对象终结规则： 一个对象的构造函数执行结束发生在这个对象的finalize() 方法之前 传递性： 如果A happens-before B，B happens-before C, 则 A happens-before C 3. Java 的 synchronized 是怎么实现的？ 【实现原理】\nsynchronized 关键字是以来 JVM 的Monitor (监视器锁)和 Object Header (对象头) 实现的。其中，重量级所依赖于 Monitor 监视器锁， 轻量级锁和偏向锁都依赖于对象头 (Object Header)\n【不同使用场景的区别】\n修饰方法：会在修饰的方法的访问标志中增加一个 ACC_SYNCHRONIZED 标志，每当有一个线程访问该方法时， JVM回去检测该方法的访问标志。如果包含ACC_SYNCHRONIZED 标志， 线程必须获得该方法对应的对象监视器锁 (对象锁)，也就是Monitor 当中的owner执行该线程。 然后再执行该方法，保持同步性。 修饰代码块：在代码块的前后分别插入 monitorenter 和 monitorexit 字节码指令， 可以理解为加锁和解锁 【可重入性】\nsynchronized 是可以重入的，每次获取一次锁。如果是当前线程的锁，计数器加1，锁释放的时候，计数器减1。直到计数器减为 0 为止，锁才真正释放\n【synchronized 锁升级】\nsynchronized 锁分为三种，偏向锁，轻量级锁，重量级锁。其升级次序为偏向锁(一个线程) -\u0026gt; 轻量级锁 (多个线程) -\u0026gt; 重量级锁 (多个线程竞争激烈)\n偏向锁：当有线程第一次获取锁的时候， JVM 会采用修改锁对象的对象头，将该线程标记为偏向状态。对象头里面会记录线程ID 和 对应的epoch 偏向锁版本。后续该线程再获取锁，基本没啥开销。 轻量级锁：当有另外的线程尝试去获取已经被偏向的锁时，锁会升级为轻量级锁。使用CAS操作来减少锁竞争的开销。 重量级锁：当CAS失败无法获取锁的时候，JVM判定其为多个线程竞争锁激烈。锁会升级成为重量锁，线程会被挂起直到释放。线程会被放入Monitor的owner当中 【锁消除和锁粗化】\n锁消除：JVM判断对象是否只在当前线程使用，如果只在当前线程使用，则消除不必要加的锁 锁粗化：多个锁频繁操作出现时，JVM会将这些锁操作合并，见锁获取和释放的开销。 ","permalink":"https://swimmingliu.cn/posts/job/java-juc-interview-questions/","summary":"\u003ch2 id=\"1-什么是-java-内存模型jmm\"\u003e1. 什么是 Java 内存模型（JMM）？\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eJMM\u003c/code\u003e 是 Java内存模型 ， 它是Java虚拟机 \u003ccode\u003eJVM\u003c/code\u003e 定义的一种规范，用于描述多线程程序中的变量，像实例字段、静态字段和数组元素，他们如何在内存中存储和传递的规则。也就是规定线程啥时候从住内存里面读数据，啥时候把数据写回到住内存。\u003ccode\u003eJMM\u003c/code\u003e 的核心目标是确保多线程环境下的\u003cstrong\u003e可见性\u003c/strong\u003e、\u003cstrong\u003e有序性\u003c/strong\u003e和\u003cstrong\u003e原子性\u003c/strong\u003e, 避免硬件和编译器优化带来的不一致问题。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【可见性、有序性、原子性定义】\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e可见性\u003c/strong\u003e：确保一个线程对共享变量的修改，能够及时被另外一个线程看到。 \u003ccode\u003evolatile\u003c/code\u003e就是用来保证可见性的，强制线程每次读写的时候，直接从主内存当中获取最新值。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e有序性\u003c/strong\u003e：指线程执行操作的顺序。JMM允许某些指令重排序之后再提高性能，但会保证线程内的操作顺序不会被破坏。通过\u003ccode\u003ehappens-before\u003c/code\u003e (线程A发生在线程B之前)的关系来保证跨线程的有序性。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e原子性\u003c/strong\u003e：操作不可分割，线程不会在执行的过程当中被打断。例如, \u003ccode\u003esynchronize\u003c/code\u003e 关键字能确保方法或代码块的原子性\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e【JMM作用】\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e因为不同的操作系统都有一套独立的内存模型，但是Java为了满足跨平台的特性，它需要定义一套内存模型屏蔽个操作系统之间的差异。我们可以利用JMM当中定义好的从Java源码到CPU指令的执行规范，也就是使用\u003ccode\u003esynchronized\u003c/code\u003e 、\u003ccode\u003evolatile\u003c/code\u003e 等关键字，还有\u003ccode\u003ehappens-before\u003c/code\u003e原则，就可以写出并发安全的代码了。\n比如说，线程A和线程B同时操作 \u003ccode\u003e变量-1\u003c/code\u003e，假如最开始\u003ccode\u003e变量-1\u003c/code\u003e 是 \u003ccode\u003e0\u003c/code\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e首先，线程A和线程B都读取了\u003ccode\u003e变量-1\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e然后，线程B对取到的\u003ccode\u003e变量-1\u003c/code\u003e自增为\u003ccode\u003e1\u003c/code\u003e，并写回主内存\u003c/li\u003e\n\u003cli\u003e此时，线程A对读取到的\u003ccode\u003e变量-1\u003c/code\u003e也自增\u003ccode\u003e1\u003c/code\u003e，并写回主内存。这就会导致线程B的操作失效了，出现并发安全问题。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e如果有JMM，我们就可以在线程A要修改数据之前,让它采用CAS乐观锁的方式进行修改。再次去读主内存当中的值，然后修改之后，再判断一下主内存的值是否发生变化。如果没有发生变化，就写回主内存。如果发生变化，就要进行自旋。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【注意】\u003c/strong\u003e 工作内存是每个线程独立的内存空间，其他线程都是看不到的。主内存是Java堆内存的一部分，所有的实例变量、静态变量和数组元素都存储在主内存当中。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"JMM架构图\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/49ddf552-f9c8-11ef-99c5-c858c0c1deba\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【内存间交互操作类型 (8种原子操作)】\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003elock 上锁\u003c/strong\u003e：把一个变量表示为一条线程独占的状态\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eunlock 解锁\u003c/strong\u003e： 把一个变量从独占状态中释放出来，释放后的变量才能被其他线程锁定\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eread 读取\u003c/strong\u003e： 从主内存当中读取一个变量到工作内存中\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eload 载入\u003c/strong\u003e：把\u003ccode\u003eread\u003c/code\u003e操作从主内存中得到的变量值放入工作内存的变量副本当中\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003euse 使用\u003c/strong\u003e：把工作内存当中的一个变量值传递给执行引擎\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eassign 赋值\u003c/strong\u003e：把一个从执行引擎接收到的值赋给工作内存中的变量\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003estore 存储\u003c/strong\u003e：把工作内存中的一个变量的值传送给主内存中\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ewrite 写入\u003c/strong\u003e：把store操作从工作内存中得到的变量值放入主内存的变量中\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e【volatile 特殊规则】\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e可见性\u003c/strong\u003e：对于 \u003ccode\u003evolatile\u003c/code\u003e 修饰的变量的写操作会立即刷新到内存中，任何线程对这个\u003ccode\u003evolatile\u003c/code\u003e 变量的读操作都能立即看到最新的值。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e禁止指令重排序\u003c/strong\u003e： 在对 \u003ccode\u003evolatile\u003c/code\u003e 变量进行读/写操作的时候，会插入内存屏障，禁止指令重排序。也就是该变量的写操作不能与之前的读/写操作重排序，它的都操作不能与之后的读/写操作重排序。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e【Happens-Before 原则】\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e见下一个问题\u003c/p\u003e\n\u003ch2 id=\"2-什么是java的-happens-before-规则\"\u003e2. 什么是Java的 happens-before 规则?\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003ehappens-before\u003c/code\u003e 原则就是 \u003ccode\u003eJMM\u003c/code\u003e 当中定义操作间顺序的规则，确保操作的有序性和可见性。\u003c/p\u003e","title":"(JUC) Java并发面试题笔记"},{"content":"1. 说说你知道的几种 I/O 模型 【常见的五大I/O模型】\n常见的五大I/O模式分别为: 同步阻塞I/O (Blocking I/O) BIO、非阻塞I/O (Non-blocking I/O) NIO、I/O多路复用、信号量驱动I/O、异步I/O AIO\n我们假如要烧水喝，看不同模型是怎么烧的水喝\nI/O 模型 特性 烧水案例 同步阻塞I/O BIO 数据从网卡到内核，再从内核到用户空间，都是阻塞操作。 自己动手烧水，一直盯着，等水烧开了，倒在杯子里喝。 非阻塞I/O NIO 数据从网卡到内核不阻塞，read不到数据直接返回，但是从内核到用户空间会阻塞 (用户轮询read) 自己动手烧水，隔两分钟看一下，水烧开没有。等水烧开了，倒在杯子里喝。 I/O多路复用 只有一个线程查看多个连接是否有数据准备就绪 (看从网卡能不能read到数据到内核) 找专门烧水的领居帮忙，他把水烧好了之后，会喊你来拿。但是你要自己倒在杯子里喝。 信号驱动I/O 数据从网卡到内核之后会自动通知用户程序，然后让他read读取数据 去烧水房烧水，全自动的，有个通知灯。水烧完了之后会按你家的门铃，但是有客人来了，也会按门铃 异步I/O AIO 全程不阻塞，拷贝到用户空间之后直接回调。 和多路复用类似，但是烧完水之后不用自己倒水，他帮你倒好了，还吹凉了，你过来喝就行。 ","permalink":"https://swimmingliu.cn/posts/job/operation-system-interview-questions/","summary":"\u003ch2 id=\"1-说说你知道的几种-io-模型\"\u003e1. 说说你知道的几种 I/O 模型\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e【常见的五大I/O模型】\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e常见的五大I/O模式分别为: 同步阻塞I/O (Blocking I/O) \u003ccode\u003eBIO\u003c/code\u003e、非阻塞I/O (Non-blocking I/O) \u003ccode\u003eNIO\u003c/code\u003e、I/O多路复用、信号量驱动I/O、异步I/O \u003ccode\u003eAIO\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e我们假如要烧水喝，看不同模型是怎么烧的水喝\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e\u003cstrong\u003eI/O 模型\u003c/strong\u003e\u003c/th\u003e\n          \u003cth\u003e特性\u003c/th\u003e\n          \u003cth\u003e烧水案例\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e同步阻塞I/O \u003ccode\u003eBIO\u003c/code\u003e\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e数据从网卡到内核，再从内核到用户空间，都是阻塞操作。\u003c/td\u003e\n          \u003ctd\u003e自己动手烧水，一直盯着，等水烧开了，倒在杯子里喝。\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e非阻塞I/O \u003ccode\u003eNIO\u003c/code\u003e\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e数据从网卡到内核不阻塞，\u003ccode\u003eread\u003c/code\u003e不到数据直接返回，但是从内核到用户空间会阻塞 (用户轮询\u003ccode\u003eread\u003c/code\u003e)\u003c/td\u003e\n          \u003ctd\u003e自己动手烧水，隔两分钟看一下，水烧开没有。等水烧开了，倒在杯子里喝。\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003eI/O多路复用\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e只有一个线程查看多个连接是否有数据准备就绪 (看从网卡能不能\u003ccode\u003eread\u003c/code\u003e到数据到内核)\u003c/td\u003e\n          \u003ctd\u003e找专门烧水的领居帮忙，他把水烧好了之后，会喊你来拿。但是你要自己倒在杯子里喝。\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e信号驱动I/O\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e数据从网卡到内核之后会自动通知用户程序，然后让他\u003ccode\u003eread\u003c/code\u003e读取数据\u003c/td\u003e\n          \u003ctd\u003e去烧水房烧水，全自动的，有个通知灯。水烧完了之后会按你家的门铃，但是有客人来了，也会按门铃\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e异步I/O \u003ccode\u003eAIO\u003c/code\u003e\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e全程不阻塞，拷贝到用户空间之后直接回调。\u003c/td\u003e\n          \u003ctd\u003e和多路复用类似，但是烧完水之后不用自己倒水，他帮你倒好了，还吹凉了，你过来喝就行。\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003cimg alt=\"IO五种模型\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/3bbe065d-f63f-11ef-a797-c858c0c1deba\"\u003e\u003c/p\u003e","title":"操作系统面试题笔记"},{"content":"个人简历详情查看 -\u0026gt; 个人简历页\n1. 异步秒杀机制的异步是如何实现的? 【正常秒杀的顺序】\n查询优惠券 -\u0026gt; 判断秒杀库存 -\u0026gt; 查询订单 -\u0026gt; 校验是否一人一单 -\u0026gt; 扣减库存 -\u0026gt; 创建订单\n【异步秒杀】\n为了实现用户异步下单，其实就是把是否能够下单的判断逻辑和下单的操作拆分开。\n采用Redis来判断是否有足够的库存和校验一人一单 如果满足条件，把用户、订单id、商品id保存到阻塞队列，直接给用户返回秒杀成功。 如果不满足条件，直接返回秒杀失败。 后台线程会去执行queue里边的消息 这样就可以实现异步的秒杀下单了，那么如果实现判断秒杀库存和校验一人一单呢？\n【秒杀库存 + 一人一单】\n用户下单之后，判断redis当中的库存key的value是否大于0 value \u0026gt; 0 -\u0026gt; 第2步 value \u0026lt;= 0 -\u0026gt; 直接返回库存不足 （返回1） 如果库存充足，判断redis当中的秒杀商品key的 set 集合是否已包含userid 包含userid， 说明用户已经下单了，直接返回当前用户已下单 (返回2) 不包含 userid -\u0026gt; 第3步 如果用户没有下单，将用户的 userid 存入 set 里面 (返回0) 【注意】 整个操作是原子性的，这样就确保了不会出现超卖现象和一人多单现象\n-- 1.参数列表 -- 1.1.秒杀商品id local voucherId = ARGV[1] -- 1.2.用户id local userId = ARGV[2] -- 1.3.订单id local orderId = ARGV[3] -- 2.数据key -- 2.1.库存key local stockKey = \u0026#39;seckill:stock:\u0026#39; .. voucherId -- 2.2.秒杀商品订单key local orderKey = \u0026#39;seckill:order:\u0026#39; .. voucherId -- 3.脚本业务 -- 3.1.判断库存是否充足 get stockKey if(tonumber(redis.call(\u0026#39;get\u0026#39;, stockKey)) \u0026lt;= 0) then -- 3.2.库存不足，返回1 return 1 end -- 3.2.判断用户是否下单 SISMEMBER orderKey userId if(redis.call(\u0026#39;sismember\u0026#39;, orderKey, userId) == 1) then -- 3.3.存在，说明是重复下单，返回2 return 2 end return 0 【阻塞队列实现下单】\n初始化一个SingleThreadExecutor 线程池，用于完成后续的下单操作 判断上面lua脚本执行后的返回值 如果返回值为0， 说明用户满足下单的资格 -\u0026gt; 第2步 如果返回值不为0， 说明用户下单失败，返回异常信息 将userid、优惠商品id、订单id等信息都存入阻塞队列(ArrayBlockingQueue)里面，返回订单id 线程池会异步获取阻塞队列里面的订单信息，然后创建订单。 2. 如果用MySQL数据库，如何解决超卖现象 超卖现象的产生是因为多线程并发的时候，出现了库存扣为负数的现象。\n假如A线程查询时，库存为1 。随后，B线程查询库存也为1 A线程完成下单之后, 库存减为0。此时，B线程又完成下单，库存扣减为-1。 【MySQL如何解决超卖问题】\n一般超卖问题都是采用乐观锁进行解决，也就是CAS 自旋。其实，就是判断读取前和第二次读取的，是否出现了数据不一致的情况。如果数据不一致，说明被其他人修改过，就放弃当前的操作。如果没有，就正常修改。\n【乐观锁】\n乐观锁会有一个版本号，每次操作数据会对版本号+1。再提交回数据是，会去校验是否比之前的版本是否大于1。如果超过1， 则说明当前的数据被修改过。\n乐观锁有一个变种是CAS，利用CAS进行无锁化机制加锁，var5 是操作前读取的内存值，while 中的var1+var2 是预估值，如果预估值 == 内存值，则代表中间没有被人修改过，此时就将新值去替换 内存值\nint var5; do { var5 = this.getIntVolatile(var1, var2); } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; 【MySQL如何解决一人一单】\n就是判断当前用于在数据库里面是否有订单, 可以用count() 去统计一下该用户秒杀订单的数量。如果大于0，则说明他已经买过商品了，就不能重复下单了。\n","permalink":"https://swimmingliu.cn/posts/job/personal-interview-hot-question/","summary":"\u003cp\u003e个人简历详情查看 -\u0026gt; \u003ca href=\"https://rxresu.me/dashboard/resumes\"\u003e个人简历页\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"1-异步秒杀机制的异步是如何实现的\"\u003e1. 异步秒杀机制的异步是如何实现的?\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e【正常秒杀的顺序】\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e查询优惠券 -\u0026gt; 判断秒杀库存 -\u0026gt; 查询订单 -\u0026gt; 校验是否一人一单 -\u0026gt; 扣减库存 -\u0026gt; 创建订单\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【异步秒杀】\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e为了实现用户异步下单，其实就是把是否能够下单的判断逻辑和下单的操作拆分开。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e采用Redis来判断是否有足够的库存和校验一人一单\n\u003cul\u003e\n\u003cli\u003e如果满足条件，把用户、订单id、商品id保存到阻塞队列，直接给用户返回秒杀成功。\u003c/li\u003e\n\u003cli\u003e如果不满足条件，直接返回秒杀失败。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e后台线程会去执行queue里边的消息\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e这样就可以实现异步的秒杀下单了，那么如果实现判断秒杀库存和校验一人一单呢？\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"1653561657295\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/8f260a35-f4b5-11ef-a915-c858c0c1deba\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【秒杀库存 + 一人一单】\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e用户下单之后，判断redis当中的库存key的value是否大于\u003ccode\u003e0\u003c/code\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003evalue \u0026gt; 0\u003c/code\u003e -\u0026gt; 第2步\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003evalue \u0026lt;= 0\u003c/code\u003e -\u0026gt; 直接返回库存不足 （返回\u003ccode\u003e1\u003c/code\u003e）\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e如果库存充足，判断redis当中的秒杀商品key的 \u003ccode\u003eset\u003c/code\u003e 集合是否已包含\u003ccode\u003euserid\u003c/code\u003e\n\u003cul\u003e\n\u003cli\u003e包含\u003ccode\u003euserid\u003c/code\u003e， 说明用户已经下单了，直接返回当前用户已下单 (返回\u003ccode\u003e2\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003e不包含 \u003ccode\u003euserid\u003c/code\u003e -\u0026gt; 第3步\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e如果用户没有下单，将用户的 \u003ccode\u003euserid\u003c/code\u003e 存入 \u003ccode\u003eset\u003c/code\u003e 里面 (返回\u003ccode\u003e0\u003c/code\u003e)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e【注意】\u003c/strong\u003e 整个操作是原子性的，这样就确保了不会出现\u003cstrong\u003e超卖现象和一人多单现象\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-lua\" data-lang=\"lua\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 1.参数列表\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 1.1.秒杀商品id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003elocal\u003c/span\u003e \u003cspan class=\"n\"\u003evoucherId\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eARGV\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 1.2.用户id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003elocal\u003c/span\u003e \u003cspan class=\"n\"\u003euserId\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eARGV\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 1.3.订单id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003elocal\u003c/span\u003e \u003cspan class=\"n\"\u003eorderId\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eARGV\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 2.数据key\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 2.1.库存key\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003elocal\u003c/span\u003e \u003cspan class=\"n\"\u003estockKey\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;seckill:stock:\u0026#39;\u003c/span\u003e \u003cspan class=\"o\"\u003e..\u003c/span\u003e \u003cspan class=\"n\"\u003evoucherId\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 2.2.秒杀商品订单key\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003elocal\u003c/span\u003e \u003cspan class=\"n\"\u003eorderKey\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;seckill:order:\u0026#39;\u003c/span\u003e \u003cspan class=\"o\"\u003e..\u003c/span\u003e \u003cspan class=\"n\"\u003evoucherId\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 3.脚本业务\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 3.1.判断库存是否充足 get stockKey\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kr\"\u003eif\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etonumber\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eredis.call\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;get\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003estockKey\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"kr\"\u003ethen\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e-- 3.2.库存不足，返回1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kr\"\u003ereturn\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kr\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e-- 3.2.判断用户是否下单 SISMEMBER orderKey userId\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kr\"\u003eif\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eredis.call\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;sismember\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eorderKey\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003euserId\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"kr\"\u003ethen\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e-- 3.3.存在，说明是重复下单，返回2\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kr\"\u003ereturn\u003c/span\u003e \u003cspan class=\"mi\"\u003e2\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kr\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kr\"\u003ereturn\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003e【阻塞队列实现下单】\u003c/strong\u003e\u003c/p\u003e","title":"个人简历常问问题"},{"content":"1. Redis主从复制的原理 【主从复制的原理】\n同步：从节点向主节点发送psync命令进行同步，从节点保存主节点返回的 runid 和 offset 全量复制：如果是第一次连接或者连接失败且repl_backlog_buffer 缓存区不包含slave_repl_offset， 则生成主节点的数据快照(RDB文件)发给从节点 增量复制：全量复制完毕后，主从节点之间会保持长连接。如果连接没有断开或者slave_repl_offset仍然在repl_backlog_buffer中，则将后续的写操作传递给从节点，让数据保持一致。 【全量复制细节】\n全量复制的过程是基于TCP长连接的，主要流程如下\n从节点发送psync ? -1表示需要建立连接进行同步，主节点返回主节点ID runid 和 复制进度offset (第一次同步用 -1 表示)。从节点接受之后，保存主节点的信息。 主节点执行bgsave命令生成数据快照RDB文件，然后将RDB文件发送给从节点。从节点接受文件后，清除现有的所有数据，然后加载RDB文件 如果在制作数据快照RDB文件的过程当中，主节点接收到了新的写操作，主节点会将其记录在repl buffer 里面。然后将repl buffer当中的写操作发给从节点，让其数据保持一致。 【增量复制细节】\n如果主从节点意外断开连接，为了保持数据的一致性，必须重新同步数据。如果使用全量复制来保持一致性的话，开销太大，所以采用增量复制。\n增量复制的具体流程如下：\n连接恢复后，从节点会发送psync {runid} {offset}， 其中主节点ID runid 和 复制进度offset用于标识是哪一个服务器主机和复制进度。 主节点收到psync 命令之后，会用conitnue响应告知从节点，采用增量复制同步数据 最后，主节点根据offset查找对应的进度，将断线期间未同步的写命令，发送给从节点。同时，主节点将所有的写命令写入repl_backlog_buffer， 用于后续判断是采用增量复制还是全量复制。 【注意】从节点 psync 携带的 offset 为 slave_repl_offset。如果 repl_backlog_buffer包含slave_repl_offset 对应的部分，则采用增量复制，否则采用全量复制。repl_backlog_buffer的默认缓冲区大小为1M\n【为什么要主从复制】\n备份数据：主从复制实现了数据的热备份，是持久化之外的数据冗余方式 故障恢复：当主节点宕机之后，可以采用从节点提供服务。 负载均衡: 主从复制实现了读写分离，只有主节点支持读写操作，从节点只有读操作。在读多写少的场景下，可以提高Redis服务器的并发量。 2. Redis集群的实现原理是什么? 【Redis集群基本知识】\n定义: Redis集群由多个实例组成，每个实例存储部分数据 (每个实例之间的数据不重复) 。 【注】集群和主从节点不是一个东西，集群的某一个实例当中可能包含一个主节点 + 多个从节点\n为什么用 问题 解决方案 容量不足 数据分片，将数据分散不存到不同的主节点 高并发写入 数据分片，将写入请求分摊到多个主节点 主机宕机问题 自动切换主从节点，避免影响服务， 不需要手动修改客户端配置 节点通信协议：Redis集群采用Gossip协议, 支持分布式信息传播、延迟低、效率高。采用去中心化思想，任意实例(主节点)都可以作为请求入口，节点间相互通信。 分片原理： 采用哈希槽(Hash Slot)机制来分配数据，整个空间可以划分为16384 (16 * 1024)个槽。 每个Redis负责一定范围的哈希槽,数据的key经过哈希函数计算之后对16384取余可定位到对应的节点。 【集群节点之间的交互协议】\n为什么用Gossip协议 分布式信息传播：每个节点定期向其他节点传播状态信息，确保所有节点对集群的状态有一致视图 (采用ping 发送 和 pong 接受，就像检查心跳一样 ) 低延迟、高效率：轻量级通信方式，传递信息很快 去中心化：没有中心节点，任意实例(主节点)都可以作为请求入口，节点间相互通信。 Gossip协议工作原理 状态报告和信息更新：特定时间间隔内，向随机的其他节点报告自身情况 （主从关系、槽位分布）。其他节点接收到之后，会相应的更新对应的节点状态信息 节点检测：通过周期性交换状态信息，可以检测到其他节点的存活状态。预定时间内未响应，则标记为故障节点。 容错处理：如果某个节点故障之后，集群中的其他节点可以重新分配槽位，保持系统的可用性 【哈希槽的相关机制】\n假定集群中有三个节点，Node1 (0 - 5460)、Node2(5461-10922)、Node3(10923-16383)\n集群使用哈希槽的流程如下：\n计算哈希槽 使用CRC16哈希算法计算user:0001的CRC16的值 将CRC16的值对16384进行取余 (哈希槽 = CRC16 % 16383) 假如CRC16为12345，哈希槽 = 12345 % 16383 = 12345 确定目标节点 ：查询到12345为Node3的存储的键，向该节点发送请求 当前非对应节点 ：假设当前连接的节点为Node1，Node1将返回MOVED错误到客户端，并让客户端根据MOVED携带的Node3的信息(ip和端口)重新进行连接，最后从新发送GET user:0001请求，获得结果。 3. Redis的哨兵机制（Sentinel）是什么？ 【哨兵作用】\n监控：哨兵不断监控主从节点的运行状态,定时发送ping进行检测 故障转移: 当主节点发生故障时, 哨兵会先踢出所有失效的节点, 然后选择一个有效的从节点作为新的主节点, 并通知客户端更新主节点的地址 通知: 哨兵可以发送服务各个节点的状态通知，方便观察Redis实例的状态变化。（比如主节点g了，已经更换为新的主节点） 【哨兵机制的主观下线和客观下线】\n主观下线：哨兵在监控的过程中，每隔1s会发送 ping 命令给所有的节点。如果哨兵超过down-after-milliseconds 所配置的时间，没有收到 pong 的响应，就会认为节点主观下线。\n客观下线：某个哨兵发现节点主线下线后，不能确认节点是否真的下线了（可能是网络不稳定），就询问其他的哨兵是否主观下线了。等待其他哨兵的确认，进行投票，如果超过半数+1 (总哨兵数/2 + 1)，就认定为客观下线。\n【注】客观下线只对主节点适用，因为从节点也没必要这样子判断，g了就g了呗。\n【哨兵leader如何选举】\n哨兵leader是采用分布式算法raft选出来的。具体流程如下：\n候选人：当哨兵判断为主观下线，则可以当选候选人 投票：每个哨兵都可以投票，但是只能投一票。候选者会优先投给自己。 选举：选取投票结果半数以上的候选人作为leader (哨兵一般设置为奇数，防止平票) 【主节点如何选举】\n哨兵判断主节点客观下线之后，会踢出所有下线的节点，然后从有效的从节点选新的主节点。选取依据如下：\n优先级：按照从节点的优先级 slave-priority，优先级的值越小越高。 主从复制offset值：如果优先级相同，则判断主从复制的offset值哪一个大，表明其同步的数据越多，优先级就越高。 从节点ID：如果上述条件均相同，则选取ID较小的从节点作为主节点。 4. Redis Cluster 集群模式与 Sentinel 哨兵模式的区别是什么？ Cluster集群模式：集群模式用于对数据进行分片，主要用于解决大数据、高吞吐量的场景。将数据自动分不到多个Redis实例上，支持自动故障转移（如果某个实例失效，集群会自动重写配置和平衡，不需要手动进行调整，因为内置了哨兵逻辑） Sentinel哨兵模式: 哨兵模式用于保证主从节点的高可用，读写分离场景。如果主节点宕机，哨兵会将从节点升为主节点。 5. Redis 在生成 RDB 文件时如何处理请求？ 首先，Redis生成RDB文件的操作是异步的，由fork子线程进行，主线程用于处理客户端的请求。下面具体说明生成RDB文件的流程\n【生成RDB文件原理】\n使用bgsave命令，开启fork子线程进行操作 fork子线程会复制主线程对应的页表（里面包含了需要操作数据的物理地址） 如果过程中，主线程接收到写命令，需要修改数据。主线程会将对应数据的所在页面复制一份，子线程仍然指向老的页面。（老的数据才叫数据快照） 【注意事项】\nRDB处理的时间比较长，过程中会发生大量的磁盘I/O和CPU负载。如果RDB生成的时间过长，并且Redis的写并发高，就可能出现系统抖动的现象，应该选取Redis使用频率较低的时间段生成RDB文件。\n[补充] 5. Redis的持久化机制有哪些？ Redis的持久化机制分为三种，RDB 、AOF 和 混合持久化这三种方式。不过 RDB 和 AOF 各有优缺点，所以一般不会单独使用，而是采用混合持久化机制。\n持久化方案 说明 优缺点 适用场景 RDB 数据快照 将内存当中的数据定期保存为dump.rdb， 记录某个时刻的数据快照 文件小，性能高，恢复快。但是数据丢失风险高，fork会阻塞主进程。 适合低频备份的场景，比如冷备份，灾难恢复，全量数据加载(主从复制) AOF 追加日志 将每个写操作记录到日志文件appendonly.aof， 通过重放日志文件恢复数据 数据更安全，文件可读性强。但是文件体积大，恢复速度慢，性能开销大 适合对持久化实时性要求高的场景，例如金融交易，用户数据保存等。 混合持久化 结合RDB 和 AOF 的优点，先生成RDB快照文件，再记录快照之后的写操作到日志文件当中。 适合需要快速恢复且尽量保证减少数据丢失的场景，一般用于生产环境 下面具体说一下不同持久化机制的执行过程\n【RDB 持久化】\n定时生成 RDB：Redis定期根据配置触发 RDB 快照 （或者主动用bgsave命令手动触发） fork 子进程： 主进程判断是否有正在执行的子进程，如果有，直接返回。如果没有，则 fork 创建一个新的子进程用于持久化数据 （fork 的过程，主进程是阻塞等待的） 子进程更新RDB文件： 子进程将数据异步写入临时 RDB 文件，完成后替换旧的 RDB 文件。同时发信号给主进程，主进程更新一下 RDB 数据快照的统计消息 【注意】 采用bgsave 而 不采用save 命令的原因是，save 命令在生成 RDB文件的过程中，会阻塞Redis执行其他操作。\n那么子进程在生成RDB临时文件的过程中，如果客户端对Redis发起新的写操作。Redis同样可以处理这些命令, 这种方式就是写时复制技术。\n【写时复制技术】\nRedis在执行bgsave命令的时候，会通过fork 创建子进程。为了节约内存，父子进程是共享同一片内存数据的。创建子进程的时候，会复制父进程的也表，但是页表指向的物理内存还是同一个。当客户端向Redis发起新的写操作时，物理内存会被复制一份。子进程仍然指向之前的内存地址 (数据快照)，主进程指向复制的物理内存地址，并完成写操作。\n【优缺点】\n优点：写时复制技术可以减少子进程的内存消耗，加快创建速度(fork 子进程，会阻塞父进程)。由于子进程共享内存当中的数据，创建后可以直接读取主进程中的内存做数据，然后把数据写入RDB文件。 缺点：客户端在写时复制操作的时候，不会把新的数据记录到RDB文件中。如果Redis在生成RDB文件后，马上宕机，那么主进程新写入的这些数据都丢失了。另外，如果数据被修改，每次复制的过程都会制造两份内存，内存占用就是之前的两倍了。 【AOF 日志文件生成过程】\nAOF 是通过把Redis的每个写操作追加到日志文件 appendonly.aof 实现持久化的方式。Redis每次重启时,会重放日志文件的命令来恢复数据。口诀：先写内存，再写日志， 过大重写。\n先写内存：每次写操作都会被写入内存的AOF缓冲当中 再写日志：然后从AOF 缓冲中同步到磁盘 (三种写回策略) 过大重写：当AOF 文件过大的时候，Redis会触发AOF 重写，将冗余命令合并，生成新的AOF 文件 【注意】 先写内存，再存日志可以避免额外的检查开销 (只存执行成功的指令)，而且不会阻塞当前操作，指令只想成功后，才将命令记录到AOF日志文件。但是如果还没写完AOF 文件就宕机了，会导致数据丢失。执行写命令和记录到日志都是主线程操作，可能会造成阻塞风险。\n写会策略配置 写回时机 作用 always 同步写回 每次都fsync 同步数据到磁盘，性能最低。如果写入AOF文件期间Redis宕机，则无法通过AOF 进行恢复 everysec 每秒写回 每秒调用一次fsync写回磁盘，安全和性能居中，Redis最多丢1s的数据 no 操作系统决定写回时间 性能高，安全性低 【AOF重写机制】 当Redis检测到AOF 文件过大的时候，会触发AOF 重写机制\n创建子进程：Redis通过BGREWRITEAOF命令创建一个子进程来进行AOF 重写 生成新AOF 文件：子进程基于当前数据库状态，将每个键的最新值转换为写命令，并写入AOF文件 处理新写入的命令：重写期间，把客户端新的写操作同时追加到现有的AOF文件和缓存区的AOF重写缓冲里面 合并新的写入指令：子进程完成AOF文件重写之后，需要确保AOF文件当中的写操作都是最新的。 替换旧的AOF 文件： 最后用新的AOF文件替换旧的AOF文件 **【MP-AOF】**Redis 7.0 采用 Multi-Part Append Only File 解决 AOF 当中的内存开销大(AOF 缓存和AOF 重写缓存包含大量重复数据)、CPU开销大(主进程需要耗时将数据写入AOF 重写缓存，然后传给子进程，子进程要耗时把AOF 重写缓存写入新的AOF 文件)、磁盘开销大(同一份数据会被写入两次，一次写入当前AOF文件，另一次写入新AOF 文件)。其处理过程如下：\n将一个AOF文件拆分成多个文件\n一个基础文件 basefile, 代表数据的初始快照 一个增量文件 incremental files，记录自基础文件创建以来的所有写操作， 可以有多个该文件 基础文件和增量文会放到一个单独的目录中，并且由一个清单文件 manifest file 进行统一跟踪和管理 该方案可以避免写入多个和AOF相关的缓存，子进程独立写基础AOF文件，进程之间无交互，不用切换上下文。\n【为什么Redis需要持久化】 Redis是基于内存的数据库，所有数据存储在内存里面。如果Redis发生了宕机事件，内存中的数据就会全部丢失。为了保证数据的安全，Redis采用持久化机制，让数据保存在磁盘中，方便宕机后进行恢复。如果没有持久化机制，Redis需要从数据库(MySQL)当中恢复数据, 可能会出现下面的问题：\n**性能瓶颈 + 恢复缓慢 **：后端数据库无法向Redis一样快速提供数据。如果数据量比较大，恢复就会变得非常缓慢。 系统压力：恢复的过程比较久，就会给数据库带来很大压力，影响其他的业务。 6. Redis集群会出现脑裂问题吗？ 脑裂定义: 在网络分区的情况下，Redis同一个集群的实例当中出现多个主节点，导致数据不一致。\n脑裂发生的原因：比如当前集群实例是一主+两从的模式，当网络发送分区，分为A区和B区。主节点(原)被分到A区,其他节点和哨兵集群都在B区。哨兵机制无法检测到A区的原主节点, 只能重新选取新的主节点(新)。此时，集群当中就有两个主节点，A区的主节点(原)被写入的新数据不会同步到B区的节点上。会出现数据不一致的情况。\n如何避免脑裂：min-slaves-to-write 主节点写操作所要求有效从节点个数、min-slaves-max-lag 从节点的最大延迟。比如 min-slaves-to-write = 3 和min-slaves-max-lag = 10 表明需要至少3个延时低于10s的从节点才可以接受写操作。\n【注意】脑裂并不能够完全避免，比如说在选举主节点的过程中，主节点(原)突然恢复了，然后发现主节点和从节点的延迟都不超过10s，客户端正常在主节点(原)进行写操作。等选举完毕，选出新的主节点，让主节点(原) slaveof 为从节点。选举时间写入的数据会被覆盖，就出现了数据不一致的现象。\n7. Redis如何实现分布式锁？ 分布式锁原理：Redis分布式锁由set ex nx 和 lua 脚本组成，分别对应加锁和解锁操作\n为什么用 set ex nx：某个进程对指定key执行 set nx 之后， 返回值为1，其他进程想要对相同的key获取锁，会发现key已存在，返回值为0。这样就是实现了上锁的操作。但是，如果A进程上完锁突然挂了，其他进程就永远不可能拿到锁。所以，设置一个ex过期时间，让其不要一直占用着锁。\n【注意】set ex nx设置value的时候，必须采用唯一值，比如uuid。 不然可能出现如下情况:\nA进程正常申请锁，值设为1。 A进程上锁后, 执行过程时间比较长, 以至于锁已经过期了, A进程还没执行完. 此时，B进程申请锁，值也设为1. 同时，A进程执行完毕, 使用lua脚本把锁删除了 B进程此时还在执行程序，一脸懵逼。（不是，哥们儿，我锁呢？谁偷了我的锁！！！） 为什么用 lua 进行解锁：如上述注意事项所说的一样，A进程执行完毕之后, 会删除锁. 假如他们的值都采用了uuid保证了唯一性。可能会出现下面的情况\nA进程先判断key和其值是否为对应的uuid，然后再删除锁. A进程准备删除锁之前, 锁过期了. B进程同时获取了锁 A进程再删除了该锁 (B进程申请的锁)，发生了误删的现象 所以需要用lua脚本保证解锁的原子性，就可以避免上述问题\n8. Redis的Red Lock是什么？你了解吗? Red Lock定义: 一种分布式锁的实现方案，主要用于解决分布式环境中使用Redis分布式锁的安全性问题 为什么用Red Lock: 假如我们采用一主+两从+哨兵方式部署Redis，如果有A进程在使用分布式锁的过程当中，主节点发送了主从更换，但是原主节点的锁信息不一定同步到新主节点上。所以当前新主节点可能没有锁信息，此时另外的B进程去获取锁，发现锁没被占，成功拿到锁并执行业务逻辑。此时两个竞争者（A和B进程）会同时操作临界资源，会出现数据不一致的情况。 Red Lock实现原理 : 假如当前有五个实例，不需要部署从节点和哨兵，只需要主节点。注意当前的五个实例之间没有任何关系，不进行任何的信息交互 (不同于Redis Cluster集群模式)。对五个实例依次申请上锁，如果最终申请成功的数量超过半数(大于总数/2 + 1)，则表明红锁申请成功。按照下面的流程进行操作： 客户端获取当前时间 t1 客户端依次对五个实例进行set ex nx 操作，锁的过期时间为 t_lock (远小于锁的总过期事件)。如果当前节点请求超时，则立马请求下一个节点。 当获取的锁超过半数，则获取当前的时间 t2。获取锁的过程总耗时t = t2 - t1。如果t小于锁的过期时间 t_lock，则可以判断为加锁成功，否则加锁失败。 加锁成功，则执行业务逻辑。若加锁失败，则依次释放所有节点的锁。 Red Lock是否安全：先说结论，不一定安全\n当前有两个客户端(Client1 和 Client2)，首先Client1 正常获取锁，然后突然被GC执行垃圾回收机制了。在GC的过程当中，Client1 的锁超时释放了，Client2开始申请并获得锁。然后Client2 写入数据并释放锁。 后面Client1 在GC 结束之后又写入数据， 此时就出现了数据不一致的情况。\n9. 说说 Redisson 分布式锁的原理? 【Redisson分布式锁定义】\nRedisson分布式锁是一种基于Redis实现的分布式锁，利用Redis的原子性操作来确保多线程、多进程或多节点系统中，只有一个线程能够获得锁。避免并发操作导致的数据不一致问题。\n主要可以分为四个部分来讲：锁的获取、锁的续期、可重入锁、锁的释放\n【锁的获取】\n执行 exist ，判断锁是否存在 若存在 -\u0026gt; 第 2 步 若不存在 ，说明当前锁别其他进程占用 -\u0026gt; 使用pttl查询锁剩余的过期时间，后续可以再次获取， 执行hincrby，设置重入计数为1 （可重入锁才有这一步操作） 执行pexpire， 设置锁的过期时间 （为了防止任务还没执行完，锁就过期了。Redisson实现了用看门狗机制来为锁进行自动续期） 【可重入锁】\n一般是在线程已经获取锁的基础上，为了后续还能拿到锁。因为假如increment()和anotherMethod都需要用到Counter锁。当increment()拿到锁之后，又调用anotherMethod()又需要获取锁。如果不能二次获取锁，那就陷入死锁了。所以，Redisson才搞了可重入锁\npublic class Counter { private int count = 0; public synchronized void increment() { count++; anotherMethod(); } public synchronized void anotherMethod() { // 可以再次获取相同的锁 count++; } } 可重入锁是在获取锁的基础上，多了一层逻辑。具体实现如下：\n实现锁的获取的所有功能 执行hexist 判断是否锁已经存在，且唯一标识匹配(线程id相关)，所以不能直接用exist判断锁是否存在 如果自己的锁存在，用hincrby把重入次数加一 用pexpire，设置锁的过期时间 如果没有获取成功锁，就和上面一样，用pttl查询锁的过期剩余时间 【锁的释放】\n用hexist判断线程自己的锁是否存在，需要判断唯一标识 如果存在 -\u0026gt; 第2步 如果不存在 -\u0026gt; 直接返回，不需要做解锁操作，因为是别人的锁 用hincry减少一次锁的可重入次数 (增加-1 就是减少一次) 判断锁的可重入次数是否大于 0 如果大于 0， 说明还有函数在使用这个锁，则重新设置过期时间 如果等于 0 -\u0026gt; 第4步 用 del 删除对应的key 用 publish 广播通知其他等待锁的进程，此时释放锁了 【Redisson锁的类型】\n公平锁：和可重入锁类似，确保多个线程按请求顺序获得锁 读写锁: 支持读写分离，多个线程同时获得读锁，而且锁是独占的 信号量与可数锁: 允许多个线程同时持有锁，适用于资源的限流和控制。 10. Redisson 看门狗（watch dog）机制了解吗？ 【为什么用看门狗机制】\n因为如果进程获取锁之后，用户的业务逻辑还没有执行完成，锁就过期了。此时，其他进程抢占临界资源，会导致数据不一致的问题。\n【看门口机制的执行流程】\n判断用户是否设置过期时间 (判断 leaseTime \u0026gt; 0 ，默认 leaseTime 为 -1 ) 如果设置了过期时间，不启用看门狗机制，等到指定的过期时间，锁自动释放。 如果没有设置过期时间 -\u0026gt; 第2步 Redssion会启动一个定时任务，用于自动续期锁的过期时间。 定时任务中，设置锁的超时时间默认为30s， 每间隔总时长的1/3，也就是10s。定时任务会自动锁进行续期，续期时间为30s 当客户端主动释放锁，那么Redisson就会取消看门狗机制。 【注意】 如果客户端主动释放锁之前，服务器突然宕机了，定时任务没法儿继续执行。等看门狗机制设置的过期时间到了，锁就自动释放了。所以，不会出现一直占用锁的情况。\n11. Redis 实现分布式锁时可能遇到的问题有哪些？ 业务未执行完，锁提前到期：用户的业务逻辑还没执行完毕，锁提前过期了。被其他的进程获取了锁，同时抢占临界资源，可能出现数据不一致的情况。\n【解决方法】\n通常要保证用户的业务逻辑需要在锁过期之前执行完，因此需要把锁的过期时间稍微设大一些。也不能太大，这样其他程序就拿不到锁，就会降低系统的整体性能。或者使用Redisson分布式锁，会自动调用看门狗机制，定时续期锁，直到任务执行完毕，就不续期锁了。\n单点故障问题：如果只部署了一个Redis节点，当实例宕机或者不可用的时候。整个分布式锁服务将无法完成工作，阻塞业务的正常执行。\n【解决方法】\n可以利用Redis Cluster集群机制，部署多个Redis实例，采用一主+两从的哨兵机制。当某个实例宕机时, 哨兵会自动选举新的有效节点作为主节点。\n主从同步但锁未同步问题：主从复制的过程是异步实现的，如果Redis主节点获取到锁，但是还没同步到从节点。此时，主节点突然宕机，然后哨兵选择新的主节点。但是，由于主从同步没有完成，现在其他客户端可以正常获取锁。就会导致多个应用同时获取锁，会出现数据不一致的问题。\n网络分区问题：在网络不稳定的情况下，客户端和Redis可能会中断再重连。如果没有设置锁的过期时间，那么可能导致锁无法正常释放。如果有多个锁，可能还会引发死锁的现象。\n【多锁死锁现象】\n有两个资源A和B，分别由锁LockA和LockB保护。\n客户端1先获取LockA，然后尝试获取LockB。\n客户端2先获取LockB，然后尝试获取LockA\n如果客户端1拿到了LockA，客户端2拿到了LockB。突然网络不稳定，锁无法正常释放。然后客户端1等待LockB，客户端2等待LockA，就会形成死锁。\n时钟漂移问题：因为Redis分布式锁依赖锁的过期时间来判断是否过期，如果出现时钟漂移，很可能导致锁直接失效。\n【解决方法】\n让所有节点的系统时钟从NTP服务进行同步，减少时钟漂移的影响。\n可重入问题：某个进程可能有多次调用锁，如果锁不能重入的话。当进程获取到锁后，再次申请获取锁，获取不到就死锁了。\n12. Redis为什么这么快? 基于内存: Redis存储的所有数据都存在内存里面，内存的访问速度比硬盘快，提升了读写速度 单线程模型 + I/O多路复用： Redis采用单线程+I/O多路复用的方式，避免了线程上下文切换和竞争条件，提高了并发处理效率 高效数据结构：提供String、List、Hash、Set、Sorted Set 五种数据结构，他们的操作复杂度大部分为O(1) 异步持久化: 持久化操作由子线程异步完成，减少了持久化对主线程的影响，提升了整体性能。 【注意】Redis从6.0开始对网络处理引入了多线程机制，提高I/O性能。网络请求可以并发处理，减少网络I/O等待的影响。但是，Redis 仍然保持了核心命令处理逻辑的单线程特性。\n【I/O多路复用技术】\nLinux多路复用技术允许多个进程的I/O注册到同一管道和内核交互，准备好数据之后再copy到用户空间，实现一个线程处理多个I/O流。 Linux下I/O多路复用有select、poll、epoll 三种，功能类似，细节不同 13. 为什么 Redis 设计为单线程？6.0 版本为何引入多线程？ 【Redis采用单线程的原因】\n基于内存操作，Redis的瓶颈主要是内存，多数操作的性能瓶颈不是CPU带来的 (增加多线程也没啥用) 单线程模型的代码简单，可以减少线程上下文切换的性能开销。 单线程结合I/O多路复用模型，能提高I/O利用率 【注意】 Redis的单线程是指网络请求模块和数据操作模块是单线程的, 但是持久化存储模块和集群支撑模块是多线程的。\n【为什么引入多线程】\n随着数据规模和请求量的增加，执行瓶颈主要在网络I/O部分。引入多线程可以提高网络I/O的速度。但是，Redis内核去还是保持单线程处理，比如读写命令部分还是单线程，所以线程安全问题就不存在了。\n【Redis多线程I/O场景下的结构】\n14. 如何使用Redis快速实现布隆过滤器? Redis可以使用位图Bitmap或者用Redis模块RedisBloom来实现布隆过滤器\n位图 bitmap 实现 bitmap 本质是一个位数组，提供了setbit和getbit来设置和获取某个值，可以用来标识某个元素是否存在 对应给定的key，可以用哈希函数来计算位置索引。如果位图中的值为1， 表示该元素可能存在 RedisBloom 模块实现：封装了哈希函数和位图大小，可以直接用于创建和管理布隆过滤器 【布隆过滤器原理】\n布隆过滤器是由一个位数组+k个独立的哈希函数组成。每次验证某个key对应的数据是否存在的时候，需要k个哈希函数都对其进行运算，如果位数组中的值都为1，说明该key对应的数据可能存在。只要有一个位置不为1， 就说明key对应的数据一定不存在。\n为什么k个函数查到的值都为1， 也不能说明key对应的数据一定存在呢？\n因为可能存在哈希冲突，比如key 和 key1 的k个hash函数的值都为1。但是key对应的数据在数据库里面，但是key1的数据不在数据库里面。\n15. Redis 中常见的数据类型有哪些？ 【Redis常见的五种数据结构】\n数据结构名称 底层 特性 适用场景 String SDS 简单动态字符串 String字符串 1.缓存数据：缓存Session、Token、序列化后的对象\n2. 分布式锁:set ex nx\n3.计数：用户单位时间访问次数，页面单位时间访问次数 List ListPack / QuickList / ZipList / LinkedList 双向有序链表，各节点都包含字符串 1. 信息流展示：历史记录、更新文章、更新动态\n2.消息队列：不推荐，缺陷多 Hash Dict / ZipList 无序散列表，存储键值对 存储信息：用户、商品、文章、购物车信息 Set Dict / Intset 无序去重集合，包含不同的字符串 1.不重复数据：点赞次数、下单次数\n2.共同资源：共同好友、统统粉丝、共同关注 (交集、并集)\n3.随机抽取: 抽奖系统、随机点名 ZSet ZipList / SkipList 跳表 + HashTable哈希表 有序集合，value包含member 成员和score分数，按照score 进行排序 1.各类排行榜：点赞排行版、热门话题排行榜\n2. 优先级/重要程度: 优先级队列 【其他数据结构】\n数据结构名称 特性 适用场景 BitMap 存储二进制数据，0 和1 1. 布隆过滤器： 防止缓存穿透\n2. 签到统计： 每日签到用 1 标记，未签到用0标记，可以快速统计某日签到人数和连续签到天数 HyperLogLog 基于概率算法实现，存储海量数据进行计数统计 一般用于页面的页面浏览量PV和独立访客数UV， 快速估算访问量 GEO 存储地理位置信息，经纬度坐标和位置名称 一般用于计算不同位置的距离，比如外卖单中计算配送距离 Stream 能够生成全局唯一消息id的消息队列 用于可靠消息传递、异步任务处理的场景 16. Redis 中如何保证缓存与数据库的数据一致性？ 为了保证缓存和数据库的数据一致性，有这么几种方案：\n先修改缓存，再修改数据库\n事务A准备修改指定id的 name 为 小张 ，先修改缓存 事务B准备修改指定id的 name 为 小王，先修改缓存, 然后修改数据库为小王 事务A修改数据库为 小张 (网络延迟)， 此时出现数据不一致的情况 先修改数据库，再修改缓存\n事务A准备修改指定id的 name 为 小张 ，先修改数据库 事务B准备修改指定id的 name 为 小王，先修改数据库, 然后修改缓存为小王 事务A修改缓存为 小张 (网络延迟)， 此时出现数据不一致的情况 先删除缓存，再修改数据库\n事务B读取指定id的name， 发现找不到缓存，读取数据库中的数据为小王\n事务A准备修改指定id的 name 为 小张 ，先删除缓存，然后修改数据库为 小张\n事务B修改缓存为小王 (读到空数据，返回来写)，此时出现数据不一致的情况\n先修改数据库，再删除缓存：基本不会出现问题 （除非删除缓存的请求失败）\n延迟双删，先删除缓存，再修改数据库，再删除缓存： 难以评定休眠时间\n如果要保证数据库和缓存的强一致性怎么办？\n用消息队列：把写策略里面的删除缓存操作加入到消息队列中，让消费者来操作数据。如果删除失败，则可以冲消息队列中重新读取，在一定重试次数下删除成功的话，将该消息删除。 （确保删除缓存成功） binlog + Canal: 模仿MySQL主从同步的方式，结合Canal 订阅MySQL的binlog。其实就是等MySQL写入数据库, 然后去删除缓存。 如果需要避免缓存失效 (比如热点Key), 如何设计呢?\n分布式锁：同一时间只允许一个请求更新缓存，确保缓存和数据库一致。但是，可能会降低写性能 添加短暂过期时间：在先修改数据库再修改缓存的基础上，给缓存加一个短暂的过期时间，确保缓存不一致的情况时间比较少。 17. Redis 中跳表的实现原理是什么？ 跳表是由多层链表组成的，它是Redis中 ZSet 的底层结构。最底层存所有的元素，上层是下层的子集 (可以理解成一种索引)。跳表的插入、删除、查找操作，实现方式如下：\n查找：从最高层开始，通过范围确定位置，逐层向下查找，时间复杂度为 O(log n) 插入：从最高层开始，先逐层向下找到存放位置，然后随机确定新节点层数，插入并更新指针 删除：从最高层开始，通过范围确定位置，在各层更新指针保持结构 【Redis跳表结构】\nRedis的跳表相对于普通的跳表多了一个回退指针, 而且 score 是可以重复的。\n首先，我们可以看一下跳表的节点实现的原理\ntypedef struct zskiplistNode { //Zset 对象的元素值 sds ele; // 采用Redis字符串底层实现sds,用于存储数据 //元素权重值 double score; //后退指针 struct zskiplistNode *backward; // 用于指向前一个节点 //节点的level数组，保存每层上的前向指针和跨度 struct zskiplistLevel { struct zskiplistNode *forward; unsigned long span; // 当前层的跨度值 } level[]; } zskiplistNode; 上面的图片看起来比较抽象，可以按照下面的图片进行理解。上述的查找、删除、插入操作，其实都是先从level[0] 开始进行遍历，然后找到合适的位置。再往下进入level[1]进行遍历，再找到合适的位置。一直重复这个操作，直到进入最底层，然后就可以确定位置了。\n然后，我们来看一下跳表的底层实现原理\ntypedef struct zskiplist{ struct zskiplistNode *header, *tail, // 头节点和尾节点 unsigned long length,\t// 跳表长度 int level; // 跳表的最大层数 } zskiplist; 【注意】跳表的头节点、尾节点、跳表长度、跳表的最大层数都可以在o(1)时间复杂度进行访问\n【跳表查询过程细节】\n从头节点的最高层开始，逐一遍历每一层 遍历某一层节点时，根据节点的 SDS 类型元素和元素权重进行判断 如果当前节点权重 \u0026lt; 要查找的权重， 继续向前遍历 如果当前节点权重 = 要找的权重 \u0026amp;\u0026amp; 当前节点的 SDS 类型数据 \u0026lt; 要查找的数据，继续向前遍历 如果上面两个条件都不满足或者下一个节点为空，则跳到下一层level数组里面，继遍历续查找 如果当前当前节点权重 = 要找的权重 \u0026amp;\u0026amp; 当前节点的 SDS 类型数据 = 要查找的数据， 返回当前节点值，查询结束 【跳表的插入细节】\n参数检查和初始化：检查要插入的节点的score是否为NaN，初始化遍历指针x指向跳表的头节点，定义update 数组记录每层查找的最右节点 (后续要修改它的指针)，rank 数组记录每层跨越的节点数。 查找插入位置：和上面查找过程一样，从最高层开始，逐层往下查询。每一层中，把满足条件的最右节点记录在 update 数组中，并更新 rank 数组记录跨越的节点数。 生成新节点层数：调用zsRandomLevel 函数生新节点的随机层数。如果新节点层数 \u0026gt; 当前跳表总层数，则更新跳表最大层数，并初始化新增层的update 和 rank 数组数据。 创建并插入新节点：创建新节点，根据 update 和 rank 数组信息，在每一层插入节点，设置forward 指针 和 span 跨度值 更新其他节点的span值：对于没有触及到的层，更新 update 节点的 span 值 设置前后指针：设置新节点的backward指针，指向下一个节点。如果下一个节点为空，则更新跳表的tail指针。 更新跳表的长度：跳标的节点数 + 1， 返回插入的新节点指针。 【为什么ZSet要用跳表不用哈希表和平衡树】\n主要有三个原因：\n内存更少：跳表相比B树可以占用更少的内存，主要取决于如何设置节点层数的概率参数 局部性良好：跳表在执行ZRANGE 和 ZREVRANGE 等操作时，其缓存局部性表现良好，不比其他平衡树差 实现简单：跳表的代码更简单和易于调试 18. Redis Zset 的实现原理是什么？ ZSet 的实现方式有两种，第一种是压缩列表 Ziplist / 紧凑列表 Listpack，另一种是跳表 skiplist + 哈希表 HashTable。主要判断条件如下：\n元素数量 \u0026lt; zset-max-ziplist-entries zset压缩列表最大键值对个数 (默认是128) 每个元素大小(key 和 value 的长度) \u0026lt; zset-max-ziplist-value (默认为64) 【ZSet压缩列表结构】\nZSet 的 压缩列表结构和数组很相似，用一段连续的内存空间存储数据。每个节点都占用相邻的一小段内存，节点之间通过内存偏移量而非指针记录相对位置。\n【注意】压缩列表比传统的链表更加节省内存，但是压缩列表也有明显的缺点，它的修改成本高。\n倒序遍历都需要依赖上一个节点的长度prevlen，如果当前节点有修改，后续节点就需要修改prevlen 当prevlen \u0026gt; 当前节点编码类型的最大大小时，就需要改变编码类型，重新分配内存 后继节点重新分配内存后，其他后面的节点都会面临同样的情况，导致发生连锁更新。 压缩列表的头部分别有记录了三个重要属性：\n列表大小zlbytes: 整段列表在内存中占用的字节数 尾节点位置 zltail：从队列头到最后一个节点起始位置的内存偏移量。 节点数量 zllen： 总共的节点个数 每个节点当中又可以化分为三个部分：\n上一节点长度 prevlen：用于倒序遍历时确认上一节点的位置 节点编码 encoding：同时记录了长度和编码类型 数据 data：节点中存放的数据 【ZSet紧凑列表结构】\n紧凑列表的头部分别有记录两个重要属性：\n列表大小size: 整段列表在内存中占用的字节数 列表元素数量num：总共的元素个数 每个节点当中又可以化分为三个部分：\n节点编码 encoding：同时记录了长度和编码类型 数据 data：节点中存放的数据 节点长度len：节点编码encoding + 数据data的总长度。正向或反向遍历都依赖它完成 紧凑列表相比压缩列表的优点：无需记录上一节点的长度，上一节点重新分配内存后，本身节点无需做任何修改。\n【跳表 + 哈希表】\n当ZSet 处理比较大的数据的时候，会选择跳表+哈希表的方式。其中，跳表的节点保存指向member的指针和score，哈希表保存member和score之间对应的关系，方便实现高效的随机查找和范围查找。\n跳表的具体实现细节可以参考17. Redis Zset 的实现原理是什么？\n19. Redis 的 hash 是什么？ Hash 是 Redis五大常规数据结构(String、List、Hash、Set、ZSet)的一种，主要用于存储key-value 键值对集合。Hash 一般会用来存储商品的属性、用户的信息等等。\n【Hash底层数据结构】\nHash 的底层数据结构要分为Redis 6.0 和 7.0来看\nRedis 6.0: 压缩列表 zipList + 哈希表 HashTable Redis 7.0: 紧凑列表 Listpack + 哈希表 HashTable 当Hash当中的数据达到指定的阈值的时候，就会从压缩列表zipList/紧凑列表ListPack 转为哈希表HashTable。当满足下面两个条件的时候才能用压缩列表zipList/紧凑列表ListPack\n哈希类型的个数 \u0026lt; 哈希紧凑列表最大键值对个数 hash-max-listpack-entries (默认是512) 哈希的 key 和 value 的长度 \u0026lt; hash-max-ziplist-value 64 【为什么Hash会选择压缩列表 zipList /紧凑列表 ListPack呢?】\nHash 结构采用压缩列表 zipList /紧凑列表 ListPack的主要目的应该是基于省内存的角度去考虑。主要有两个原因吧：\n内存占用少： 压缩列表 zipList 和 紧凑列表 ListPack 都属于紧凑型的内存结构，没有哈希表那样存在额外的指针开销。哈希表为了维持快速查找的特性，内部才用了链表解决哈希冲突，每个哈希桶的内部都会带有指针，比较占用内存空间。另外的两个数据结构主要通过将数据存储在一块连续的内存，利用了计算机的局部性原理，从而使得内存占用最小。 时间复杂度：哈希表的访问速率是O(1)，但是如果冲突比较多，最坏也会降到(O(n))。因为冲突之后，就需要遍历链表或者查红黑树。但是 压缩列表 zipList 和 紧凑列表 ListPack 是连续数组存储，肯定能在O(1)的时间找到这个元素 【Redis中HashTable的结构】\nHashTable 就是由哈希表数组实现的，查询时间复杂度为O(1)， 效率比较快。具体数据结构如下\ntypedef struct dictht { //哈希表数组 dictEntry **table; //哈希表大小 unsigned long size; //哈希表大小掩码，用于计算索引值 (index = hash(key) \u0026amp; sizemask), sizemask = size - 1 unsigned long sizemask; //该哈希表已有的节点数量 unsigned long used; } dictht; 哈希节点dictEntry 由三个key、value 和 下一个哈希节点指针next组成\ntypedef struct dictEntry { //键值对中的键 void *key; // 键值对中的值 union { void *val; // 用于指向实际值的指针，比如存放string uint64_t u64; int64_t s64; double d; } v; //指向下一个哈希表节点，形成链表 struct dictEntry *next; } dictEntry; 【渐进式扩容rehash】\nRedis中的hash表结构会随着数据量的增大而扩容, 将数组的大小扩张为原来的两倍。在扩张的过程当中，由于容量的变化，会导致之前的节点，移动到新的位置，这个变化的过程就是 rehash 实现的。\nrehash 扩容的过程可以分为一下三步:\n增加哈希表2的空间：给哈希表2分配空间，一般是哈希表1的两倍。此时，rehash 索引的值rehashidx 从 -1 暂时变成 0。 迁移数据：将哈希表1的数据迁移到哈希表2 （迁移的过程，一般是在对指定节点做增删改查的时候，所以叫渐进扩容，有点类似 ConcurrentHashMap 的扩容机制），迁移之后，rehashidx + 1。 迁移过程分为多次完成。 释放原哈希表1：迁移完成之后，哈希表1的空间会被释放，并且把哈希表2设置为哈希表1。然后，哈希表2再创建一个空白的哈希表。为下一次 rehash 做准备。 【注意】 rehash的出发条件和其负载因子相关，负载因子 = 已存储的哈希表节点数量 / 哈希表总容量 。当达到下面的任一条件就可能触发。\n负载因子 \u0026gt;= 1 ， 资源相对紧张，如果Redis没有在执行bgsave 和 bgrewriteAOF 命令 (生成RDB文件和AOF文件)，就会触发 负载因子 \u0026gt;= 5，资源非常紧张，直接触发 20. Redis String 类型的底层实现是什么？（SDS） Redis中的 String 类型的底层实现是简单动态字符串 SDS, 结合 int 、embstr 、raw等不同的编码方式进行优化存储。\n【简单动态字符串 SDS 结构】\nlen 字符数组长度：表示整个 SDS 字符串数组的长度，获取长度时直接返回该值 (时间复杂度 o(1)) alloc 分配内存： 表示已分配字符数组的存储空间大小，通过alloc - len 可以计算剩余空间。可用于判断是否满足修改要求，解决缓冲区溢出的问题。 flags SDS类型: 一共有 sdshdr5、sdshdr8、sdshdr16、sdshdr32、sdshdr64 五种类型，后面的数字表示2的幂次方，能够灵活存储不同大小的字符串，节省内存空间 buf 存储数据的字符数组： 用于保存字符串，二进制数据等 struct __attribute__ ((__packed__)) sdshdr64 { uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; 【Redis底层结构 redisObject】\nBTW, Redis的底层结构就是redisObject。\nredisObject 包含数据类型，编码类型和数据指针三个元素。其中编码类型，包含int、embstr、raw 等类型\nstruct redisObject { unsigned type:4; // 数据类型（字符串、哈希等） unsigned encoding:4; // 编码类型（int、embstr、raw等） int64_t ptr; // 实际的数据指针，这里直接存储整数值 }; redisObject 的具体编码类型由下面几个条件决定：\n如果字符串对象保存的整数值能用long 类型表示，该对象会把整数值存储到ptr 数据指针指向的long 结构里面 （将 void* 转为 long），并将编码设置为int 如果字符串对象保存的字符串长度 \u0026lt;= 32 个字节，会用 上面提到的sds 保存字符串，并且把对象编码设置为embstr。 如果字符串对象保存的字符串长度 \u0026gt; 32 个字节，也会用上面提到的sds 保存字符串，并且把对象编码设置为raw。 【注意】\n上面32个字节是redis 2.0版本，redis 5.0 版本是44 个字节 embstr 和 raw编码区别：embstr 只调用一次内存分配函数，分配一块连续内存保存redisObject和 SDS。raw 调用两次内存分配函数，分别分配两块内存空间保存 redisObject 和 SDS。 21. Redis 中的缓存击穿、缓存穿透和缓存雪崩是什么？ (缓存三兄弟) 问题类型 说明 解决方案 缓存穿透 查询的数据是不存在的，数据库和缓存都没有。所有的请求都会绕过缓存，直接打到数据库上，可能会遭受恶意攻击。 1.请求参数校验 2. 缓存空值 3. 布隆过滤器 缓存雪崩 大量的缓存同时失效或者Redis宕机了，导致请求直接打到数据库，可能造成系统崩溃。 1. 设置随机过期时间 2.Redis 高可用集群 3.服务熔断或限流 缓存击穿 某个热点数据缓存失效，大量并发请求直接访问数据库，导致数据库压力剧增，性能下降。 1. 互斥锁 2. 逻辑过期 【缓存穿透具体解决方案】\n请求参数校验：如果请求参数含有非法字段，则直接返回错误，避免进一步查询缓存和数据库\npublic boolean validateRequest(String key) { if(key == null || key.isEmpty()) { return false;\t} } 缓存空值：如果查到不存在的数据，也将其存入缓存，value 采用 ”null“ 字符串。后续查询，直接返回给用户。\npublic Object getDataWithEmptyCache(String key) { //先从缓存中获取数据 String value = redisTemplate.opsForValue().get(key); //如果缓存为空 if (value == null) { Object databaseValue = queryFromDatabase(key);\t//从数据库中获取 if (databaseValue == null) { //缓存空值 redisTemplate.opsForValue().set(key, \u0026#34;null\u0026#34;, 60, TimeUnit.SECONDS); return null; } else { redisTemplate.opsForValue().set(key, databaseValue, 3600, TimeUnit.SECONDS); return databaseValue; } } return \u0026#34;null\u0026#34;.equals(value) ? null : value; // 如果是空值缓存，返回 null } 布隆过滤器：写入数据库时用布隆过滤器做一个标记，然后在用户请求的时候，确认缓存失效了。先通过布隆过滤器快速判断数据是否存在，如果不存在就直接返回。但是，布隆过滤器在一定程度上会出现误判。 因为可能会出现哈希冲突，导致一小部分请求穿透到数据库。 可以采用第三方工具类 Guava 实现布隆过滤器 ）\npublic class TestBloomFilter { public static void main(String[] args) { /** * 构造: * 第二个参数: expectedInsertions 期望插入的元素数量 * 第三个参数: 预测错误率 传入 0.01 表示预测正确的概率是 99% * */ BloomFilter\u0026lt;Integer\u0026gt; filter = BloomFilter.create( Funnels.integerFunnel(), 500, 0.01 ); filter.put(1); filter.put(2); filter.put(3); Assert.assertTrue(filter.mightContain(1)); Assert.assertTrue(filter.mightContain(2)); Assert.assertTrue(filter.mightContain(3)); Assert.assertFalse(filter.mightContain(1000)); } /* 当我们设计布隆过滤器时，为预期的元素数量提供一个合理准确的值是很重要的。 否则，我们的过滤器将以比期望高得多的比率返回误报。 让我们看一个例子。 假设我们创建了一个具有 1% 期望误报概率和预期一些元素等于 5 的过滤器， 但随后我们插入了 100,000 个元素： */ @Test public void testOverSaturatedBloomFilter() { BloomFilter\u0026lt;Integer\u0026gt; filter = BloomFilter.create( Funnels.integerFunnel(), 5, 0.01); IntStream.range(0, 100_000).forEach(filter::put); Assert.assertTrue(filter.mightContain(1)); Assert.assertTrue(filter.mightContain(2)); Assert.assertTrue(filter.mightContain(3)); Assert.assertFalse(filter.mightContain(1000000)); //测试不通过 } } 【缓存雪崩具体解决方案】\n缓存雪崩要分为两种不同的情况来解决：大量key同时过期 和 Redis宕机\n【大量key同时过期】\n设置随机的过期时间：写入缓存的时候，给其在基础时间上 + 一个随机的过期时间 互斥锁： 保证同一时间只有一个请求来构建缓存 后台更新缓存：后台采用Scheduled 的方式检查缓存是否失效，如果失效了，就查询数据库更新缓存。 【Redis宕机】\n服务熔断或者限流机制：暂定服务对于缓存服务的访问，直接返回错误。或者启用限流规则，只允许商家请求发送数据库进行处理，过多的请求就会拒接。一般会使用Hystrix 或者 Sentinel 实现熔断或者限流\n@HystrixCommand(fallbackMethod = \u0026#34;fallbackMethod\u0026#34;) public String getDataFromCache(String key) { // 从 Redis 获取数据 return redisTemplate.opsForValue().get(key); } public String fallbackMethod(String key) { return \u0026#34;服务繁忙，请稍后重试！\u0026#34;; // 熔断处理逻辑 } 构建Redis缓存高可用集群: 如果单个缓存服务节点发生故障自动迁移访问流量到另外一个节点.\n【缓存击穿具体解决方案】\n互斥锁：同一时间只允许一个业务线程更新缓存。未获取互斥锁的请求，可以等待锁释放后读取缓存，或者返回空值/默认值。 (对数据一致性要求比较高)\n逻辑过期：不给缓存设置过期时间，value 采用 hash 的方式，设置一个逻辑过期时间。每次判断数据是否过期，未过期直接返回数据。如果已经过期了，则获取互斥锁重建缓存，然后释放锁。如果获取互斥锁失败，则返回已过期缓存数据。\n服务熔断或者限流机制\n22.Redis 数据过期后的删除策略是什么？ 【Redis过期删除策略】\nRedis采用的是 定期删除 + 惰性删除 的结合方式\n策略 实现方式 优缺点 定期删除 Redis每个一段时间 (默认为100ms 随机检查 一定数量的键，非全部key)，过期则删除 可以减少内存占用, 但是对CPU有一定消耗，且不能保证及时删除所有过期键 惰性删除 当客户端访问一个key时，Redis会检查是否过期，若过期则立即删除 对CPU友好，大量过期键未被访问时仍占用内存 【定期删除细节】\nRedis会周期性执行过期key检查，默认每100ms 执行一次 每次检查会随机抽取部分key，默认每次 20 个， 判断是否过期 为了避免过多的CPU占用，Redis限制检查的执行时间 (默认为执行时间的25%，也就是25ms) 和 过期键的比例 (默认只检查 10% ) 如果过期间比例超过限制，则会重复检查以提高清理效率 【为什么Redis删除不直接吧所有过期key都删除了？】\n定期删除不能除所有过期key原因: 如果一次性清理所有过期间,可能会导致Redis长时间阻塞，影响性能。随机抽样和时间限制的方式能在清理内存和性能之间取得平衡。 惰性删除不能删除所有过期key原因：惰性删除旨在访问key的时候触发，如果没有被访问到，就可能一致存在，无法清理。 【如何优化大量key集中过期的情况 - 缓存雪崩】\n设置随机过期时间：设置过期时间的时候，加上一个随机值 开启lazy free 机制： 配置 lazyfree-lazy-expire， 让过期的key删除操作由后台线程异步执行，减少主线程的压力 23. 如何解决 Redis 中的热点 key 问题？ 热点 key 是指访问频率显著高于其他 key 的键，通常表现为以下几种情况：\n类别 特性 QPS 集中 某个key 的QPS (每秒请求量) 占Redis总QPS的较大比例 带宽集中 某个key 的数据量较大(比如1MB 以上的hash 数据)，被频繁请求 CPU消耗集中 某个key的复杂操作(比如ZRANGE查询较大的ZSet数据) 占用Redis过多CPU时间 热点key 问题就是某个瞬间，大量的请求集中访问Redis里的同一个固定key，假如热点key过期，可能会导致缓存击穿，让大量的请求直接打到数据库里面。像热点新闻、热点评论、明星直播 这种读多写少的场景，就很容易出现热点key 问题。因为Redis的单节点查询性能一般在 2w QPS， 一般超过 这个数值，可能就会宕机。\n【热点key的危害】\n消耗CPU和带宽资源： 热点 key 可能占用Redis大部分资源，影响其他请求的处理时间 Redis宕机风险: 如果超过Redis所能承载的最大QPS， 可能会导致Redis宕机。然后大量的请求转发到后端数据库，导致数据库崩溃。 【如何发现热点key】\n根据业务经验判断：比如像明星八卦爆料、重大新闻、热点评论都会能会导致热点key。 好处是不需要消耗什么成本，坏处是无法预防突发情况。 Redis进行集群监控： 查看哪个Redis出现了 QPS 倾斜，出现QPS倾斜的实例有很大概率存在热点key hotkey 监控：命令行执行redis-cli 的时候添加--hotkeys 参数，它是基于scan + object freq 扫描目标出现频率时间的。但是需要设置maxmemory-policy 参数，来采用不同的淘汰手段： volatile-lfu (least frequently used)： 淘汰已经过期数据集中最不常用的数据 allkeys-lfu：当内存不足的时候，移除最不常用的key monitor 命令： 集合一些Redis的日志和相关分析工具进行统计, 非常消耗性能, 单客户端会消耗 50% 的性能 代理层收集：利用有些服务在请求Redis前会先请求代理服务的特点, 在代理层统一收集Redis热key数据。比如采用 京东的 JD-hotkey、有赞透明多级缓存解决方案(TMC) 客户端收集：在操作Redis前添加统计每个key的查询频次，将统计数据发送到聚合计算平台计算，之后查看结果。对性能消耗较低，但是成本比较大，需要介入聚合计算平台。 【如何解决热点key】\n多级缓存：结合使用一级缓存和二级缓存。一级缓存就是应用程序的本地缓存，比如JVM内存中的缓存，可采用Caffeine 、阿里巴巴jetcache )。 二级缓存是Redis缓存，当以及缓存中不存在的时候，再访问二级缓存。\n针对热点key请求, 本地一级缓存可以将同一个key的大量请求，根据网络层负载均衡到不同的机器节点上，避免全部打到单个Redis节点的情况，减少网络交互。但是需要耗费更多的经历去保证分布式缓存一致性，会增加系统复杂度。\n热点key备份：在多个Redis节点上备份热key，避免固定key总是访问同一个Redis节点。通过初始化时为key 拼接 0~2n (n为集群数量) 之间的随机数，让其散落在各个姐电商。若有热点key请求的时候，随机选一个备份的节点进行取值。可以有效减轻单个Redis节点的负担。 热点key拆分：将热点key拆分为多个带后缀名的key，让其分散存储在多个实例当中。客户端请求的时候按照规则计算出固定key，然后请求对应的Redis节点。比如“某音热搜某明星离婚”。可以拆分为多个带编号后缀的key存储在不同的节点，用户查询时根据用户id 算出要访问的对应节点。虽然用户只能看到一部分数据，等待热点降温后再汇总数据，挑选优质内容重新推送给未收到的用户。 【注意】 热点key备份和热点key拆分的区别在于，热点key备份是同一份数据全量复制到其他节点，热点key拆分是把一份数据拆分成多份。\nRedis集群 + 读写分离: 增加Redis从节点, 分散读请求压力。然后利用集群，可以将热点key拆分或者备份到不同的Redis实例上。 限流和降级：采用限流策略，减少对Redis的请求，在必要的时候返回降级的数据或者空值。 24. Redis 中的 Big Key 问题是什么？如何解决？ Redis当中的 Big Key (也可以叫big memory key)是指某个key 对应的value数据量过大，比如包含大量元素的List、Hash、Set、ZSet 或超长字符串), 可能会导致性能瓶颈和系统不稳定。 一般来说，String 类型的value 超过 1MB ，或者符合类型当中的元素超过5000个，就算big key。\n【Big Key 典型场景】\nString: 存储超大JSON文本、图片base64数据等 Hash：存储海量的字段，比如用户的行为记录 List / Set：存储百万个元素 ZSet： 包含大量的排序元素 【Big Key 导致的问题】\n性能问题：Redis是单线程处理机制，在处理big key的时候，需要更长的时间，阻塞工作流程，没法儿处理后面的命令。如果处理的时间过长，会导致客户端长时间未收到响应。另外，big key 占用的带宽过高，传输时间比较长，也容易导致阻塞。 内存问题：big key 会导致Redis内存变得很大，增加内存碎片化风险。单次大对象内存分配失败，可能导致整个Redis服务崩溃。集群模式下，会出现数据和查询倾斜的情况，big key 的 Redis节点会占用较多的内存 持久化问题：如果AOF写回策略为always，也就是说主线程执行完指令之后，把对应数据写入AOF文件后，直接 fsync 写入磁盘操作。如果是一个大key， 阻塞的时间可能比较就，同步到硬盘的过程很耗时。 【如何找Big Key】\n内置--bigkeys： 采用内置的--bigkeys命令，基于scan 查找所有的big key\nredis-cli --bigkeys 使用第三方工具\nhttps://github.com/sripathikrishnan/redis-rdb-tools https://github.com/weiyanwei412/rdb_bigkeys 【如何处理Big Key问题】\nBig Key 问题可以从下面说三个层面来解决：\n开发层面：将数据压缩后再存; 将大JSON对象拆分为多个小字段; 将数据保存为更合理的数据结构 (利用hash替代大字符串); 避免会造成阻塞的命令\n业务层面：调整存储策略，只存储必要的数据 (比如用户的收货地址等不常用信息不存储，只存储用户ID、姓名、头像等); 优化业务逻辑，使用更小的数据来满足业务要求; 规划好数据的生命\n架构层面：采用Redis集群的方式进行Redis部署，然后将大Key拆分散落到不同的服务器上面, 加快响应速度\n","permalink":"https://swimmingliu.cn/posts/job/redis-interview-questions/","summary":"\u003ch2 id=\"1-redis主从复制的原理\"\u003e1. Redis主从复制的原理\u003c/h2\u003e\n\u003cp\u003e【\u003cstrong\u003e主从复制的原理\u003c/strong\u003e】\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e同步：从节点向主节点发送\u003ccode\u003epsync\u003c/code\u003e命令进行同步，从节点保存主节点返回的 \u003ccode\u003erunid\u003c/code\u003e 和 \u003ccode\u003e offset\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e全量复制：如果是第一次连接或者连接失败且\u003ccode\u003erepl_backlog_buffer\u003c/code\u003e 缓存区不包含\u003ccode\u003eslave_repl_offset\u003c/code\u003e， 则生成主节点的数据快照(RDB文件)发给从节点\u003c/li\u003e\n\u003cli\u003e增量复制：全量复制完毕后，主从节点之间会保持长连接。如果连接没有断开或者\u003ccode\u003eslave_repl_offset\u003c/code\u003e仍然在\u003ccode\u003erepl_backlog_buffer\u003c/code\u003e中，则将后续的写操作传递给从节点，让数据保持一致。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e【全量复制细节】\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e全量复制的过程是基于TCP长连接的，主要流程如下\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e从节点发送\u003ccode\u003epsync ? -1\u003c/code\u003e表示需要建立连接进行同步，主节点返回主节点ID \u003ccode\u003erunid\u003c/code\u003e 和 复制进度\u003ccode\u003eoffset\u003c/code\u003e (第一次同步用 -1 表示)。从节点接受之后，保存主节点的信息。\u003c/li\u003e\n\u003cli\u003e主节点执行\u003ccode\u003ebgsave\u003c/code\u003e命令生成数据快照RDB文件，然后将RDB文件发送给从节点。从节点接受文件后，清除现有的所有数据，然后加载RDB文件\u003c/li\u003e\n\u003cli\u003e如果在制作数据快照RDB文件的过程当中，主节点接收到了新的写操作，主节点会将其记录在\u003ccode\u003erepl buffer\u003c/code\u003e 里面。然后将\u003ccode\u003erepl buffer\u003c/code\u003e当中的写操作发给从节点，让其数据保持一致。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg alt=\"Redis主从全量复制\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/ac630d4c-ef8d-11ef-a882-c858c0c1deba\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【增量复制细节】\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e如果主从节点意外断开连接，为了保持数据的一致性，必须重新同步数据。如果使用全量复制来保持一致性的话，开销太大，所以采用增量复制。\u003c/p\u003e\n\u003cp\u003e增量复制的具体流程如下：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e连接恢复后，从节点会发送\u003ccode\u003epsync {runid} {offset}\u003c/code\u003e， 其中主节点ID \u003ccode\u003erunid\u003c/code\u003e 和 复制进度\u003ccode\u003eoffset\u003c/code\u003e用于标识是哪一个服务器主机和复制进度。\u003c/li\u003e\n\u003cli\u003e主节点收到\u003ccode\u003epsync\u003c/code\u003e 命令之后，会用\u003ccode\u003econitnue\u003c/code\u003e响应告知从节点，采用增量复制同步数据\u003c/li\u003e\n\u003cli\u003e最后，主节点根据\u003ccode\u003eoffset\u003c/code\u003e查找对应的进度，将断线期间未同步的写命令，发送给从节点。同时，主节点将所有的写命令写入\u003ccode\u003erepl_backlog_buffer\u003c/code\u003e， 用于后续判断是采用增量复制还是全量复制。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e【注意】从节点 \u003ccode\u003epsync\u003c/code\u003e 携带的 \u003ccode\u003eoffset\u003c/code\u003e 为 \u003ccode\u003eslave_repl_offset\u003c/code\u003e。如果 \u003ccode\u003erepl_backlog_buffer\u003c/code\u003e包含\u003ccode\u003eslave_repl_offset\u003c/code\u003e 对应的部分，则采用增量复制，否则采用全量复制。\u003ccode\u003erepl_backlog_buffer\u003c/code\u003e的默认缓冲区大小为\u003ccode\u003e1M\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"Redis主从增量复制\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/ac9f21a3-ef8d-11ef-9016-c858c0c1deba\"\u003e\u003c/p\u003e\n\u003cp\u003e【\u003cstrong\u003e为什么要主从复制\u003c/strong\u003e】\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e备份数据\u003c/strong\u003e：主从复制实现了数据的热备份，是持久化之外的数据冗余方式\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e故障恢复\u003c/strong\u003e：当主节点宕机之后，可以采用从节点提供服务。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e负载均衡\u003c/strong\u003e:  主从复制实现了读写分离，只有主节点支持读写操作，从节点只有读操作。在读多写少的场景下，可以提高Redis服务器的并发量。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Redis主从读写分离\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/acad0d12-ef8d-11ef-b17f-c858c0c1deba\"\u003e\u003c/p\u003e\n\u003ch2 id=\"2-redis集群的实现原理是什么\"\u003e2. Redis集群的实现原理是什么?\u003c/h2\u003e\n\u003cp\u003e【\u003cstrong\u003eRedis集群基本知识\u003c/strong\u003e】\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e定义\u003c/strong\u003e: Redis集群由多个实例组成，每个实例存储部分数据 (每个实例之间的数据不重复) 。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e【注】集群和主从节点不是一个东西，集群的某一个实例当中可能包含一个主节点 + 多个从节点\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e为什么用\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e问题\u003c/th\u003e\n          \u003cth\u003e解决方案\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e容量不足\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e数据分片，将数据分散不存到不同的主节点\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e高并发写入\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e数据分片，将写入请求分摊到多个主节点\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e主机宕机问题\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e自动切换主从节点，避免影响服务， 不需要手动修改客户端配置\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e节点通信协议\u003c/strong\u003e：Redis集群采用Gossip协议, 支持分布式信息传播、延迟低、效率高。采用去中心化思想，任意实例(主节点)都可以作为请求入口，节点间相互通信。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e分片原理\u003c/strong\u003e： 采用哈希槽(Hash Slot)机制来分配数据，整个空间可以划分为\u003cstrong\u003e16384\u003c/strong\u003e (16 * 1024)个槽。 每个Redis负责一定范围的哈希槽,数据的key经过哈希函数计算之后对\u003cstrong\u003e16384\u003c/strong\u003e取余可定位到对应的节点。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Redis集群架构图\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/acc54635-ef8d-11ef-971e-c858c0c1deba\"\u003e\u003c/p\u003e","title":"Redis面试题笔记"},{"content":"1. 说说 Java 中 HashMap 的原理？ 【HashMap定义】\n结构：数组 + 链表 + 红黑树 (JDK 1.8 之后)\n默认值：初始容量为16 (数组长度)，负载因子为 0.75。当存储的元素为 16 * 0.75 = 12个时，会触发Resize() 扩容操作，容量 x 2 并重新分配位置。但是扩容是有一定开销的，频繁扩容会影响性能。另外，TREEIFY_THRESHOLD 转换为红黑树的默认链表长度阈值为 8, UNTREEIFY_THRESHOLD 从红黑树转换为链表的阈值为 6。 两个阈值采用不同值的原因是防止刚转换为红黑树，又变成链表，反复横跳，消耗资源。\n数组下标位置计算方法：首先使用key的hashCode()方法计算下标位置，然后通过 indexFor() (JDK 1.7 以前) 计算下标值。 JDK 1.7后，为了提高计算效率采用 (len - 1) \u0026amp; hash 来确定下标值。\n【注】数组的长度len 是2的幂次方时，(len - 1) \u0026amp; hash 等价于 hash % len。 这也是为什么数组长度必须是2的幂次方。\n【HashMap线程不安全】\n为了保证HashMap的读写效率高，它的操作是非同步的，也就是说读写操作没有锁保护。所以多线程场景下是线程不安全的。\n【HashMap不同版本区别】\nJDK 1.7: 数组 + 链表，链表部分采用头插法，多线程会导致出现环形链表。扩容会计算每个元素hash值，并分配到新的位置，开销大。 JDK 1.8：数组 + 链表 + 红黑树，采用高低位置来分配位置，即判断(e.hash \u0026amp; oldCap) == 0， 减少了计算hash的次数 【HashMap的PUT方法】\nHashMap在存储数据时，按照如下流程：\n判断数组table是否为空或长度为0，如果是第一次插入，需要对数组进行扩容 Resize() 计算key的数组索引值 index = hash(key) \u0026amp; (len - 1) 得到索引i , len 表示数组长度 判断table[i]是否为空？ 若为空，则直接插入 -\u0026gt; 第7步 若不为空 -\u0026gt; 第4步 判断key是否存在 若存在，直接覆盖 -\u0026gt; 第7步 若不存在 -\u0026gt; 第5步 判断table[i]是否为TreeNode 如果是TreeNode ，在红黑树中插入/覆盖 (同第4步，判断key是否存在) -\u0026gt; 第7步 如果不是 -\u0026gt; 遍历链表 -\u0026gt; 在链表中插入/覆盖 (同第4步，判断key是否存在) -\u0026gt; 第6步 如果是链表插入节点，判断链表长度listLen 是否 \u0026gt;= TREEIFY_THRESHOLD, 默认为8 如果 listLen \u0026gt;= 8，转换为红黑树 -\u0026gt; 第7步 如果 listLen \u0026lt; 8 -\u0026gt; 第7步 元素个数自增，判断是否大于阈值 threshold， 其中threshold = len * factor 默认为 16 * 0.75 = 12。若超过阈值，则对数组扩容 Resize() 【HashMap的GET方法】\n计算key的数组索引值 index = hash(key) \u0026amp; (len - 1) 得到索引i , len 表示数组长度 判断table[i]是否直接key.equals(k)命中 命中 -\u0026gt; 返回结果 未命中 -\u0026gt; 第3步 判断第一个节点是否为TreeNode 若是TreeNode，在红黑树中查找 若不是，遍历链表查找 返回查找结果 【Resize扩容操作】\nResize() 源码如下\n/** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */ final HashMap.Node\u0026lt;K,V\u0026gt;[] resize() { HashMap.Node\u0026lt;K,V\u0026gt;[] oldTab = table; // 记录Map当前的容量 int oldCap = (oldTab == null) ? 0 : oldTab.length; // 记录Map允许存储的元素数量，即阈值（容量*负载因子） int oldThr = threshold; // 声明两个变量，用来记录新的容量和阈值 int newCap, newThr = 0; // 若当前容量不为0，表示存储数据的数组已经被初始化过 if (oldCap \u0026gt; 0) { // 判断当前容量是否超过了允许的最大容量 if (oldCap \u0026gt;= MAXIMUM_CAPACITY) { // 若超过最大容量，表示无法再进行扩容 // 则更新当前的阈值为int的最大值，并返回旧数组 threshold = Integer.MAX_VALUE; return oldTab; } // 将旧容量*2得到新容量，若新容量未超过最大值，并且旧容量大于默认初始容量（16）， // 才则将旧阈值*2得到新阈值 else if ((newCap = oldCap \u0026lt;\u0026lt; 1) \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; oldCap \u0026gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr \u0026lt;\u0026lt; 1; // double threshold } // 若不满足上面的oldCap \u0026gt; 0，表示数组还未初始化， // 若当前阈值不为0，就将数组的新容量记录为当前的阈值； // 为什么这里的oldThr在未初始化数组的时候就有值呢？ // 这是因为HashMap有两个带参构造器，可以指定初始容量， // 若你调用了这两个可以指定初始容量的构造器， // 这两个构造器就会将阈值记录为第一个大于等于你指定容量，且满足2^n的数（可以看看这两个构造器） else if (oldThr \u0026gt; 0) // initial capacity was placed in threshold newCap = oldThr; // 若上面的条件都不满足，表示你是调用默认构造器创建的HashMap，且还没有初始化table数组 else { // zero initial threshold signifies using defaults // 则将新容量更新为默认初始容量（16） // 阈值即为（容量*负载因子） newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } // 经过上面的步骤后，newCap一定有值，但是若运行的是上面的第二个分支时，newThr还是0 // 所以若当前newThr还是0，则计算出它的值（容量*负载因子） if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; ft \u0026lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } // 将计算出的新阈值更新到成员变量threshold上 threshold = newThr; // 创建一个记录新数组用来存HashMap中的元素 // 若数组不是第一次初始化，则这里就是创建了一个两倍大小的新数组 @SuppressWarnings({\u0026#34;rawtypes\u0026#34;,\u0026#34;unchecked\u0026#34;}) HashMap.Node\u0026lt;K,V\u0026gt;[] newTab = (HashMap.Node\u0026lt;K,V\u0026gt;[])new HashMap.Node[newCap]; // 将新数组的引用赋值给成员变量table table = newTab; // 开始将原来的数据加入到新数组中 if (oldTab != null) { // 遍历原数组 for (int j = 0; j \u0026lt; oldCap; ++j) { HashMap.Node\u0026lt;K,V\u0026gt; e; // 若原数组的j位置有节点存在，才进一步操作 if ((e = oldTab[j]) != null) { // 清除旧数组对节点的引用 oldTab[j] = null; // 若table数组的j位置只有一个节点，则直接将这个节点放入新数组 // 使用 \u0026amp; 替代 % 计算出余数，即下标 if (e.next == null) newTab[e.hash \u0026amp; (newCap - 1)] = e; // 若第一个节点是一个数节点，表示原数组这个位置的链表已经被转为了红黑树 // 则调用红黑树的方法将节点加入到新数组中 else if (e instanceof HashMap.TreeNode) ((HashMap.TreeNode\u0026lt;K,V\u0026gt;)e).split(this, newTab, j, oldCap); // 上面两种情况都不满足，表示这个位置是一条不止一个节点的链表 // 以下操作相对复杂，所以单独拿出来讲解 else { // preserve order HashMap.Node\u0026lt;K,V\u0026gt; loHead = null, loTail = null; HashMap.Node\u0026lt;K,V\u0026gt; hiHead = null, hiTail = null; HashMap.Node\u0026lt;K,V\u0026gt; next; do { next = e.next; if ((e.hash \u0026amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } // 将新创建的数组返回 return newTab; } 单独分析中间链表拆分的代码\n定义两个链表 (lo 和 hi)， 包括头节点和尾节点 Node\u0026lt;K,V\u0026gt; loHead = null, loTail = null; Node\u0026lt;K,V\u0026gt; hiHead = null, hiTail = null; 按照顺序遍历table携带的链表的每个节点，如果(e.hash \u0026amp; oldCap) == 0，就放入lo链表，其他的放入hi链表 do { next = e.next; // 根据元素的哈希值和旧容量的位运算结果将元素分类 if ((e.hash \u0026amp; oldCap) == 0) { // if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next)!= null); 将原来的链表拆分为两个链表，然后将低位置元素存储到新数组原索引位置，将高位置元素存储到新数组原索引加旧容量的位置。 位置的高低按照 (e.hash \u0026amp; oldCap) == 0 来区分 // 将低位置元素存储到新数组原索引位置 if (loTail!= null) { loTail.next = null; newTab[j] = loHead; } // 将高位置元素存储到新数组原索引加旧容量的位置 if (hiTail!= null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } 2.ConcurrentHashMap了解吗? / Java 中 ConcurrentHashMap 1.7 和 1.8 之间有哪些区别？ 首先，提到 ConcurrentHashMap 我们要分成JDK 1.7 和 JDK 1.8 两个版本来看：\nJDK 1.7: 在1.7中， ConcurrentHashMap 采用分段锁。就是分成不同的segment，默认有16个。每个segment 中都包含多个的 HashEntry (可以理解成一个HashMap)。 锁的方式源于Segment,这个类实际集成了ReentrantLock\nJDK 1.8：在1.8中，ConcurrnetHashMap的数据结构和HashMap一样，它做了更小范围的锁控制。它的数组的每个位置上都有一把锁。如果需要扩容，会使用CAS 自旋操作保证线程安全，避免锁整个数组。如果是在链表/红黑树插入某个node，只需要用synchronize进行上锁。\n【JDK1.7和1.8扩容区别】\nJDK 1.7：当某个Segment内的HashMap 达到扩容阈值的时候，单独为该Segment进行扩容。\nJDK 1.8：大致可以分为三个特点全局扩容、基于CAS扩容、渐进式扩容\n全局扩容：1.8 因为取消了 1.7 里面的Segment， 本身是数组+链表+红黑树的结构。所以是一个全局的数组，当任意位置的元素超过阈值时，整个数组都会被扩容。\n基于CAS的扩容： 采用和 HashMap 相似的扩容机制，采用 CAS操作确保线程安全，同时避免锁住整个数组。\n渐进式扩容：扩容不是一次性将所有数据重新分配，而是多个线程共同参与，逐步迁移就数据到新数组当中，降低扩容新能。(假如当前数组长度为32，那么可以A线程负责0~15，B线程负责16~31)\n3. 为什么 Java 的 ConcurrentHashMap 不支持 key 或 value 为 null？ ConcurrentMap不支持key或value为 null 是为了避免歧义和简化代码实现方式\n因为多线程环境下，get(key) 方法如果返回 null ，不知道其表示的是key不存在还是value本来就是 null。为了避免这个歧义，代码就需要频繁的判断null是代表key不存在还是 value 本来就是 null，增加复杂度。\n【为什么HashMap支持 key 或 value 为null】\n因为HashMap设计的初衷就是单线程模式使用的，本身就是线程不安全的。在 HashMap 的实现中，null 键被特殊处理。当 key 为 null 时，HashMap 不会调用 hashCode() 方法，而是直接将 null 键存储在表的第一个桶（table[0]）中。这样可以避免 NullPointerException 。\n【注意】 像HashTable、ConcurrentSkipListMap、CopyOnWriteArrayList这些并发集合，都是线程安全的，都不支持key或value为 null\n4 . Java 中 ConcurrentHashMap 的 get 方法是否需要加锁？ ConcurrentHashMap 的 get 方法不需要加锁。因为get 方式是读取操作，不需要对资源做任何处理，所以每次只需要保证读取到最新的数据即可，所以不需要加锁。\n另外,ConcurrentHashMap 中 get 方法对于数组中的节点，是通过Unsafe 方法 getObjectVolatile() 来保证可见性的。对于链表或者红黑树节点，是采用volatile 关键字去修饰 val 和 next 节点的，也可以保证可见性。\n5. Java 中有哪些集合类？请简单介绍 Java中的集合类都是在java.util。 主要可以分为单列类型 Collection 和 双列 Map 两类来看。 其中单列 Collection 里面包括 (List、Set、Queue），具体如下图。\n【两个基本接口】\nCollection 单列集合接口：一个由单个元素组成的序列，这些元素要符合一条或多条规则。其中，List 是有序的，Set 是去重的， Queue 是符合队列规则的。 Map 双列集合接口： 一组键值对，可以用 key 来检索 value。 上面的 ArrayList 是采用索引来查找一个值。Map 可以采用另外一个对象来查找某个对象。 【List 系列】 List 接口的实现类用于存储有序的、允许重复的元素。必须按照元素插入顺序来保存他们。\nArrayList：擅长随机访问元素，但是在 List 的中间插入或者删除元素比较慢。适合读操作多的场景。 LinkedList：提供理想的顺序访问性能，在 List 的中间插入和删除元素的成本都比较低。 LinkedList 随机访问性能相对较差， 适合频繁插入和删除的场景。 Vector：基于动态数据实现，线程安全 (方法加锁)， 效率比较低，已经很少用了。 【Set 系列】 Set 接口的实现类用于存储不重复的元素。继承于Collection\nHashSet：无序，采用哈希表存储，查找和插入性能高。 LinkedHashSet：有序，采用哈希表 + 链表(存储插入顺序) TreeSet：排序 (或自定义排序)，采用红黑树实现，查找、插入、删除操作性能高。 【Queue 队列/优先系列】 Queue 接口的实现类用于处理先进先出的队列数据结构。\npriorityQueue： 基于堆实现，用于优先级队列。元素按自然顺序或自定义顺序排列。不是FIFO的顺序，优先处理优先级搞的元素 LinkedList： 也实现了Queue 接口，支持双端队列结构。 Stack： 双端队列 【Map 系列】 键唯一，值可重复\nHashMap： 无序，数组 + 链表 + 红黑树， key 和 value 都可以为 null LinkedHashMap：有序，数组 + 链表 + 红黑树，额外链表记录插入顺序 TreeMap：红黑树实现，对key进行自然排序(或者自定义排序) HashTable: 数组 + 链表 + 红黑树，有sychronized 锁， 不允许key 和 value 为 null ，线程安全。 6. Java 中的 CopyOnWriteArrayList 是什么？ CopyOnWriteArrayList 是一种线程安全的ArrayList， 其主要的原理就和名字一样，在写的时候复制，写时复制。\nCopyOnWirteArrayList 的读操作不需要上锁，但是写操作会锁。而且进行写操作的时候，会复制一份原数组出来，然后在新的数组上进行写操作，读操作还是在老数组的基础上，适合读多写少的场景。到那时复制数组有一定的性能消耗，而且会消耗内存。\n","permalink":"https://swimmingliu.cn/posts/job/java-set-interview-questions/","summary":"\u003ch2 id=\"1-说说-java-中-hashmap-的原理\"\u003e1. 说说 Java 中 HashMap 的原理？\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e【HashMap定义】\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e结构：数组 + 链表 + 红黑树 (\u003ccode\u003eJDK 1.8\u003c/code\u003e 之后)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e默认值：初始容量为16 (数组长度)，负载因子为 0.75。当存储的元素为 16 * 0.75 = 12个时，会触发\u003ccode\u003eResize()\u003c/code\u003e 扩容操作，容量 x 2 并重新分配位置。但是扩容是有一定开销的，频繁扩容会影响性能。另外，\u003ccode\u003eTREEIFY_THRESHOLD\u003c/code\u003e 转换为红黑树的默认链表长度阈值为 8, \u003ccode\u003eUNTREEIFY_THRESHOLD\u003c/code\u003e 从红黑树转换为链表的阈值为 6。 两个阈值采用不同值的原因是防止刚转换为红黑树，又变成链表，反复横跳，消耗资源。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e数组下标位置计算方法：首先使用key的\u003ccode\u003ehashCode()\u003c/code\u003e方法计算下标位置，然后通过  \u003ccode\u003eindexFor()\u003c/code\u003e (\u003ccode\u003eJDK 1.7\u003c/code\u003e 以前) 计算下标值。 \u003ccode\u003eJDK 1.7\u003c/code\u003e后，为了提高计算效率采用 \u003ccode\u003e(len - 1) \u0026amp; hash\u003c/code\u003e 来确定下标值。\u003c/p\u003e\n\u003cp\u003e【注】数组的长度\u003ccode\u003elen\u003c/code\u003e 是2的幂次方时，\u003ccode\u003e(len - 1) \u0026amp; hash\u003c/code\u003e 等价于 \u003ccode\u003ehash % len\u003c/code\u003e。 这也是为什么数组长度必须是2的幂次方。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"HashMap底层结构\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/65f25922-ef8d-11ef-827a-c858c0c1deba\"\u003e\u003c/p\u003e\n\u003cp\u003e【\u003cstrong\u003eHashMap线程不安全\u003c/strong\u003e】\u003c/p\u003e\n\u003cp\u003e为了保证HashMap的读写效率高，它的操作是非同步的，也就是说读写操作没有锁保护。所以多线程场景下是线程不安全的。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e【HashMap不同版本区别】\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eJDK 1.7: 数组 + 链表，链表部分采用头插法，多线程会导致出现环形链表。扩容会计算每个元素hash值，并分配到新的位置，开销大。\u003c/li\u003e\n\u003cli\u003eJDK 1.8：数组 + 链表 + 红黑树，采用高低位置来分配位置，即判断\u003ccode\u003e(e.hash \u0026amp; oldCap) == 0\u003c/code\u003e， 减少了计算hash的次数\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e【HashMap的PUT方法】\u003c/strong\u003e\u003c/p\u003e","title":"Java集合面试题笔记"},{"content":"1. 序列化和反序列化 1.序列化和反序列化：把对象转换为字节流，用于存储和传输；读取字节流数据，重新创建对象。 2.序列化不包括静态对象：序列化和反序列化的本质是调用对象的writeObject和readObject方法,来实现将对象写入输出流和读取输入流。但是，静态变量不属于对象，所以调用这两个方法就没法儿让静态变量参与。\n2. 什么是不可变类？ 1.不可变类：初始化之后，就不能修改的类。 2.修饰方法：final 和 private 修饰所有类和变量 3.不可修改：不暴露set方法，只能通过重新创建对象替代修改功能(String的replace方法) 4.优缺点： 优点：线程安全，缓存友好 缺点：频繁拼接和修改会浪费资源\n3. Exception和Error区别? 1.Exception和Error定义区别：Exception是可处理程序异常，Error是系统级不可回复错误 2.try-catch建议： 1.范围能小则小 2.Exception最好要写清楚具体是哪一个Exception(IOException) 3.null值等能用if判断的，不要用try-catch,因为异常比条件语句低效 4.finally不要直接return和处理返回值\n4. Java 中的 hashCode 和 equals 方法之间有什么关系？ 1、equals() 和 hashCode() 的关系\n如果两个对象euqals() 为 true， 则其 hashCode()一定相同 如果两个对象hashCode() 相同，其equals()结果不一定为true 2、为什么重写equals()之后，一定要重写hashCode()\n当重写equals() 之后，通常是重新定义了两个对象相等的逻辑。如果不重写hashCode()方法， 则在散列集合（HashMap 和 HashSet）中，可能无法正确存储和检索，因为两个相同的对象可能有不同的hash值。\n例如，下方Person类重写了equals() 方法，但是没有重新hashCode()\npublic class Person { private String name; private int age; @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null || getClass() != obj.getClass()) return false; Person person = (Person) obj; return age == person.age \u0026amp;\u0026amp; Objects.equals(name, person.name); } } 创建相同的对象，并添加到HashSet中\nPerson p1 = new Person(\u0026#34;Alice\u0026#34;, 25); Person p2 = new Person(\u0026#34;Alice\u0026#34;, 25); Set\u0026lt;Person\u0026gt; set = new HashSet\u0026lt;\u0026gt;(); set.add(p1); set.add(p2); 由于hashCode() 没有重写，所有两个相同的对象可能有不同的散列码，导致集合当中有两个相同的元素\n如何重写hashCode()?\n只需要让其hash值，采用equals()当中相同的判断条件生成合理的散列值即可\n@Override public int hashCode() { return Objects.hash(name, age); } ","permalink":"https://swimmingliu.cn/posts/job/java-basic-interview-questions/","summary":"\u003ch2 id=\"1-序列化和反序列化\"\u003e1. 序列化和反序列化\u003c/h2\u003e\n\u003cp\u003e1.序列化和反序列化：把对象转换为字节流，用于存储和传输；读取字节流数据，重新创建对象。\n2.序列化不包括静态对象：序列化和反序列化的本质是调用对象的\u003ccode\u003ewriteObject\u003c/code\u003e和\u003ccode\u003ereadObject\u003c/code\u003e方法,来实现将对象写入输出流和读取输入流。但是，静态变量不属于对象，所以调用这两个方法就没法儿让静态变量参与。\u003c/p\u003e\n\u003ch2 id=\"2-什么是不可变类\"\u003e2. 什么是不可变类？\u003c/h2\u003e\n\u003cp\u003e1.不可变类：初始化之后，就不能修改的类。\n2.修饰方法：final 和 private 修饰所有类和变量\n3.不可修改：不暴露set方法，只能通过重新创建对象替代修改功能(\u003ccode\u003eString\u003c/code\u003e的replace方法)\n4.优缺点：\n优点：线程安全，缓存友好\n缺点：频繁拼接和修改会浪费资源\u003c/p\u003e\n\u003ch2 id=\"3-exception和error区别\"\u003e3. Exception和Error区别?\u003c/h2\u003e\n\u003cp\u003e1.Exception和Error定义区别：Exception是可处理程序异常，Error是系统级不可回复错误\n2.try-catch建议：\n1.范围能小则小\n2.Exception最好要写清楚具体是哪一个Exception(IOException)\n3.null值等能用if判断的，不要用try-catch,因为异常比条件语句低效\n4.finally不要直接return和处理返回值\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"Exception和Error区别\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/946b73cc-ef5d-11ef-95ab-c858c0c1deba\"\u003e\u003c/p\u003e\n\u003ch2 id=\"4-java-中的-hashcode-和-equals-方法之间有什么关系\"\u003e4. Java 中的 hashCode 和 equals 方法之间有什么关系？\u003c/h2\u003e\n\u003cp\u003e1、\u003ccode\u003eequals()\u003c/code\u003e 和 \u003ccode\u003ehashCode()\u003c/code\u003e 的关系\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e如果两个对象\u003ccode\u003eeuqals()\u003c/code\u003e 为 \u003ccode\u003etrue\u003c/code\u003e， 则其 \u003ccode\u003ehashCode()\u003c/code\u003e一定相同\u003c/li\u003e\n\u003cli\u003e如果两个对象\u003ccode\u003ehashCode()\u003c/code\u003e 相同，其\u003ccode\u003eequals()\u003c/code\u003e结果不一定为\u003ccode\u003etrue\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e2、为什么重写\u003ccode\u003eequals()\u003c/code\u003e之后，一定要重写\u003ccode\u003ehashCode()\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e当重写\u003ccode\u003eequals()\u003c/code\u003e 之后，通常是重新定义了两个对象相等的逻辑。如果不重写\u003ccode\u003ehashCode()\u003c/code\u003e方法， 则在散列集合（\u003ccode\u003eHashMap\u003c/code\u003e 和 \u003ccode\u003eHashSet\u003c/code\u003e）中，可能无法正确存储和检索，因为两个相同的对象可能有不同的\u003ccode\u003ehash\u003c/code\u003e值。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e例如，下方Person类重写了\u003ccode\u003eequals()\u003c/code\u003e 方法，但是没有重新\u003ccode\u003ehashCode()\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-Java\" data-lang=\"Java\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003ePerson\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"kd\"\u003eprivate\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"kd\"\u003eprivate\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eage\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"nd\"\u003e@Override\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003eboolean\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003eequals\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eObject\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eobj\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003ethis\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eobj\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kc\"\u003etrue\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eobj\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kc\"\u003enull\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e||\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003egetClass\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e!=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eobj\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003egetClass\u003c/span\u003e\u003cspan class=\"p\"\u003e())\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kc\"\u003efalse\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"n\"\u003ePerson\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eperson\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ePerson\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eobj\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eage\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eperson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eage\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eObjects\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eequals\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eperson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e创建相同的对象，并添加到\u003ccode\u003eHashSet\u003c/code\u003e中\u003c/p\u003e","title":"Java基础题面试笔记"},{"content":"1.MySQL 中的数据排序是怎么实现的？ 1.排序方法：索引排序和文件排序 (filesort)\n2.索引排序：如果order by xxx的字段为索引字段，则利用索引进行排序。效率最高，索引默认有序。\n3.文件排序 (filesort)：内存排序(单路排序和双路排序)和磁盘排序，具体取决于排序数据的大小。其中，内存排序使用单路排序或双路排序，取决于max_length_for_sort_data(默认为4096个字节)\n4.双路排序：取row_id(如果有主键，则为主键)和select a,b,c order by xxx的xxx字段放入sort_buffer(排序缓存)中，将排序后的row_id回表查询a,b,c\n5.单路排序: 直接把要查的所有字段放入sort_buffer里，排序后直接得到结果集合\n6.磁盘排序（归并排序）:将数据分为多份文件，单独对文件进行排序，然后合并成一个有序的大文件\n2. MySQL 的 Change Buffer 是什么？它有什么作用？ 1.ChangeBuffer定义：Change Buffer是InnoDB缓冲当中的一块缓存区，用于暂存二级索引的修改，避免二级索引页修改产生的随机IO 2.ChangeBuffer注意事项：只能用于二级索引，不能用于其他任何索引，包括主键索引和唯一索引都不行。 3.如果ChangeBuffer挂了，更改操作未执行，是否会出现脏数据？ 首先，ChangeBuffer也会保存在磁盘空间里面，redo log会记录Change Buffer当中的修改操作，确保数据一致性。\n知识拓展1：一级索引和二级索引区别\n一级索引（聚簇索引）：数据表的主键索引，数据和索引存储在同一B+树的叶子节点中。每个表只能有一个一级索引。\n二级索引（非聚簇索引）：除主键外的其他索引，叶子节点存储索引列的值和对应的主键值。通过二级索引查询时，需要先通过二级索引获取主键值，再通过主键值查询数据，这个过程称为“回表”。\n知识拓展2: MySQL中有哪些常见索引？都有什么区别？\n在MySQL中，索引是提高查询效率的关键工具。常见的索引类型包括主键索引、唯一索引、普通索引、全文索引和空间索引。\n1. 主键索引（Primary Key Index）\n定义：主键索引是一种特殊的唯一索引，用于唯一标识表中的每一行数据。每个表只能有一个主键索引，且主键列的值不能为空。 特点：主键索引的叶子节点存储完整的数据行，因此查询效率高。在InnoDB存储引擎中，主键索引是聚簇索引，数据存储与索引结构合并。 2. 唯一索引（Unique Index）\n定义：唯一索引确保索引列的每个值都是唯一的，但允许有空值。与主键索引类似，不同之处在于唯一索引允许列值为NULL。 特点：唯一索引的叶子节点存储索引列的值和对应的主键值。在InnoDB中，唯一索引是非聚簇索引，数据存储与索引结构分开。 3. 普通索引（Index）\n定义：普通索引是最基本的索引类型，没有任何限制。索引列的值可以重复，也可以为NULL。 特点：普通索引的叶子节点存储索引列的值和对应的主键值。在InnoDB中，普通索引是非聚簇索引，数据存储与索引结构分开。 4. 全文索引（Fulltext Index）\n定义：全文索引用于对文本数据进行全文搜索，适用于MyISAM存储引擎。它允许对文本字段进行复杂的搜索，如查找包含特定单词的记录。 特点：全文索引的叶子节点存储文档的词项信息。在MyISAM中，全文索引是非聚簇索引，数据存储与索引结构分开。 5. 空间索引（Spatial Index）\n定义：空间索引用于对地理空间数据进行索引，支持空间数据类型的快速查询。它适用于存储地理位置、地图等空间数据的表。 特点：空间索引的叶子节点存储空间数据的索引信息。在MyISAM中，空间索引是非聚簇索引，数据存储与索引结构分开。 总结：\n主键索引：用于唯一标识每一行数据，值不能为空。 唯一索引：确保索引列的值唯一，但允许有空值。 普通索引：最基本的索引类型，允许重复和空值。 全文索引：用于对文本数据进行全文搜索，适用于MyISAM存储引擎。 空间索引：用于对地理空间数据进行索引，支持空间数据类型的快速查询。 3. 详细描述一条 SQL 语句在 MySQL 中的执行过程。 连接器判断用户是否成功建立连接，数据库连接的权限校验 连接器会查询缓存，key 是 SQL 语句，value 是查询结果。如果命中，直接返回查询结果。(MySQL 8.0之后，就移除这个功能了)。 分析器分析SQL语法和词法是否有误 优化器生成SQL的执行计划，确定使用的索引和调整where的执行顺序（包括连表顺序） 执行器判断当前用户是否有权限查询该表，然后执行该SQL语句 [参考文献] 执行一条 select 语句，期间发生了什么？\n[补充] 3. MySQL 日志：undo log、redo log、binlog 有什么用？ undo log（回滚日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的原子性，主要用于事务回滚和 MVCC。 redo log（重做日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的持久性，主要用于掉电等故障恢复； binlog （归档日志）：是 Server 层生成的日志，主要用于数据备份和主从复制；\n直接看参考文献当中的七个问题和其解决方案\n[参考文献] MySQL 日志：undo log、redo log、binlog 有什么用？\n4. MySQL 的存储引擎有哪些？它们之间有什么区别？ InnoDB : 支持事务、行锁、外键; 高并发性能、支持高负载的OLTP应用 (银行交易、电子商务订单、库存管理等); 聚集索引存储，检索效率高\nMyISAM: 表锁、不支持事务和外键; 适用于读多写少的场景(数据仓库); 较高读性能和j较快的表级锁定\nMEMORY: 存储在内存中，速度快，重启后数据丢失; 适用于临时数据存储和快速存储\n5. MySQL 的索引类型有哪些？ 划分方向 索引类型 数据结构 B+树索引、Hash索引、倒排索引 (全文索引)、R-树索引 (多维空间树)、位图索引(Bitmap) 物理存储 聚簇索引、非聚簇索引 字段特性 主键索引、唯一索引、普通索引(二级索引、辅助索引)、前缀索引 字段个数 单列索引、联合索引 6. MySQL InnoDB 引擎中的聚簇索引和非聚簇索引有什么区别？ 聚簇索引：就像是图书馆里按照书籍主题顺序摆放的书架。在这个书架（也就是聚簇索引）上，每本书（也就是数据库中的行数据）都是按照某个主题（通常是主键）来排列的。所以，当你想要找某一主题的书时，只要知道主题名（主键值），就能很快在书架上找到它，而且相邻主题的书也是挨在一起的，找起来很方便。但是，这种方式的缺点是，如果你想要改变某本书的主题（更新主键），可能就需要移动整本书到新的位置，甚至可能需要重新整理整个书架（数据页），这样就比较麻烦了。\n非聚簇索引：则更像是图书馆里的一个索引卡片箱。在这个卡片箱里，每张卡片（也就是非聚簇索引的节点）上都写着书籍的主题（索引列的值）和书籍在书架上的位置（主键值或ROWID）。当你想要找一本书时，可以先在卡片箱里找到对应的卡片，然后根据卡片上的位置信息去书架上找书。这种方式的好处是灵活，你可以为不同的书籍主题制作多张卡片，方便从不同的角度查找书籍。但是，坏处是每次找书都需要两步：先在卡片箱里找卡片，再去书架上找书，这样可能会比直接在书架上找书要慢一些。\n总的来说，聚簇索引和非聚簇索引的主要区别在于它们如何存储数据和索引，以及它们如何影响数据的查询和更新操作。聚簇索引将数据直接存储在索引上，查询效率高，但更新操作可能较复杂；而非聚簇索引则通过索引指向数据，提供了更多的灵活性，但查询时可能需要额外的步骤。在选择使用哪种索引时，需要根据具体的应用场景和查询需求来决定。\nMySQL InnoDB的聚簇索引和非聚簇索引就像图书馆的两种找书的方式。 1.聚簇索引：图书馆在书架上(聚簇索引)摆放各种编号(主键名称)的书本(数据库中每一行的数据)。当你需要从图书馆找某一本书时，只需要知道书籍的编号(主键值)，就能够快速找到他。它的缺点是，如果需要换某一本书的编号(更新主键)，就需要移动整本书到新的位置，甚至重新整理书架(数据页)。这也是推荐使用select *的原因，因为如果需要查找索引列的数据，直接用二级索引就可以找到数据。例如通过姓名（二级索引）查询id(主键索引)，直接用二级索引就可以拿到对应的id.但是如果用select *,数据库就会回表查询其他的数据（性别，年龄等等）。 2.非聚簇索引：就像图书馆单独设置编号卡片箱，每张卡片(非聚簇索引)上包含了书籍名称(索引列的值)和书籍在书架上的编号位置(主键值或者ROWID)。当你想要找某本书的时候，可以根据卡片里面对应的编号进行查找。坏处是每次都需要两步走，查找起来没那么方便。 总结：聚簇索引是包含数据的，所以查找起来方便，但是更新操作开销大。非聚簇索引不包含数据，只包含索引列的值和其指向的数据索引，需要两步走才能查到数据。\n7. MySQL 中的回表是什么？ 回表：用二级索引中的主键取聚簇索引中查找数据行的过程 为什么需要回表：使用非聚簇索引的二级索引查询时，只能查到索引列的值和其主键值，无法获取其他数据 回表的缺点：回表会带来随机I/O, 频繁回表会导致效率非常低。所以不推荐使用 select * 回表的其他场景：当查询的部分列没有包含在索引中时，即便使用了索引，也需要会去获取缺失的列数据，称为覆盖索引缺失。 覆盖索引缺失发送场景：select 语句当中包含了非索引列; 索引的类型为Hash和full-text索引 （不存储列的值），不支持覆盖索引。 如何减少回表：MySQL5.6之后，引入了提高查询效率的优化技术，默认开启。允许MySQL用索引查找数据时，将部分查询条件下推到索引引擎层来过滤，减少了需要读取的数据行。 8. MySQL索引的最左前缀匹配原则是什么? 最左前缀匹配原则的定义：使用联合索引的时候，查询的条件必须从索引的最左侧开始匹配。如果联合索引包含多个列，查询条件必须包含第一个列，然后是第二个列，以此类推。 最左前缀匹配原则的原理：联合索引在B+树中的排列方式遵循从左到右的原则，例如联合索引(a, b, c)，在查询时，首先按照a的值进行排序，如果a的值相同，再查b的值，以此类推。 常见场景：= 、\u0026gt;= 、\u0026lt;= 、 BETWEEN 、like (xx%) 都包含等值的情况，可以定位到某个数，然后进行范围扫描，不会出现停止匹配的现象。但是 \u0026gt; 和 \u0026lt; 则不行。 部分不符合最左前缀匹配原则也能使用索引的原因：MySQL8当中引入了 Skip Can Range Access Method, 将缺失的左边的值查出来，如果左边缺失的列数据量少，则拼凑左边的索引，让SQL符合最左前缀匹配原则。 9. MySQL的覆盖索引是什么？ 覆盖索引定义：查询的所有字段都是二级索引，从而使查询可以直接访问二级索引二不需要访问实习的表数据(主键索引)。 覆盖索引优点：减少I/O操作 ; 提高查询速度 (索引比表数据更加紧凑); 减少内存占用 (读取的索引页面而不是表数据页面) 10. MySQL的索引下推 (ICP) 是什么? 索引下推(ICP)定义: 减少回表查询，提高查询效率的行为。允许MySQL使用索引查找数据的时候，将部分查询条件下推到存储引擎层进行过滤，从而减少需要从表中读取的数据行，减少I/O。\n应用场景：比如当前表建了一个联合索引(a, b, c)，使用where条件的时候，由于b用得是 like '%xxx%' 需要回表查询 (like 'xx%' 不需要)。即先查询a = '1' 的数据， 然后回表查询，最后进行where条件的过滤。如果使用索引下推之后 (MySQL 5.6)，在查询晚a = '1'的数据之后，可以先由存储引擎层进行where条件过滤，然后再回表查询， 减少回表查询的次数。\nSELECT * FROM people WHERE a=\u0026#39;1\u0026#39; AND b LIKE \u0026#39;%123%\u0026#39; 如联合索引index_name_age，假设数据库中有数据（张三，18）、（张三，28）、（张三，48）、（张三，8)\n【没有索引下推】查询name=\u0026lsquo;张三\u0026rsquo;和age\u0026gt;30的数据时，会先匹配有四条数据name=\u0026lsquo;张三\u0026rsquo;匹配成功，回表四次查询出带有name=\u0026lsquo;张三\u0026rsquo;的四条数据，然后再根据age\u0026gt;30对这四条数据进行范围查找\n【使用索引下推】查询name=\u0026lsquo;张三\u0026rsquo;和age\u0026gt;30的数据时，会先匹配有四条数据name=\u0026lsquo;张三\u0026rsquo;匹配成功，然后age\u0026gt;30的数据，过滤完成后，再用主键索引去进行一次回表操作\n11. MySQL建索引需要注意哪些事项？ 【索引适合场景】\n频繁使用where 、order by 、group by、distinct 的字段 (加快操作速度) 关联字段 (如果没有索引，连接的过程中，每个只都会进行一次全表扫描) 【不适合场景】\n字段频繁更新 (更新除了修改数据外，还需要维护索引信息 =\u0026gt; 调整B+树会降低性能) 字段值重复率高（区分度低，建立索引更加消耗资源） 参与列计算的字段 (索引会失效) 长字段 (text、 longtext) ：长字段占据的内存大，提升性能不明显。 【注】索引不是越多越好，因为每次修改都需要维护索引数据，消耗资源\n12. MySQL中使用索引一定有效吗？如何排查索引效果？ 【索引失效的情况】\n联合索引不符合最左匹配原则 对索引列使用了运算(where id + 3 = 8)、函数 (lower()、count())、like '%xx%' 等操作 对索引列和非索引列使用 or 操作 (where name = \u0026quot;swimmingliu\u0026quot; or age = 34) 索引列类型不匹配导致的强制转换 (where name = 1 ==\u0026gt; where CAST(name AS signed int) = 1) 【如何查看失效】\n利用explain命令 (前面最好加上analyse table xxx)\nEXPLAIN 的 type 表示查询的访问类型，影响查询的效率。常见的值：\nref: 使用索引，查找匹配某个单一列的值（比如通过外键查找）。比 range 更高效。 range: 使用索引扫描某个范围内的值，适用于 BETWEEN、\u0026gt; \u0026lt; 等条件。 index: 全索引扫描，扫描整个索引结构，不读表数据，通常效率比全表扫描好。 all: 全表扫描，没有使用索引 总结：ref \u0026gt; range \u0026gt; index \u0026gt; all。\n13. MySQL的索引数是否越多越好？why? 索引不是越多越好，因为对索引字段进行更新操作，需要调整B+树的结构，会导致数据库增加开销。\n【注】阿里巴巴规范上表示索引一般不超过16个\n**【时间开销】**进行增删改操作的时候，索引也必须更新。索引越多，需要修改的地方就越多，时间开销大。B+树可能会出现页分裂、合并等操作，时间开销更大。\n【空间开销】 建立二级索引，都需要新建一个B+树，每个数据页面都是16KB。如果数据大，索引又多，占用的空间不小。\n14. 为什么 MySQL 选择使用 B+ 树作为索引结构？ 【B+树的优势】\n高效的查找性能：B+树是一种自平衡树，每个叶子结点到根节点的路径长度相同。增删改查的事件复杂度都是O(logn)，且具有一定的冗余节点，删除节点的时候，树的结构变化较小。 I/O次数相对较少：首先，B+树不会像红黑树一样，随着数据的增多树变得越来越高，它是多叉树。计算机访问数据时，往往具有局部性原理。当读取一个节点时，B树和B+树会将多个相关的数据加载到内存中，后续直接从内存反问，减少了磁盘的I/O。另外，相较于B树来说， B+树所有的数据都存放在叶子节点，而不像B树会在非叶子节点存储数据。B+树的非叶子节点仅存储索引值/主键和页面指针。 对范围查询友好：B+树的叶子节点之间通过链表链接。当使用between语句时，会从根节点找到满足条件的起始记录。然后从起始记录，沿着叶子结点的链表进行顺序遍历。 【B+树存在的部分缺点】\n当插入和删除节点，会触发分裂和合并操作，保持树的平衡，有一定的开销。\n【跳表】\n跳表其实就是一个多级链表，为了让链表更高效的查询。在不同的部分插入高级索引，让其能够缩小查找范围。有一种二分的思想在里面。其中，Redis的有序集合(sorted set)底层的结构就是跳表结构。\n【为什么MySQL不用跳表而用B+树】\n跳表的I/O效率低：B+树通常只有3~4层，可以存储海量的数据。B+树的节点大小设计适配磁盘页的大小，磁盘页能够顺序存储大量数据。一次磁盘I/O操作就能读取节点的数据，减少I/O。跳表是多级索引的结构，虽然可以加速查找，但是其查找的过程当中会涉及到多次随机的I/O。 范围查询： B+树的叶子节点是有序链表，在采用between时，能够找从叶子结点按照链表顺序遍历即可。跳表虽然支持范围查询，但是实现起来很复杂， 而且其多层的索引结构，范围查询时不能像B+树那样直接高效。 跳表维护成本高：B+树在增删改的时候，又高效的算法平衡树结构，确保性能稳定。而跳表在新增和删除操作的时候，涉及多层链表的调整，开销较大，容易出现性能波动。 跳表内存占用大：B+树的节点紧凑，非叶子节点只存储索引项和页面指针。而跳表除了每个节点存储数据以外，还需要额外的开销存储多层索引。相同数据量下，跳表的开销比B+树大得多。 15. MySQL 三层 B+ 树能存多少数据？ 算法名称 数据页大小 叶子节点存储的数据记录大小 (假设) 节点的索引值(主键大小) 节点的页面指针大小 B+树 16KB 1KB 8B （bigint） 6B 【三层B+树存储数据计算】\nnodesCount = 16 * 1024 / (6 + 8) = 1170 // 每个节点可以存多少个子节点 recordCount = 16KB / 1KB = 16 // 每个节点可以存多少条数据记录 dataCount = nodesCount * nodesCount * recordCount = 1170 * 1170 * 16 = 21,902,400 所以如果一条数据为1KB大小，B+树大约能存2000w条数据 【拓展】\nMySQL的InnoDB引擎中，B+树m每个节点的数据页大小可以通过调整innodb_page_size来修改 (一般为 4KB / 8KB / 16KB)\n16. MySQL如何进行SQL调优 分为预防和解决慢查询两个角度阐述。总结起来就三点，命中索引、减少回表、减少I/O.\n【预防】\n合理设计索引，减少回表次数，减少I/O 避免 select * 操作。因为正常情况下，部分字段是没有二次索引的，它会用主键id或者rowid 进行回表查询，会增加系统的I/O。 避免让索引失效，比如对索引字段进行计算、聚合函数、非同类型比较 (强制转换)和范围查询 (\u0026gt;、\u0026lt;、like %xxx%)。还有联合索引不匹配最左前缀原则 避免对非索引字段，使用group by、order by、dinstinct等函数 连表查询的是否需要保持不同字段的字符集一致，不然也会导致全表扫描。比如A表用utf-8，B表用latin1，查询的是否需要进行字符集转换，需要额外的计算，不能使用索引。 【解决慢查询】\n开启慢SQL日志记录功能，使用set global slow_query_log = \u0026quot;ON\u0026quot;， 默认是关闭的。设置一个查询延迟的阈值，把超过规定时间的SQL查询找出来。 利用explain关键字分析慢SQL的原因，比如看看是否有索引失效、select *等情况 17. 如何使用MySQL的EXPLAIN语句进行查询分析? 【EXPLAIN查询结果解释】\n名称 id select_type type key rows Extra 中文名称 查询的执行顺序 查询的类型 访问类型 关键索引 扫描行数 额外信息 说明 值越大优先级越高 SIMPLE简单查询、PRIMARY主查询、SUBQUERY 子查询 const \u0026gt; eq_ref \u0026gt; ref \u0026gt; range \u0026gt; index \u0026gt; ALL 实际用到的索引 值越小越好 Using index 表示覆盖索引、Using where 表示where条件过滤、Using temporary 表示临时表、Using filesort 表示需要额外的排序步骤 【type说明】\nsystem: 表明查询的表只有一行 (系统表)\nconst : 表明查询的表最多只有一行匹配结果。通常是查询条件为主键或唯一索引， 并且是常量比较。\neq_ref: 表明对于每个来自钱一张表的行，MySQL只访问一次该表，通常发生在链接查询中使用主键或唯一索引的情况下。\nref：MySQL 使用非唯一索引查询。查询的条件是非唯一的\nrange: MySQL 会扫描表的一部分，不是全部行。通常出现在索引的范围查询中 (比如\u0026gt;=、\u0026lt;=、BETWEEN)\nindex: 表示MySQL扫描索引中的所有行，但不是扫描表的所有行。\nall：表示需要扫描表的所有行，全表扫描。一般出现在没有索引的查询条件中。\n18. 请详细描述 MySQL 的 B+ 树中查询数据的全过程 【B+树查询过程】\n可以类比成去电影院 (4号厅 ) 找位置 的过程\n买票进门，从根节点(Page 20)出发，主键值为4, 范围在[1,5)中间，需要到 Page 2 非叶子节点查询 进入 Page 2 非叶子节点，主键值大于3，需要到Page 5 的叶子节点查询 进入Page 5 的叶子节点，通过Page Directory 内的槽查找记录，使用二分法快速定位查询记录在那个槽。 定位到槽之后遍历所有的记录，找到主键为 4 的记录 【Page Directory 页目录查找过程】\n假如页目录当中有5个槽，现在需要查找主键值为3的记录。查找过程如下：\n二分查找定位到槽2 槽2的最大记录是4，记录二分查找定位到槽1 槽1的最大记录是2，因为3 \u0026gt; 2， 直接向前遍历查询到主键值为 3 的记录 【B+树数据页的结构】\nInnoDB 当中B+树的每个节点以数据页(Page)为单位存储，每页默认大小为16KB。\n文件头： 记录叶子节点的上下页 (因为叶子节点是双向链表连接起来的) 最大和最小记录：表示页面当中最小的记录和最大的记录 （虚拟的记录） 在真实行记录的两侧 页目录: 数据页被分为若干个组，每个组对应一个槽 (Slot)。页目录内记录这些槽的位置，实现基于当前数据也的二分查找的快速定位。 【B+树的优势】\n参见问题14. 为什么 MySQL 选择使用 B+ 树作为索引结构？\n19. MySQL 中 count(*)、count(1) 和 count(字段名) 有什么区别？ 【效率层面】 count(*) ≈ count(1) \u0026gt; count(唯一索引) \u0026gt; count(主键) \u0026gt; count(其他字段)\n【具体区别】\n类型 统计内容 说明 count(*) 表中所有记录，包括NULL值 直接统计表的记录数，不依赖字段内容。MySQL特定优化，开销最低 count(1) 表中所有记录，包括NULL值 参数1被视为常量，不依赖字段内容。未优化，性能略低于count(*) count(唯一索引) 唯一索引字段中的所有非 NULL 的记录 遍历非聚簇索引统计字段行数，因为没有NULL 值，所以结果和count(*)差不多 count(主键) 主键字段中的所有非 NULL 的记录 遍历聚簇索引统计主键字段行数，因为没有NULL 值，所以结果和count(*)差不多。但是，有回表操作，会产生额外的I/O。 count(其他字段) 其他字段中的所有非 NULL 的记录 读取字段值，判断是否未NULL。如果记录较大，性能较差。 20. MySQL 中 varchar 和 char 有什么区别？ 【主要区别】\n特点 char varchar 长度 固定长度，不足的用空格补齐 (InnoDB会自动忽略补齐的空格) 非固定长度 存储空间 始终占用固定长度空间 随着长度的变化而变化，还有1~2字节的额外空间，用于说明长度信息 性能影响 如果长度忽大忽小，可能浪费 比较节省空间 使用场景 存储长度固定且较短的字符串 存储变化或稍微较长的字符串 【注意事项】\nvarchar 长度不要太大：因为MySQL在利用order by排序的过程当中，会用到 sort_buff。如果varchar所设定的长度过大，就会使用双路排序。而双路排序在对排序字段排序之后，只能拿到主键值和索引列的值。需要使用主键值再进行回表查询操作，会增加系统的I/O，降低系统性能。 varchar(n) 当中的n 表示的是字符数，而不是字节数。通常最大行长度是 65535 字节，如果允许未null， 需要额外一个字节标注是否未null。 而varchar 需要1~2个字节来标注字段的长度。所以，支持的最大长度为65535-2 = 65533 字节。一般情况下，UTF-8字符集占用3个字节。所以，最大字符数n 为 65533 / 3 = 21844 个字符 21. MySQL 是如何实现事务的？ 【事务四个特性 - AIDC】\n原子性：事务要么全部执行成功，要么全部执行失败 隔离性：并发的事务之间相互是不干扰的，可见性由隔离级别进行控制。MySQL的默认隔离级别是RR，可重复读 持久性：事务一旦提交，确保修改的数据会被永久保存 一致性：事务执行前后，数据库要保持一直的状态，所有的业务规则、约束和触发器的规则必须满足。 【如何实现事务】\n实现事务其实就是要确保满足事务的四个特性，如何满足呢？\n原子性：通过Uodo Log 实现，从事务开始的时候，Undo Log 里面会存储事务的反向操作。就是保存数据的历史版本把，用于事务的回滚，让事务执行失败之后可以恢复到之前的样子。\n隔离性: 通过锁和MVCC 多版本并发控制来实现的，主要是控制不同隔离级别下事务间的方法，确保事务之间不相互干扰。\n持久性：通过Redo Log来实现的，Redo Log会记录事务对数据库的所有修改操作。当MySQL发送宕机或崩溃的时候，可以根据Redo Log 里面的记录来恢复数据。满足事务的持久性。\n一致性： 其实事务的一致性就是AID实现的，也就是说事务是通过原子性、隔离性、持久性来满足一致性的。\n22. MySQL有哪些锁的类型? 【按粒度分类】\n全局锁: 对整个数据库进行加锁，处于只读的状态，一般用于数据库逻辑备份。这个时候所有的数据操作(增删改)和表结构操作(ALTER 和 DROP)都会被阻塞。 表级锁: 锁的是整张表。实现比较简单，资源消耗低。 行级锁：锁的是某一行。粒度最小，支持高并发。但是加锁的开销大，可能导致死锁。 【按功能分类】\n共享锁 (S 锁, share Lock): 读锁，顾名思义是共享的，所以可以共享锁之间可以兼容，一般用于事务读取数据的时候 排他锁 (X 锁, exclusive lock)：写锁，顾名思义是拒绝别人的，所以不允许多个事务同时获取，排他锁之间不兼容。一般用于事务修改记录的时候。 -- 添加共享锁 SELECT ... LOCK IN SHARE MODE;\t-- 共享锁 SELECT ... FOR SHARE # MySQL 8.x 版本 -- 排他锁 SELECT .... FOR UPDATE; 【全局锁】\n直接锁住整个数据库，处于只读模式。业务只能读取数据，不能更新数据。\nFLUSH TABLES WITH READ LOCK 【表级锁】\n表锁\n表级共享锁：阻止其他会话对表的写操作，当前会话只能读该表，不能访问其他表 表级排他锁：阻止其他会话对标进行任何操作（读和写），当前会话只能读该表，不能访问其他表 # 添加表级共享锁 lock tables user read; # 添加表级别排它锁 lock tables user write; 元数据锁：事务执行SELECT 的时候，其他线程的DDL操作(ALTER、DROP)操作会被阻塞，直到事务提交\n意向锁\n意向共享锁 (IS)：表明有意向对该表某些记录添加共享锁 (S 锁) 意向排他锁 (IX)：表明有意向对该表某些记录添加排他锁 (X 锁) 意向锁之间相互兼容，不会和行级别的共享锁和排他锁发生冲突。但是，意向排他锁和共享锁、排他锁之间是冲突的。\n锁名称 S X IS IX S ✅ ❌ ✅ ❌ X ❌ ❌ ❌ ❌ IS ✅ ❌ ✅ ✅ IX ❌ ❌ ✅ ✅ 自增锁\n用于主键自增的一种锁。事务向有自增列的表插入数据是会先获取自增锁，拿不到锁就被阻塞。但是可以通过修改innodb_autoinc_lock_mode自增锁模式进行调整，自增锁的具体实现方式：\n自增锁模式 介绍 说明 0 传统模式 采用AUTO-INC 锁，语句执行结束释放 1 连续模式 对普通insert，自增锁申请后马上释放。对于批量插入，等语句执行结束之后释放 2 交错模式 申请自增主键后马上释放，无需等待语句执行完 【行级锁】\n记录锁\n事务对某条记录加S锁，其他记录也可以加，但是不能加X锁 事务对某条记录加X锁，其他事务既不能加S锁也不能加X锁 BEGINE; # 针对主键 id 为 2 的这条记录添加 X 型的记录锁；其他事务就无法对这条记录进修改 SELECT * FROM user WHERE id = 2 FOR UPDATE; 间隙锁\n防止在可重复读的隔离级别下，出现幻读问题。\n比如，事务A开始读取数据, 发现是3条数据。然后，事务B加了一条数据进去。事务A在读去数据,发现是4条数据, 前后数据总数不一致就是幻读。\n临键锁：记录锁 + 间隙锁的组合，既可以锁住记录，也可以防止幻读\n插入意向锁\n意向锁用于快速判断是否可以对某张表加表锁，而无需判断表中具体行的锁定情况。\n插入意向锁的作用：\n标记插入意向图：事务告诉InnoDB，它计划在某个间隙范围内插入新数据。 允许多个事务并发插入不同位置：也就是说如果插入的范围不同，插入意向锁之间互不从突。 【注意】\n一个事务有间隙锁时，另外一个事务不能在相同范围内加插入意向锁 一个事务有插入意向锁是，另外一个事务不能在相同范围内假如间隙锁 23. MySQL 中的 MVCC 是什么？ 【当前读和快照读】\n当前读：select ... lock in share mode、select ... for update、insert/delete/upate 有锁，会阻塞其他事务。当前读不会生成ReadView， 只会加上临键锁next-key lock (记录锁+间隙锁) 快照读：直接 select，普通的查询操作，不加任何锁，不会阻塞其他事务。会生成ReadView，不会有幻行 【隔离级别】\n不同的隔离级别分别解决了脏读、不可重复读、幻读的问题。\n隔离性 读未提交 RU 读已提交 RC 可重复读 RR 串行读 脏读 ❌ ✅ ✅ ✅ 不可重复读 ❌ ❌ ✅ ✅ 幻读 ❌ ❌ ❌ ✅ 【注意】只有读已提交 RC 和可重复读 RR 才会用到快照读\n可重复读 RR，快照会在事务开始时生成，对数据进行更改才修改快照 读已提交 RC ，每次读取都会重新生成快照，总是读取行的最新版本，所以不可重复读 【MVCC】\nMVCC多版本控制并发主要是用来解决 读-写并发 所引起的问题的\n隐藏字段： db_row_id: 如果没有创建主键，就用这个字段来创建聚簇索引 db_trx_id：对该记录左最新一次修改的事务的ID db_roll_ptr: 回滚指针，指向这条记录的上一个版本。其实是只想undo log当中上一个版本的快找地址 Read View: 隐藏字段和 undo log版本决定的是返回的数据，但是具体返回哪个版本，由read view 和版本链返回规则可见性算法控制\ntrx_ids : 表示生成readview是,当前系统中活跃的读写事务的事务ID列表 low_limit_id：应该分配给下一个事务的id值 (最大事务id + 1) up_limit_id: 未提交的事务中最小的事务id (最小事务id) creator_trx_id: 创建该readview的事务id 什么情况是可以看见的? trx_id == creator_trx_id (当前事务修改的)、trx_id \u0026lt; up_limit_id (事务已提交)，up_limit_id \u0026lt; trx_id \u0026lt; low_limit_id (如果trx_id 不在 trx_ids 里面，说明不是这条数据不是存活的事务掌控的，数据已经提交了) 都是可见的。 trx_id \u0026gt; low_limit_id 是不可以访问的\n如果发现当前的记录是不可见的，那么就需要找undo log日志的历史快照了，如果找不到，则返回空。\n【不同隔离版本ReadView的产生时机】\n读已提交 RC，每次select 都会获取一次Read View 读未提交 RR， 只有第一次select才会获取Read View 【二级索引在索引覆盖通过的时候可以用MVCC吗？】\n已知如果查询字段包含了所有的二级索引，那么就会走索引覆盖，而不会回表用主键或row_id去读主键索引的页记录。但是，版本链的头节点在主键索引当中 ( 版本链包含row_id ), 通过二级索引的记录没法儿直接找到版本链。这种情况如何用MVCC？\n二级索引中，用一个额外的page_max_trx_id 来记录修改过该页的最大事务id\n如果查询到的readview 的最小未提交的事务id \u0026gt; page_max_trx_id， 说明在创建该readview时，最后一次更新二级索引的事务已经提交了，也就是说对当前查询是可见的，如果二级索引的记录没有被删除，就直接走索引覆盖。 如果最小未提交的事务id \u0026lt;= page_max_trx_id， 意味着数据可能被修改了。不能直接查询，需要回表，用聚簇索引进行查询。聚簇索引中，叶子结点行记录包含了版本链，可以用MVCC。 【可重复读RR隔离级别是否可以解决幻读】\nRR隔离机制不能完全解决幻读的现象，虽然它用了间隙锁，在一定程度上可以解决幻度。\n但是，如果存在下面这种情况就不行。\n事务A进行快照读, 然后事务B插入了一条记录并提交。此时，事务A是可以update 这条语句的，这样就出现了幻读。 当事务中先执行快照读，再执行当前读时，可能因读取最新数据而触发幻读 -- 事务A（RR隔离级别） BEGIN; SELECT * FROM users WHERE age \u0026gt; 20; -- 快照读，返回空结果 -- 事务B插入 age=25 的记录并提交 SELECT * FROM users WHERE age \u0026gt; 20 FOR UPDATE; -- 当前读，返回事务B插入的记录 24. MySQL 中的日志类型有哪些？binlog、redo log 和 undo log 的作用和区别是什么？ binlog 二进制日志: binlog是MySQL的二进制文件，用于记录所有的增删改操作 (包括表结构和数据的操作)。binlog是在事务提交后生成的，可以用于恢复数据库和备份数据库。(一般MySQL都有主库+从库两个数据库，防止单台故障，binlog就是为了同步主库和从库的) redo log 重做日志: redo log使用来恢复数据的，保证数据的一致性和持久性。当MySQL发生修改是，redolog会将这些操作记录下来，并写入磁盘。当数据库宕机时，可以通过重放redo log恢复数据 undo log 回滚日志: undo log是用于回滚操作的。当MySQL开始事务的时候，undo log会记录这些操作的反向操作。当需要回滚的时候，通过执行相反的操作，就可以回滚事务。 【区别】\n日志名称 作用层级 作用 内容 写入方式 写入时间点 binlog Server层 记录所有操作，支持备份恢复和主从复制 记录逻辑操作 (SQL语句 / 行的变化) 追加写入，写满之后创建新文件，再写 事务提交完成后，写入一次 redo log InnoDB存储引擎层 保证数据的一致性和持久性，用于故障恢复(断电宕机) 记录物理修改 (数据页的修改) 循环写入，固定大小，写完之后从头开始写 事务进行中，不断写入 undo log InnoDB存储引擎层 保证事务的原子性，用于回滚数据 记录事务修改钱的数据，用于回滚和MVCC 随事务变化生成，形成版本链 事务进行中，不断写入 【undo log 结构图】 【Redo Log + Undo log 结构图】\n25. MySQL隔离级别有哪些? MySQL的隔离级别包括四类: 读未提交 RU、读已提交 RC、可重复读 RR、串行化\n读未提交 RU : 顾名思义，如果有两个事务，事务A会在执行过程中读取,事务B还没有提交的修改数据。会出现脏读的情况， 就是读取了其他事务还没提交的数据。 读已提交 RC: 顾名思义，如果有两个事务，事务A会在执行过程中，读取事务B提交之后的数据，若未提交不会读取。但是会出现不可重复读的现象，过程如下。 事务A第一次select name where id = 1读取的数据为 小邓 事务B update user set name = '小刘' 并提交 事务A再次select name where id = 1读取的数据为 小刘 ，结果发生了变化 (你**的究竟是谁) 可重复读 RR: 为了解决不可重复读的现象，RR 隔离级别下，事务A会只用第一次 select (快照读)的时候，生成read view。如果事务B修改同一行的数据并提交。事务A第二次select (快照读)的时候，会用第一次的查询结果。但是，它会出现幻读的现象，过程如下。 事务A第一次select count(*) 读取的数据为 10， 采用的快照读 事务B insert xxx 新增了一条数据并提交 事务A第二次用select count(*) for update，采用当前读。读出来的数据为11条 串行化： 可以理解成把RR隔离级别下，所有的快照读都替换成当前读。当前读的状态下，其他事务不能修改正在读取的数据，实现了读的一致性，避免了幻读。 但是并发性能很低。 【不同隔离级别的特性】\n特性 读未提交 RU 读已提交 RC 可重复读 RR 串行读 脏读 ❌ ✅ ✅ ✅ 不可重复读 ❌ ❌ ✅ ✅ 幻读 ❌ ❌ ❌ ✅ 并发量 高 较高 较低 低 【RR 隔离级别幻读的解决方案】\n只采用下面的某一种方式进行读，就不会出现幻读\n快照读 (MVCC机制)：利用MVCC多版本控制，不会出现幻读。 当前读 (加锁查询)：通过临键锁Next-key Lock (记录锁 + 间隙锁)，避免其他事务修改数据，防止幻读。其实就是串行化隔离级别。 26. 数据库的脏读、不可重复读和幻读分别是什么？ 名称 定义 定义(整活版) 脏读 事务A读取到了事务B还没提交的数据 骗子啊!!! 不可重复读 事务A第一次读取的数据和后面读取到的数据不一致 谁**动我东西了? 幻读 事务A第一次读取的数据总数和第二次读取的数据总数不一样 闹鬼了，进去前3个人，出来了4个人 整活版解释参见ID为 小明 的天才选手\n27. MySQL 默认的事务隔离级别是什么？为什么选择这个级别？ MySQL默认的事务隔离级别是可重复读 RR 。\n【为什么选 RR 隔离级别】\n因为MySQL当中一般是有主库 + 从库两个数据库，为了避免一个库突然g了，数据库就全g了。主库和从库之间是采用binlog进行备份的，如果binlog是statement格式，在RU和RC的隔离级别下，主库和从库就会出现数据不一致的问题。\n【binlog 格式】\n格式名称 内容 优点 缺点 statement 记录执行的SQL语句，发送到从库执行 日志量少，传输率高，简单操作 limit 这种依赖环境的函数，可能出现数据不一致情况 row 记录每行数据变化，发送到从库应用 准确复制数据，避免主从不一致的情况 日志量大，占用带宽和空间 mixed 结合语句和行复制，自动切换 日志量一般，主从一致性较高 自动切换操作复杂 【RU 和 RC 导致主从不一致】\nsession1 session2 事务A开始 delete from user where age \u0026lt; 10 事务B开始 insert into user value(5,...) 事务B提交 事务A提交 此时，binlog里面记录的如下，执行顺序显然和原始的不一样，从库里面age = 5 这条数据肯定没了\ninsert into user value(10,...) delete from user where age \u0026lt; 10 【为什么 RR 不会出现主从数据不一致】\n因为 RR 隔离级别不仅会对更新的数据行添加行级的记录锁， 还会添加间隙锁和临键锁。如果有这两个锁的话，在事务B执行insert的时候，会被阻塞的。\n【为什么大厂一般用 RC 】\n先来对比一下RC 和 RR 隔离级别的区别\n特性 RC RR binlog格式 只能用row, 用mixed也会自动切换未row statement、row、mixed 锁机制 只有行级的记录锁 记录锁、间隙锁、临键锁 读机制 当前读：每次都生成新的快照，读取行的最新版本 同时支持当前读和快照读，默认select是快照读 并发性 并发性高 并发性低：因为有间隙锁、临键锁，会导致锁竞争加剧，降低系统的并发性能。 用RC的原因有两个:\n提高并发：因为相较于RR，RC 的并发率更高 减少死锁：因为RR 当中的间隙锁和临键锁会使得锁的粒度变大，死锁的几率会变大。 【 RC 如何解决不可重复读问题】\n如果只是单纯的不可重复读，其实还好，只要后面修改数据不基于这个值。所以，在修改核心表的时候，增加乐观锁的标记。更新的时候带上乐观锁进行版本判断之后，再更新。\n28. MySQL 事务的二阶段提交是什么？/ MySQL里面的 Redolog 和 BinLog 怎么保持一致? 首先，事务的二阶段提交就是为了让MySQL中的 binlog 和 redo log 保持一致。\n【为什么需要两阶段提交】\n如果没有两阶段提交，可能会导致binlog和redo log不一致，可以参考下面两种情况\n**情况一：**先写完 redo log，再写binlog：如果写完redo log后，MySQL突然宕机了，binlog还没写入数据。此时，MySQL重启后，根据 redo log 恢复事务的修改，但是binlog没有本次事务提交的数据。所以通过binlog恢复的时候，这次事务的修改就丢了。\n**情况二：**先写完binlog，再写redo log：如果写完binlog之后，突然MySQL宕机了，redo log还没写入数据。重启后因为redo log里面没有记录，所以没法儿恢复事务的修改。但是binlog记录了本次事务提交的数据，后续用binlog恢复数据的时候，就导致和原库不一样了。(binlog是用来给从库复制的)\n为了避免上面的两种情况发生，就把单个事务的提交拆分为2个阶段：准备阶段(prepare) + 提交阶段(commit)\n【事务的二阶段提交过程】\nprepare 准备阶段: InnoDB 将内部事务id XID 写入redo log，并将其标记为 prepare 状态。然后将redo log 持久化到磁盘或者写入redo log buffer，具体取决于 innodb_flush_log_at_trx_commit 参数 commit 提交阶段：将内部事务id XID写入到binlog，调用write()函数写入到文件系统的Page Cache。当binlog写入磁盘成功就认为事务就是执行完成了，就算redo log 还是prepare状态也没事儿。 如何解决的上面提到的两种情况呢？\n情况一： 写完 redo log 之后，还处于prepare状态，还没写入binlog， 突然宕机了。 MySQL重启后，会顺序扫描redo log文件，如果还处于prepare状态，就查看redo log当中的内部事务IDXID在binlog中是否存在 如果binlog不存在内部事务idXID，表明redolog已经刷盘(写入磁盘了)，但是binlog还没有刷盘，直接回滚事务，就当这条事务执行失败 情况二： 写完bin log之后，还处于prepare状态，还没commit， 突然宕机了。 MySQL重启后，会顺序扫描redo log文件，如果还处于prepare状态，就查看redo log当中的内部事务IDXID在binlog中是否存在。 (一般都是先扫描redolog，再看binlog) 如果binlog里面有当前内部事务idXID，说明redolog和binlog都刷盘了，直接提交事务就好了。 【两阶段提交有没有什么问题】\n两阶段提交确实会导致磁盘I/O次数增高和锁的竞争变得激烈\n磁盘I/O的次数增高: 每次事务提交都会进行两次写入磁盘 fsync，一次redolog刷盘，一次binlog刷盘 锁竞争激烈：为了保证单事务的两个日志内容一致，所以需要在提交流程上，添加锁保证两阶段的原子性。确保日志里面的顺序，不受多事务提交的影响。 【优化二阶段提交：组提交】\n为了减少二阶段提交的I/O次数和锁的竞争，MySQL新增了组提交机制，可以让多个事务提交时合并多个binlog，只进行一次刷盘操作。组提交版本的二阶段提交只有commit提交部分有些变化：\nflush阶段：多个事务按照顺序将binlog从Cache写入到文件 (不刷盘)， 为了支撑redo log组提交 sync同步阶段：对binlog进行写入磁盘fsync操作，多个事务的binlog一并写入磁盘，为了支撑binlog的组提交 commit阶段: 所有事务按照顺序进行commit提交操作 每个阶段都有队列维护，锁针对队列进行保护，减小锁的范围的同时，提高效率。\n【binlog刷盘时间】\n事务执行过程中，线写日志到binlog cache (Server层的cache) 事务提交的时候，从binlog cache 写入到 binlog文件。单个事务的binlog不能拆开，只能一次性写入。 ​ MySQL分配了一片内存用于缓冲binlog ，就是binlog cache。可以用binlog_cache_size修改它的大小。\n29. 什么是 Write-Ahead Logging (WAL) 技术？它的优点是什么？MySQL 中是否用到了 WAL？ WAL 是用来确保在修改真正的数据之前，先将修改记录写入日志的技术。为了当系统宕机的时候，通过日志也可以恢复数据，MySQL的redo log就是依靠的 WAL技术。它的核心就是, 先写日志，再写数据\nMySQL事务从开启到提交的过程，大致如下：\n开启事务 -\u0026gt; 查询数据到内存 -\u0026gt; 记录undo log -\u0026gt; 记录redo log(prepare阶段) -\u0026gt; 更新内存 -\u0026gt; 记录binlog -\u0026gt; 记录redo log (commit之后)\n30. MySQL 中如果发生死锁应该如何解决？ 【如何处理MySQL死锁】\n设置MySQL死锁自动检测机制\nMySQL自带死锁检测机制innodb_deadlock_detect，开启即可。如果检查到死锁的发生，数据库会自动回滚一个持有资源较少的事务，然后另一个事务就可以执行了。\n-- 查看主动死锁检测是否开启 show variable like \u0026#39;%innodb_deadlock_detect%\u0026#39; -- 开启主动死锁检测 (默认为ON) set global innodb_deadlock_detect=\u0026#39;ON\u0026#39; 设置锁等待超时参数\n可以设置获取锁的等待时间(默认为50s)，如果超过了这个时间，就会主动释放锁，让事务回滚\n-- 事务等待锁的超时时间 (默认为50s) show variable like \u0026#39;%innodb_lock_wait_timeout%\u0026#39; KILL死锁事务\n如果MySQL已经上线了，且没有设置那些检测，可以直接把死锁的事务kill掉。kill之前，需要查看一下执行的事务和表信息，用show engine innodb status\n-- 查看死锁日志 -- 查看正在执行的事务, 和相关的表信息 SHOW ENGINE INNODB STATUS -- 通过线程ID, 手动KILL死锁事务 kill 线程ID 【如何避免死锁的发生】\n避免大事务: 大事务占用的时间比较长，容易导致死锁发生。可以把大事务拆解成多个小事务，就可以降低死锁的发生概率。 更改数据库的隔离级别：MySQL的默认隔离级别是RR，它包含间隙锁和临键锁。如果改成RC，可以减少死锁的概率。 合理加索引，减少加锁范围：命中索引会对该行加上行锁，没有命中则会对整张表加上表锁。表锁的冲突概率比较大，容易导致死锁。 31. MySQL 中如何解决深度分页的问题？ 深度分页问题定义：深度分页是指当用户需要查询很久以前的数据，比如早年某个范围的订单。 SQL语句当中的 limit 偏移量变得非常大，MySQL性能直线下降的现象。\n为什么会性能下降: 因为MySQL会选择全表扫描，而不用索引扫描，导致效率低下。当 limit 偏移量偏大的时候，查询流程如下：\n扫描偏移量之前的1000000行，丢弃不符合条件的结果 每一次查询都需要用 age 列查到的主键值去回表，效率很低。(MySQL优化器就选择了，全表扫描 + 文件排序) 返回符合条件的最终记录 select * from user where sex = \u0026#39;女\u0026#39; order by age limit 1000000, 10 【如何解决深度分析带来的性能问题】\n记录上一次的最大ID，修改为范围查询 (如果能够保证 id 连续递增)\n查询的过程中，会走主键索引，加快查询速度。但是高并发的情况下，可能出现数据重复或者遗漏的情况。\n# 可以通过记录上次查询结果的最后一条记录进行下一页的查询 SELECT * FROM user WHERE id \u0026gt; 1000000 LIMIT 10; 子查询\n通过子查询来获取 id 的起始值，把 limit 2000000 的条件转移到子查询。 查询过程如下：\n子查询语句利用id的主键索引快速找到这条记录，然后定位到 1000001 这条记录的主键 主查询语句将子查询返回的起始 ID 作为过滤条件，然后使用查询条件过滤掉前面的数据 可以减少全表扫描，提高性能。但是，子查询会生成临时表，复杂场景会导致性能下降。\nSELECT * FROM user WHERE id \u0026gt;= ( SELECT id FROM user order by id limit 1000000,1 ) LIMIT 10; 延迟关联\n和子查询类似，将limit 操作转移到主键索引上，让其减少回表次数来优化查询 (只查询id不用回表)。然后将子查询中的结果合并到主查询当中，避免创建临时表。整体性能比子查询好。查询过程如下:\n子查询语句利用 id 的主键索引来快速找到符合条件的前10条记录的id 通过inner join 内连接将id 和 主表进行关联，获取完整记录 select user.* from user t1 inner join (SELECT id FROM user order by id limit 1000000, 10) t2 on t1.id = t2.id 覆盖索引：\n覆盖索引包含所有需要查询的字段(都是索引的，可以避免回表操作\n-- 覆盖索引查询 SELECT id, name FROM user by id limit 1000000, 10 优化方法 适用场景 优点 缺点 范围查询 主键或索引字段，连续性高 简单高效，减少扫面范围 不适用于非主键字段; 如果有高并发，可能会出现数据重复或者遗漏的情况。 子查询 偏移量大，索引列存在 利用索引快速定位，减少全表扫描 需要创建临时表，增加开销，复杂场景性能下降 延迟关联 主键索引存在，查询字段多 减少回表次数 查询逻辑复杂 覆盖索引 需要查询字段都包含在索引里面 无需回表查询，查询效率高 只能用于简单字段查询，查询的字段有优先 【如果出现表分页怎么办】\n假如出现表分页，比如现在有表1和表2。表1中按score字段排序为100,90,80，表2中按score字段排序为95,85,75。然后适用select score from student_info limit 1, 2 查询出来的是 90 (表1) 和 85 (表2)的合并结果。\n解决方案：将分页条件改写为limit 0, 3，取出所有前两页数据，再结合排序条件计算出正确的数据。如果遇到表分页的情况，必须从offset = 0的地方开始查询，避免漏掉数据。\n32. 什么是 MySQL 的主从同步机制？它是如何实现的？ 主从同步机制: 将主数据库上的数据同步到多个从数据库中的技术 为什么会有主从同步?: 因为如果MySQL只有一个数据库，当数据库文件损坏了，所有的数据都没了。为了防止这种单台故障，就有了主从数据库。主从数据库之间为了保持数据一致，就有了主从同步。 【主从同步的流程】\n从服务器创建线程: 从服务器开启主从复制之后，创建I/O线程和SQL线程 从服器和住服务器建立连接：从服务器的I/O线程和主服务器建立连接，主服务器的binlog dump 线程和从服务器进行交互 从服务器告知同步位置：从服务器的I/O线程会告知住服务器的 dump 线程从哪里开始接受 binlog。 **主服务器更新binlog：**主服务器把所有的更新记录从Page Cache 写入binlog 文件 (有三种格式：statement、row、mixed) dump线程控制binlog传输： 主服务器的dump线程检测到binlog变化，从指定位置读取。从服务器的I/O线程开始拉取binlog 文件，采用拉取模式有利于从库管理同步进度和处理延迟 中继存储到relay log： 从服务器的I/O线程将接收到的来自binlog中的内容，存储到relay log 重放relay log，写入数据：从服务器的SQL线程读取relay log 内容，解析成具体操作之后写入到对应的表中 【主从同步的三种方式】\n同步模式 说明 优点 缺点 异步复制(默认) 主库执行完事务马上给客户端返回，从库异步进行复制操作。 性能高 数据一致性低 同步复制 主库执行完事务等待从库复制完的信息，然后再给客户端返回 数据一致性高 性能较差，延迟大 半同步复制 主库执行完事务等待指定个数的从库复制完信息，然后给客户端返回 数据一致性和性能都居中 仍有丢失数据的可能 下面图片就是半同步复制/同步复制的过程，半同步复制可以设置检查从库的个数\n【从数据库的并行复制】\n从数据库默认是按照顺序逐条执行binlog的日志指令(也就是重放relay log)，但是串行执行可能导致从库的复制数据赶不上主库，所以就出现了下面的几种并行复制模式\n并行复制模式 特点 优缺点 MySQL 5.6 库级别并行 将不同数据库db1和db2的事务同时分开执行 事务都在同一个库时，失效 MySQL 5.7 组提交事务 将组提交的事务当作独立的事务，多线程并行执行 如果事务的last_commited相同，则说明再同一个组提交的，即便不冲突，也不能并发执行 MySQL 5.7 逻辑时钟 给prepare阶段的不存在锁冲突的事务打上时间标记sequece_number，后面直接提交 sequence_number就是last_commited，假如这个值相同，不冲突，也不能并发 MySQL 8.0 WriteSet WriteSet可以通过哈希算法对主键生成标识，来判断事务之间是否冲突，不冲突就可以并行复制 可能实现起来比较复杂 33. 如何处理 MySQL 的主从同步延迟？ 首先，MySQL的主从同步是一定存在延迟的。主从同步延迟是指主库更新完成之后，从库还没来得及更新，导致主从数据不一致。这种延迟对一些实时数据需求高的业务场景(比如金融系统)会造成影响。\n【为什么有主从同步延迟】\n从整体上看，有下面两个原因：\nrelay log赶不上binlog: 从库接受binlog的速度跟不上主库写入binlog的速度，从库的redo log就会比主库的binlog滞后 SQL执行赶不上relay log: 从库SQL线程执行relay log的速度比不上I/O线程接受binlog的速度，导致从库滞后relay log 导致上面两个情况发送的原因可能是：\n从库性能不足：CPU、内存、磁盘I/O比主库差一些，同步速度慢 从库读请求多：要分配一部分资源去满足读请求，影响同步的效率 主库提交太多大事务：从库去同步一个大事务需要较长的时间 从库数量过多：主库推送binlog开销大，导致延迟 网络延迟：主库和从库之间的网络延迟比较大，导致同步速度受限制 复制模式：默认采用异步复制模式，主库不等待从库完成复制，肯定有延迟 【避免延迟的方法】\n强行把写入后的读请求交给主库处理 （不推荐）: 把写入后的读请求给主库处理，可以避免主从延迟，但是主库承受的压力也会增大\n用半同步复制：半同步复制可以保证至少有一个从库复制完成了\nSET GLOBAL rpl_semi_sync_master_enabled = 1; SET GLOBAL rpl_semi_sync_slave_enabled = 1; 优化主从结构\n提升从库性能：配好一点的CPU、内存、磁盘I/O 减少从库数量：减少主库的同步开销 拆分读流量：把读请求负载均衡到多个从库上 sleep方案：假设主从库的延迟为1s，可以每次执行一个 select sleep(1)， 保证拿到最新的数据。\n34. MySQL中的长事务可能会导致哪些问题？ 长时间的锁竞争，阻塞资源：长事务持有的锁时间比较长，容易导致其他事务再获取相同锁的时候，发送阻塞，增加系统的等待时间和降低并发性能。业务线程会因为长时间的数据库请求而被阻塞，部分业务的阻塞会影响到其他的业务，导致产生雪崩。最终可能会让服务全面崩盘，导致严重的线上事故。 死锁风险：长事务更容易产生死锁，因为可能存在多个事务在互相等待对方释放锁，导致系统死锁。 主从延迟：长事务容易导致主从延迟，因为长事务需要主库花更长的时间执行，然后通过binlog传给从库。从库读取relay log的时候，重发操作又需要一长段时间，可能导致一大段时间数据是不同步的。 回滚导致时间浪费：如果事务执行了很长一段时间，突然执行出错，需要事务回滚，之前的执行都浪费了，耗费时间。 版本链过长：假如事务A对某条数据执行了10000次修改操作，在没有提交之前，事务B进行select 操作，会需要耗费很长的时间。 【长事务的SQL如何处理】\n拆分长事务SQL: 把单条SQL拆分为多条短事务SQL\n# 假如需要删除2021年的数据(4.8亿条)，共5亿条数据 delete from yes where create_date \u0026gt; \u0026#34; 2020-12-31\u0026#34; and create_date \u0026lt; \u0026#34;2022-01-01\u0026#34;; # 按照日期进行拆分成多条事务 delete from yes where create_date \u0026gt; \u0026#34; 2020-12-31\u0026#34; and create_date \u0026lt; \u0026#34;2021-02-01\u0026#34;; .... delete from yes where create_date \u0026gt; \u0026#34; 2021-11-31\u0026#34; and create_date \u0026lt; \u0026#34;2022-01-01\u0026#34;; 反向操作减轻事务时间：把需要旧表删除的数据转成新增到新的表，然后用新表替换旧表就可以了。\n长时间的锁竞争，阻塞资源：长事务持有的锁时间比较长，容易导致其他事务再获取相同锁的时候，发送阻塞，增加系统的等待时间和降低并发性能。业务线程会因为长时间的数据库请求而被阻塞，部分业务的阻塞会影响到其他的业务，导致产生雪崩。最终可能会让服务全面崩盘，导致严重的线上事故。\n死锁风险：长事务更容易产生死锁，因为可能存在多个事务在互相等待对方释放锁，导致系统死锁。\n主从延迟：长事务容易导致主从延迟，因为长事务需要主库花更长的时间执行，然后通过binlog传给从库。从库读取relay log的时候，重发操作又需要一长段时间，可能导致一大段时间数据是不同步的。\n回滚导致时间浪费：如果事务执行了很长一段时间，突然执行出错，需要事务回滚，之前的执行都浪费了，耗费时间。\n版本链过长：假如事务A对某条数据执行了10000次修改操作，在没有提交之前，事务B进行select 操作，会需要耗费很长的时间。\n【长事务的SQL如何处理】\n拆分长事务SQL: 把单条SQL拆分为多条短事务SQL\n# 假如需要删除2021年的数据(4.8亿条)，共5亿条数据 delete from yes where create_date \u0026gt; \u0026#34; 2020-12-31\u0026#34; and create_date \u0026lt; \u0026#34;2022-01-01\u0026#34;; # 按照日期进行拆分成多条事务 delete from yes where create_date \u0026gt; \u0026#34; 2020-12-31\u0026#34; and create_date \u0026lt; \u0026#34;2021-02-01\u0026#34;; .... delete from yes where create_date \u0026gt; \u0026#34; 2021-11-31\u0026#34; and create_date \u0026lt; \u0026#34;2022-01-01\u0026#34;; 反向操作减轻事务时间：把需要旧表删除的数据转成新增到新的表，然后用新表替换旧表就可以了。\n","permalink":"https://swimmingliu.cn/posts/job/mysql-interview-questions/","summary":"\u003ch2 id=\"1mysql-中的数据排序是怎么实现的\"\u003e1.MySQL 中的数据排序是怎么实现的？\u003c/h2\u003e\n\u003cp\u003e1.\u003cstrong\u003e排序方法\u003c/strong\u003e：索引排序和文件排序 (filesort)\u003c/p\u003e\n\u003cp\u003e2.\u003cstrong\u003e索引排序\u003c/strong\u003e：如果\u003ccode\u003eorder by xxx\u003c/code\u003e的字段为索引字段，则利用索引进行排序。效率最高，索引默认有序。\u003c/p\u003e\n\u003cp\u003e3.\u003cstrong\u003e文件排序 (filesort)\u003c/strong\u003e：内存排序(单路排序和双路排序)和磁盘排序，具体取决于排序数据的大小。其中，内存排序使用单路排序或双路排序，取决于\u003ccode\u003emax_length_for_sort_data\u003c/code\u003e(默认为4096个字节)\u003c/p\u003e\n\u003cp\u003e4.\u003cstrong\u003e双路排序\u003c/strong\u003e：取\u003ccode\u003erow_id\u003c/code\u003e(如果有主键，则为主键)和\u003ccode\u003eselect a,b,c order by xxx\u003c/code\u003e的\u003ccode\u003exxx\u003c/code\u003e字段放入\u003ccode\u003esort_buffer\u003c/code\u003e(排序缓存)中，将排序后的\u003ccode\u003erow_id\u003c/code\u003e回表查询\u003ccode\u003ea,b,c\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e5.\u003cstrong\u003e单路排序\u003c/strong\u003e: 直接把要查的所有字段放入\u003ccode\u003esort_buffer\u003c/code\u003e里，排序后直接得到结果集合\u003c/p\u003e\n\u003cp\u003e6.\u003cstrong\u003e磁盘排序\u003c/strong\u003e（归并排序）:将数据分为多份文件，单独对文件进行排序，然后合并成一个有序的大文件\u003c/p\u003e\n\u003ch2 id=\"2-mysql-的-change-buffer-是什么它有什么作用\"\u003e2. MySQL 的 Change Buffer 是什么？它有什么作用？\u003c/h2\u003e\n\u003cp\u003e1.ChangeBuffer定义：Change Buffer是InnoDB缓冲当中的一块缓存区，用于暂存二级索引的修改，避免二级索引页修改产生的随机IO\n2.ChangeBuffer注意事项：只能用于二级索引，不能用于其他任何索引，包括主键索引和唯一索引都不行。\n3.如果ChangeBuffer挂了，更改操作未执行，是否会出现脏数据？\n首先，ChangeBuffer也会保存在磁盘空间里面，redo log会记录Change Buffer当中的修改操作，确保数据一致性。\u003c/p\u003e\n\u003cp\u003e知识拓展1：一级索引和二级索引区别\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e一级索引（聚簇索引）\u003c/strong\u003e：数据表的主键索引，数据和索引存储在同一B+树的叶子节点中。每个表只能有一个一级索引。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e二级索引（非聚簇索引）\u003c/strong\u003e：除主键外的其他索引，叶子节点存储索引列的值和对应的主键值。通过二级索引查询时，需要先通过二级索引获取主键值，再通过主键值查询数据，这个过程称为“回表”。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e知识拓展2:  MySQL中有哪些常见索引？都有什么区别？\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e在MySQL中，索引是提高查询效率的关键工具。常见的索引类型包括主键索引、唯一索引、普通索引、全文索引和空间索引。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e1. 主键索引（Primary Key Index）\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e定义\u003c/strong\u003e：主键索引是一种特殊的唯一索引，用于唯一标识表中的每一行数据。每个表只能有一个主键索引，且主键列的值不能为空。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e特点\u003c/strong\u003e：主键索引的叶子节点存储完整的数据行，因此查询效率高。在InnoDB存储引擎中，主键索引是聚簇索引，数据存储与索引结构合并。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e2. 唯一索引（Unique Index）\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e定义\u003c/strong\u003e：唯一索引确保索引列的每个值都是唯一的，但允许有空值。与主键索引类似，不同之处在于唯一索引允许列值为NULL。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e特点\u003c/strong\u003e：唯一索引的叶子节点存储索引列的值和对应的主键值。在InnoDB中，唯一索引是非聚簇索引，数据存储与索引结构分开。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e3. 普通索引（Index）\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e定义\u003c/strong\u003e：普通索引是最基本的索引类型，没有任何限制。索引列的值可以重复，也可以为NULL。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e特点\u003c/strong\u003e：普通索引的叶子节点存储索引列的值和对应的主键值。在InnoDB中，普通索引是非聚簇索引，数据存储与索引结构分开。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e4. 全文索引（Fulltext Index）\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e定义\u003c/strong\u003e：全文索引用于对文本数据进行全文搜索，适用于MyISAM存储引擎。它允许对文本字段进行复杂的搜索，如查找包含特定单词的记录。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e特点\u003c/strong\u003e：全文索引的叶子节点存储文档的词项信息。在MyISAM中，全文索引是非聚簇索引，数据存储与索引结构分开。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e5. 空间索引（Spatial Index）\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e定义\u003c/strong\u003e：空间索引用于对地理空间数据进行索引，支持空间数据类型的快速查询。它适用于存储地理位置、地图等空间数据的表。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e特点\u003c/strong\u003e：空间索引的叶子节点存储空间数据的索引信息。在MyISAM中，空间索引是非聚簇索引，数据存储与索引结构分开。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e主键索引\u003c/strong\u003e：用于唯一标识每一行数据，值不能为空。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e唯一索引\u003c/strong\u003e：确保索引列的值唯一，但允许有空值。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e普通索引\u003c/strong\u003e：最基本的索引类型，允许重复和空值。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e全文索引\u003c/strong\u003e：用于对文本数据进行全文搜索，适用于MyISAM存储引擎。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e空间索引\u003c/strong\u003e：用于对地理空间数据进行索引，支持空间数据类型的快速查询。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"3-详细描述一条-sql-语句在-mysql-中的执行过程\"\u003e3. 详细描述一条 SQL 语句在 MySQL 中的执行过程。\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e连接器判断用户是否成功建立连接，数据库连接的权限校验\u003c/li\u003e\n\u003cli\u003e连接器会查询缓存，\u003ccode\u003ekey\u003c/code\u003e 是 SQL 语句，\u003ccode\u003evalue\u003c/code\u003e 是查询结果。如果命中，直接返回查询结果。(MySQL 8.0之后，就移除这个功能了)。\u003c/li\u003e\n\u003cli\u003e分析器分析SQL语法和词法是否有误\u003c/li\u003e\n\u003cli\u003e优化器生成SQL的执行计划，确定使用的索引和调整where的执行顺序（包括连表顺序）\u003c/li\u003e\n\u003cli\u003e执行器判断当前用户是否有权限查询该表，然后执行该SQL语句\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg alt=\"MySQL架构图\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/7457976c-ef5d-11ef-b738-c858c0c1deba\"\u003e\u003c/p\u003e","title":"MySQL面试题笔记"},{"content":"== 和 equals 区别 == 基本类型(int, long, float, char, boolean) 值比较， 引用类型(String，List) 进行地址比较\nequals 默认就是 == ，但是部分引用类型(String，List)重写了该方法，进行值比较\nget 和 post 区别 特性 GET POST 目的 获取资源，查询数据 提交数据，创建或更新资源 请求数据方式 参数通过 URL 查询字符串传递 数据通过请求体传递 数据暴露 数据暴露在 URL 中，较不安全 数据存储在请求体中，相对安全 数据大小限制 URL 长度有限制（约 2048 个字符） 没有数据大小限制 适用场景 获取数据，查询，展示资源 提交表单，上传文件，修改资源，发送敏感数据等 SpringMVC中@ReponseBody、@PathVariable、@RequestParameters在什么情况下使用? @ReponseBody 用于接受请求体数据，一般用于POST请求\n@PathVariable 用于接受路径参数，一般用户接受 id\n@RequestParameters 用于接受请求参数，一般用于GET请求\nJVM堆的结构、GC介绍和作用 JVM堆结构的参考文章 、 GC垃圾回收过程\n区域 主要用途 特点 新生代（Young Generation） 存储新创建的对象，快速垃圾回收 包含 Eden 区和两个 Survivor 区，采用复制算法进行回收 老年代（Old Generation） 存储长期存活的对象 回收频率较低，垃圾回收较耗时 永久代（Permanent Generation) (jdk 1.7） 存储类的元数据、方法字节码等 在 jdk 1.8 被 Metaspace 替代 元空间（jdk 1.8） 存储类的元数据 不再属于堆，使用本地内存，大小由系统限制 GC 是垃圾回收器， 作用是自动内存管理和避免内存泄漏\nInnodb和MYISAM的特点 InnoDB 和 MyISAM 是 MySQL 数据库管理系统中的两种主要存储引擎。 InnoDB 是 MySQL 5.5 版本的默认引擎。\n特性 InnoDB MyISAM 事务支持 支持事务（ACID），提供 COMMIT, ROLLBACK, SAVEPOINT 等语句 不支持事务 存储方式 行级锁（Row-level locking） 表级锁（Table-level locking） 支持外键 支持外键约束（Foreign Key） 不支持外键约束 崩溃恢复 支持崩溃恢复，自动恢复到一致性状态 不支持崩溃恢复，数据可能会丢失 性能特点 适合高并发读写的应用，性能较慢（因为使用行级锁） 适合读多写少的应用，性能较快（因为使用表级锁） 数据完整性 数据完整性和一致性强，支持原子性操作 不支持数据完整性，容易出现数据不一致 缓存机制 使用内存缓冲池来提高性能 使用内存缓存提高查询速度 适用场景 高并发、需要事务和数据一致性的应用，如金融、银行等 读多写少、数据一致性要求较低的应用，如日志记录、数据仓库等 行级锁（Row Lock）：InnoDB使用行级锁，避免了对整张表加锁的性能问题，允许多个事务并发访问不同的行。\n表级锁（Table Lock）：MySQL使用表级锁时，整个表会被锁定，导致其他事务无法访问表中的任何行，性能较低。\n意向锁（Intention Lock）：行锁和表锁之间的一种锁，InnoDB用来处理行锁和表锁之间的兼容性问题。\n如何理解数据库中的MVCC原理? MVCC原理解析\n脏读、幻读、不可重复读区别 快速理解脏读、不可重复读、幻读和MVCC\nMySQL事务 事务特性 (AIDC) 原子性（Atomicity）：事务中的操作要么全部成功，要么全部失败。MySQL会保证即使发生崩溃或中断，未提交的事务会被回滚。\n隔离性（Isolation）：事务的执行不应该被其他事务干扰。隔离级别控制了事务之间的“可见性”。\n持久性（Durability）：一旦事务提交，变更将永久保存，即使系统崩溃，数据也不会丢失。\n一致性（Consistency）：事务必须让数据库从一个一致的状态转换到另一个一致的状态，保证数据完整性。\n事务的隔离级别 读未提交：事务可以读取到其他事务未提交的数据，可能导致脏读。\n读已提交：事务只能读取已提交的事务数据，避免了脏读，但仍然可能出现不可重复读。\n可重复读：事务在其生命周期内读取的数据始终一致，避免了脏读和不可重复读。可能会出现幻读。\n串行化：最高的隔离级别，事务强制串行执行，避免脏读、不可重复读和幻读。但性能差，容易产生资源瓶颈。\n如何优化数据库 SQL优化 1.**避免使用 select ***\n2.索引优化\n索引使用：创建适当的索引，尤其是常用于 WHERE、ORDER BY、JOIN、GROUP BY 中的字段。\n覆盖索引：尽量让查询可以通过索引直接返回结果，避免回表。\n避免过多的索引：索引虽能加速查询，但也会增加插入、更新的成本。\n联合索引：对于多个字段常一起查询的情况，可以考虑创建联合索引。\n3.避免全表扫描\n使用 EXPLAIN 来分析SQL执行计划，检查是否有全表扫描，并优化查询。\n示例：EXPLAIN SELECT * FROM orders WHERE user_id = ? 可以检查是否使用了索引。\n数据库架构优化 1.分库分表：\n当数据量非常大时，可以通过分库分表来提高查询和插入的效率。 例如：按时间范围、ID范围或业务维度进行水平分表，按业务模块进行垂直分库。 2.读写分离 (Redis)：\n使用主从复制，主库处理写操作，从库处理读操作，减轻主库压力，提高系统的并发处理能力。 示例：主库执行 INSERT、UPDATE、DELETE，从库执行 SELECT。 (现在用Redis用来第一步判断，数据库后操作) 3.数据库冗余与备份：\n增加数据库的冗余副本，定期进行备份，确保数据的高可用性。 缓存优化 1.使用缓存来减轻数据库压力：对频繁查询的数据进行缓存（如使用 Redis），比如热门商品信息。\n2.合理的缓存策略：\n缓存穿透 : Redis 和 数据库都不存在，用空对象缓存到Redis\n缓存雪崩 :\n大量key同时过期：设置随机的TLL\nRedis服务宕机 : 设置Redis集群 + 哨兵模式 / 缓存业务降级限流 / 业务添加多级缓存\n缓存击穿：Redis的热点Key过期，互斥锁 / 逻辑过期\n3.避免缓存不一致：使用双写策略（更新数据库同时更新缓存），或通过异步更新缓存来避免缓存与数据库数据不一致。\n数据库连接池 使用连接池（如 HikariCP、Druid）可以有效地减少数据库连接的开销，避免频繁创建和销毁连接。\n数据库并发控制 1.事务与锁机制优化\n通过合理的事务管理和锁策略，避免死锁和性能瓶颈。 控制事务的粒度，避免长时间持有锁，减少锁竞争。 2.乐观锁与悲观锁：\n在适当的场景下使用乐观锁（如使用版本号），避免对数据加锁。 在高并发下，使用悲观锁（如数据库行级锁、悲观锁）确保数据一致性。 Redis一主两从+哨兵模式 Redis 采用一主两从+哨兵的集群方案，主要是为了在高并发和高可用的场景下保证系统的稳定性和可靠性。主节点(master)处理写请求，从节点(slave1 和 slave2)处理读请求，减少主节点的压力；哨兵机制监控主节点和从节点，能够自动进行故障转移，确保 Redis 集群在节点故障时的高可用性。\n普通的主从模式，当主数据库崩溃时，需要手动切换从数据库成为主数据库，这就需要人工干预，费事费力，还会造成一段时间内服务不可用，即存在高可用问题。我们又使用了哨兵。哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送ping命令，等待Redis服务器响应，从而监控运行的多个Redis实例。哨兵可以实现自动故障修复，当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换master。同时那台有问题的旧主节点也会变为新主节点的从节点，也就是说当旧的主即使恢复时，并不会恢复原来的主身份，而是作为新主的一个从。\nOAuth2.0 / 单点登录 (SSO) OAuth2.0 介绍、单点登录SSO介绍\n如何防注入攻击？ 1.使用预编译语句（Mybatis）： 将 SQL 语句与参数分离，防止恶意输入被解释为代码\n2.最小权限原则: 为指定数据库用户分配最小必要的权限，限制其只能执行特定操作，减少潜在的安全风险。\n3.避免动态拼接SQL ( XML里面 # 和 $ 区别): 使用#，而不用 $ 防止直接拼接\n如何设计表的映射关系 有一个订单表，一个产品表，一个产品订单表\n订单表（Order）：存储订单的基本信息，如订单ID、用户ID、订单日期、订单状态等。\n产品表（Product）：存储产品的详细信息，如产品ID、产品名称、产品价格、库存数量等。\n订单项表（Order_Item）：用于表示订单与产品之间的多对多关系，记录每个订单中包含的产品及其数量、价格等信息。\n哪些表需要加索引？对哪些字段加索引? 需要索引的表 对于记录数较多的表，建立索引可以显著提升查询性能。\n需要加索引的字段 1.主键字段：主键字段默认建立唯一索引，确保记录的唯一性和快速定位。\n2.经常作为查询条件的字段：在 WHERE 子句中频繁出现的字段，特别是在大表中，应建立索引，以提高查询效率。\n3.用于表连接的字段：在与其他表进行连接操作时，连接字段应建立索引，以加速连接操作。\n4.用于排序（ORDER BY）和分组（GROUP BY）的字段：这些字段建立索引后，可提高排序和分组操作的性能。\n5.选择性高的字段：选择性高意味着字段值的唯一性较高。在此类字段上建立索引，可以有效过滤数据，提高查询效率。\n下面是不需要加索引的\n避免在频繁更新的字段上建立索引：因为每次更新不仅要修改数据，还需维护索引，可能影响写操作性能。 (商品库存，商品信息)\n避免在低选择性字段上建立索引：如性别字段，只有 \u0026ldquo;男\u0026rdquo; 和 \u0026ldquo;女\u0026rdquo; 两种值，建立索引效果不明显。\n控制索引数量：过多的索引会增加数据库的维护成本，特别是在频繁写操作的场景下，需要在查询性能和写操作开销之间找到平衡点。\n组合索引 / 复合索引 / 联合索引 像组合索引和复合索引你知道吗?比如说我建了一个a,b,c联合索引。我写代码的时候先写的c，b，a可以吗?\n组合索引（也称复合索引或联合索引）是指在多个列上创建的单个索引，用于提高多条件查询的性能。\n当创建了包含列 a、b、c 的组合索引时，查询条件的顺序会影响索引的使用效果。\n这遵循 最左前缀原则，即索引的使用从最左边的列开始匹配，必须按照索引定义的列顺序进行匹配。\n所以不能使用 c，b ，a 查询。\nMySQL的索引在什么条件下会失效? 对索引字段的运算或函数操作\nSELECT * FROM users WHERE YEAR(birthdate) = 1990; 使用了通配符（LIKE '%abc'）\nSELECT * FROM products WHERE name LIKE \u0026#39;%abc\u0026#39;; 在 WHERE 子句中使用了不等于（\u0026lt;\u0026gt;）操作符\nSELECT * FROM orders WHERE status \u0026lt;\u0026gt; 1; 进行 NULL 值查询时未优化\nSELECT * FROM users WHERE phone_number IS NULL; 数据类型不匹配\nSELECT * FROM users WHERE age = \u0026#39;25\u0026#39;; 使用了 OR 操作符，特别是跨字段时\nSELECT * FROM products WHERE price = 100 OR category = \u0026#39;electronics\u0026#39;; 索引列的数据分布不均匀: 当索引列的数据分布极其不均匀时，即使索引可以使用，MySQL 也可能选择不使用索引，因为扫描全表比扫描索引更高效。\n事务放在MVC当中的哪一层？ 事务的管理应放在 Service层，这是因为Service层负责业务逻辑，可以统一控制跨多个DAO操作的事务。Controller层应该尽量避免直接管理事务，以保持系统的解耦性和职责清晰。而DAO层则专注于数据的持久化操作，不应承担事务管理的责任。\n什么时候应该添加事务？ 那我们查询list会加事物吗? 使用delete删除时会加事物吗?\n事务的使用场景：事务通常用于数据修改操作（如插入、更新、删除），确保数据一致性。\n查询操作的事务性：查询操作一般不需要事务，除非有一致性需求，需通过隔离级别来控制。\n增、删、改操作的事务性：增、删、改应该放在事务中进行，确保增、删、改的原子性。\n并发修改请求如何控制? 假设我的银行卡里面只有10块钱，现在过来10个请求都要扣10块钱，是你的话你会怎么控制?\n最直接的方式是保证每个扣款操作具有原子性。可以通过悲观锁或乐观锁来控制并发，确保多个请求不会同时扣款。\n1.悲观锁和乐观锁\n悲观锁通过数据库层面的锁机制（如 SELECT FOR UPDATE）防止并发修改余额。\n乐观锁通过版本号或 CAS 原理进行操作，适用于并发冲突较少的情况。\n2.分布式锁 （Redission）\n在分布式系统中，可以使用分布式锁来保证对共享资源的独占访问。\n3.队列和限流 (RabbitMQ)\n队列和限流 控制请求的处理速度，避免突发的高并发请求。\n分布式事务如何处理？它的作用? 为什么需要分布式事务：分布式事务用于解决分布式系统中不同服务之间的数据一致性问题，确保跨服务操作能够保证最终的一致性。\n分布式事务解决什么问题：主要解决跨服务的一致性，保证多个服务中的操作要么全部成功，要么全部回滚，保持数据一致性。\n分布式事务的解决方案：（后期学习）\n2PC：适合强一致性要求的场景。 TCC：用于操作更复杂的分布式场景。 Saga模式：适合长事务的分布式事务，通常用于最终一致性场景。 开发过程中Git分支管理 1.开发的时候来了一个新需求，你们的分支是怎么管理的?\n我们采用三种不同的前缀来管理 feat 新增、fix 修复、refactor 重构\n2.增加新需求，分支是从哪里新增的?\n每个新需求都会从 main 分支上创建一个 feat 分支进行开发。\n3.建完一个分支之后就开始改代码吗?\n确保你从主分支（main）创建了最新的分支，避免后续合并时的冲突。\n在开发前，应该确认需求的具体内容，并与相关团队成员对接，然后配置好对应环境，再进行开发。\n4.开发完之后测试的话，这个代码放到哪里去?\n我们会commit feat 分支，然后打包上传到测试环境，提交给测试\n5.假如现在又来了两个新需求，一个需求先上线，一个需求过几天上线。你们的分支是怎么管理的?\n当有多个需求时，先满足第一个要上线的 需求A 。然后再拉取代码，编写 需求B 的代码\n6.你们那个测试拉代码是运维拉代码还是测试拉代码？\n测试拉取代码\nSpringboot和Spring区别及理解 Spring：\n核心特性：Spring 提供了控制反转（IoC）和面向切面编程（AOP）的支持，主要用于构建企业级应用程序。 配置方式：Spring的配置是非常灵活但复杂的。通常，开发者需要通过 XML 配置、注解配置或 Java 配置类来配置 Spring 容器和各种模块。 模块化：Spring 框架分为多个模块，如 Spring Core、Spring AOP、Spring Data、Spring MVC 等，开发者需要根据需要集成和配置这些模块。 Spring Boot：\n自动配置：Spring Boot 提供了大量的自动化配置，开发者只需要少量的配置，甚至可以省去 XML 配置，简化了传统 Spring 配置的复杂度。 内嵌服务器：Spring Boot 提供了 Tomcat、Jetty、Undertow 等内嵌服务器，使得应用可以直接打包为可执行 JAR 文件，无需外部容器支持。 开箱即用：Spring Boot 提供了很多开箱即用的功能，例如，默认的应用结构、内置的健康检查、自动化的日志配置等，极大提高了开发效率。 Spring Boot Starter：使用“Starter”可以让开发者方便地引入常见的依赖包，避免手动配置和集成常用组件。 Spring和Springboot区别 特性 Spring Spring Boot 目标 提供企业级应用开发框架。 简化 Spring 应用的配置和启动过程。 配置方式 需要大量的 XML 或 Java 配置。 通过自动配置简化配置，几乎不需要手动配置。 应用启动 需要外部应用服务器（如 Tomcat）。 支持内嵌服务器，应用可以打包为可执行 JAR 文件。 依赖管理 需要手动配置依赖和版本。 提供预设的 Spring Boot Starter，自动管理依赖。 模块集成 需要开发者手动集成各个模块（如 Spring MVC, Spring Data）。 自动化集成各个模块，并提供开箱即用的功能。 开发效率 配置和集成较为繁琐，开发效率较低。 通过自动配置和开箱即用的功能，大大提高开发效率。 启动时间 启动速度较慢，需要等待容器的初始化。 启动速度快，集成化和内嵌式服务减少了初始化时间。 环境依赖 配置较为灵活，环境依赖需要手动管理。 内嵌服务器和自动配置降低了环境依赖问题。 RabbitMQ和Kafka区别和理解 Kafka 和 RabbitMQ 对比 - 原理\n应用场景 RabbitMQ Kafka 消息大小和格式 适合处理中小型消息，支持各种消息格式，包括文本、JSON等 适合处理大型消息和流式数据，支持批量消息传递和日志存储 实时性要求 支持低延迟的消息传递和定时功能，适用于实时消息处理 （微秒级） 延迟较高，主要优化吞吐量，适合高吞吐量数据流处理 （毫秒级） 吞吐量 吞吐量较低，适合低并发场景 吞吐量极高，适用于高并发、大数据场景 数据一致性和可靠性 提供消息确认机制和强大的持久化功能，保证消息不丢失 通过日志存储、分区和副本机制保证数据可靠性和高可用性 分布式系统支持 支持集群模式，但在扩展性上不如 Kafka 原生支持分布式架构，适用于大规模分布式系统 插件支持和生态系统 丰富的插件支持，易与各种技术和工具集成，功能多样化 插件支持较少，但生态系统广泛，主要用于流处理、大数据平台 ","permalink":"https://swimmingliu.cn/posts/job/java-interview-questions-notes/","summary":"\u003ch2 id=\"-和-equals-区别\"\u003e== 和 equals 区别\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003e==\u003c/code\u003e 基本类型(int, long, float, char, boolean) 值比较， 引用类型(String，List) 进行地址比较\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eequals\u003c/code\u003e 默认就是 \u003ccode\u003e==\u003c/code\u003e ，但是部分引用类型(String，List)重写了该方法，进行值比较\u003c/p\u003e\n\u003ch2 id=\"get-和-post-区别\"\u003eget 和 post 区别\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e特性\u003c/th\u003e\n          \u003cth\u003eGET\u003c/th\u003e\n          \u003cth\u003ePOST\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e目的\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e获取资源，查询数据\u003c/td\u003e\n          \u003ctd\u003e提交数据，创建或更新资源\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e请求数据方式\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e参数通过 URL 查询字符串传递\u003c/td\u003e\n          \u003ctd\u003e数据通过请求体传递\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e数据暴露\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e数据暴露在 URL 中，较不安全\u003c/td\u003e\n          \u003ctd\u003e数据存储在请求体中，相对安全\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e数据大小限制\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003eURL 长度有限制（约 2048 个字符）\u003c/td\u003e\n          \u003ctd\u003e没有数据大小限制\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e适用场景\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e获取数据，查询，展示资源\u003c/td\u003e\n          \u003ctd\u003e提交表单，上传文件，修改资源，发送敏感数据等\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"springmvc中reponsebodypathvariablerequestparameters在什么情况下使用\"\u003eSpringMVC中@ReponseBody、@PathVariable、@RequestParameters在什么情况下使用?\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003e@ReponseBody\u003c/code\u003e 用于接受请求体数据，一般用于POST请求\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e@PathVariable\u003c/code\u003e 用于接受路径参数，一般用户接受 \u003ccode\u003eid\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e@RequestParameters\u003c/code\u003e 用于接受请求参数，一般用于GET请求\u003c/p\u003e\n\u003ch2 id=\"jvm堆的结构gc介绍和作用\"\u003eJVM堆的结构、GC介绍和作用\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://www.51cto.com/article/710705.html\"\u003eJVM堆结构的参考文章\u003c/a\u003e 、 \u003ca href=\"https://www.bilibili.com/video/BV1dt411u7wi\"\u003eGC垃圾回收过程\u003c/a\u003e\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e区域\u003c/th\u003e\n          \u003cth\u003e主要用途\u003c/th\u003e\n          \u003cth\u003e特点\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e新生代（Young Generation）\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e存储新创建的对象，快速垃圾回收\u003c/td\u003e\n          \u003ctd\u003e包含 Eden 区和两个 Survivor 区，采用复制算法进行回收\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e老年代（Old Generation）\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e存储长期存活的对象\u003c/td\u003e\n          \u003ctd\u003e回收频率较低，垃圾回收较耗时\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e永久代（Permanent Generation) (jdk 1.7）\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e存储类的元数据、方法字节码等\u003c/td\u003e\n          \u003ctd\u003e在 jdk 1.8 被 Metaspace 替代\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e元空间（jdk 1.8）\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e存储类的元数据\u003c/td\u003e\n          \u003ctd\u003e不再属于堆，使用本地内存，大小由系统限制\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003ccode\u003eGC\u003c/code\u003e 是垃圾回收器， 作用是自动内存管理和避免内存泄漏\u003c/p\u003e","title":"Java面试题-随手记"},{"content":"Abstract 肺癌是全球最致命的癌症之一，早期诊断对于患者的生存至关重要。肺结节是早期肺癌的主要表现，通常通过 CT 扫描进行评估。如今，计算机辅助诊断系统被广泛用于辅助医生进行疾病诊断。肺结节的准确分割受到内部异质性和外部数据因素的影响。为了克服结节的细微、混合、粘附型、良性和不确定类别的分割挑战，提出了一种新的混合手动特征网络，可增强灵敏度和准确性。该方法通过双分支网络框架和多维融合模块集成特征信息。通过使用多个数据源和不同数据质量进行训练和验证，我们的方法在 LUNA16、多厚度切片图像数据集 (Multi-thickness Slice Image dataset)、LIDC 和 UniToChest 上表现出领先的性能，Dice 相似系数达到 86.89%、75.72%、84.12% 和 80.74分别超过了当前大多数肺结节分割方法。我们的方法进一步提高了肺结节分割任务的准确性、可靠性和稳定性，即使是在具有挑战性的 CT 扫描中也是如此。本研究中使用的代码发布在 GitHub 上，可通过以下 URL (https://github.com/BITEWKRER/DBNet) 获取。\nIntroduction 肺癌是全球癌症相关死亡的主要原因[1]。仅在美国，预计 2023 年将有 127,070 人死于肺癌，占所有癌症死亡的 21% [2]。不幸的是，超过 50% 的肺癌病例发生在发展中国家或不发达国家，与发达国家相比，这些国家的医疗资源有限[3]。\n为了增加生存机会，早期诊断和治疗肺癌仍然至关重要。在中国，研究表明，小于1厘米的I期肺癌的5年生存率为92%。然而，晚期肺癌的5年生存率低得多，仅为7.0%[4]。利用计算机断层扫描 (CT) 进行肺癌筛查已显示出可大幅降低死亡率的潜力 [5]、[6]。低剂量CT是目前肺癌筛查最常用的方法。此外，移动CT的引入有助于解决欠发达国家和偏远地区缺乏CT扫描仪的问题[6]。由于可能没有明显的症状，检测早期肺癌的存在可能会带来重大挑战。\n这种医学背景数据可以直接借鉴，Chatgpt润色改写就完事儿\n在 CT 图像上识别肺结节提供了疾病的关键指标 [1], [3]。这些结节代表圆形异常，其大小各异，直径范围为 3 至 30 毫米 [7]。为了进一步研究肺结节，美国国家癌症研究所组装了“肺部图像数据库联盟和图像数据库资源计划（LIDC）”数据集[8]。\n欠发达地区设备不足、人员不足，导致医生的诊断和治疗时间有限[9]。在这种情况下，医生的工作量很大、重复且耗时[10]、[5]。此外，由于与CT切片相比，肺部结节性病变占据相对较小的面积，长时间和密集的CT筛查可能会导致漏检小的、细微的或 GGO (肺磨玻璃结节) [3]，[6]。为了解决这些问题，计算机辅助诊断系统（CAD）出现并得到了快速发展，特别是随着基于深度学习技术的诊断方法的进步。 CAD系统大大减轻了医生的工作量，最大限度地降低了未发现结节的风险，并提高了肺结节诊断的效率和可靠性。然而，当前用于肺结节分割的 CAD 系统仍然面临一些挑战。\n下面详细阐述了肺结节分割的几个现有挑战，可以从这些挑战入手\n首先，放射科医生标记的肺结节包含九个诊断特征[11]，异质性表型阻碍了肺结节分割的发展。如图1所示，实心结节（a，b）具有清晰的形状和边界，而微妙的GGO结节（e）具有低对比度和模糊的边界[4]，使得网络很容易将它们分类为背景区域。空洞（g）结节降低了网络分割的敏感性，并且由于背景和分割目标之间的极度不平衡，小结节很容易被遗漏[12]。\n由于周围多余的组织结构，血管旁或胸膜旁（c、d、f）可能会导致网络分类错误[13]。此外，部分实性结节（h）比纯GGO更致密，产生更复杂的异质纹理，更容易发展成恶性结节[14]。\n其次，肺结节内部因素造成的分割困难在于医生注释、层厚、数据来源和数据质量。数据质量差或不同医生的经验可能会导致不同的注释和注释者数量。由多名医生注释的病变区域通常更可靠，减少了潜在的临床风险。在资源有限的地区，由于 CT 扫描仪短缺和成像设备陈旧，CT 扫描质量差的情况很常见。较厚的切片更有可能产生“体积平均效应”和伪影，使医生难以达成一致的诊断。即使使用移动 CT 扫描仪也可能无法提供完整的诊断详细信息。最后，目前大多数肺结节分割方法都是基于2D图像，但这些方法忽略了空间关系，因此提出一种有效的3D肺结节分割模型来捕获肺结节的空间位置、纹理和其他详细信息变得越来越重要以避免误诊和漏诊。\nChallenge:\n异质性: 肺结节的形状多异 （实心结节、磨玻璃结节 (GGO) 、空洞结节、血管和胸膜旁边的结节）\n数据集缺陷：数据集质量不好、较厚的切片和医生的不同标注都可能影响最后的分割结果\n2D网络缺陷：忽略了CT信息中的空间关系\n背景知识补充：在医学成像，特别是在使用计算机断层扫描（CT）进行诊断时，“体积平均效应”和“伪影”是两个可能影响图像质量和解读准确性的问题。\n体积平均效应：这是一种由于扫描切片厚度较大而引起的现象。在一个较厚的切片中，多个不同密度的结构可能被平均到同一个体素（三维像素）里。这意味着高密度和低密度区域可能会混合在一起，从而降低了图像的对比度和分辨率。这种效应使得较小的结构，如小肺结节，更难以被准确识别和分割，因为它们可能在较厚的切片中“消失”或与周围组织混合。 伪影：伪影是指在成像过程中由各种原因产生的非实际存在于原始对象中的图像特征。在CT扫描中，伪影可能由患者移动、成像设备的限制、软件处理算法或扫描参数设置不当等因素引起。较厚的切片可能加剧这些伪影，因为每个切片覆盖更大的体积，增加了平均和重建过程中出现错误的机会。 这段话中提到，“较厚的切片更有可能产生‘体积平均效应’和伪影”，意味着在使用较厚切片进行CT扫描时，上述两个问题更容易发生，这会降低图像的质量和可解释性。结果，医生在解读这些图像时可能会遇到困难，因为图像的不清晰和伪影可能导致诊断不一致或误诊。这就强调了使用高分辨率、薄层切片扫描和高质量成像设备的重要性，以提高诊断的准确性和一致性。\n针对上述肺结节的异质性特征，我们提出了一种新的混合手动特征，旨在提供额外的边界和病灶信息，显着提高肺结节分割的灵敏度，减少漏诊的发生，降低像素点的可能性错误分类。为了保证分割结果的可靠性，我们采用多位医师标注结果的平均值作为GroundTruth，并对单位医师标注的样本进行二次筛选。为了确保模型在不同数据源和数据质量上的鲁棒性，我们在不同来源、质量和尺度的数据集上训练模型，并在不同数据源和切片厚度上进行验证。为了有效地整合主、辅分支的特征信息，我们设计了多维融合模块，并从空间和通道维度进行学习，以增强网络的表示和泛化能力。最后，所提出的网络能够进行三维分割，有利于病变信息的全面获取。\n下面是 Main Contribution\n（a）提出了一种新的端到端双分支网络和融合模块，有效完成肺结节分割任务，简单易用，泛化性较好能力。\n（b）提出了混合手动特征来同时增强肺结节边界信息和对比度信息。\n（c）我们的方法显示了分割各种类型的肺结节的性能改进，特别是在细微的、混合纹理的、粘连的、良性的和不确定的结节中。\n(d) 研究并总结了不同层厚和尺寸下模型的性能变化和模式。\nRelated work 目前，肺部结节的分割方法有很多，可以分为基于算法的传统分割方法和数据驱动的深度学习分割方法。然而，传统的肺结节分割方法存在明显的缺陷，特别是当肺结节的边缘变得模糊时，导致性能急剧下降[15]。相比之下，数据驱动的方法表现出更好的性能[16]。\n数据驱动算法 \u0026gt; 传统分割算法 ==\u0026gt; 调研数据驱动算法的论文，利用数据驱动来创新\n多分支网络架构引起了广泛的关注和研究。这些结构擅长集成不同规模、视角和维度的不同特征，从而提高性能。为了解决肺结节的异质性以及结节与其周围环境的相似性的挑战，Wang等人[17]引入了中央聚焦卷积神经网络。该网络从 2D 和 3D CT 图像块中提取肺结节信息，并通过中央池化层保留中央位置的基本细节。 Chen等人[18]引入了Fast Multi-crop Guided Attention，一种基于残差的多尺度引导分割网络来解决这个问题。该方法最初将 2D 和 3D 图像输入单独的分支网络，以从多维相邻轴捕获上下文特征信息。随后，采用全局卷积层来感知和融合上下文特征，同时通过中央池化层增强对图像块的中心区域的关注。 Wang等[19]提出了一种提高不规则肺结节分割效率的方法，同时保持简单结节的准确分割。他们利用双分支框架来处理 CT 图像和边界梯度信息，使用密集注意力模块来关注关键结节特征，并使用多尺度选择性注意力模块来连接不同尺度的特征。此外，他们引入了边界上下文增强模块来合并和增强边缘相关的体素特征，从而实现简单型肺结节的准确分割。 Xu等人[20]提出了一种用于分割非典型结节的双编码融合网络。他们首先使用金字塔上采样方法来创建平滑的病变图像，并减少 CT 图像中高粒度像素的干扰。然后，他们使用全局和局部分支对上采样的 CT 图像块和原始图像块进行编码，以捕获全局和局部信息。此外，他们采用了金字塔池化模块来增强本地分支的输出特征。最后，他们融合并解码了来自双分支的特征信息。 Wang等人[21]提出了一种混合深度学习模型（H-DL），用于分割各种大小和形状的肺结节。该模型结合了基于VGG19的浅层U-Net网络和基于密集连接的深层U-Net网络，增强了复杂肺结节分割的学习能力。与独立的 UNet 结构模型相比，将这两个模型集成到混合模型 H-DL 中证明了分割结果得到了改善。\n基本块的设计对于肺结节分割也具有重要意义。研究人员探索了多种设计概念来提高模型性能和效率。 Wang等人[22]设计了一个基于空洞卷积的深度尺度感知模块来聚合上下文。该模块将具有不同扩张率（1、2和3）的并行分支嵌入到瓶颈层中，以捕获更丰富的语义信息。 Agnes等人[23]提出了一种多尺度全卷积3D UNet模型，其中作者设计了一个多尺度基本块，使用 $3×3×3$ 和$5×5×5$ 卷积从各种尺度中提取特征信息。他们使用 Maxout 激活函数优化多尺度特征信息，抑制低贡献特征。 Chen等人[15]提出了一种用于分割GGO的注意力级联残差网络。该网络通过残差结构和扩张的空间金字塔池模块捕获肺结节的特征信息。在后处理阶段，应用基于体素的条件随机场来进一步细化分割结果。 Zhou等[3]介绍了一种级联的2.5D肺结节检测和分割方法。在分割网络中，作者将卷积块注意力模块（CBAM）[24]合并到编码器中，以增强网络的编码能力。在瓶颈层设计了不同的多尺度卷积扩张率，以实现结节区域的精细分割。\n另一种方法是使用对抗性生成网络进行肺结节分割。训练数据稀缺和类别不平衡一直是影响肺结节分割性能的关键因素。数据稀缺会导致过度拟合或模型收敛失败，而类别不平衡则增加了目标区域分割的挑战。为了解决这些问题，Song等人[25]提出了一种基于生成对抗网络对多种类型肺结节进行全自动分割的端到端架构。该模型包括两个分支。第一个分支用于潜在的肺结节分割和结节生成。第二个分支旨在减少第一个分支产生的潜在假阳性结节。此外，Tyagi 等人[26]引入了一种基于条件生成网络的分割方法。该方法利用生成器（基于具有空间和通道挤压和激励模块的 UNet）和判别器进行对抗训练来学习训练数据集的样本分布，从而提高分割性能。在Luna16数据集上，其DSC得分为80.74%，灵敏度为85.46%。这两种方法背后的动机是利用生成对抗网络的特征来学习肺结节内的抽象特征并生成适用于临床环境的训练样本。虽然这种方法在有足够数量的训练样本时是可行的，但由于肺结节数据集中的样本分布不平衡，它面临着挑战。目前，生成高质量和多样化的数据仍然是一个重大挑战。\nMethod A. Pre-processing 肺结节CT图像预处理步骤如下：\n(a) Ground Truth: 同一结节的Mask 根据质心坐标进行聚类，并使用开源Pyldc工具库对不同医生的注释进行平均，级别设置为0.5[27]。然后获得真实值 (GT)，如图 2 所示。\n(b) 重新采样：将裁剪后的肺结节区域重新采样为 1 mm，并将生成的图像块大小调整为 64×64×64 [28]，[29].\n(c) 归一化和混合特征：使用Z-score对原始图像块进行标准化，将CT图像转换为标准正态分布，提高网络训练的稳定性。混合特征通过变换和加权求和，同时保留了切归一化后的对比度信息（Cut-norm，eq（1））和 Sobel算子的边界信息，如图3所示。肺HU值的切归一化范围为**[-1000, 400]** [3]，然后将截断的 CT 图像映射到 [0,1]，从而提高 CT 图像中低对比度组织和细节的可视性，同时增强网络的灵敏度。 Sobel算子是一种简单且稳定的算子，可以有效突出细微、血管旁和胸膜旁结节的边界信息。另外，Prewitt算子的成像结果与Sobel算子相似，因此没有进行进一步的研究。\nB. Overall Design of the Dual-branch network 双分支网络 (DBNet) 的架构如图 4 所示。它代表了一种端到端肺结节分割方法，包括信息编码和解码两个阶段。在编码阶段，我们采用主网络和辅助网络概念。主网络（$En_raw$）以原始CT图像作为输入，而辅助网络（$En_aid$）则利用混合特征图像作为输入。主、辅分支的输入图像块大小为 $Image^{C×H×W×D}{raw}$ , $Image^{C×H×W×D}{help}$ ∈ $R^{1×64×64×64}$，其中 $C$、$H$、$W$、$D$表示输入通道、长度、宽度和深度。编码阶段总共包括5个编码块和4次下采样操作，不同编码阶段的特征图可以表示为 $f^i_r$ , $f^i_a$ , $i$ ∈ [1, 5]，$r$ 和 $a$ 表示主分支和辅助分支，特征图从 $32 × 64 × 64 × 64$ 过渡到 $64 × 32 × 32 × 32$，然后过渡到 $128 × 16 × 16 × 16$、$256 × 8 × 8 × 8$，最后过渡到 $512 × 4 × 4 × 4$\n在解码阶段，采用双分支设计，减少网络参数和计算量，同时提供更多的特征选择和更强的泛化能力。针对双分支特征信息的融合设计，提出了多维融合模块，从多个维度的空间通道中提取特征信息。然后，注意力模块的输出特征图将被上采样并与相应的编码阶段特征图 $ f^i_r $ 和 $f^i_a$ 融合，其中 $i$ ∈ [1,4]，以补偿下采样过程造成的信息损失。该融合过程重复四次，以逐渐预测肺结节区域。经过 $3×3×3$ 卷积的特征提取和优化后，得到预测的肺结节区域为 $Output^{1×64×64×64}$ ∈ [0,1]。设置阈值0.5，如果该值大于阈值，则该像素被认为是肺结节的一部分；否则，它被视为背景的一部分。\n网络的基本单元包括卷积（Conv）、BatchNorm（BN）和Swish激活函数[30]，统称为CBS。 BN 加速网络收敛并增强其表达能力，而 Swish 激活函数可以减轻与更深网络相关的梯度消失问题。可训练参数 $beta$ = 1.0 动态调整 Swish 激活函数的形状，以更好地适应肺结节分割任务，如（2）所示，其中 $σ$ 表示 sigmoid 激活函数。将基本块的数量增加到2，并添加残差连接，得到残差基本块RCBS。\nC. Design of the Multi-Dimensional Fusion Module 多维融合模块（MDFM）由两部分组成：通道挤压洗牌注意力模块（CESA）和轴向多尺度空间注意力模块（AMSA），模块设计和内部注意力变化[31]如图5所示，整个过程可以表示为方程3至方程5。\n1) Channel Extrusion Shuffle Attention Module 通道挤压洗牌注意力模块 (CESA) 的输入来自双分支编码器的级联输出特征图。在优化通道特征之前，首先使用自适应均值池化和自适应最大池化将特征图聚合为 $C×1×1×1$，并使用CBS基本块来融合两类特征信息。多尺度设计可以扩大网络的感受野，获得更丰富的局部细节和全局信息。受这一思想的启发，在通道维度上对通道特征进行多尺度采样，在不改变融合特征图大小的情况下优化特征信息。通道多尺度涉及通道维度上的降维和扩展操作，深度依次为 $C/2$、$C/4$、$C/8$、$C/16$。此外，通过密集连接设计，网络的表达和泛化能力得到进一步增强，该过程称为“挤出”。通道混洗操作将通道分为8组，并通过混洗通道内的特征信息引入一定程度的随机性和多样性。然后将打乱后的特征添加到挤压操作后的特征图上，最后通过点积操作恢复特征图。利用Sigmoid（σ）方法，将特征图转换为[0,1]之间的概率分布，并将注意力权重映射到原始特征图。\n2) Axial Multiscale Spatial Attention Module 准确捕获肺结节的空间位置、纹理和形状信息对于分割任务至关重要。因此，提出了轴向多尺度空间注意力模块。首先，我们使用 $7 × 7 × 7 $ 窗口大小的 CBS 块来感知全局上下文信息，同时以 8、16、32 和 64 的压缩比 (r) 压缩特征图通道。压缩后的特征信息不仅更加关注空间维度特征，而且减少了网络参数和计算量。然后，我们利用窗口大小 $H×3×3$ 、$3×W×3$ 和 $3×3×D$ 的基本块来感知 Coronal、Sagittal 和 Axis 方向的特征图，其中 H、W 和 D 分别是特征图尺寸，从而捕获不同平面**（冠状矢状、矢状轴、冠状矢状）**的局部信息以及不同轴向的全局信息。这种设计有助于强调和突出肺结节的关键特征，使模型能够更好地理解和表达多维数据中的特征。对多维特征信息进行汇总，并利用残差连接补充梯度信息。最后利用 $7×7×7$ 的卷积核来恢复特征图，完成空间特征信息的提取。\nD. Loss Function Dice相似系数[32]（DSC）是一种相似性测量函数，通常用于计算两个样本的相似性。 DSC ∈ [0,1]，值越小表明**模型预测结果 **与 真实标签差距越大。\n其中 $P$ 表示二进制预测结果像素的集合，$G$ 表示二进制真实标签结果的集合。 $| P ∩ G |$ 表示 $P $ 和 $G$ 的交集。\nExperiments A. Datasets 本文在其实验设置中介绍了四个数据集：\n（1）LIDC： 肺部图像数据库联盟和图像数据库资源倡议 (LIDC) 数据集是全球最大的公开肺癌数据集。它包括来自多家医院的 1, 018 个研究病例，包含 11 种不同厚度类型的数据，最多有四名医生在 CT 图像中注释病变信息 [8]，如图 6 所示。首先，直径为 3mm 或 3mm 的结节由至少两名医生注释的较大的被保留[21]。然后，对由一名医生注释的结节进行二次筛查，以去除不确定或注释错误的样本，总共得到 2, 615 个肺结节样本。\n2）Luna16： Luna16 数据集是 LIDC 数据集的子集，旨在解决 LIDC 数据集中 CT 切片厚度变化和数据质量等问题。 Luna16数据集总共包括1186个肺结节样本，这些样本由三名或更多医生注释，直径为3毫米或更大，切片厚度为2.5毫米或更小[33]。\n(3) 多厚度切片图像数据集(mThickSImg)： 剔除Luna16肺结节样本后，共获得1429个多层结节，主要用于内模型性能测试，实验数据的样本分布如图7所示。\n(4) UniToChest： UniToChest [34] 数据集包括 306,440 个匿名胸部 CT 扫描切片和相应的肺结节分割掩模。这些数据来自623名不同的患者，经过处理和筛选后，总共获得了211张结节大小从3到35mm的多层CT图像用于外部测试集。\nB. Lung nodule characteristic attributes classification LIDC 数据集总共包含由医生注释的 9 个视觉特征。在该实验中，去除了内部结构和钙化特性，并重新定义了良性和恶性的分类[35]，同时还纳入了肺结节的大小[24]。为了保证多个医师对同一肺结节标注的一致性，肺结节属性分类采用两种策略：（1）良恶性肺结节的定义是多个医师对结节标注结果的中位数 [35]。 (2)其他特征属性通过投票过程获得。肺结节属性分类如表1所示。\nC. Evaluation Metrics 在本文中，我们使用精度（PRE）、灵敏度（SEN）、骰子相似系数（DSC）和并集平均交集（mIoU）作为评估指标，如方程（7）至（10）所示。 True Positive（TP）表示正确分割的焦点区域，True Negative（TN）表示正确分割的正常组织区域，False Positive（FP）表示正常组织区域被错误地分割为焦点区域，False Negative（FN）表示焦点区域被错误地分割为正常组织区域。\nD. Training Details 本实验使用Ubuntu 18.04.3 LTS操作系统作为实验基础平台。 CPU型号为Intel(R)Xeon(R)-Gold 6140，内存大小为187.4G，软件环境为Python 3.8、Conda 10.1、Pytorch 1.8.1在Tesla V100-SXM2-32GB显卡上实验。\n实验遵循所有 CAD 方法的一致设置。在训练阶段，数据集被分为5个子集，每个子集循环用作验证集，其余4个子集作为训练数据。应用数据增强技术，包括水平和垂直翻转、旋转和平移，来增强训练样本并增强模型的鲁棒性。最终的性能评估基于5倍交叉验证获得的平均结果。 Adam 优化器 [37] 的初始学习率为 3e-4，批量大小为 12，最多 500 次训练迭代。使用的损失函数是 Dice 损失。另外，我们使用提前停止机制来防止过拟合。在 50 轮训练中，如果没有达到较小的损失，模型训练将结束。\nResult A. CAD model performance comparison 如表2所示，所提出的方法与一些最近优秀的CAD模型进行了比较。根据样本数量和选择策略，这些方法分为小样本肺结节分割方法和一般样本数量肺结节分割方法。这些方法的筛选标准列于表中。在使用小样本量的肺结节分割方法中，我们提出的模型在包含 1,186 个结节的 Luna16 数据集上实现了最先进的性能，通过 5 folder 交叉验证实现了最高 DSC 87.68%（最佳）和 86.89%（平均）。就整体 DSC 而言，这比当前顶级小样本方法 DS-CMSF 领先 0.93%。这证明了我们的方法在相对较小的训练样本量下的有效性。此外，为了研究大样本量的性能，我们的方法在 LIDC 数据集中的 2,618 个节点集上进行了训练。我们取得了最佳 DSC 分数和平均 DSC 分数分别为 85.42% 和 84.12%，显着优于当前领先的 LNHG 模型（82.05%）和其他主流算法。\n总体而言，不同数据量下的测试结果表明本文方法具有较强的稳定性和泛化能力。\nB. Ablation studies 在本节中，我们对所提出的 CAD 模型的不同部分进行了消融研究，以评估它们对性能的贡献。消融研究中使用的模型是基于 Luna16 数据集进行训练的。\n在影响模型性能的因素中，研究人员普遍认为模型规模是关键因素。目前，大多数学者倾向于使用 $64×64×64$ 的 patch大小作为神经网络的输入。按照此设置，模型的初始通道数设置为32，考虑到输入大小的约束，模型的最大下采样次数设置为4。此时，瓶颈层的输入大小为 $4 × 4 × 4$ ，512 个通道。基于此，我们设计了四种双分支分割模型（称为模型A、B、C和D），深度分别为2、3、4和5层。这些模型均使用CBAM模块作为双分支模型的融合模块。实验结果表明，随着网络深度和通道数的增加，模型性能呈现出不断增加的趋势，DSC从80.61%上升到85.8%，如表3所示。因此，得出结论：在输入尺寸为64×64×64的情况下，本研究模型的最佳深度为5，瓶颈层有512个通道。\n实验中主要探索了两类辅助特征。一种是利用Cut-norm来突出病变的特征信息，另一种方法主要利用Sobel梯度算子来增强边界信息。在最佳模型规模的讨论中，所有模型均使用Z-score标准方法进行训练。训练这两个手动特征并与模型 D 进行比较后，发现使用 Cut-norm 的模型 E 和使用 Sobel 算子的模型 F 在 DSC 中分别与模型 D 相差 0.61% 和 0.78%。这说明了该辅助分支策略的有效性。此外，进一步验证了Sobel算子在不同数据尺度下的有效性，发现模型D和模型F在LIDC数据集上的DSC性能分别达到83.56%和83.82%，相差0.26%。这表明，即使在更大规模的测试集中，Sobel算子仍然有效，因此，暂时将Sobel算子用作辅助特征。\n进一步基于Sobel算子作为辅助特征，提出了通道挤压洗牌注意力模块和轴向多尺度空间注意力模块，即模型G和模型H，模型性能最优达到86.63%。最后，为了同时保留高对比度病变区域和突出显示的边界细节以方便学习，我们使用变换操作和加权求和来整合这两个特征。通过这种策略，本文提出的方法获得了 86.89% DSC 的最佳结果，超过了单独使用 Sobel 滤波器特征的性能。直接的性能提升验证了我们辅助功能的有效性。\n虽然模型 H 和我们的整体性能差距并不显着，但模型 H 在内部数据集中的 DSC 性能为 63.03%，对于 GGO 类型评估的灵敏度为 62.42%。然而，使用混合特征的进一步替代导致灵敏度和 DSC 性能显着提高，分别达到 65.27% 和 65.08%。观察模型G、H和Ours的收敛速度，随着注意力模块数量的增加和混合特征的替换，模型拟合所需的epoch逐渐增加，但综合考虑，总体费用是值得的。\nC. Comparison experiments of different datasets and segmentation CADs 本节将我们的方法与开源医学分割模型 UNet [38]、UNet++ [28]、ReconNet [39]、Unetr [40] 和 Asa [41] 在不同数据集上的测试结果进行比较。结果如表IV所示。总体而言，该方法在 Luna16 数据集上实现了 86.89% 的 DSC，分别领先 UNet 和 ReconNet 模型 1.38% 和 0.77%。在基于Transformer的方法中，在DSC方面，它以4.01%和2.66%的优势超过了Unetr和ASA。整体性能超过了经典和现有的优秀分割模型。具体而言，该方法的精度为87.13%，灵敏度为87.02%。更高的灵敏度可以更好地识别结节，防止漏诊；而更高的精度为医生提供了更可靠的分割区域，减少误诊。这对于肺结节分割任务至关重要。此外，该方法实现了高 mIoU，表明预测与真实情况之间有更大的重叠。可以很好地分割大部分肺部病变区域，辅助合理诊断，有利于临床使用。\n随后，所有方法都在内部 mThickImgs 数据集和外部 UniToChest 数据集上进行了验证。在这两个数据集上，UNet++ 达到了最高的精度，但灵敏度较低。这表明 UNet++ 在真阳性区域中假阴性的比例较大，丢失了更多样本并最终影响了灵敏度指标。这种不平衡对于临床目的是有害的。此外，ReconNet在mThickImgs数据集中具有较高的灵敏度。我们的方法在两个数据集中实现了 75.32% 和 80.64% DSC，分别超过次优方法 0.57% 和 0.59%，实验结果再次证明了我们方法强大的泛化能力。\n总体而言，我们的方法在不同数据集的指标上比其他最先进的3D CAD模型具有明显的优势，特别是在灵敏度和DSC这两个最关键的分割性能指标方面，验证了我们方法的分割能力在多源医学图像中。\nAnalysis of lung nodule performance A. Effect of different layer thicknesses on model performance 我们分析了 mThickSImg 数据集中肺结节的分布，并检查了不同 CT 切片厚度和尺寸的结节性能变化。我们将数据分为六组，数据样本分布如表六所示。然后对不同的CAD模型进行测试，并将不同模型的平均测试结果作为最终的性能趋势，如表5所示。\n我们的方法是基于2.5mm层厚度以下的样本进行训练的，通过观察精度，我们发现在1.5mm和1.5mm ~ 2.5mm的比较中，网络的灵敏度随着层厚度的减小而增加。\n另外，在观察DSC性能时，注意到DSC性能随着层厚度的增加而增加。然而，似乎存在随着层厚度减小灵敏度增加而DSC降低的现象。为什么会出现这种现象呢？一方面，这种趋势可能会受到数据分布、样本数量和样本标签的影响而有些偏差。一般来说，随着 CT 层厚度的增加，图像分辨率会降低，可能导致神经网络难以捕获更精细的特征和结构。\n因此，由于较厚的 CT 层中详细信息的丢失，网络随着层厚度的增加而表现出较低的灵敏度。另一方面，虽然层厚度的减少提高了 CT 图像的层内分辨率，并能够更准确地呈现解剖结构和病变，但同时也减少了接收到的光子数量。与较厚的图像相比，光子计数的减少可能会导致噪声增加和对比度降低。这些因素会对肺结节（尤其是 GGO）的分割产生负面影响，可能导致验证集的性能下降。\n我们还发现，在基于薄层图像进行训练然后在厚层图像上进行验证后，网络表现出更好的性能。我们相信，更薄的 CT 图像由于具有更高的分辨率和更详细的信息，使网络能够学习更微妙的特征。这些细微的特征在2.5mm以上的层厚图像中具有更强的泛化能力，这是基于厚层数据所不具备的。因此，这种现象可能表明关于层厚度效应的更好的性能。\nB. Heterogeneity analysis of lung nodules 本节演示不同分割模型在Luna16数据集和mThickSImg数据集上的测试性能。总的来说，我们的方法在两个数据集上的大多数肺结节分割属性上都取得了领先的结果\n1) Subtle feature 肺结节的早期诊断和治疗对于疾病的诊断具有重要意义。\n可以看出，在Luna16数据集中，我们的方法和UNet在 “Extremely Subtle” 属性和“Moderately Subtle”属性的分割上表现更好，并且我们的方法仅次于UNet的方法，达到了70.99%和76.69%。在mThickImgs测试集中，我们的方法在所有Subtlety特征属性上都达到了最佳性能，“Extremely Subtle”和“Moderately Subtle”属性分别超过UNet和ReconNet 2.75％、1.03％和2.33％、0.94％ 。 UNet网络在两个数据集中表现出不同的性能变化，这并不排除数据分布和数据质量的影响。由于双分支和混合特征的设计，我们的方法在 mThickImgs 测试集上对“Extremely Subtle”属性和“Moderately Subtle”属性分割有较大的性能提升，这证明了我们的方法具有很强的泛化能力和鲁棒性，并提高了临床使用的可靠性。 Extremely Subtle GGO 的分割结果如图 10-(1) 所示。\n2) Texture feature 观察两个数据集中“Texture”特征的测试结果可以发现，在Luna16数据集中，我们的方法在“Solid/Mixed”和“NonSolid/Mixed”类别上表现出了很大的进步，分别为2.73%与次优方法相比，分别提高了 1.62% 和 1.62%。在 mThickSImg 数据集中，我们的方法在 GGO 类和“NonSolid/Mixed”类中达到了 65.08% 和 70.2%，分别领先次优 0.35% 和 1.33%。\n虽然对于 GGO 样肺结节，我们的方法没有显着改进，但对于具有混合纹理的结节，我们的方法进一步减轻了分割挑战。固体/混合分割结果如图10-（3至7）所示。\n3) Maligancy feature 良性和恶性的区分是肺结节分割任务的关键特征。良性结节常呈圆形或椭圆形，而恶性结节往往体积较大，并有明显的针状或分叶状特征。两个数据集的测试结果表明，不确定属性的分割结果最差，其次是良性结节。我们的方法改进了这三类属性的分割，与次优方法、不确定和恶性分割相比，在 Luna16 数据集中增加了 0.73%（良性）、0.28%（不确定）和 0.87%（恶性）如图10（1、2～7）所示。在mThickSImg测试集中，该方法的性能提升更为显着，分别领先1%（良性）、0.83%（不确定）和0.61%（恶性）。提高肺结节良性和不确定性的分割性能对于临床诊断至关重要。采用相同的CAD方法对这两类结节进行分割可以有效观察其发展趋势。与医生手工勾画相比，该方法提高了诊断的准确性和可靠性。\n4) Other features 除了上述三种常见且具有挑战性的分割特征外，肺结节的“球形”、“边缘”、“分叶”和“毛刺”特征对临床诊断具有一定的指导意义。观察“球形”特征，可以发现当前方法在常见的“卵形或圆形”属性上表现出更好的性能。一方面它有更多的训练样本，另一方面也更简单地分割该类的样本。我们的方法在 mThickSImg 数据集中的“线性”和“卵形/线性”病变形状属性中表现出显着优势，导致“线性”和“卵形/线性”属性中的 DSC 次优，分别为 2.74% 和 1.81% 。线性分割结果如图10-(6)所示。还值得注意的是，我们的方法在 Luna16 数据集的 Margin 特征中的五个属性上显示出巨大的改进，特别是“Poorly Defined”属性。\n在 mThickImgs 测试集中，我们的方法在五个属性上分别与次优值相差 0.65%、0.93%、0.7%、0.94% 和 1.02%，这也表明辅助特征可以减轻图像边界的复杂性。病变区域。分叶和毛刺是判断恶性程度的重要指标。这些特征可以帮助医生区分结节边缘的规律性，并有助于对结节进行初步分类和观察。\n可以看出，与次优相比，我们的方法在 mThickImgs 数据集的性能方面表现出了显着的改进。然而，“标记分叶”和“标记毛刺”特征属性的分割仍然具有挑战性。在不同尺寸的结节中，我们的方法在分割3到6mm范围内的实性结节方面也表现出了一定的性能改进。\n与次优方法相比，我们的方法在两个测试集中分别提高了 0.73% 和 1.39%。然而，在“SubSolid”中，大多数方法没有表现出显着差异。\nCONCLUSION 我们提出了一种简单有效的双分支网络分割方法。五折交叉验证的结果表明，该方法能够有效、稳定地执行分割任务。此外，我们的方法对大多数肺结节的特征特征和复杂数据样本的分割具有一定的适用性，特别是对于细微的、纹理混合的、边界模糊的、良性的和不确定的结节，可以大大降低临床应用的难度，并提供为医生提供更可靠的参考。\n这种方法也有一些局限性。首先，虽然混合特征设计保留了边界和对比度信息，但它间接引入了额外的噪声，这可能会干扰网络的特征学习。其次，我们的方法在“Subsolid”小结节的分割方面没有表现出显着的性能改进，未来可能会尝试更深或更详细的多尺度设计来缓解这个问题。另外，由于实验整体采用多位医师标注的平均值作为最终的GT，一定程度上保证了结果的准确性。但也可能导致最终的GT与实际情况存在差异，导致区域不完整或有刺状等详细信息丢失，如图10-(7)所示，对“Marked Lobulation”的分割提出挑战”和“标记毛刺”属性。未来，可能会开发多置信区域方法来缓解这个问题。\n读完的第一感觉： 太长了\u0026hellip;.\n","permalink":"https://swimmingliu.cn/posts/papernotes/2023-dbnet/","summary":"\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e肺癌是全球最致命的癌症之一，早期诊断对于患者的生存至关重要。\u003cstrong\u003e肺结节\u003c/strong\u003e是\u003cstrong\u003e早期肺癌的主要表现\u003c/strong\u003e，通常通过 \u003cstrong\u003eCT 扫描\u003c/strong\u003e进行评估。如今，计算机辅助诊断系统被广泛用于辅助医生进行疾病诊断。\u003cstrong\u003e肺结节的准确分割\u003c/strong\u003e受到\u003cstrong\u003e内部异质性和外部数据\u003c/strong\u003e因素的影响。为了克服\u003cstrong\u003e结节的细微、混合、粘附型、良性和不确定类别\u003c/strong\u003e的分割挑战，提出了一种新的\u003cstrong\u003e混合手动特征网络\u003c/strong\u003e，可\u003cstrong\u003e增强灵敏度和准确性\u003c/strong\u003e。该方法通过\u003cstrong\u003e双分支网络框架和多维融合模块\u003c/strong\u003e集成\u003cstrong\u003e特征信息\u003c/strong\u003e。通过使用\u003cstrong\u003e多个数据源和不同数据质量\u003c/strong\u003e进行训练和验证，我们的方法在 \u003cstrong\u003eLUNA16\u003c/strong\u003e、\u003cstrong\u003e多厚度切片图像数据集 (Multi-thickness Slice Image dataset)\u003c/strong\u003e、\u003cstrong\u003eLIDC\u003c/strong\u003e 和 \u003cstrong\u003eUniToChest\u003c/strong\u003e 上表现出领先的性能，Dice 相似系数达到 86.89%、75.72%、84.12% 和 80.74分别超过了当前大多数肺结节分割方法。我们的方法进一步提高了肺结节分割任务的\u003cstrong\u003e准确性、可靠性和稳定性\u003c/strong\u003e，即使是在具有挑战性的 CT 扫描中也是如此。本研究中使用的代码发布在 GitHub 上，可通过以下 URL (\u003ca href=\"https://github.com/BITEWKRER/DBNet\"\u003ehttps://github.com/BITEWKRER/DBNet\u003c/a\u003e) 获取。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e肺癌是全球癌症相关死亡的主要原因[1]。仅在美国，预计 2023 年将有 127,070 人死于肺癌，占所有癌症死亡的 21% [2]。不幸的是，超过 50% 的肺癌病例发生在发展中国家或不发达国家，与发达国家相比，这些国家的医疗资源有限[3]。\u003c/p\u003e\n\u003cp\u003e为了增加生存机会，早期诊断和治疗肺癌仍然至关重要。在中国，研究表明，\u003cstrong\u003e小于1厘米的I期肺癌的5年生存率为92%\u003c/strong\u003e。然而，\u003cstrong\u003e晚期肺癌的5年生存率低得多\u003c/strong\u003e，仅为\u003cstrong\u003e7.0%\u003c/strong\u003e[4]。\u003cstrong\u003e利用计算机断层扫描 (CT) 进行肺癌筛查已显示出可大幅降低死亡率的潜力\u003c/strong\u003e [5]、[6]。低剂量CT是目前肺癌筛查最常用的方法。此外，移动CT的引入有助于解决欠发达国家和偏远地区缺乏CT扫描仪的问题[6]。由于可能没有明显的症状，检测早期肺癌的存在可能会带来重大挑战。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e这种医学背景数据可以直接借鉴，Chatgpt润色改写就完事儿\u003c/strong\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e在 \u003cstrong\u003eCT 图像上识别肺结节提供了疾病的关键指标\u003c/strong\u003e [1], [3]。这些结节代表\u003cstrong\u003e圆形异常\u003c/strong\u003e，其\u003cstrong\u003e大小各异\u003c/strong\u003e，直径范围为 \u003cstrong\u003e3 至 30 毫米\u003c/strong\u003e [7]。为了进一步研究肺结节，美国国家癌症研究所组装了“肺部图像数据库联盟和图像数据库资源计划（LIDC）”数据集[8]。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e欠发达地区设备不足、人员不足，导致医生的诊断和治疗时间有限\u003c/strong\u003e[9]。在这种情况下，\u003cstrong\u003e医生的工作量很大、重复且耗时\u003c/strong\u003e[10]、[5]。此外，由于与CT切片相比，\u003cstrong\u003e肺部结节性病变\u003c/strong\u003e占据相对\u003cstrong\u003e较小的面积\u003c/strong\u003e，\u003cstrong\u003e长时间和密集的CT筛查\u003c/strong\u003e可能会导致\u003cstrong\u003e漏检小的、细微的或 GGO\u003c/strong\u003e (肺磨玻璃结节) [3]，[6]。为了解决这些问题，计算机辅助诊断系统（CAD）出现并得到了快速发展，特别是随着基于深度学习技术的诊断方法的进步。 \u003cstrong\u003eCAD系统大大减轻了医生的工作量，最大限度地降低了未发现结节的风险，并提高了肺结节诊断的效率和可靠性\u003c/strong\u003e。然而，当前用于肺结节分割的 CAD 系统仍然面临一些挑战。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e下面详细阐述了肺结节分割的几个现有挑战，可以从这些挑战入手\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e首先，\u003cstrong\u003e放射科医生标记的肺结节\u003c/strong\u003e包含\u003cstrong\u003e九个诊断特征\u003c/strong\u003e[11]，\u003cstrong\u003e异质性表型\u003c/strong\u003e阻碍了\u003cstrong\u003e肺结节分割的发展\u003c/strong\u003e。如图1所示，\u003cstrong\u003e实心结节（a，b）具有清晰的形状和边界\u003c/strong\u003e，而\u003cstrong\u003e微妙的GGO结节（e）具有低对比度和模糊的边界\u003c/strong\u003e[4]，使得网络很容易将\u003cstrong\u003e它们分类为背景区域\u003c/strong\u003e。\u003cstrong\u003e空洞（g）结节降低了网络分割的敏感性\u003c/strong\u003e，并且由于\u003cstrong\u003e背景和分割目标之间的极度不平衡，小结节很容易被遗漏\u003c/strong\u003e[12]。\u003c/p\u003e\n\u003cp\u003e由于周围多余的组织结构，\u003cstrong\u003e血管旁或胸膜旁（c、d、f）可能会导致网络分类错误\u003c/strong\u003e[13]。此外，\u003cstrong\u003e部分实性结节（h）比纯GGO更致密\u003c/strong\u003e，产生更\u003cstrong\u003e复杂的异质纹理，更容易发展成恶性结节\u003c/strong\u003e[14]。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cimg alt=\"image-20240303102609243\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/262f8e71-d931-11ee-b68c-c858c0c1debd\"\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e其次，肺结节内部因素造成的分割困难在于\u003cstrong\u003e医生注释、层厚、数据来源和数据质量\u003c/strong\u003e。\u003cstrong\u003e数据质量差\u003c/strong\u003e或\u003cstrong\u003e不同医生的经验\u003c/strong\u003e可能会导致\u003cstrong\u003e不同的注释和注释者数量\u003c/strong\u003e。由\u003cstrong\u003e多名医生注释的病变区域\u003c/strong\u003e通常更\u003cstrong\u003e可靠\u003c/strong\u003e，减少了潜在的临床风险。\u003cstrong\u003e在资源有限的地区\u003c/strong\u003e，由于 \u003cstrong\u003eCT 扫描仪短缺和成像设备陈旧\u003c/strong\u003e，\u003cstrong\u003eCT 扫描质量差的情况很常见\u003c/strong\u003e。\u003cstrong\u003e较厚的切片\u003c/strong\u003e更有可能产生“\u003cstrong\u003e体积平均效应”和伪影\u003c/strong\u003e，使医生\u003cstrong\u003e难以达成一致的诊断\u003c/strong\u003e。即使使用\u003cstrong\u003e移动 CT 扫描仪\u003c/strong\u003e也可能\u003cstrong\u003e无法提供完整的诊断详细信息\u003c/strong\u003e。最后，目前\u003cstrong\u003e大多数肺结节分割方法\u003c/strong\u003e都是基于\u003cstrong\u003e2D图像\u003c/strong\u003e，但这些方法忽略了\u003cstrong\u003e空间关系\u003c/strong\u003e，因此提出一种有效的\u003cstrong\u003e3D肺结节分割模型\u003c/strong\u003e来\u003cstrong\u003e捕获肺结节的空间位置\u003c/strong\u003e、\u003cstrong\u003e纹理和其他详细信息变得越来越重要以避免误诊和漏诊\u003c/strong\u003e。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003eChallenge\u003c/strong\u003e:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e异质性: 肺结节的形状多异 （实心结节、磨玻璃结节 (GGO) 、空洞结节、血管和胸膜旁边的结节）\u003c/p\u003e","title":"A Dual-Branch Framework with Prior Knowledge for Precise Segmentation of Lung Nodules in Challenging CT Scans"},{"content":"Abstract 如今的深度学习方法主要关注如何设计最合适的目标函数，使模型的预测结果能够最接近真实情况。同时，必须设计一个适当的架构，可以帮助获取足够的信息进行预测。现有方法忽略了一个事实，即当输入数据经过逐层特征提取和空间变换时，大量信息将会丢失。本文将深入研究数据通过深度网络传输时数据丢失的重要问题，即信息瓶颈和可逆函数。我们提出了可编程梯度信息（PGI）的概念来应对深度网络实现多个目标所需的各种变化。 PGI可以为目标任务计算目标函数提供完整的输入信息，从而获得可靠的梯度信息来更新网络权值。此外，还设计了一种基于梯度路径规划的新型轻量级网络架构——通用高效层聚合网络（GELAN）。GELAN的架构证实了PGI在轻量级模型上取得了优异的结果。我们在基于 MS COCO 数据集的目标检测上验证了所提出的 GELAN 和 PGI。结果表明，与基于深度卷积开发的最先进方法相比，GELAN 仅使用传统的卷积算子即可实现更好的参数利用率。 PGI 可用于从轻型到大型的各种模型。它可以用来获取完整的信息，使得train-from-scratch (从零开始训练) 模型能够比使用大数据集预训练的state-of-theart模型获得更好的结果，对比结果如图1所示。源代码位于：https： //github.com/WongKinYiu/yolov9。\n核心创新点: 依然是网络结构的创新\nProgrammable Gradient Information (PGI) Generalized Efficient Layer Aggregation Network（GELAN） Introduction 基于深度学习的模型在计算机视觉、语言处理和语音识别等各个领域都表现出了比过去的人工智能系统更好的性能。近年来，深度学习领域的研究人员主要关注如何开发更强大的系统架构和学习方法，例如CNN，Transformers[8,9,40] 、41、60、69、70]，Perceivers[26、26、32、52、56、81、81]和Mambas[17、38、80]。此外，一些研究人员尝试开发更通用的目标函数，例如损失函数[5,45,46,50,77,78]，标签分配[10,12,33,67,79]和辅助监督[18] 、20、24、28、29、51、54、68、76]。上述研究都试图精确地找到输入和目标任务之间的映射。然而，大多数过去的方法都忽略了输入数据在前馈过程中可能会产生不可忽略的信息丢失量。这种信息丢失可能会导致有偏差的梯度流，随后用于更新模型。上述问题可能导致深度网络在目标和输入之间建立不正确的关联，导致训练后的模型产生不正确的预测。\n在深度网络中，输入数据在前馈过程中丢失信息的现象俗称信息瓶颈[59]，其示意图如图2所示。目前可以缓解这种现象的主要方法有：（1）可逆架构的使用[3,16,19]：该方法主要使用重复的输入数据，并以显式的方式维护输入数据的信息； （2）使用Masked建模[1,6,9,27,71,73]：主要利用重构损失，采用隐式方式最大化提取特征并保留输入信息； （3）引入深度监督概念[28,51,54,68]：它利用没有丢失太多重要信息的浅层特征来预先建立从特征到目标的映射，以确保重要信息能够被传递到更深的层次。然而，上述方法在训练过程和推理过程中都存在不同的缺点。例如，可逆架构需要额外的层来组合重复馈送的输入数据，这将显着增加推理成本。另外，由于输入数据层到输出层不能有太深的路径，这种限制将导致在训练过程中难以对高阶语义信息进行建模。对于 Masked 建模，其重建损失有时与目标损失相冲突。此外，大多数掩码机制还会产生与数据的不正确关联。 对于深层监督机制来说，会产生误差累积，如果浅层监督在训练过程中丢失信息，后续层将无法检索到所需信息。上述现象在困难任务和小模型上会更加显着。\n针对上述问题，我们提出了一个新的概念，即可编程梯度信息（PGI）。其概念是通过辅助可逆分支生成可靠的梯度，使得深层特征仍然能够保持执行目标任务的关键特征。\n辅助可逆分支的设计可以避免传统的融合多路径特征的深度监督过程可能造成的语义损失。换句话说，我们在不同语义层面上编程梯度信息传播，从而达到最佳的训练结果。 PGI的可逆架构建立在辅助分支上，因此没有额外的成本。由于PGI可以自由选择适合目标任务的损失函数，因此也克服了Masked建模遇到的问题。所提出的PGI机制可以应用于各种规模的深度神经网络，并且比仅适用于非常深的神经网络的深度监督机制更通用。\n在本文中，我们还基于ELAN[65]设计了广义ELAN（GELAN），GELAN的设计同时考虑了参数量、计算复杂度、准确性和推理速度。这种设计允许用户针对不同的推理设备任意选择合适的计算块。我们将提出的PGI和GELAN结合起来，然后设计了新一代YOLO系列物体检测系统，我们称之为YOLOv9。我们使用MS COCO数据集进行实验，实验结果验证了我们提出的YOLOv9在所有比较中都取得了顶尖的性能。\n我们总结本文的贡献如下：\n我们从可逆函数的角度对现有的深度神经网络架构进行了理论分析，通过这个过程我们成功地解释了许多过去难以解释的现象。我们还基于此分析设计了PGI和辅助可逆分支，并取得了优异的结果。\n我们设计的PGI解决了深度监督只能用于极深的神经网络架构的问题，从而让新的轻量级架构真正应用于日常生活中。\n我们设计的GELAN仅使用常规卷积来实现比基于最先进技术的深度卷积设计更高的参数利用率，同时表现出轻、快速、准确的巨大优势。\n结合所提出的PGI和GELAN，YOLOv9在MS COCO数据集上的目标检测性能在各个方面都大大超过了现有的实时目标检测器。\nProgrammable Gradient Information (PGI)：\n自由选择适合目标任务的损失函数\n可逆结构建立辅助分支，不增加推理成本\n适用于各种规模的深度神经网络\nGELAN：\n轻、快速、准确 采用常规卷积吊打其他新颖卷积 Related work 2.1 Real-time Object Detectors 目前主流的实时目标检测器是YOLO系列[2,7,13–15,25,30,31,47–49,61–63,74,75]，这些模型大多数使用CSPNet[64]或 ELAN [65] 及其变体作为主要计算单元。在特征集成方面，通常使用改进的PAN[37]或FPN[35]作为工具，然后使用改进的YOLOv3头[49]或FCOS头[57, 58]作为预测头。最近也提出了一些实时目标检测器，例如 RT DETR [43]，其基础是 DETR [4]。然而，由于DETR系列目标检测器在没有相应领域预训练模型的情况下很难应用于新领域，因此目前应用最广泛的实时目标检测器仍然是YOLO系列。本文选择 YOLOv7 [63] 作为开发该方法的基础，该方法已在各种计算机视觉任务和各种场景中被证明有效。\n我们使用 GELAN 来改进所提出的 PGI 的架构和训练过程。上述新颖方法使所提出的 YOLOv9 成为新一代顶级实时目标检测器。\n2.2 Reversible Architectures 可逆架构[3,16,19]的运算单元必须保持可逆转换的特性，因此可以保证每层运算单元的输出特征图都能保留完整的原始信息。之前，RevCol[3]将传统的可逆单元推广到多个层次，这样做可以扩展不同层单元表达的语义层次。通过对各种神经网络架构的文献回顾，我们发现有许多高性能架构具有不同程度的可逆特性。例如，Res2Net模块[11]以分层方式将不同的输入分区与下一个分区组合起来，并在向后传递之前连接所有转换后的分区。 CBNet [34, 39]通过复合主干网重新引入原始输入数据以获得完整的原始信息，并通过各种组合方法获得不同级别的多级可逆信息。这些网络架构通常具有出色的参数利用率，但额外的复合层导致推理速度缓慢。 DynamicDet [36]结合了CBNet [34]和高效实时目标检测器YOLOv7 [63]，在速度、参数数量和精度之间实现了非常好的权衡。本文介绍了 DynamicDet 架构作为设计可逆分支的基础。此外，可逆信息被进一步引入到所提出的PGI中。所提出的新架构在推理过程中不需要额外的连接，因此可以充分保留速度、参数量和准确性的优势。\n2.3 Auxiliary Supervision 深度监督[28,54,68]是最常见的辅助监督方法，它通过在中间层插入额外的预测层来进行训练。尤其是基于Transformer的方法中引入的多层解码器的应用是最常见的一种。\n另一种常见的辅助监督方法是利用相关元信息来指导中间层产生的特征图，并使它们具有目标任务所需的属性[18,20,24,29,76]。这种类型的示例包括使用分割损失或深度损失来提高对象检测器的准确性。\n最近，文献[53,67,82]中有许多报告使用不同的标签分配方法来生成不同的辅助监督机制，以加快模型的收敛速度，同时提高鲁棒性。然而，辅助监督机制通常只适用于大型模型，因此当其应用于轻量级模型时，很容易造成欠参数化现象，从而使性能变差。我们提出的PGI设计了一种重新编程多级语义信息的方法，这种设计让轻量级模型也受益于辅助监督机制。\nProblem Statement 通常，人们将深度神经网络收敛问题的困难归因于梯度消失或梯度饱和等因素，而这些现象在传统深度神经网络中确实存在。然而，现代深度神经网络已经通过设计各种归一化和激活函数从根本上解决了上述问题。尽管如此，深度神经网络仍然存在收敛速度慢或收敛结果差的问题。\n在本文中，我们进一步探讨上述问题的本质。通过对信息瓶颈的深入分析，我们推断出这个问题的根本原因是原本来自很深网络的初始梯度在传输后很快就丢失了实现目标所需的大量信息。为了证实这一推论，我们将不同架构的深度网络前馈了初始权重，然后将其可视化并在图2中进行说明。显然，PlainNet丢失了深层物体检测所需的大量重要信息。至于ResNet、CSPNet、GELAN能够保留重要信息的比例，确实与训练后能够获得的准确率呈正相关。我们进一步设计了基于可逆网络的方法来解决上述问题的原因。本节我们将详细阐述对信息瓶颈原理和可逆函数的分析。\n3.1. Information Bottleneck Principle 根据信息瓶颈原理，我们知道数据X在进行变换时可能会造成信息丢失，如式(1)所示。\n其中 $I$ 表示相互信息，$f$ 和 $g$ 是变换函数，$θ$ 和 $ϕ$ 分别是 $f$ 和 $g$ 的参数。\n在深度神经网络中，$f_θ (·)$ 和 $g_ψ (·)$ 分别表示深度神经网络中两个连续层的操作。从方程（1）我们可以预测**，随着网络层数越深，原始数据丢失的可能性就越大**。然而深度神经网络的参数是基于网络的输出以及给定的目标，然后通过计算损失函数生成新的梯度后更新网络。\n可以想象**，更深的神经网络的输出不太能够保留有关预测目标的完整信息**。这将使得在网络训练期间使用不完整的信息成为可能，从而导致梯度不可靠和收敛性差。\n解决上述问题的一种方法是直接增加模型的尺寸。当我们使用大量的参数来构建模型时，它更有能力对数据进行更完整的转换。上述方法使得即使在数据前馈过程中信息丢失，仍然有机会保留足够的信息来执行到目标的映射。上述现象解释了为什么在大多数现代模型中宽度比深度更重要。然而，上述结论并不能从根本上解决非常深的神经网络中梯度不可靠的问题。\n下面，我们将介绍如何利用可逆函数来解决问题并进行相关分析。\n3.2. Reversible Functions 当函数 $r$ 有一个逆变换函数 $v$ 时，我们称该函数为可逆函数，如式(2)所示。\n其中 $ψ$ 和 $ζ$ 分别是 $r$ 和 $v$ 的参数。数据 $X$ 通过可逆函数转换而不会丢失信息，如式(3)所示。\n当网络的变换函数由可逆函数组成时，可以获得更可靠的梯度来更新模型。当今流行的深度学习方法几乎都是符合可逆性质的架构，例如式（4）。\n其中 $l$ 表示 PreAct ResNet 的第 $l$ 层，$f$ 是第 $l$ 层的变换函数。 PreAct ResNet [22] 以显式方式重复将原始数据 X 传递到后续层。这样的设计虽然可以让一千多层的深度神经网络收敛得很好，但却破坏了我们需要深度神经网络的一个重要原因。也就是说，对于困难的问题，我们很难直接找到简单的映射函数将数据映射到目标。这也解释了为什么当层数较少时，PreAct ResNet 的性能比 ResNet [21] 差。\n【Remind】PreAct ResNet 和 ResNet 结构图比较一下\n此外，我们尝试使用Masked建模，使 Transformer 模型取得重大突破。我们使用近似方法，例如方程 (5) 尝试求 $r$ 的逆变换 $v$，使得变换后的特征能够利用稀疏特征保留足够的信息。方程(5) 如下：\n其中 $M$ 是动态二进制掩码。其他常用于执行上述任务的方法是扩散模型和可变化自动编码器，它们都具有查找反函数的功能。然而，当我们将上述方法应用于轻量级模型时，就会存在缺陷，因为轻量级模型对大量原始数据的参数化不足。由于上述原因，将数据 $X$ 映射到目标 $Y$ 的重要信息 $I(Y，X)$ 也会面临同样的问题。对于这个问题，我们将使用信息瓶颈的概念来探讨它[59]。信息瓶颈的计算公式如下：\n一般来说，$I(Y,X)$ 只会占据 $I(X,X)$ 的很小一部分。然而，这对于目标任务至关重要。因此，即使前馈阶段丢失的信息量并不大，只要覆盖了 $I(Y,X)$，训练效果就会受到很大影响。轻量级模型本身处于欠参数化状态，因此在前馈阶段很容易丢失很多重要信息。因此，我们轻量级模型的目标是如何从 $I(X, X)$ 中准确过滤出 $I(Y, X)$。至于完全保留 $X$ 的信息，这是很难做到的。基于上述分析，我们希望提出一种新的深度神经网络训练方法，不仅能够生成可靠的梯度来更新模型，而且适用于浅层和轻量级神经网络。\nMethodology 4.1 Programmable Gradient Information 为了解决上述问题，我们提出了一种新的辅助监督框架，称为可编程梯度信息（PGI），如图3（d）所示。 PGI主要包括三个组成部分，即（1）主分支，（2）辅助可逆分支，（3）多级辅助信息。从图3(d)中我们可以看出，PGI的推理过程仅使用主分支，因此不需要任何额外的推理成本。\n至于其他两个组件，它们用于解决或减缓深度学习方法中的几个重要问题。其中，辅助可逆分支是为了处理神经网络加深带来的问题而设计的。网络加深会造成信息瓶颈，导致损失函数无法生成可靠的梯度。对于多级辅助信息，旨在处理深度监督带来的误差累积问题，特别是针对多个预测分支的架构和轻量级模型。接下来我们将逐步介绍这两个组件。\n4.1.1 Auxiliary Reversible Branch 在PGI中，我们提出了辅助可逆分支来生成可靠的梯度并更新网络参数。通过提供从数据映射到目标的信息，损失函数可以提供指导并避免从与目标不太相关的不完整前馈特征中发现错误相关性的可能性。我们提出通过引入可逆架构来维护完整信息，但是在可逆架构中添加主分支会消耗大量的推理成本。\n我们分析了图3(b)的架构，发现当添加从深层到浅层的额外连接时，推理时间将增加20%。当我们反复将输入数据添加到网络的**高分辨率计算层（黄色框）**时，推理时间甚至超过了两倍。\n由于我们的目标是使用可逆架构来获得可靠的梯度，因此**“可逆”并不是推理阶段的唯一必要条件**。鉴于此，我们将可逆分支视为深度监督分支的扩展，然后设计辅助可逆分支，如图3(d)所示。对于由于信息瓶颈而丢失重要信息的主分支深度特征，它们将能够从辅助可逆分支接收可靠的梯度信息。\n这些梯度信息将驱动参数学习来协助提取正确且重要的信息，上述动作可以使主分支获得对目标任务更有效的特征。此外，可逆架构在浅层网络上的表现比在一般网络上差，因为复杂的任务需要在更深的网络中进行转换。我们提出的方法并不强迫主分支保留完整的原始信息，而是通过辅助监督机制生成有用的梯度来更新它。这种设计的优点是所提出的方法也可以应用于较浅的网络。\n最后，由于在推理阶段可以去除辅助可逆分支，因此可以保留原始网络的推理能力。我们也可以选择PGI中的任意可逆架构来起到辅助可逆分支的作用。\n4.1.2 Multi-level Auxiliary Information 在本节中，我们将讨论多级辅助信息如何工作。包括多个预测分支的深度监督架构如图 3 (c) 所示。对于目标检测，不同的特征金字塔可用于执行不同的任务，例如它们一起可以检测不同大小的目标。因此，连接到深度监督分支后，会引导浅层特征学习小物体检测所需的特征，此时系统会将其他尺寸的物体的位置视为背景。然而，上述行为会导致深层特征金字塔丢失大量预测目标对象所需的信息。关于这个问题，我们认为每个特征金字塔都需要接收所有目标对象的信息，以便后续的主分支可以保留完整的信息来学习对各种目标的预测。\n辅助可逆分支： (1) 可以还原所有的特征信息 （2）推理的时候，不会额外增加计算量\n多级辅助信息： 不分大、中、小目标，把所有物体的特征都汇聚在一起\n4.2. Generalized ELAN 在本节中，我们将描述所提出的新网络架构——GELAN。通过结合采用梯度路径规划设计的两种神经网络架构CSPNet [64]和ELAN [65]，我们设计了兼顾轻量级、推理速度和准确性的广义高效层聚合网络（GELAN）。其整体架构如图 4 所示。我们将最初仅使用卷积层堆叠的 ELAN [65] 的功能推广到可以使用任何计算块的新架构。\nELAN 和 GELAN 的区别：\nELAN使用的是常规的卷积操作\nGELAN是把卷积换成了任意的模块，最后转到相同的通道数、相同维度大小即可\nExperiments 实验是一篇论文，审稿人看的比较仔细的地方。学习一下别人的写法\n附录可以给审稿人和读者，更直观的看到实现的细节\n5.1. Experimental Setup 我们使用 MS COCO 数据集验证了所提出的方法。\n所有实验设置均遵循 YOLOv7 AF [63]，而数据集为 MS COCO 2017 分割。我们提到的所有模型都是使用从头开始训练策略进行训练的，总训练次数为 500 epoch。在设置学习率时，我们在前三个epoch中使用线性预热，随后的epoch根据模型规模设置相应的衰减方式。至于最后 15 个时期，我们关闭马赛克数据增强。更多设置请参考附录。\n5.2 Implementation Details 我们分别基于 YOLOv7 [63] 和 Dynamic YOLOv7 [36] 构建了 YOLOv9 的通用版本和扩展版本。\n在网络架构的设计中，我们使用 CSPNet 块 [64] 和计划的 RepConv [63] 作为计算块，用 GELAN 替换了 ELAN [65]。我们还简化了下采样模块并优化了无锚预测头。至于PGI的辅助损失部分，我们完全遵循YOLOv7的辅助头设置。详情请参阅附录。\n5.3 Comparison with state-of-the-arts 表 1 列出了我们提出的 YOLOv9 与其他从头开始训练的实时目标检测器的比较。总体而言，现有方法中性能最好的方法是用于轻量级模型的 YOLO MS-S [7]、用于中型模型的 YOLO MS [7]、用于通用模型的 YOLOv7 AF [63] 和用于大型模型的 YOLOv8-X [15]。与轻量级和中型模型YOLO MS[7]相比，YOLOv9的参数减少了约10%，计算量减少了5∼15%，但AP仍然有0.4∼0.6%的提升。与YOLOv7 AF相比，YOLOv9-C的参数减少了42%，计算量减少了21%，但达到了相同的AP（53%）。与YOLOv8-X相比，YOLOv9-X参数减少15%，计算量减少25%，AP显着提升1.7%。上述对比结果表明，我们提出的YOLOv9与现有方法相比在各方面都有显着改进。\n另一方面，我们也将ImageNet预训练模型纳入对比，结果如图5所示。我们分别根据参数和计算量进行比较。就参数数量而言，性能最好的大型模型是 RT DETR [43]。从图5中我们可以看到，使用传统卷积的YOLOv9在参数利用率上甚至比使用深度卷积的YOLO MS还要好。至于大型模型的参数利用率，也大大超过了使用ImageNet预训练模型的RT DETR。更棒的是，在深度模型中，YOLOv9展示了使用PGI的巨大优势。通过准确保留和提取将数据映射到目标所需的信息，我们的方法仅需要 64% 的参数，同时保持 RT DETR-X 的精度。\n至于计算量，现有最好的模型从最小到最大依次是YOLO MS [7]、PP YOLOE [74]和RT DETR [43]。从图5中我们可以看到，YOLOv9在计算复杂度方面远远优于从头开始训练的方法。另外，如果与基于深度卷积和基于ImageNet的预训练模型相比，YOLOv9也很有竞争力。\n5.4 Ablation Studies 5.4.1 Generalized ELAN 对于 GELAN，我们首先对计算模块进行消融研究。我们分别使用Res块[21]、Dark块[49]和CSP块[64]进行实验。表2表明，用不同的计算块替换ELAN中的卷积层后，系统可以保持良好的性能。用户确实可以自由更换计算块并在各自的推理设备上使用它们。在不同的计算块替换中，CSP 块的性能特别好。它们不仅减少了参数量和计算量，而且将 AP 提高了 0.7%。因此，我们选择CSPELAN作为YOLOv9中GELAN的组成单元。\n接下来，我们对不同尺寸的GELAN进行ELAN块深度和CSP块深度实验，并将结果显示在表3中。我们可以看到，当ELAN的深度从1增加到2时，精度显着提高。但当深度大于等于2时，无论是提高ELAN深度还是CSP深度，参数数量、计算量和精度总是呈现线性关系。这意味着 GELAN 对深度不敏感。\n也就是说，用户可以任意组合GELAN中的组件来设计网络架构，无需特殊设计即可拥有性能稳定的模型。在表3中，对于YOLOv9-{S,M,C}，我们将ELAN深度和CSP深度的配对设置为{{2, 3}, {2, 1}, {2, 1}}。\n5.4.2 Programmable Gradient Information 在PGI方面，我们分别对backbone和neck的辅助可逆分支和多级辅助信息进行了消融研究。我们设计了辅助可逆分支ICN来使用DHLC[34]链接来获取多级可逆信息。对于多级辅助信息，我们使用FPN和PAN进行消融研究，PFH的作用相当于传统的深度监督。所有实验的结果列于表4中。从表4中我们可以看出，PFH仅在深度模型中有效，而我们提出的PGI可以在不同组合下提高精度。尤其是使用ICN时，我们得到了稳定且更好的结果。我们还尝试将YOLOv7[63]中提出的lead-head指导分配应用于PGI的辅助监督，并取得了更好的性能。\n我们进一步将PGI和深度监督的概念应用到不同规模的模型上，并比较结果，结果如表5所示。正如一开始分析的那样，深度监督的引入会导致浅层模型精度的损失。对于一般模型来说，引入深度监督会导致性能不稳定，而深度监督的设计理念只能在极深的模型中带来收益。所提出的PGI可以有效处理信息瓶颈和信息破碎等问题，并且可以全面提高不同规模模型的准确性。 PGI 的概念带来了两个宝贵的贡献。第一个是让辅助监督方法适用于浅层模型，第二个是让深层模型训练过程获得更可靠的梯度。这些梯度使深度模型能够使用更准确的信息来建立数据和目标之间的正确相关性\n最后，我们在表中显示了从基线 YOLOv7 到 YOLOv9E 逐渐增加组件的结果。我们提出的GELAN和PGI给模型带来了全面的改进。\n5.5 Visualization 本节将探讨信息瓶颈问题并将其可视化。此外，我们还将可视化所提出的 PGI 如何使用可靠的梯度来找到数据和目标之间的正确相关性。在图6中，我们展示了在不同架构下使用随机初始权重作为前馈获得的特征图的可视化结果。我们可以看到，随着层数的增加，所有架构的原始信息逐渐减少。例如，在PlainNet的第50层，很难看到物体的位置，并且所有可区分的特征将在第100层丢失。对于ResNet，虽然在第50层仍然可以看到物体的位置，但边界信息已经丢失。当深度达到第100层时，整个图像变得模糊。 CSPNet 和提出的 GELAN 都表现得非常好，并且它们都可以保持支持清晰识别对象的特征直到第 200 层。对比中，GELAN结果更稳定，边界信息更清晰\n图7用于展示PGI是否可以在训练过程中提供更可靠的梯度，使得用于更新的参数能够有效捕获输入数据与目标之间的关系。图7显示了GELAN和YOLOv9（GELAN + PGI）的特征图在PAN偏置预热中的可视化结果。从图7（b）和（c）的比较中，我们可以清楚地看到PGI准确而简洁地捕获了包含对象的区域**。对于不使用PGI的GELAN，我们发现它在检测物体边界时存在发散**，并且在某些背景区域也产生了意想不到的响应。这个实验证实了PGI确实可以提供更好的梯度来更新参数，并使主分支的前馈阶段能够保留更重要的特征。\nConclusions 在本文中，我们提出使用PGI来解决信息瓶颈问题以及深度监督机制不适合轻量级神经网络的问题。我们设计了 GELAN，一个高效、轻量级的神经网络。在物体检测方面，GELAN在不同的计算块和深度设置下都具有强大且稳定的性能。它确实可以广泛扩展为适合各种推理设备的模型。针对以上两个问题，PGI的引入使得轻量级模型和深度模型都获得了精度的显着提升。 PGI和GELAN相结合设计的YOLOv9已经展现出强大的竞争力。其出色的设计使得深度模型相比YOLOv8减少了49%的参数数量和43%的计算量，但在MS COCO数据集上仍然有0.6%的AP提升。\n","permalink":"https://swimmingliu.cn/posts/papernotes/2024-yolov9/","summary":"\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e如今的深度学习方法主要关注如何设计\u003cstrong\u003e最合适的目标函数\u003c/strong\u003e，使模型的预测结果能够最接近真实情况。同时，必须设计一个\u003cstrong\u003e适当的架构\u003c/strong\u003e，可以帮助\u003cstrong\u003e获取足够的信息进行预测\u003c/strong\u003e。现有方法忽略了一个事实，即\u003cstrong\u003e当输入数据经过逐层特征提取和空间变换时\u003c/strong\u003e，\u003cstrong\u003e大量信息将会丢失\u003c/strong\u003e。本文将深入研究数据通过\u003cstrong\u003e深度网络传输时数据丢失的重要问题\u003c/strong\u003e，即\u003cstrong\u003e信息瓶颈和可逆函数\u003c/strong\u003e。我们提出了\u003cstrong\u003e可编程梯度信息（PGI）\u003cstrong\u003e的概念来应对深度网络实现\u003c/strong\u003e多个目标所需的各种变化\u003c/strong\u003e。\nPGI可以为\u003cstrong\u003e目标任务计算目标函数\u003c/strong\u003e提供\u003cstrong\u003e完整的输入信息\u003c/strong\u003e，从而获得\u003cstrong\u003e可靠的梯度信息来更新网络权值\u003c/strong\u003e。此外，还设计了一种基于\u003cstrong\u003e梯度路径规划的新型轻量级网络架构\u003c/strong\u003e——\u003cstrong\u003e通用高效层聚合网络（GELAN）\u003c/strong\u003e。GELAN的架构证实了PGI在轻量级模型上取得了优异的结果。我们在基于 MS COCO 数据集的目标检测上验证了所提出的 GELAN 和 PGI。结果表明，与基于深度卷积开发的最先进方法相比，GELAN 仅使用\u003cstrong\u003e传统的卷积算子\u003c/strong\u003e即可实现更好的参数利用率。 PGI 可用于从轻型到大型的各种模型。它可以用来获取完整的信息，使得\u003cstrong\u003etrain-from-scratch (从零开始训练) 模型能够比使用大数据集预训练\u003c/strong\u003e的state-of-theart模型获得更好的结果，对比结果如图1所示。源代码位于：https： //github.com/WongKinYiu/yolov9。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e核心创新点:  依然是网络结构的创新\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eProgrammable Gradient Information (PGI)\u003c/li\u003e\n\u003cli\u003eGeneralized Efficient Layer Aggregation Network（GELAN）\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg alt=\"image-20240301113226341\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/f6b3ea45-d79d-11ee-a66b-c858c0c1debd\"\u003e\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e基于深度学习的模型在计算机视觉、语言处理和语音识别等各个领域都表现出了比过去的人工智能系统更好的性能。近年来，深度学习领域的研究人员主要关注如何开发更强大的系统架构和学习方法，例如CNN，Transformers[8,9,40] 、41、60、69、70]，Perceivers[26、26、32、52、56、81、81]和Mambas[17、38、80]。此外，一些研究人员尝试开发更通用的目标函数，例如损失函数[5,45,46,50,77,78]，标签分配[10,12,33,67,79]和辅助监督[18] 、20、24、28、29、51、54、68、76]。上述研究都试图精确地找到\u003cstrong\u003e输入和目标任务之间的映射\u003c/strong\u003e。然而，大多数过去的方法都忽略了\u003cstrong\u003e输入数据在前馈过程中可能会产生不可忽略的信息丢失量\u003c/strong\u003e。这种\u003cstrong\u003e信息丢失\u003c/strong\u003e可能会导致\u003cstrong\u003e有偏差的梯度流\u003c/strong\u003e，随后用于更新模型。上述问题可能导致深度网络\u003cstrong\u003e在目标和输入之间建立不正确的关联\u003c/strong\u003e，导致训练后的模型产生不正确的预测。\u003c/p\u003e\n\u003cp\u003e在深度网络中，\u003cstrong\u003e输入数据在前馈过程中丢失信息的现象\u003c/strong\u003e俗称\u003cstrong\u003e信息瓶颈\u003c/strong\u003e[59]，其示意图如图2所示。目前可以缓解这种现象的主要方法有：（1）\u003cstrong\u003e可逆架构\u003c/strong\u003e的使用[3,16,19]：该方法主要\u003cstrong\u003e使用重复的输入数据，并以显式的方式维护输入数据的信息\u003c/strong\u003e； （2）使用\u003cstrong\u003eMasked建模\u003c/strong\u003e[1,6,9,27,71,73]：主要利用重构损失，采用\u003cstrong\u003e隐式方式最大化提取特征并保留输入信息\u003c/strong\u003e； （3）引入\u003cstrong\u003e深度监督\u003c/strong\u003e概念[28,51,54,68]：它利用\u003cstrong\u003e没有丢失太多重要信息的浅层特征来预先建立从特征到目标的映射\u003c/strong\u003e，以确保\u003cstrong\u003e重要信息能够被传递到更深的层次\u003c/strong\u003e。然而，上述方法在训练过程和推理过程中都存在不同的缺点。例如，\u003cstrong\u003e可逆架构需要额外的层来组合重复馈送的输入数据\u003c/strong\u003e，这将显着增加推理成本。另外，由于\u003cstrong\u003e输入数据层到输出层不能有太深的路径\u003c/strong\u003e，这种限制将导致\u003cstrong\u003e在训练过程中难以对高阶语义信息进行建模\u003c/strong\u003e。对于 \u003cstrong\u003eMasked 建模\u003c/strong\u003e，其\u003cstrong\u003e重建损失有时与目标损失相冲突\u003c/strong\u003e。此外，大多数\u003cstrong\u003e掩码机制还会产生与数据的不正确关联\u003c/strong\u003e。 对于\u003cstrong\u003e深层监督\u003c/strong\u003e机制来说，会产生\u003cstrong\u003e误差累积\u003c/strong\u003e，如果\u003cstrong\u003e浅层监督在训练过程中丢失信息\u003c/strong\u003e，\u003cstrong\u003e后续层将无法检索到所需信息\u003c/strong\u003e。上述现象在\u003cstrong\u003e困难任务\u003c/strong\u003e和\u003cstrong\u003e小模型上\u003c/strong\u003e会更加\u003cstrong\u003e显着\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e针对上述问题，我们提出了一个新的概念，即\u003cstrong\u003e可编程梯度信息（PGI）\u003c/strong\u003e。其概念是通过\u003cstrong\u003e辅助可逆分支生成可靠的梯度\u003c/strong\u003e，使得\u003cstrong\u003e深层特征仍然能够保持执行目标任务的关键特征\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e辅助可逆分支的设计\u003c/strong\u003e可以避免传统的\u003cstrong\u003e融合多路径特征的深度监督过程\u003c/strong\u003e可能造成的\u003cstrong\u003e语义损失\u003c/strong\u003e。换句话说，我们在\u003cstrong\u003e不同语义层面上编程梯度信息传播\u003c/strong\u003e，从而达到最佳的训练结果。 PGI的\u003cstrong\u003e可逆架构建立在辅助分支上\u003c/strong\u003e，因此\u003cstrong\u003e没有额外的成本\u003c/strong\u003e。由于PGI可以\u003cstrong\u003e自由选择适合目标任务的损失函数\u003c/strong\u003e，因此也克服了\u003cstrong\u003eMasked建模\u003c/strong\u003e遇到的问题。所提出的\u003cstrong\u003ePGI机制\u003c/strong\u003e可以应用于各种规模的\u003cstrong\u003e深度神经网络\u003c/strong\u003e，并且比仅适用于\u003cstrong\u003e非常深的神经网络\u003c/strong\u003e的\u003cstrong\u003e深度监督机制更通用\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e在本文中，我们还基于ELAN[65]设计了\u003cstrong\u003e广义ELAN（GELAN）\u003c/strong\u003e，GELAN的设计同时\u003cstrong\u003e考虑了参数量、计算复杂度、准确性和推理速度\u003c/strong\u003e。这种设计允许用户\u003cstrong\u003e针对不同的推理设备任意选择合适的计算块\u003c/strong\u003e。我们将提出的PGI和GELAN结合起来，然后设计了新一代YOLO系列物体检测系统，我们称之为YOLOv9。我们使用MS COCO数据集进行实验，实验结果验证了我们提出的YOLOv9在所有比较中都取得了顶尖的性能。\u003c/p\u003e\n\u003cp\u003e我们总结本文的贡献如下：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e我们从\u003cstrong\u003e可逆函数的角度\u003c/strong\u003e对\u003cstrong\u003e现有的深度神经网络架构进行了理论分析\u003c/strong\u003e，通过这个过程\u003cstrong\u003e我们成功地解释了许多过去难以解释的现象\u003c/strong\u003e。我们还基于此分析\u003cstrong\u003e设计了PGI和辅助可逆分支\u003c/strong\u003e，并取得了优异的结果。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e我们设计的PGI解决了\u003cstrong\u003e深度监督\u003c/strong\u003e只能用于\u003cstrong\u003e极深的神经网络架构的问题\u003c/strong\u003e，从而让\u003cstrong\u003e新的轻量级架构真正应用于日常生活中\u003c/strong\u003e。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e我们设计的GELAN仅使用\u003cstrong\u003e常规卷积\u003c/strong\u003e来实现比基于最先进技术的\u003cstrong\u003e深度卷积设计更高的参数利用率\u003c/strong\u003e，同时表现出\u003cstrong\u003e轻、快速、准确\u003c/strong\u003e的巨大优势。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e结合所提出的PGI和GELAN，YOLOv9在MS COCO数据集上的目标检测性能在各个方面都大大超过了现有的实时目标检测器。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eProgrammable Gradient Information (PGI)：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e自由选择适合目标任务的损失函数\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e可逆结构建立辅助分支，不增加推理成本\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e适用于各种规模的深度神经网络\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eGELAN：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e轻、快速、准确\u003c/li\u003e\n\u003cli\u003e采用常规卷积吊打其他新颖卷积\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"related-work\"\u003eRelated work\u003c/h2\u003e\n\u003ch3 id=\"21-real-time-object-detectors\"\u003e2.1 Real-time Object Detectors\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e目前主流的实时目标检测器是YOLO系列[2,7,13–15,25,30,31,47–49,61–63,74,75]，这些模型大多数使用CSPNet[64]或 ELAN [65] 及其变体作为主要计算单元。在特征集成方面，通常使用改进的PAN[37]或FPN[35]作为工具，然后使用改进的YOLOv3头[49]或FCOS头[57, 58]作为预测头。最近也提出了一些实时目标检测器，例如 RT DETR [43]，其基础是 DETR [4]。然而，由于DETR系列目标检测器在没有相应领域预训练模型的情况下很难应用于新领域，因此目前应用最广泛的实时目标检测器仍然是YOLO系列。本文选择 YOLOv7 [63] 作为开发该方法的基础，该方法已在各种计算机视觉任务和各种场景中被证明有效。\u003c/p\u003e","title":"YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information"},{"content":"Introduction YOLOSHOW is a graphical user interface (GUI) application embed with YOLOv5 YOLOv7 YOLOv8 YOLOv9 YOLOv10 YOLOv11 RT-DETR SAM MobileSAM FastSAM algorithm.\nEnglish \u0026nbsp; | \u0026nbsp; 简体中文 Demo Video YOLOSHOW v1.x : YOLOSHOW-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI\nYOLOSHOW v2.x : YOLOSHOWv2.0-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI\nTodo List Add YOLOv9 YOLOv10 RT-DETR YOLOv11 SAM MobileSAM FastSAM Algorithm Support Instance Segmentation （ YOLOv5 YOLOv8 YOLOv11 SAM MobileSAM FastSAM） Support Pose Estimation （ YOLOv8 YOLOv11） Support Oriented Bounding Boxes ( YOLOv8 YOLOv11 ) Support Http Protocol in RTSP Function ( Single Mode ) Add Model Comparison Mode（VS Mode） Support Dragging File Input Tracking \u0026amp; Counting ( Industrialization ) Functions 1. Support Image / Video / Webcam / Folder (Batch) / IPCam Object Detection Choose Image / Video / Webcam / Folder (Batch) / IPCam in the menu bar on the left to detect objects.\n2. Change Models / Hyper Parameters dynamically When the program is running to detect targets, you can change models / hyper Parameters\nSupport changing model in YOLOv5 / YOLOv7 / YOLOv8 / YOLOv9 / YOLOv10 / YOLOv11 / RTDETR / YOLOv5-seg / YOLOv8-seg YOLOv11-seg / YOLOv8-pose / YOLOv11-pose / YOLOv8-obb / YOLOv11-obb / SAM / MobileSAM / FastSAM dynamically Support changing IOU / Confidence / Delay time / line thickness dynamically 3. Loading Model Automatically Our program will automatically detect pt files including YOLOv5 Models / YOLOv7 Models / YOLOv8 Models / YOLOv9 Models / YOLOv10 Models / YOLOv11 Models / RT-DETR Models / SAM Models / MobileSAM Models / FastSAM Models that were previously added to the ptfiles folder.\nIf you need add the new pt file, please click Import Model button in Settings box to select your pt file. Then our program will put it into ptfiles folder.\nNotice :\nAll pt files are named including yolov5 / yolov7 / yolov8 / yolov9 / yolov10 / yolo11 / rtdetr / sam / samv2 / mobilesam / fastsam. (e.g. yolov8-test.pt) If it is a pt file of segmentation mode, please name it including yolov5n-seg / yolov8s-seg / yolo11-seg . (e.g. yolov8n-seg-test.pt) If it is a pt file of pose estimation mode, please name it including yolov8n-pose / yolo11n-pose . (e.g. yolov8n-pose-test.pt) If it is a pt file of oriented bounding box mode, please name it including yolov8n-obb / yolo11n-obb . (e.g. yolov8n-obb-test.pt) 4. Loading Configures After startup, the program will automatically loading the last configure parameters. After closedown, the program will save the changed configure parameters. 5. Save Results If you need Save results, please click Save Mode before detection. Then you can save your detection results in selected path.\n6. Support Object Detection, Instance Segmentation and Pose Estimation From YOLOSHOW v3.0，our work supports both Object Detection , Instance Segmentation, Pose Estimation and Oriented Bounding Box. Meanwhile, it also supports task switching between different versions，such as switching from YOLOv5 Object Detection task to YOLOv8 Instance Segmentation task.\n7. Support Model Comparison among Object Detection, Instance Segmentation, Pose Estimation and Oriented Bounding Box From YOLOSHOW v3.0，our work supports compare model performance among Object Detection, Instance Segmentation, Pose Estimation and Oriented Bounding Box.\nPreparation Experimental environment OS : Windows 11 CPU : Intel(R) Core(TM) i7-10750H CPU @2.60GHz 2.59 GHz GPU : NVIDIA GeForce GTX 1660Ti 6GB 1. Create virtual environment create a virtual environment equipped with python version 3.9, then activate environment.\nconda create -n yoloshow python=3.9 conda activate yoloshow 2. Install Pytorch frame Windows: pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 Linux: pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 Change other pytorch version in 3. Install dependency package Switch the path to the location of the program\ncd {the location of the program} Install dependency package of program\npip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple 4. Add Font Windows User Copy all font files *.ttf in fonts folder into C:\\Windows\\Fonts\nLinux User mkdir -p ~/.local/share/fonts sudo cp fonts/Shojumaru-Regular.ttf ~/.local/share/fonts/ sudo fc-cache -fv MacOS User The MacBook is so expensive that I cannot afford it, please install .ttf by yourself. 😂\n5. Run Program python main.py Frames Reference YOLO Algorithm YOLOv5 YOLOv7 YOLOv8 / YOLOv11 / RT-DETR / SAM / MobileSAM / FastSAM YOLOv9 YOLOv10\nYOLO Graphical User Interface YOLOSIDE\tPyQt-Fluent-Widgets\n","permalink":"https://swimmingliu.cn/posts/diary/yoloshow/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003eYOLOSHOW\u003c/strong\u003e\u003c/em\u003e is a graphical user interface (GUI) application embed with \u003ccode\u003eYOLOv5\u003c/code\u003e \u003ccode\u003eYOLOv7\u003c/code\u003e \u003ccode\u003eYOLOv8\u003c/code\u003e \u003ccode\u003eYOLOv9\u003c/code\u003e \u003ccode\u003eYOLOv10\u003c/code\u003e \u003ccode\u003eYOLOv11\u003c/code\u003e  \u003ccode\u003eRT-DETR\u003c/code\u003e \u003ccode\u003eSAM\u003c/code\u003e \u003ccode\u003eMobileSAM\u003c/code\u003e \u003ccode\u003eFastSAM\u003c/code\u003e algorithm.\u003c/p\u003e\n \u003cp align=\"center\"\u003e \n  English \u0026nbsp; | \u0026nbsp; \u003ca href=\"https://github.com/SwimmingLiu/YOLOSHOW/blob/master/README_cn.md\"\u003e简体中文\u003c/a\u003e\n \u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"YOLOSHOW-Screen\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/YOLOSHOW-SNAPSHOT.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"demo-video\"\u003eDemo Video\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eYOLOSHOW v1.x\u003c/code\u003e : \u003ca href=\"https://www.bilibili.com/video/BV1BC411x7fW\"\u003eYOLOSHOW-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eYOLOSHOW v2.x\u003c/code\u003e : \u003ca href=\"https://www.bilibili.com/video/BV1ZD421E7m3\"\u003eYOLOSHOWv2.0-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"todo-list\"\u003eTodo List\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e Add \u003ccode\u003eYOLOv9\u003c/code\u003e \u003ccode\u003eYOLOv10\u003c/code\u003e  \u003ccode\u003eRT-DETR\u003c/code\u003e  \u003ccode\u003eYOLOv11\u003c/code\u003e  \u003ccode\u003eSAM\u003c/code\u003e  \u003ccode\u003eMobileSAM\u003c/code\u003e  \u003ccode\u003eFastSAM\u003c/code\u003e Algorithm\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e Support Instance Segmentation （ \u003ccode\u003eYOLOv5\u003c/code\u003e  \u003ccode\u003eYOLOv8\u003c/code\u003e  \u003ccode\u003eYOLOv11\u003c/code\u003e \u003ccode\u003eSAM\u003c/code\u003e  \u003ccode\u003eMobileSAM\u003c/code\u003e  \u003ccode\u003eFastSAM\u003c/code\u003e）\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e Support Pose Estimation （ \u003ccode\u003eYOLOv8\u003c/code\u003e  \u003ccode\u003eYOLOv11\u003c/code\u003e）\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e Support Oriented Bounding Boxes ( \u003ccode\u003eYOLOv8\u003c/code\u003e  \u003ccode\u003eYOLOv11\u003c/code\u003e )\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e Support Http Protocol in \u003ccode\u003eRTSP\u003c/code\u003e Function ( \u003ccode\u003eSingle\u003c/code\u003e Mode )\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e Add Model Comparison Mode（VS Mode）\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e Support Dragging File Input\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Tracking \u0026amp; Counting ( \u003ccode\u003eIndustrialization\u003c/code\u003e )\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"functions\"\u003eFunctions\u003c/h2\u003e\n\u003ch3 id=\"1-support-image--video--webcam--folder-batch--ipcam-object-detection\"\u003e1. Support Image / Video / Webcam / Folder (Batch) / IPCam Object Detection\u003c/h3\u003e\n\u003cp\u003eChoose Image / Video / Webcam / Folder (Batch) / IPCam in the menu bar on the left to detect objects.\u003c/p\u003e","title":"YOLOSHOW - YOLOv5/YOLOv7/YOLOv8/YOLOv9/RTDETR GUI based on Pyside6"},{"content":"介绍 YOLOSHOW 是一款集合了 YOLOv5 YOLOv7 YOLOv8 YOLOv9 YOLOv10 YOLOv11 RT-DETR SAM MobileSAM FastSAM 的图形化界面程序\nEnglish \u0026nbsp; | \u0026nbsp; 简体中文 演示视频 YOLOSHOW v1.x : YOLOSHOW-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI\nYOLOSHOW v2.x : YOLOSHOWv2.0-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI\n待做清单 加入 YOLOv9 YOLOv10 RT-DETR YOLOv11 SAM MobileSAM FastSAM算法 支持实例分割 （ YOLOv5 YOLOv8 YOLOv11 SAM MobileSAM FastSAM） 支持姿态估计 （YOLOv8 YOLOv11） 支持旋转框 (YOLOv8 YOLOv11) RTSP 功能 支持 Http 协议 ( Single Mode ) 支持模型对比模式（VS Mode） 支持拖拽文件输入 追踪和计数模型 ( 工业化 ) 功能 1. 支持 图片 / 视频 / 摄像头 / 文件夹（批量）/ 网络摄像头 目标检测 选择左侧菜单栏的图片 / 视频 / 摄像头 / 文件夹（批量）/ 网络摄像头 进行目标检测\n2. 动态切换模型 / 调整超参数 程序开始检测时，支持动态切换模型 / 调整超参数\n支持动态切换 YOLOv5 / YOLOv7 / YOLOv8 / YOLOv9 / YOLOv10 / YOLOv11 / RTDETR / YOLOv5-seg / YOLOv8-seg YOLOv11-seg / YOLOv8-pose / YOLOv11-pose / YOLOv8-obb / YOLOv11-obb / SAM / MobileSAM / FastSAM 模型 支持动态修改 IOU / Confidence / Delay time / line thickness 超参数 3. 动态加载模型 程序可以自动检测ptfiles 文件夹中包含 YOLOv5 Models / YOLOv7 Models / YOLOv8 Models / YOLOv9 Models / YOLOv10 Models / YOLOv11 Models / RT-DETR Models / SAM Models / MobileSAM Models / FastSAM Models pt 模型.\n如果你需要导入新的 pt 文件, 请点击 Settings 框中的 Import Model 按钮 来选择需要导入的 pt 文件. 然后程序会把该文件复制到 ptfiles 文件夹下.\nNotice :\n所有的 pt 模型文件命名必须包含 yolov5 / yolov7 / yolov8 / yolov9 / yolov10 / yolo11 / rtdetr / sam / samv2 / mobilesam / fastsam 中的任意一个版本. (如 yolov8-test.pt) 如果是分割类型的 pt 文件, 命名中应包含 yolov5n-seg / yolov8s-seg / yolo11-seg 中的任意一个版本. (如 yolov8n-seg-test.pt) 如果是姿态检测类型的 pt 文件, 命名中应包含 yolov8n-pose / yolo11n-pose 中的任意一个版本. (如 yolov8n-pose-test.pt) 如果是旋转框类型的 pt 文件, 命名中应包含 yolov8n-obb / yolo11n-obb 中的任意一个版本. (e.g. yolov8n-obb-test.pt) 4. 加载超参数配置 程序启动后, 自动加载最近保存的超参数配置. 程序关闭后, 自动保存最近修改的超参数配置. 5. 保存检测结果 如果需要保存检测结果，请在检测前点击 Save Mode . 然后等待检测完毕，选择需要保存的路径进行结果保存.\n6. 同时支持目标检测、实例分割和姿态估计 从 YOLOSHOW v3.0 起 ，支持目标检测、实例分割、姿态估计和旋转框多种任务。同时支持不同版本的任务切换，如从YOLOv5 目标检测任务 切换到 YOLOv8 实例分割任务。\n7. 支持目标检测、实例分割、姿态估计和旋转框模型对比模式 从 YOLOSHOW v3.0 起，支持目标检测、实例分割、姿态估计和旋转框模型对比模式。\n运行准备工作 实验环境 OS : Windows 11 CPU : Intel(R) Core(TM) i7-10750H CPU @2.60GHz 2.59 GHz GPU : NVIDIA GeForce GTX 1660Ti 6GB 1. 创建虚拟环境 创建内置Python 3.9的conda虚拟环境, 然后激活该环境.\nconda create -n yoloshow python=3.9 conda activate yoloshow 2. 安装Pytorch框架 Windows: pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 Linux: pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 安装其他版本的 Pytorch : 3. 安装依赖包 切换到YOLOSHOW程序所在的路径\ncd {YOLOSHOW程序所在的路径} 安装程序所需要的依赖包\npip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple 4. 添加字体 Windows 用户 把所有的fonts 文件夹中的字体文件 *.ttf 复制到 C:\\Windows\\Fonts\nLinux 用户 mkdir -p ~/.local/share/fonts sudo cp fonts/Shojumaru-Regular.ttf ~/.local/share/fonts/ sudo fc-cache -fv MacOS 用户 MacBook实在太贵了，我买不起。你们自己想办法安装吧~😂\n5. 运行程序 python main.py 使用框架 参考文献 YOLO 算法 YOLOv5 YOLOv7 YOLOv8 / YOLOv11 / RT-DETR / SAM / MobileSAM / FastSAM YOLOv9 YOLOv10\nYOLO 图形化界面 YOLOSIDE\tPyQt-Fluent-Widgets\n","permalink":"https://swimmingliu.cn/posts/diary/yoloshow-cn/","summary":"\u003ch2 id=\"介绍\"\u003e介绍\u003c/h2\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003eYOLOSHOW\u003c/strong\u003e\u003c/em\u003e 是一款集合了 \u003ccode\u003eYOLOv5\u003c/code\u003e \u003ccode\u003eYOLOv7\u003c/code\u003e \u003ccode\u003eYOLOv8\u003c/code\u003e \u003ccode\u003eYOLOv9\u003c/code\u003e \u003ccode\u003eYOLOv10\u003c/code\u003e \u003ccode\u003eYOLOv11\u003c/code\u003e  \u003ccode\u003eRT-DETR\u003c/code\u003e \u003ccode\u003eSAM\u003c/code\u003e \u003ccode\u003eMobileSAM\u003c/code\u003e \u003ccode\u003eFastSAM\u003c/code\u003e 的图形化界面程序\u003c/p\u003e\n\u003cp align=\"center\"\u003e \n  \u003ca href=\"https://github.com/SwimmingLiu/YOLOSHOW/blob/master/README.md\"\u003e English\u003c/a\u003e \u0026nbsp; | \u0026nbsp; 简体中文\u003c/a\u003e\n \u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"YOLOSHOW-Screen\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/YOLOSHOW-SNAPSHOT.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"演示视频\"\u003e演示视频\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eYOLOSHOW v1.x\u003c/code\u003e : \u003ca href=\"https://www.bilibili.com/video/BV1BC411x7fW\"\u003eYOLOSHOW-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eYOLOSHOW v2.x\u003c/code\u003e : \u003ca href=\"https://www.bilibili.com/video/BV1ZD421E7m3\"\u003eYOLOSHOWv2.0-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"待做清单\"\u003e待做清单\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e 加入 \u003ccode\u003eYOLOv9\u003c/code\u003e \u003ccode\u003eYOLOv10\u003c/code\u003e  \u003ccode\u003eRT-DETR\u003c/code\u003e  \u003ccode\u003eYOLOv11\u003c/code\u003e  \u003ccode\u003eSAM\u003c/code\u003e  \u003ccode\u003eMobileSAM\u003c/code\u003e  \u003ccode\u003eFastSAM\u003c/code\u003e算法\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e 支持实例分割 （ \u003ccode\u003eYOLOv5\u003c/code\u003e  \u003ccode\u003eYOLOv8\u003c/code\u003e  \u003ccode\u003eYOLOv11\u003c/code\u003e \u003ccode\u003eSAM\u003c/code\u003e  \u003ccode\u003eMobileSAM\u003c/code\u003e  \u003ccode\u003eFastSAM\u003c/code\u003e）\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e 支持姿态估计 （\u003ccode\u003eYOLOv8\u003c/code\u003e \u003ccode\u003eYOLOv11\u003c/code\u003e）\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e 支持旋转框 (\u003ccode\u003eYOLOv8\u003c/code\u003e \u003ccode\u003eYOLOv11\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e \u003ccode\u003eRTSP\u003c/code\u003e 功能 支持 Http 协议 ( Single Mode )\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e 支持模型对比模式（VS Mode）\u003c/li\u003e\n\u003cli\u003e\u003cinput checked=\"\" disabled=\"\" type=\"checkbox\"\u003e 支持拖拽文件输入\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e 追踪和计数模型 ( \u003ccode\u003e工业化\u003c/code\u003e )\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"功能\"\u003e功能\u003c/h2\u003e\n\u003ch3 id=\"1-支持-图片--视频--摄像头--文件夹批量-网络摄像头-目标检测\"\u003e1. 支持 图片 / 视频 / 摄像头 / 文件夹（批量）/ 网络摄像头 目标检测\u003c/h3\u003e\n\u003cp\u003e选择左侧菜单栏的图片 / 视频 / 摄像头 / 文件夹（批量）/ 网络摄像头 进行目标检测\u003c/p\u003e","title":"YOLOSHOW 中文版 - YOLOv5/YOLOv7/YOLOv8/YOLOv9/RTDETR GUI based on Pyside6"},{"content":"安装 Xshell 和 Xftp https://www.netsarang.com/en/xshell-download/ # Xshell下载连接 https://blog.csdn.net/m0_67400972/article/details/125346023 # 安装教程 添加Xshell连接 其中 server.ip 为服务器公网ip地址，端口为 6969\n安装Anaconda3 每个用户均被分配 AnacondaAnaconda3-2023.07-1-Linux-x86_64.sh 于主目录\nbash AnacondaAnaconda3-2023.07-1-Linux-x86_64.sh # 安装anaconda3 输入 yes 后， 再按回车键 即可\n初始化Anaconda3 conda init bash\t# 初始化conda 然后重新使用Xshell 连接即可\nMagic Network 下载外网文件、克隆Github项目等操作，必须使用Magic Network\nexport http_proxy=http://127.0.0.1:7890 export https_proxy=http://127.0.0.1:7890 取消Magic Network\nunset http_proxy unset https_proxy 如果使用上面的命令，不能连接Google. 需要远程桌面连接，打开CFW (默认是打开的)\nnohup bash /home/dell/LYJ/Clash/cfw \u0026gt; cfw.out 国内镜像下载 pip 清华源下载\npip install -i https://pypi.tuna.tsinghua.edu.cn/simple packge # packge为包名 conda 配置镜像\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ # 以上两条是Anaconda官方库的镜像 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ # 以上是Anaconda第三方库 Conda Forge的镜像 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ # 以上是Pytorch的Anaconda第三方镜像 远程桌面连接 远程连接直接找师兄问 向日葵 和 Teamviewer 密码，连接即可\n注意事项 建议非必要不使用远程连接（由于在同一时间段内，远程连接只能单用户使用） 使用远程连接，请先阅读服务器壁纸上的注意事项 如需上传文件，尽量使用移动硬盘，到918实验室拷贝至服务器上 ","permalink":"https://swimmingliu.cn/posts/diary/zstu_server_manuscript/","summary":"\u003ch2 id=\"安装-xshell-和-xftp\"\u003e安装 Xshell 和 Xftp\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ehttps://www.netsarang.com/en/xshell-download/ \u003cspan class=\"c1\"\u003e# Xshell下载连接\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ehttps://blog.csdn.net/m0_67400972/article/details/125346023 \u003cspan class=\"c1\"\u003e# 安装教程\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"添加xshell连接\"\u003e添加Xshell连接\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"image-20240105113129928\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/B6xRW.png\"\u003e\u003c/p\u003e\n\u003cp\u003e其中 \u003ccode\u003eserver.ip\u003c/code\u003e 为服务器公网ip地址，端口为 \u003ccode\u003e6969\u003c/code\u003e\u003c/p\u003e\n\u003ch2 id=\"安装anaconda3\"\u003e安装Anaconda3\u003c/h2\u003e\n\u003cp\u003e每个用户均被分配 \u003ccode\u003eAnacondaAnaconda3-2023.07-1-Linux-x86_64.sh \u003c/code\u003e 于主目录\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ebash AnacondaAnaconda3-2023.07-1-Linux-x86_64.sh \u003cspan class=\"c1\"\u003e# 安装anaconda3\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cimg alt=\"image-20240105113942737\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/B6KTv.png\"\u003e\u003c/p\u003e\n\u003cp\u003e输入 \u003ccode\u003eyes\u003c/code\u003e 后， 再按回车键 即可\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20240105114146047\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/B6one.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"初始化anaconda3\"\u003e初始化Anaconda3\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003econda init bash\t\u003cspan class=\"c1\"\u003e# 初始化conda\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e然后重新使用Xshell 连接即可\u003c/p\u003e\n\u003ch2 id=\"magic-network\"\u003eMagic Network\u003c/h2\u003e\n\u003cp\u003e下载外网文件、克隆Github项目等操作，必须使用Magic Network\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eexport\u003c/span\u003e \u003cspan class=\"nv\"\u003ehttp_proxy\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003ehttp://127.0.0.1:7890\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eexport\u003c/span\u003e \u003cspan class=\"nv\"\u003ehttps_proxy\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003ehttp://127.0.0.1:7890\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e取消Magic Network\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eunset\u003c/span\u003e http_proxy\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eunset\u003c/span\u003e https_proxy\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e如果使用上面的命令，不能连接Google. 需要远程桌面连接，打开CFW (默认是打开的)\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003enohup bash /home/dell/LYJ/Clash/cfw \u0026gt; cfw.out\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cimg alt=\"image-20240105115600487\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/B6So3.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"国内镜像下载\"\u003e国内镜像下载\u003c/h2\u003e\n\u003cp\u003epip 清华源下载\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003epip install -i https://pypi.tuna.tsinghua.edu.cn/simple packge      \u003cspan class=\"c1\"\u003e# packge为包名\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003econda 配置镜像\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003econda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003econda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 以上两条是Anaconda官方库的镜像\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003econda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 以上是Anaconda第三方库 Conda Forge的镜像\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003econda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 以上是Pytorch的Anaconda第三方镜像\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"远程桌面连接\"\u003e远程桌面连接\u003c/h2\u003e\n\u003cp\u003e远程连接直接找师兄问 向日葵 和 Teamviewer 密码，连接即可\u003c/p\u003e","title":"ZSTU服务器使用教程 (Yang Li Lab)"},{"content":"FRP配置 跳板机 # frps.ini 配置 [common] bind_port = 7000 #frps服务监听的端口 token = 123 # 链接口令 ./frps -c frps.ini # 启动frps 服务器 # frpc.ini [common] server_addr = x.x.x.x # 此处为 跳板机 的公网ip server_port = 7000 # 跳板机上frps服务监听的端口 token = 123 # 链接口令 [ssh] type = tcp local_ip = 127.0.0.1 local_port = 22 # 需要暴露的内网机器的端口 remote_port = 6000 # 暴露的内网机器的端口在vps上的端口 SSH连接 ssh -p 6000 swimmingliu@server.ip # 普通ssh 连接 ssh swimmingliu@server.ip 6000\t# xshell ssh连接 用户管理 添加用户 sudo adduser xxx 删除用户 sudo deluser xxx Magic Network export http_proxy=http://127.0.0.1:7890 export https_proxy=http://127.0.0.1:7890 Anaconda3 安装和配置 安装Anaconda3 wget --user-agent=\u0026#34;Mozilla\u0026#34; https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2023.07-1-Linux-x86_64.sh bash Anaconda3-2023.07-1-Linux-x86_64.sh # https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive 清华源 配置之前的envs cp -r old_envs_path anaconda/envs/\t#迁移之前的envs环境 完结撒花❀❀❀ ","permalink":"https://swimmingliu.cn/posts/diary/zstu_server_management/","summary":"\u003ch2 id=\"frp配置\"\u003eFRP配置\u003c/h2\u003e\n\u003ch3 id=\"跳板机\"\u003e跳板机\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# frps.ini 配置\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e[\u003c/span\u003ecommon\u003cspan class=\"o\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003ebind_port\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"m\"\u003e7000\u003c/span\u003e \u003cspan class=\"c1\"\u003e#frps服务监听的端口\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003etoken\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"m\"\u003e123\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 链接口令\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e./frps -c frps.ini \u003cspan class=\"c1\"\u003e# 启动frps\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"服务器\"\u003e服务器\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# frpc.ini\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e[\u003c/span\u003ecommon\u003cspan class=\"o\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003eserver_addr\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e x.x.x.x \u003cspan class=\"c1\"\u003e# 此处为 跳板机 的公网ip\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003eserver_port\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"m\"\u003e7000\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 跳板机上frps服务监听的端口\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003etoken\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"m\"\u003e123\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 链接口令\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e[\u003c/span\u003essh\u003cspan class=\"o\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003etype\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e tcp\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003elocal_ip\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e 127.0.0.1 \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003elocal_port\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"m\"\u003e22\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 需要暴露的内网机器的端口\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003eremote_port\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"m\"\u003e6000\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 暴露的内网机器的端口在vps上的端口\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"ssh连接\"\u003eSSH连接\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003essh -p \u003cspan class=\"m\"\u003e6000\u003c/span\u003e swimmingliu@server.ip \u003cspan class=\"c1\"\u003e# 普通ssh 连接\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003essh swimmingliu@server.ip 6000\t  \u003cspan class=\"c1\"\u003e# xshell ssh连接\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"用户管理\"\u003e用户管理\u003c/h2\u003e\n\u003ch3 id=\"添加用户\"\u003e添加用户\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo adduser xxx\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"删除用户\"\u003e删除用户\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo deluser xxx\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"magic-network\"\u003eMagic Network\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eexport\u003c/span\u003e \u003cspan class=\"nv\"\u003ehttp_proxy\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003ehttp://127.0.0.1:7890\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eexport\u003c/span\u003e \u003cspan class=\"nv\"\u003ehttps_proxy\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003ehttp://127.0.0.1:7890\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"anaconda3-安装和配置\"\u003eAnaconda3 安装和配置\u003c/h2\u003e\n\u003ch3 id=\"安装anaconda3\"\u003e安装Anaconda3\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ewget --user-agent\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;Mozilla\u0026#34;\u003c/span\u003e https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2023.07-1-Linux-x86_64.sh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ebash Anaconda3-2023.07-1-Linux-x86_64.sh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive 清华源\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"配置之前的envs\"\u003e配置之前的envs\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecp -r old_envs_path anaconda/envs/\t\t\u003cspan class=\"c1\"\u003e#迁移之前的envs环境\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"完结撒花\"\u003e完结撒花❀❀❀\u003c/h2\u003e","title":"ZSTU Server Management"},{"content":"Introduction 基于知识图谱和neo4j图数据库的电影知识问答系统\nWorkflow DataBase 爬取豆瓣TOP1000电影信息数据\nFrontend 获取用户输入的信息 （语音输入 / 文本输入） 向电影知识问答后端服务器发送请求 获取返回结果 (成功 -\u0026gt; 4 / 失败 -\u0026gt; 5) 如果返回结果包含image信息，则显示图片和文字，否则只显示文字 请求基于gpt的AI模型服务器，并显示返回结果 Backend ​\t[准备工作] 训练 TF-IDF 向量算法和朴素贝叶斯分类器，用于预测用户文本所属的问题类别\n接受前端请求，获取用户输入信息 使用分词库解析用户输入的文本词性，提取关键词 根据贝叶斯分类器，分类出用户文本的问题类型 结合关键词与问题类别，在 Neo4j 中查询问题的答案 返回查询结果 （若问题类型为 演员信息 / 电影介绍，则附加图片url） WorkFlow Graph Frame DataBase Frontend Backend Reference Frontend 微信小程序：微信聊天机器人\nBackEnd 基于知识图谱的电影知识问答系统\n电影知识库问答机器人\n","permalink":"https://swimmingliu.cn/posts/diary/2023-moviekgqa/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003e基于知识图谱和neo4j图数据库的电影知识问答系统\u003c/p\u003e\n\u003cdiv style=\"display:flex; justify-content: space-around; \"\u003e\r\n\u003cimg src=\"https://i.imgs.ovh/2023/12/12/mM4uR.png\" alt=\"image-20231212102658908\" style=\"box-shadow: 0 0 10px rgba(200, 200, 200);\" width=30% height:300px/\u003e\r\n\u003cimg src=\"https://i.imgs.ovh/2023/12/12/mM58p.png\" alt=\"image-20231212102738360\" style=\"box-shadow: 0 0 10px rgba(200, 200, 200);\" width=30% height:300px/\u003e\r\n\u003cimg src=\"https://i.imgs.ovh/2023/12/12/mMdFT.png\" alt=\"image-20231212103113278\" style=\"\" width=30% height:300px/\u003e\r\n\u003c/div\u003e\r\n\u003ch2 id=\"workflow\"\u003eWorkflow\u003c/h2\u003e\n\u003ch3 id=\"database\"\u003eDataBase\u003c/h3\u003e\n\u003cp\u003e爬取豆瓣TOP1000电影信息数据\u003c/p\u003e\n\u003ch3 id=\"frontend\"\u003eFrontend\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e获取用户输入的信息 （语音输入 / 文本输入）\u003c/li\u003e\n\u003cli\u003e向电影知识问答后端服务器发送请求\u003c/li\u003e\n\u003cli\u003e获取返回结果  (成功 -\u0026gt; 4 / 失败 -\u0026gt; 5)\u003c/li\u003e\n\u003cli\u003e如果返回结果包含image信息，则显示图片和文字，否则只显示文字\u003c/li\u003e\n\u003cli\u003e请求基于gpt的AI模型服务器，并显示返回结果\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"backend\"\u003eBackend\u003c/h3\u003e\n\u003cp\u003e​\t[准备工作]  训练 TF-IDF 向量算法和朴素贝叶斯分类器，用于预测用户文本所属的问题类别\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e接受前端请求，获取用户输入信息\u003c/li\u003e\n\u003cli\u003e使用分词库解析用户输入的文本词性，提取关键词\u003c/li\u003e\n\u003cli\u003e根据贝叶斯分类器，分类出用户文本的问题类型\u003c/li\u003e\n\u003cli\u003e结合关键词与问题类别，在 Neo4j 中查询问题的答案\u003c/li\u003e\n\u003cli\u003e返回查询结果 （若问题类型为 演员信息 / 电影介绍，则附加图片url）\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"workflow-graph\"\u003eWorkFlow Graph\u003c/h3\u003e\n\u003cp\u003e\u003cimg alt=\"workflow graph\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/0IEuW.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"frame\"\u003eFrame\u003c/h2\u003e\n\u003ch3 id=\"database-1\"\u003eDataBase\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://neo4j.com/\"\u003e\u003cimg alt=\"Neo4j\" loading=\"lazy\" src=\"https://img.shields.io/badge/neo4j-test?style=for-the-badge\u0026logo=neo4j\u0026logoColor=white\u0026color=blue\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"frontend-1\"\u003eFrontend\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://developers.weixin.qq.com/\"\u003e\u003cimg alt=\"wechat mini programs\" loading=\"lazy\" src=\"https://img.shields.io/badge/wechat%20mini%20programs-test?style=for-the-badge\u0026logo=wechat\u0026logoColor=white\u0026color=%2320B2AA\"\u003e\u003c/a\u003e\u003c/p\u003e","title":"MovieKGQA: 基于知识图谱和neo4j图数据库的电影知识问答系统"},{"content":"Abstract 在本文中，我们介绍了 U-Net v2，这是一种用于医学图像分割的新的稳健且高效的 U-Net 变体。它的目的是增强语义信息在低级特征中的注入，同时用更精细的细节来细化高级特征。对于输入图像，我们首先使用深度神经网络编码器提取多级特征。接下来，我们通过注入来自更高级别特征的语义信息并通过 Hadamard 乘积集成来自较低级别特征的更精细的细节来增强每个级别的特征图。我们新颖的跳跃连接赋予所有级别的功能以丰富的语义特征和复杂的细节。改进后的特征随后被传输到解码器以进行进一步处理和分割。我们的方法可以无缝集成到任何编码器-解码器网络中。我们在几个公共医学图像分割数据集上评估了我们的方法，用于皮肤病变分割和息肉分割，实验结果证明了我们的新方法相对于最先进的方法的分割准确性，同时保留了内存和计算效率。代码位于：https://github.com/yaoppeng/U-Net_v2。\n主要工作就在于中间的skip-connection\nIntroduction 随着现代深度神经网络的进步，语义图像分割取得了重大进展。语义图像分割的典型范例涉及具有跳跃连接的编码器-解码器网络[1]。在此框架中，编码器从输入图像中提取层次和抽象特征，而解码器获取编码器生成的特征图并重建像素级分割掩模或图，为输入图像中的每个像素分配类标签。人们进行了一系列研究[2, 3]，将全局信息纳入特征图中并增强多尺度特征，从而大大提高了分割性能。 在医学图像分析领域，精确的图像分割在计算机辅助诊断和分析中起着至关重要的作用。 U-Net [4] 最初是为了医学图像分割而引入的，利用跳跃连接来连接每个级别的编码器和解码器阶段。跳跃连接使解码器能够访问早期编码器阶段的特征，从而保留高级语义信息和细粒度空间细节。这种方法有助于精确描绘对象边界并提取医学图像中的小结构。此外，还应用了密集连接机制，通过连接所有级别和所有阶段的特征来减少编码器和解码器中特征之间的差异[5]。设计了一种机制来通过连接较高和较低级别的不同尺度的特征来增强特征[6]。 然而，基于 U-Net 的模型中的这些连接在集成低级和高级特征方面可能不够有效。例如，在 ResNet [7] 中，深度神经网络是作为多个浅层网络的集合而形成的，并且显式添加的残差连接表明，即使在百万规模的训练中，网络也很难学习恒等映射函数图像数据集。\n对于编码器提取的特征，低级特征通常保留更多细节，但缺乏足够的语义信息，并且可能包含不需要的噪声。相反，高级特征包含更多语义信息，但由于分辨率显着降低而缺乏精确的细节（例如对象边界）。通过串联简单地融合特征将在很大程度上依赖于网络的学习能力，这通常与训练数据集的大小成正比。这是一个具有挑战性的问题，特别是在医学成像领域，通常受到有限数据的限制。这种信息融合是通过密集连接跨多个级别连接低级和高级特征来实现的，可能会限制来自不同级别的信息的贡献并可能引入噪声。另一方面，尽管引入的额外卷积并没有显着增加参数数量，但 GPU 内存消耗将会增加，因为必须存储所有中间特征图和相应的梯度以进行前向传递和后向梯度计算。这会导致 GPU 内存使用量和浮点运算 (FLOP) 增加。\n(a) U-Net v2 模型的整体架构，由编码器、SDI（语义和细节注入）模块和解码器组成。 (b) SDI模块的架构。为简单起见，我们仅显示第三级特征的细化（l = 3）。 SmoothConv 表示用于特征平滑的 3 × 3 卷积。$\\bigotimes$ 表示哈达玛积。\n在[8]中，利用反向注意力来明确地建立多尺度特征之间的联系。在[9]中，ReLU激活应用于较高级别的特征，并将激活的特征与较低级别的特征相乘。此外，在[10]中，作者提出分别从 CNN 和 Transformer 模型中提取特征，在多个级别上组合来自 CNN 和 Transformer 分支的特征来增强特征图。然而，这些方法都很复杂，而且它们的性能仍然不是很令人满意，因此需要进一步改进。\n在本文中，我们提出了 U-Net v2，这是一种基于 U-Net 的新分割框架，具有简单且高效的跳跃连接。我们的模型首先使用 CNN 或 Transformer 编码器提取多级特征图。接下来，对于第 i 层的特征图，我们通过简单的哈达玛乘积操作显式地注入高层特征（包含更多语义信息）和低层特征（捕获更精细的细节），从而增强语义和细节第 i 级特征。随后，细化的特征被传输到解码器进行分辨率重建和分割。我们的方法可以无缝集成到任何编码器-解码器网络中。\n我们使用公开的数据集在两个医学图像分割任务（皮肤病变分割和息肉分割）上评估我们的新方法。实验结果表明，我们的 U-Net v2 在这些分割任务中始终优于最先进的方法，同时保持 FLOP 和 GPU 内存效率。\nMethod 2.1 Overall Architecture 我们的 U-Net v2 的整体架构如图 1（a）所示。它包括三个主要模块：编码器、SDI（语义和细节注入）模块和解码器。给定输入图像 I，其中 I ∈ $R^{H×W×C}$ ，编码器产生 M 个级别的特征。我们将第 i 级特征表示为$ f^0_i$ , 1 ≤ i ≤ M。这些收集到的特征，{$ f^0_1$ ,$ f^0_2$,… , $ f^0_M$}，然后传输到 SDI 模块进行进一步细化。\n2.2 Semantics and Detail Infusion (SDI) Module 利用编码器生成的分层特征图，我们首先将空间和通道注意机制[11]应用于每个级别 i 的特征 $ f^0_i$。此过程使特征能够集成局部空间信息和全局通道信息，如下所示：\n其中$f^1_i$表示第 i 层处理后的特征图，$φ^s_i$ 和 $\\phi^c_i$ 分别表示第 i 层空间注意力和通道注意力的参数。此外，我们应用 1 × 1 卷积将$f^1_i$的通道减少到 c，其中 c 是超参数。得到的特征图表示为$f^2_i$，其中 $f^2_i$ ∈ $R^{H_i × W_i × c}$ ，其中$H_i$、$W_i$ 和 c 分别表示 $f^2_i$ 的宽度、高度和通道。\n接下来，我们需要将精炼后的特征图发送到解码器。在每个解码器级别 i，我们使用 $f^2_i$ 作为目标参考。然后，我们调整每个第 j 层的特征图的大小，以匹配与 $f^2_i$ 相同的分辨率，公式为：\n其中 D 、 I 和 U 分别表示自适应平均池化、恒等映射和双线性插值 $f^2_i$ 到 $H_i$、$W_i$ 的分辨率，其中 1 ≤ i，j ≤ M。\n然后，应用 3 × 3 卷积来平滑每个调整大小的特征图 $f^3_{ij}$ ，公式为：\n其中$θ_{ij}$表示平滑卷积的参数， $f^4_{ij}$ 是第i层的第j个平滑特征图。\n将所有第 i 级特征图调整为相同的分辨率后，我们将元素级哈达玛积应用于所有调整大小的特征图，以通过更多语义信息和更精细的细节来增强第 i 级特征，如下所示：\n其中$H(·)$表示哈达玛积 (见图1(b))。然后，$f^5_i$ 被分派到第i级解码器以进行进一步的分辨率重建和分割。\nExperiments 3.1 Datasets 我们使用以下数据集评估新的 U-Net v2。 ISIC 数据集：使用两个皮肤病变分割数据集：ISIC 2017 [15, 16]，其中包含 2050 个皮肤镜图像，ISIC 2018 [15]，其中包含 2694 个皮肤镜图像。为了公平比较，我们遵循[13]中概述的训练/测试分割策略。 息肉分割数据集：使用五个数据集：Kvasir-SEG [17]、ClinicDB [18]、ColonDB [19]、Endoscene [20] 和 ETIS [21]。为了公平比较，我们使用[8]中的训练/测试分割策略。具体来说，使用来自 ClinicDB 的 900 张图像和来自 Kvasir-SEG 的 548 张图像作为训练集，其余图像作为测试集。\n3.2 Experimental Setup 我们使用 PyTorch 在 NVIDIA P100 GPU 上进行实验。我们的网络使用 Adam 优化器进行优化，初始学习率 = 0.001，β1 = 0.9，β2 = 0.999。\n我们采用幂为 0.9 的多项式学习率衰减。训练时期的最大数量设置为 300。超参数 c 设置为 32。按照[13]中的方法，我们报告 ISIC 数据集的 DSC（骰子相似系数）和 IoU（并集交集）分数。对于息肉数据集，我们报告 DSC、IoU 和 MAE（平均绝对误差）分数。每个实验运行 5 次，并报告平均结果。我们使用金字塔视觉变换器（PVT）[22]作为特征提取的编码器。\n3.3 Results and Analysis 表 1 列出了 ISIC 数据集上最先进方法的比较结果。如图所示，我们提出的 UNet v2 将 DSC 分数提高了 1.44% 和 2.48%，IoU 分数提高了 2.36% 和 3.90%。分别是 ISIC 2017 和 ISIC 2018 数据集。这些改进证明了我们提出的将语义信息和更精细的细节注入每个特征图的方法的有效性。\n表 2 列出了息肉分割数据集上最先进方法的比较结果。如图所示，我们提出的 U-Net v2 在 Kavasir-SEG、ClinicDB、ColonDB 和 ETIS 上优于 Poly-PVT [14]数据集，DSC 得分分别提高了 1.1%、0.7%、0.4% 和 0.3%。这强调了我们提出的方法在将语义信息和更精细的细节注入每个级别的特征图中的一致有效性。\n3.4 Ablation Study 我们使用 ISIC 2017 和 ColonDB 数据集进行消融研究，以检查 U-Net v2 的有效性，如表 3 所示。具体来说，我们使用 PVT [22] 模型作为 UNet++ [5] 的编码器。请注意，当我们的 SDI 模块被移除时，U-Net v2 将恢复为具有 PVT 主干的普通 U-Net。 **SC 表示 SDI 模块内的空间和通道关注点。**从表 3 可以看出，与不带 SDI 的 U-Net v2（即带 PVT 编码器的 U-Net）相比，UNet++ 的性能略有下降。\n这种下降可能归因于密集连接生成的多级特征的简单串联，这可能会混淆模型并引入噪声。表 3 表明 SDI 模块对整体性能贡献最大，突出显示我们提出的跳跃连接（即 SDI）持续带来性能改进。\n3.5 Qualitative Results 图 2 给出了 ISIC 2017 数据集的一些定性示例，这表明我们的 U-Net v2 能够将语义信息和更精细的细节合并到每个级别的特征图中。因此，我们的分割模型可以捕获对象边界的更精细的细节。\n3.6 Computation, GPU Memory, and Inference Time 为了检查 U-Net v2 的计算复杂性、GPU 内存使用情况和推理时间，我们报告了我们的方法 U-Net [4] 的参数、GPU 内存使用情况、FLOP 和 FPS（每秒帧数），以及表 4 中的 UNet++ [5]。实验使用 float32 作为数据类型，这导致每个变量使用 4B 的内存。 GPU内存使用记录了前向/后向传递过程中存储的参数和中间变量的大小。\n(1, 3, 256, 256) 表示输入图像的大小。所有测试均在 NVIDIA P100 GPU 上进行。\n从表4中可以看出，UNet++引入了更多的参数，并且由于在密集前向过程中存储中间变量（例如特征图），其GPU内存使用量更大。通常，此类中间变量比参数消耗更多的 GPU 内存。\n此外，U-Net v2 的 FLOPs 和 FPS 也优于 UNet++。与 U-Net (PVT) 相比，我们的 U-Net v2 的 FPS 降低是有限的。\nConclusion 引入了新的 U-Net 变体 U-Net v2，它采用新颖且简单的跳跃连接设计，以改进医学图像分割。该设计明确地将来自较高级别特征的语义信息和来自较低级别特征的更精细细节集成到编码器使用 Hadamard 乘积生成的每个级别的特征映射中。在皮肤病变和息肉分割数据集上进行的实验验证了我们的 UNet v2 的有效性。复杂性分析表明 U-Net v2 在 FLOP 和 GPU 内存使用方面也很高效\n这篇文章比较简单，整体的行文风格一看就是会议论文。核心创新点就一个SDI（Semantic and Detail Infusion）模块。SDI模块作用就是 连接高级特征的语义信息和低级特征的细节信息。首先通过通道和特征注意力机制，分别关注不同级别的通道和空间信息。然后将所有的通道都 padding / scaling 到和第i级别相同的通道数，然后通过双线性插值 / 自适应平均池化到相同大小的尺寸。最后，使用哈达码乘积进行特征融合。 对，没错就这么简单！！！\n（思考: 能不能用减法单元来融合差异性？？？）\n","permalink":"https://swimmingliu.cn/posts/papernotes/2023-unet_v2/","summary":"\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e在本文中，我们介绍了 U-Net v2，这是一种用于医学图像分割的新的稳健且高效的 U-Net 变体。它的目的是\u003cstrong\u003e增强语义信息在低级特征中的注入\u003c/strong\u003e，同时\u003cstrong\u003e用更精细的细节来细化高级特征\u003c/strong\u003e。对于输入图像，我们首先使用\u003cstrong\u003e深度神经网络编码器提取多级特征\u003c/strong\u003e。接下来，我们通过\u003cstrong\u003e注入来自更高级别特征的语义信息\u003c/strong\u003e并通过 \u003cstrong\u003eHadamard 乘积\u003c/strong\u003e集成来自\u003cstrong\u003e较低级别特征的更精细的细节\u003c/strong\u003e来\u003cstrong\u003e增强每个级别的特征图\u003c/strong\u003e。我们新颖的\u003cstrong\u003e跳跃连接\u003c/strong\u003e赋予\u003cstrong\u003e所有级别的功能\u003c/strong\u003e以\u003cstrong\u003e丰富的语义特征和复杂的细节\u003c/strong\u003e。\u003cstrong\u003e改进后的特征随后被传输到解码器\u003c/strong\u003e以进行\u003cstrong\u003e进一步处理和分割\u003c/strong\u003e。我们的方法可以\u003cstrong\u003e无缝集成到任何编码器-解码器网络中\u003c/strong\u003e。我们在几个公共医学图像分割数据集上评估了我们的方法，用于皮肤病变分割和息肉分割，实验结果证明了我们的新方法相对于最先进的方法的分割准确性，同时\u003cstrong\u003e保留了内存和计算效率\u003c/strong\u003e。代码位于：https://github.com/yaoppeng/U-Net_v2。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e主要工作就在于中间的skip-connection\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e随着现代深度神经网络的进步，语义图像分割取得了重大进展。语义图像分割的典型范例涉及具有\u003cstrong\u003e跳跃连接的编码器-解码器网络[\u003cstrong\u003e1]。在此框架中，编码器从\u003c/strong\u003e输入图像中提取层次和抽象特征\u003c/strong\u003e，而解码器获取\u003cstrong\u003e编码器生成的特征图并重建像素级分割掩模或图\u003c/strong\u003e，\u003cstrong\u003e为输入图像中的每个像素分配类标签\u003c/strong\u003e。人们进行了一系列研究[2, 3]，\u003cstrong\u003e将全局信息纳入特征图\u003c/strong\u003e中并增强多尺度特征，从而大大提高了分割性能。\n在医学图像分析领域，\u003cstrong\u003e精确的图像分割\u003c/strong\u003e在计算机辅助诊断和分析中起着至关重要的作用。 U-Net [4] 最初是为了\u003cstrong\u003e医学图像分割\u003c/strong\u003e而引入的，利用\u003cstrong\u003e跳跃连接\u003c/strong\u003e来连接每个级别的\u003cstrong\u003e编码器和解码器阶段\u003c/strong\u003e。\u003cstrong\u003e跳跃连接\u003c/strong\u003e使解码器能够访问\u003cstrong\u003e早期编码器阶段\u003c/strong\u003e的特征，从而保留\u003cstrong\u003e高级语义信息\u003c/strong\u003e和\u003cstrong\u003e细粒度空间细节\u003c/strong\u003e。这种方法有助于\u003cstrong\u003e精确描绘对象边界\u003c/strong\u003e并提取\u003cstrong\u003e医学图像中的小结构\u003c/strong\u003e。此外，还应用了\u003cstrong\u003e密集连接机制\u003c/strong\u003e，通过\u003cstrong\u003e连接所有级别\u003c/strong\u003e和\u003cstrong\u003e所有阶段的特征\u003c/strong\u003e来减少\u003cstrong\u003e编码器和解码器中特征之间的差异\u003c/strong\u003e[5]。设计了一种机制来\u003cstrong\u003e通过连接较高和较低级别\u003c/strong\u003e的\u003cstrong\u003e不同尺度的特征\u003c/strong\u003e来\u003cstrong\u003e增强特征\u003c/strong\u003e[6]。\n然而，基于 U-Net 的模型中的这些连接在\u003cstrong\u003e集成低级和高级特征方面\u003c/strong\u003e可能\u003cstrong\u003e不够有效\u003c/strong\u003e。例如，在 ResNet [7] 中，深度神经网络是作为\u003cstrong\u003e多个浅层网络的集合\u003c/strong\u003e而形成的，并且\u003cstrong\u003e显式添加的残差连接\u003c/strong\u003e表明，即使在百万规模的训练中，网络也很难学习\u003cstrong\u003e恒等映射函数图像\u003c/strong\u003e数据集。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e对于编码器提取的特征，低级特征通常保留更多细节，但缺乏足够的语义信息，并且可能包含不需要的噪声\u003c/strong\u003e。相反，\u003cstrong\u003e高级特征包含更多语义信息，但由于分辨率显着降低而缺乏精确的细节（例如对象边界）\u003c/strong\u003e。通过\u003cstrong\u003e串联简单地融合特征\u003c/strong\u003e将在\u003cstrong\u003e很大程度上依赖于网络的学习能力\u003c/strong\u003e，这\u003cstrong\u003e通常与训练数据集的大小成正比\u003c/strong\u003e。这是一个具有挑战性的问题，特别是在医学成像领域，\u003cstrong\u003e通常受到有限数据的限制\u003c/strong\u003e。这种信息融合是\u003cstrong\u003e通过密集连接跨多个级别连接低级和高级特征\u003c/strong\u003e来实现的，可能会限制来自\u003cstrong\u003e不同级别的信息的贡献\u003c/strong\u003e并可能引入噪声。另一方面，尽管\u003cstrong\u003e引入的额外卷积并没有显着增加参数数量\u003c/strong\u003e，但 \u003cstrong\u003eGPU 内存消耗将会增加\u003c/strong\u003e，因为必须\u003cstrong\u003e存储所有中间特征图和相应的梯度\u003c/strong\u003e以进行前向传递和后向梯度计算。这会导致 \u003cstrong\u003eGPU 内存使用量\u003c/strong\u003e和\u003cstrong\u003e浮点运算 (FLOP) 增加\u003c/strong\u003e。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cimg alt=\"image-20231211193109745\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/mCdvu.png\"\u003e\u003c/p\u003e\n\u003cp\u003e(a) U-Net v2 模型的整体架构，由\u003cstrong\u003e编码器、SDI（语义和细节注入）模块和解码器\u003c/strong\u003e组成。 (b) SDI模块的架构。为简单起见，我们仅显示第三级特征的细化（l = 3）。 \u003cstrong\u003eSmoothConv 表示用于特征平滑的 3 × 3 卷积\u003c/strong\u003e。$\\bigotimes$ 表示哈达玛积。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e在[8]中，利用\u003cstrong\u003e反向注意力\u003c/strong\u003e来明确地建立\u003cstrong\u003e多尺度特征之间\u003c/strong\u003e的联系。在[9]中，ReLU激活应用于\u003cstrong\u003e较高级别\u003c/strong\u003e的特征，并\u003cstrong\u003e将激活的特征与较低级别的特征相乘\u003c/strong\u003e。此外，在[10]中，作者提出分别从 \u003cstrong\u003eCNN 和 Transformer 模型\u003c/strong\u003e中提取特征，在多个级别上组合\u003cstrong\u003e来自 CNN 和 Transformer 分支\u003c/strong\u003e的特征来\u003cstrong\u003e增强特征图\u003c/strong\u003e。然而，这些方法\u003cstrong\u003e都很复杂\u003c/strong\u003e，而且它们的\u003cstrong\u003e性能仍然不是很令人满意\u003c/strong\u003e，因此需要进一步改进。\u003c/p\u003e\n\u003cp\u003e在本文中，我们提出了 U-Net v2，这是一种基于 U-Net 的新分割框架，具有\u003cstrong\u003e简单且高效的跳跃连接\u003c/strong\u003e。我们的模型首先\u003cstrong\u003e使用 CNN 或 Transformer 编码器\u003c/strong\u003e提取\u003cstrong\u003e多级特征图\u003c/strong\u003e。接下来，\u003cstrong\u003e对于第 i 层的特征图\u003c/strong\u003e，我们通过\u003cstrong\u003e简单的哈达玛乘积操作\u003c/strong\u003e显式地注入\u003cstrong\u003e高层特征（包含更多语义信息）\u003cstrong\u003e和\u003c/strong\u003e低层特征（捕获更精细的细节）\u003c/strong\u003e，从而\u003cstrong\u003e增强语义和细节第 i 级特征\u003c/strong\u003e。随后，\u003cstrong\u003e细化的特征\u003c/strong\u003e被传输到解码器进行\u003cstrong\u003e分辨率重建和分割\u003c/strong\u003e。我们的方法可以无缝集成到任何编码器-解码器网络中。\u003c/p\u003e\n\u003cp\u003e我们使用公开的数据集在两个医学图像分割任务（皮肤病变分割和息肉分割）上评估我们的新方法。实验结果表明，我们的 U-Net v2 在这些分割任务中始终优于最先进的方法，\u003cstrong\u003e同时保持 FLOP 和 GPU 内存效率\u003c/strong\u003e。\u003c/p\u003e","title":"U-NET V2: RETHINKING THE SKIP CONNECTIONS OF U-NET FOR MEDICAL IMAGE SEGMENTATION"},{"content":"Abstract 放射科医生拥有不同的培训和临床经验，导致肺结节的分割注释存在差异，从而导致分割的不确定性。传统方法通常选择单个注释作为学习目标或尝试学习包含多个注释的潜在空间。\n然而，这些方法无法利用多个注释之间的共识和分歧所固有的有价值的信息。在本文中，我们提出了一种不确定性感知注意机制（UAAM），它利用多个注释之间的共识和分歧来促进更好的分割。为此，我们引入了多置信度掩模（MCM），它结合了低置信度（LC）掩模和高置信度（HC）掩模。 LC 掩模表示分割置信度较低的区域，放射科医生可能有不同的分割选择。继UAAM之后，我们进一步设计了一个不确定性引导多置信分割网络（UGMCS-Net），它包含三个模块：一个捕获肺结节一般特征的特征提取模块，一个为肺结节产生三个特征的不确定性感知模块。注释的并集、交集和注释集，以及一个交集并集约束模块，该模块使用三个特征之间的距离来平衡最终分割和 MCM 的预测。为了全面展示我们方法的性能，我们提出了 LIDC-IDRI 上的复杂结节验证，它测试了 UGMCS-Net 对使用常规方法难以分割的肺结节的分割性能。实验结果表明，我们的方法可以显着提高传统方法难以分割的结节的分割性能。\nINTRODUCTION 肺结节分割在肺癌计算机辅助诊断 (CAD) 系统中至关重要 [1]，可提供结节大小、形状和其他重要医学特征等关键信息。然而，对于深度学习方法的一般训练和测试范例，每个结节图像数据只有一个由一名放射科医生描绘的注释掩模[2]-[6]。因此，网络每次只能提供结节区域的单个预测。\n然而，在临床实践中，不同的放射科医生由于其不同的培训和临床经验可能会为肺结节提供不同的分割注释[7]-[9]。\n因此，基于单一注释的传统方法无法反映临床经验的多样性，限制了深度学习方法的应用。\n解决放射科医生之间注释不同问题的一个直接解决方案是为每个肺结节图像合并多个注释。这导致了另一个问题：多个注释不可避免地会带来不确定性和冲突，因为放射科医生可能会对同一区域进行不同的注释。为了克服这个问题，Kohl 等人在 2018 年提出了一种概率 U-Net，它利用条件变分自动编码器将多个分割变体编码到低维潜在空间中 [8]、[10]。通过从该空间采样，网络可以影响相应的分割图。基于这项研究，Hu等人提出将真实不确定性与概率UNet相结合，这可以提高预测不确定性估计、样本准确性和样本多样性[7]。这些方法依赖于潜在空间和该空间中的随机样本。因此，这些方法只能通过多次预测来提供不确定区域。\n在本文中，我们提出了一个论点，即多个注释之间的不确定性遵循特定的模式。\n为了演示这种现象，我们引入了多重置信掩码 (MCM)，它结合了高置信度 (HC) 掩码和低置信度 (LC) 掩码，如图 1 所示。 A. 交叉掩码等于 HC mask，代表所有注释的交集。\n联合掩码是所有注释的联合。 LC掩模是交集掩模和并集掩模之间的差异。当在 LIDC-IDRI 数据集 [11] 上计算 HC 和 LC 的 Hounsfield 单位 (HU) 核估计时，如图 1.B 所示，我们可以观察到 LC 和 HC 掩模之间的 HU 分布存在明显区别。具体地，LC区域具有比HC区域更低的HU值。从像素分布来看，HU值越低，对应区域的密度越低。就CT图像特征而言，LC区域主要由结节边缘、毛刺和磨玻璃特征等边界相关特征组成，而HC区域主要分布在结节核心内。因此，我们提出了这样的假设：导致放射科医生之间差异的区域主要与低密度组织和边界相关特征有关。\n与其他方法不同，我们建议利用 MCM (多重置信掩码) ** 和注释集作为具有不同分割确定性的特征的学习指导**，有助于更好的分割性能。我们将这种训练称为UncertaintyAware Attention Mechanism，如图2所示。按照这种机制，我们进一步设计了用于肺结节分割的Uncertainty-Guide Multi-Confidence Segmentation Network（UGMCS-Net）。\nUGMCS-Net 包含三个模块：基于 U-Net 的特征提取模块、不确定性感知模块和交集并集约束模块。\n首先，标签分为交集标签( $L_\\cap$ )、并集标签 ( $L_\\cup$ )、原始标签 (L)。\n其次，HC (consensus) 表示 $L_\\cap$ 、 LC（disagreement）表示 $L_\\cup$ - $L_\\cap$。\nMCM (Multi Confidence Mask) 表示 HC 和 LC的统称\n首先，特征提取模块从输入的CT图像中提取通用特征图R。其次，不确定性感知模块在标签的交集、并集、和原标签的指导下，将通用特征图R转换为三个独立的特征图$R_{LC}$、$R_{HC}$和$R_{Uni}$。 $R_{LC}$、$R_{HC}$用于预测并集掩码和交集掩码，并将结果组合为MCM。$R_{Uni}$用于预测初步分割结果。我们稍后使用 $\\cup(X)$, $\\cap(X)$, $X_{Uni}$ 来表示预测的并集掩码、交集掩码和初步分割结果。第三，约束模块使用来自$R_{LC}$、$R_{HC}$ 和 $R_{Uni}$的特征感知注意块捕获首选特征，然后用特征距离约束最终预测$X_S$，确保分割结果以合理的方式受到约束。为了更好地利用多个注释，我们还引入了多注释融合损失来优化 $X_{Uni}$和 $X_S$，它计算预测和所有注释之间的平均 BCE 损失。\n该方法具有两个明显的优点： （1）与学习潜在空间的传统基于 VAE 的方法相比，该方法具有特定的学习目标，使其能够提供不确定结节区域的稳定预测。 （2）该方法利用所有注释来优化预测，以确保最终预测平衡不同条件，充分利用可用信息。\n我们在之前的出版物中报告了这项工作的初步版本[12]。本文的新贡献可概括如下: （1）一种称为不确定性感知注意机制（UAAM）的新颖机制：UAAM 最大限度地利用多个注释，并采用多重置信掩码（MCM）来指导低置信度和高置信度特征的学习。\n（2）升级后的Uncertainty-Guide Multi-Confidence Segmentation Network (UGMCS-Net)：基于该机制，我们将UGS-Net更新为UGMCSNet，其中包含特征提取模块、不确定性感知模块和新的交并集约束模块。为了充分利用多个注释，我们还引入了多注释融合损失。所提出的模块是即插即用的，可以应用于不同情况下的其他分割网络。\n（3）全面验证：我们提出了ComplexNodule Validation，测试UGMCS-Net对U-Net难以分割的肺结节的分割性能。实验表明，对于UNet上DSC分数低于60％的结节，我们网络的DSC分数可以提高11.03％，我们网络的IoU分数可以提高11.88％。我们还为不同的模块、主干和模型设置提供足够的消融研究。\nRelated Work 2.1 Lung Nodule Segmentation 肺结节分割对于肺结节计算机辅助检测 (CAD) 系统至关重要。其主要目标是准确地描绘目标结节的边界，以提供其直径、大小和语义特征等细节[13]-[16]。这项任务的主要挑战是肺结节具有各种形状、大小和微妙的特征。早年，研究人员提供了多种肺结节分割方法，例如基于形态学的方法和基于区域生长的方法[17]，[18]。近年来，深度学习已成为该领域最流行的方法。\n2017年，Wang等人提出了一种用于肺结节分割的多视图卷积网络。所提出的网络同时从 CT 图像的轴向、冠状和矢状视图中捕获了一组不同的结节敏感特征。使用多分支 CNN 网络对这些特征进行分析，平均 DSC 相似系数 (DSC) 为 77.67% [19]。此外，Wang 等人在 2017 年提出了一种具有中心池层的中心聚焦卷积神经网络，可以彻底分析 2D 和 3D 结节 [1]。 2020年，Cao等人设计了带有强度池层的双分支残差网络，增强了强度信息的学习，并将DSC提高到82.74％[20]。 2021年，Pezzano等人推出了一种CNN网络，可以通过生成两个代表CT中所有背景和次要重要元素的掩模来学习结节的背景，从而使网络可以更好地区分结节特征[15]。后来在2022年，Shariaty等人进一步提出了纹理特征提取和特征选择算法来改进分割，实现了84.75%的DSC[2]。\n根据上述研究的观察结果，显然现有方法主要优先考虑实现更精确的分割，而忽略了不同放射科医生对如何分割同一肺结节可能持有不同意见的事实。在这项研究中，我们认为注释之间的分歧也具有诊断价值。因此，我们的方法旨在生成一个分割，通过从注释集学习并识别具有不同分割确定性的区域来有效地平衡所有注释。\n2.2 Uncertainty in Lung Nodule Segmentation 许多医学图像视觉问题都存在模糊性。在临床情况下，仅通过 CT 扫描可能无法明确哪个特定区域是癌组织 [10]、[21]。因此，即使是经验丰富的医生和放射科医生也可能对相同的组织或肿瘤提供不同的分割。\n2018 年，Kohl 等人提出将此任务建模为学习肺结节多样化但合理的分割上的分布。基于 U-Net [5]，他们引入了概率 U-Net，它是 UNet 和条件 VAE 的组合，可以产生无限数量的合理分割。 2019年晚些时候，Kohl等人进一步提出了一种分层概率U-Net，它使用分层潜在空间分解来制定高保真度分割的采样和重建[8]。同样在 2019 年，Hu 等人分析了两种类型的不确定性：任意的和认知的 [7]。他们利用多个注释的可变性作为“ground truth”任意不确定性的来源，将这种不确定性与概率 UNet 结合起来，并尝试定量分析分割不确定性。 2021年，Long等人将[7]中的概念扩展到V-Net和3D肺结节CT图像。作为包含 1000 多个肺结节的多个注释的理想数据集，所有这些研究 [7]-[10] 都分析了 LIDC-IDRI。\n与基于VAE的网络不同，我们的工作更关注导致各种标注的原因，表现为分割分歧。我们引入了一种专门针对不确定性区域的替代方法，使我们能够对不确定的结节区域和整体肺结节分割做出稳定的预测。这种方法使我们能够深入了解分割差异的根本原因，并在不确定的肺结节区域中产生更可靠的结果。\n在医学图像处理中，\u0026ldquo;条件变分自编码器（Conditional Variational Autoencoder, CVAE）\u0026ldquo;是一种生成模型，它结合了变分自编码器（VAE）的特性和条件生成的能力。VAE是一种深度学习模型，能够学习输入数据的潜在表示，然后从这些表示中生成新的数据实例。CVAE在此基础上增加了条件变量，使得生成的过程可以依赖于某些条件或标签。\n对于医学图像，CVAE可以用于多种任务，如生成特定类型的医学图像（例如，根据特定疾病状态生成CT或MRI图像），数据增强（生成新的训练样本），以及特征提取和表示学习等。通过将条件信息（如疾病标签、图像类型或患者信息）融入到生成过程中，CVAE能够生成更符合特定条件的图像，从而在特定医学应用中发挥作用。\nMethod 3.1 Uncertainty-Guided Multi-Confidence Segmentation Network 在图 3 中，我们展示了 UncertaintyGuided Multi-Confidence Segmentation Network (UGMCSNet) 的架构。该网络以肺结节 CT 图像作为输入，并产生两个输出：预测的多置信度掩模（MCM）和最终的分割 $X_S$。 MCM 结合了预测的并集 $\\cup(X)$ 和交集 $\\cap(X)$。网络的学习目标是注释集 GT，以及它们的 Union Mask $\\cup(GT)$ 和 Intersection Mask $\\cap(GT)$。输入图像及其相应的掩模的尺寸为 50 × 50 像素，通过从带有官方注释的 LIDC-IDRI 数据集裁剪获得。在输入网络之前，输入图像和掩模的大小被调整为 3 × 64 × 64 像素的尺寸。\nUGMCS-Net 包含三个模块：(1) 特征提取模块，(2) 不确定性感知模块，(3) 交并并约束模块。特征提取模块可以使用任何基于UNet结构的分割网络，初步获得形状为32×64×64的特征图R。本文使用具有五个下采样和上采样层的Attention U-Net [4] 。每个上采样层由两个卷积层和一个注意力块组成。不确定性感知模块分析 R 并生成$R_{LC}$、$R_{HC}$和$R_{Uni}$。然后将这些特征图输入 MCM BCE Loss Block 和 Multiple Annotation Loss Block，生成初始的 $\\cup(X)$、$\\cap(X)$ 和合理的分割 $X_{Uni}$。计算并集以 $\\cup(X)$、$\\cap(X)$获得 MCM。 Intersection-Union Constraining Module 学习 $R_{LC}$、$R_{HC}$和$R_{Uni}$的不同特征，并将这三个特征融合到$R_{final}$ 中。然后该模块通过分析RF ianl提供更合理的最终分割$X_S$。\n3.2 Uncertainty-Aware Module 引入不确定性感知模块（UAM），通过学习$\\cup(GT)$、$\\cap(GT)$ 和 GT来充分合理地利用所有注释信息。该模块有两个任务：（1）从低置信度（LC）区域、高置信度（HC）区域和所有注释中捕获不同的特征； (2) 生成多重置信掩模 (MCM) 的初始预测和一般分割。\n如图3所示，UAM采用三分支CNN网络作为骨干。它以 R (32 × 64 × 64) 作为输入，并使用内核大小为 1×1 的三个不同卷积层提取 $R_{LC}$、$R_{HC}$和$R_{Uni}$。 $R_{LC}$、$R_{HC}$和$R_{Uni}$的大小相同，均为 32 × 64 × 64。 MCM BCE Loss Block 接收 $R_{LC}$、$R_{HC}$ ，用三个不同的卷积层生成 $\\cup(X)$ 和 $\\cap(X)$ ，内核大小为 3× 3. BCE损失计算$\\cup(X)$ 和 $\\cup(GT)$的损失以及$\\cap(X)$ 和 $\\cap(GT)$。 $\\cup(X)$和$\\cap(X)$通过归一化操作Normal($\\cup(X)$+$\\cap(X)$)组合为MCM\u0026rsquo;，反映了不同区域的不确定性程度。与我们之前的工作 [12] 不同，$R_{Uni}$ 的分支是通过多重注释损失块进行优化的，这将在稍后讨论。此外，具有相同形状的 1 × 64 × 64 的特征图 $R_{LC}$、$R_{HC}$和$R_{Uni}$ 将被输入到下一个模块中进行进一步分析。\n主要还是用来生成一个MCM\n3.3 Intersection-Union Constraining Module 如上所述，$\\cup(GT)$和$\\cap(GT)$ 是UAM的学习目标。具体地，$\\cup(GT)$表示所有可能是结节组织的区域，表示置$\\cap(GT)$信度最高的结节区域。为了在极端情况之间实现平衡，我们进一步开发了一个新模块，称为交集并集约束模块（IUCM）。\n该模块旨在捕获所有三个学习目标的特征，并产生更合理的分割预测，可以在极端情况之间取得平衡。\n如图 4 所示，IUCM 将 $R_{LC}$、$R_{HC}$和$R_{Uni}$作为输入，并将对应的 $R_{LC}^{\\prime}$、$R_{HC}^{\\prime}$和$R_{Uni}^{\\prime}$与特征感知注意块 (FAAB) 对应。 $R_{LC}^{\\prime}$、$R_{HC}^{\\prime}$和$R_{Uni}^{\\prime}$的尺寸相同，均为 32 × 32 × 32。FAAB 是基于自注意力块 [22] 和特征感知滤波器构建的。\n这些注意力块使用不同的特征感知滤波器处理$R_{LC}$、$R_{HC}$和$R_{Uni}$，使网络能够针对不同的学习目标制定不同的学习偏好，并获得更多有助于分割的图像特征[23]、[24]。更具体地说，假设输入$R_z$，FAAB的过程可以总结为：\n其中 z ∈ {Uni, LC, HC},A表示自注意力架构。 Г是一个特征感知滤波器，在本研究中，$R_{Uni}$和$R_{LC}$的Г是Gabor[25]，$R_{HC}$的Г是Otsu[26]。 Γ(A($R_z$)) 与$R_z$逐像素相加，以便网络可以从输入中保留更多信息。\n通过对数据集和Hounsfield Unit Kernel Estimations的观察，我们可以看到，$R_{HC}$主要是密度较高的实性结节，而$R_{LC}$则包括更多的低密度组织（如毛刺），主要分布在结节的边缘。 Otsu对密度特征敏感，可以帮助网络更准确地识别高密度组织。因此，我们应用 Otsu 从 $R_{HC}$ 中提取 $R_{HC}^{\\prime}$。同时，Gabor对图像边缘敏感，能够提供良好的方向选择和尺度选择特征，从而能够捕获图像局部区域多个方向的局部结构特征。因此，我们选择Gabor从$R_{LC}$和$R_{Uni}$中提取$R_{LC}^{\\prime}$和$R_{Uni}^{\\prime}$。关于过滤器选择的消融研究将在第四节中提供。\n得到 $R_{LC}^{\\prime}$、$R_{HC}^{\\prime}$和$R_{Uni}^{\\prime}$后，IUCM 得到 $S_z$ = d{$R_Z$,$R$},d是计算余弦相似度的运算。\nIUCM 的输出为 $R_{Aug}$ = Concat($S_{Uni}$× $R_{Uni}^{\\prime}$ ; $S_{LC}$× $R_{LC}^{\\prime}$; $S_{HC}$× $R_{HC}^{\\prime}$ )。$R_{Aug}$将与来自特征提取模块的 R 连接，输入到卷积层，并生成最终的分割预测 $X_S$。 R 和 $R_{Aug}$ 的串联保留了来自 CT 输入的更多信息。\n3.4 Loss Function 在图 3 中，UGMCS-Net 包含两个优化：MCM BCE 损失块和多注释损失块。\nMCM BCE Loss Block 计算$\\cup(X)$ 和 $\\cup(GT)$之间; $\\cap(X)$ 和$\\cap{(GT)}$之间的 BCE 损失可表示为：\n我们使用多注释融合损失来优化多注释损失块中的$X_{Uni}$和$X_S$，表示为Φ。在我们之前的工作中，只选择了一组注释来优化$X_{Uni}$和$X_S$，这导致其他注释中有价值的信息丢失。\n本研究引入了多重注释融合损失，它将预测与所有可能的注释进行比较。\n首先，$R_{Uni}$和$R_F$最终产生$X_{Uni}$和$X_S$。其次，如图 5 所示，多注释融合损失函数计算优化对象（$X_{Uni}$和$X_S$）与注释集之间的 BCE 损失，并合并这些损失的平均值。根据我们的设计，$X_{Uni}$应该倾向于整个注释集，XS应该从注释集中学习足够的信息并产生平衡所有注释的分割，因此我们选择使用多注释融合损失来优化$X_{Uni}$和$X_S$。我们有：\n网络的损失融合可以定义为：\n其中 α1、α2 和 α3 是预定义参数。根据经验，本文中α1设置为0.5，α2设置为0.5，α3设置为1。重量选择的消融研究将在第四节中显示。\nEXPERIMENT 4.1 Dataset and Experimental Settings 在本研究中，我们使用 LIDC-IDRI 数据集 [11] 评估所提出的网络，该数据集由 1018 个研究实例和超过 2600 个结节组成。在本研究中，我们选择了 1860 个直径为 3-30mm 且具有多个注释的肺结节。每个结节数据至少有两个注释，以便我们可以获得其CT图像、多个注释集GT、它们的并集$\\cup(GT)$和交集$\\cap(GT)$。输入图像及其掩模均为 50 × 50 像素，根据官方注释从 LIDC-IDRI 数据集中裁剪。每个像素反映 CT 图像的亨斯菲尔德单位。\n在训练之前，我们将 CT 图像的强度值裁剪到范围 [1000,1000] 并将所有强度值归一化到范围 [0, 1]。数据处理的代码在网站 https://github.com/qiuliwang/LIDCIDRI-Toolbox-python 上提供。\n我们在运行 Ubuntu 18.04、Tesla V100 GPU 的服务器上进行实验，使用 CUDA 11.2，GPU 内存约为 16G。该网络使用PyTorch-v1.0.1和Python3.7实现。我们使用五重验证来评估网络的有效性，确保数据分割的稳健性。我们使用热重启随机梯度下降（SGDR）作为优化器，初始学习率（LR）为0.00001，批量大小为32，动量为0.9，权重衰减率为0.0001。每个网络都训练 200 个 epoch，学习率每 50 个 epoch 更新一次。 UGMCS-Net的源代码、原始USGNet以及所有实验设置将上传到https://github.com/yanghan-yh/UGS-Net。\n4.2 Performance of Lung Nodule Segmentation 每个结节的相关注释Label1，它是注释集中的第一个。 Probabilistic U-Net是一种基于VAE的模糊分割方法，因此我们取其四个样本的平均值作为最终的分割结果。本研究使用三个指标来评估网络对病变区域的预测能力：平均 Dice 相似系数（DSC）、交集交集（IoU）和归一化表面 Dice（NSD）[35]。在表 I 中，所有方法均使用 Label1 进行评估。\n这实验数据太丰富了把！！！\n表I显示UGMCS-Net在DSC、IoU和NSD方面取得了最高分数，分别为87.65%（±0.56%）、78.78%（±0.83%）和95.62%（±0.59%）。与 U-Net 相比，UGMCS-Net 在三个指标上分别提高了 1.39%、1.99% 和 1.16%。同样，与 Attention U-Net 相比，UGMCS-Net 在各个指标上实现了 0.98%、1.45% 和 0.68% 的增强。这些结果凸显了 UGMCS-Net 卓越的分割性能，特别是 NSD 分数的大幅提高，表明其强大的边界特征分割能力。此外，与 UGSNet 相比，UGMCS-Net 在所有指标上都表现出了相当大的进步，DSC 分数提高了 0.49%，IoU 分数提高了 0.74%，NSD 分数提高了 0.34%。此外，从 UGMCS-Net 的五重交叉验证中获得的三个指标的方差始终小于 UGS-Net 的方差，表明通过集成多重注释融合损失和约束操作增强了网络稳定性。 nnU-Net 是用于分割任务的流行网络。然而，它在 DSC 中仅达到 84.60%，在 IoU 中仅达到 74.45%。这是因为nnU-Net的训练需要很大的数据集。然而，我们在此任务中只有 1860 个结节图像。\n图6显示了上述方法的部分分割结果。输入列中的红色框表示感兴趣的区域或结节容易出错的分割位置。结节(a)-(c)包含许多低密度区域，结节(d)-(f)在其边界处具有不规则形状，例如毛刺迹象，并且结节(g)-(h)具有空腔。 UGMCS-Net 对这些区域的分割明显比其他方法更符合病灶的实际形状。\n对比实验结果的套话 （可以学习一下）\n（U-Net、Attention U-Net、R2U-Net、Channel U-Net、Nested U-Net、UGS-Net 和 UGMCS-Net 的分割结果。输入列对应的红色框表示分割时应注意的特征或结节容易出错的位置。 UGMCS-Net 列中的红色框表示 UGMCS-Net 在这些位置的分割细节。绿色框表示次优分割结果的不足之处。最后一栏是相应结节的直径，单位为毫米）\n这个定性结果的对比方法，值得学习。\n图 6 和表 I 表明：（1）从注释集及其并集和交集中学习，为分割任务提供了更丰富的视觉信息。\n(2)从LC区域学习提高了网络识别低密度区域的能力。\n值得注意的是，图6（g）-（h）中，标注中没有空洞，但UGMCS-Net得到的分割结果反映了空洞特征。我们选择保留这些特征有两个原因：（1）常见结节组织的密度高于肺实质。但肺结节内的空腔密度极低，甚至是空的。\n我们可以将它们视为结节的一部分，也可以不视为结节的一部分。 (2) 分割图应提供更多有关结节特征的信息。空腔是重要的特征，因此保留这些空腔是更好的选择。如果需要，可以使用 cv2.findContours 等方法轻松去除预测中的空洞。\n表II，UGMCS-Net对于U-Net、Attention UNet、UGS-Net在Dice和IoU分数中的p值远小于0.05，并且t值的绝对值较大，表明UGMCS-Net在性能上明显优于U-Net、Attention U-Net和UGS-Net。\nP值 (P-value)：在统计分析中，P值用于量化结果发生的概率，假设零假设（通常是无效假设，如两组之间无差异）为真。在医学图像分析的研究中，如果涉及到统计检验（例如，比较两种分割方法的性能），P值可以用来表示这种比较的显著性水平。 V值：这个术语在医学图像分析中不常见，可能指的是特定研究或技术中使用的一个特定参数或度量。例如，它可能代表体积（Volume）的度量，特别是在分析器官大小或肿瘤体积时。在不同的上下文中，它可能有不同的含义。 上面的实验是基于注释集中的第一个注释Label1 。为了消除掩码选择的影响，我们还提供了 U-Net、Attention U-Net、UGS-Net 和 UGMCS-Net 在标注集中的第二个标签 Label2 上的性能。表III中列出的实验结果表明UGMCS-Net在Label2上保持了其优越的性能。这意味着所提出的方法可以在不同的掩模选择上保持稳定的性能。在传统的训练方法中，每个结节都被分配一个单一的掩模，无法为具有复杂结构特征的结节提供足够的信息。\n在我们的网络中，每个结节与 2-4 个掩模相关联。通过整合多重注释融合损失，我们将更全面的信息注入到学习过程中。它对于分割具有复杂结构和低密度纹理的结节特别有益。因此，多重注释融合损失显着提高了性能，特别是对于具有复杂结构的结节。\n4.3 Uncertain Region Prediction 除了能够分割结节之外，UGMCS-Net 还可以预测更有可能是结节组织的区域和可能性较低的区域。图 7 说明了预测结果 $\\cup(X)$和$\\cap(X)$、最终分割结果 $X_S$ 以及生成的 MCM’。在MCM’和MCM+UGSNet中，红色表示高置信度区域，蓝色表示低置信度区域，绿色对应于最终分割$X_S$。在理想情况下，$X_S$应有效地在高置信度和低置信度区域之间取得平衡。\n（预测交集$\\cap(X)$、预测并集$\\cup(X)$、最终分割$X_S$ 和 MCM 由 UGMCS-Net 生成。 MCM 中的颜色用于更好的可视化，红色表示$\\cap(X)$，蓝色表示$\\cup(X)$。此外，最终的分割在 MCM 中表示并标记为绿色以方便比较。红色框表示不易区分的结节区域或特征。最后一栏是相应结节的直径（以毫米为单位）)\n根据图 7，我们的最终分割结果位于高置信度区域和低置信度区域这两种极端情况之间。这些中间结果表明（1）我们的预测认识到所有潜在的注释，并且（2）预测被限制在$\\cap(X)$和$\\cup(X)$之间。\n具体来说，在肺结节特征分割中使用MCM具有以下几个优点，可以更好地显示结节的语义特征：（1）MCM可以更好地突出结节的显着空腔特征（图7.（g）（h））。与其他方法相比，UGMCS-Net 的预测掩模上的结节腔特征更加明显。这是由于UGMCS-Net能够在交叉掩模$\\cap(GT)$和联合掩模$\\cup(GT)$的指导下捕获结节组织的密度差异，这有助于保留结节腔的更多特征。\n(2)MCM可以更好地分割毛刺征象，这是诊断良恶性肺结节的重要特征(图7.(a)-(f))。针状结构是由结节侵入周围组织引起的星状变形，通常是低密度的并分布在结节边缘周围。这一特征是传统深度学习方法难以分割的。 UGMCS-Net在union mask $\\cup(GT)$的指导下可以更加关注结节边界特征，从而对分布在结节边界的毛刺有更好的分割性能。\n（3）MCM可以更好地分割结节的低密度组织（图7.（i）-（l）），该区域常见于磨玻璃结节，是造成专家标记差异的主要区域。 UGMCSNet通过对注释集GT和union mask $\\cup(GT)$的研究，可以最大程度地识别低密度组织，这对于磨玻璃结节的诊断很有帮助。\n由于LC掩模尺寸较小，传统的定量评估指标如DSC和IoU不足以衡量MCM的预测质量。为了解决这个问题，我们将预测的 HC 和 LC 掩模的 HU 分布与实际的 HC 和 LC 掩模进行比较。我们假设UGMCS-Net能够合理地预测不同区域的不确定性程度。因此，预测的 HC 和 LC 掩模的 HU 值分布应与实际分布相似。图8显示预测曲线与实际曲线吻合较好，表明我们预测的区域不确定性水平在统计上是可靠的。\n4.4 Ablation Study 我真的要被这个工作量给吓鼠了，太能做实验了把\n模块的消融研究：如果不指出实用性，我们会在每个部分进行五倍验证。为了更好地利用多个注释的信息并增强 $R_{LC}$ 、 $R_{HC}$ 和 $R{final}$ 之间的关系，我们用多注释融合损失和交叉联合约束模块更新了 UGMCS-Net。为了进一步证明这两个模块的贡献，我们基于 UGMCS-Net 构建了 UGMCS-$Φ_a$、UGMCS-$Φ_b$、UGMCS-$Φ_a$+$Φ_b$ 和 UGMCS-IUCM 进行消融实验。在UGMCS-$Φ_a$中，多注释融合损失仅应用于$\\cup(X)$;在UGMCS-$Φ_b$中，Multiple Annotation Fusion Loss仅应用于网络XS的最终输出；在UGMCS-$Φ_a$+$Φ_b$ 中，多重注释融合损失应用于$\\cup(X)$和$X_S$；在UGMCS-IUCM中，我们使用USG-Net中的Intersection-Union约束模块，但没有多重注释融合损失。\n我们的 UGMCS-Net 及其四种变体的性能列于表 IV，“-”表示 Attention U-Net。 V1是指没有IUCM和多重注释融合损失的UGS-Net，它作为其他变体的基础网络。\n结果表明：（1）UGMCS-$Φ_a$、UGMCS-$Φ_b$网络相对于UGMCS-Net的性能改进表明，所有标注信息的融合可以使网络更准确地捕获结节区域并获得更好的分割性能。 (2) UGMCS-$Φ_a$+$Φ_b$ 网络的 DSC、IoU 和 NSD 高于 UGMCS-$Φ_a$、UGMCS-$Φ_b$网络，表明同时对 UAM 和最终输出使用多重注释融合损失优于单独使用其中之一。 (3) 我们的 UGMCS-Net 优于UGMCS-$Φ_a$+$Φ_b$和 UGMCS-IUCM，证明了交集并集约束模块的有效性。尽管仅添加交集-并集约束模块（UGMCS-IUCM）时网络的定量性能略有下降，但观察到了显着的定性改进，这将在后面讨论。此外，UGMCS-Net的优越性能表明，多重注释融合损失和交叉联合约束模块可以相互增强，约束不确定性并促进更好的分割性能。\n为了进一步验证多注释融合损失和交叉联合约束模块的有效性，我们在图 9 中使用 Grad-CAM [36]、[37] 演示了特征图可视化。每种情况下的结果代表了网络的最终预测。 M3、M2和M1分别表示不同网络配置下倒数第三个、第二个和第一个卷积层的视觉特征图。基于图9，我们观察到：（1）当将多重注释融合损失应用于$\\cup(X)$或$X_S$时，网络对低密度组织的识别能力显着提高（UGMCS-$Φ_a$和UGMCS-$Φ_b$，结节A-D)； （2）$\\cup(X)$或$X_S$中同时使用Multiple Annotation Fusion Loss，可以在提高对低密度组织的敏感性的基础上，使网络勾勒出结节边界更加清晰（UGMCS-$Φ_a$+$Φ_b$网络，结节A-D）。 (3) IntersectionUnion Constraining Module使网络能够学习更多的边界特征，例如spiculation（毛刺）（UGMCS-IUCM网络，Nodule A-C）。 （4）当同时使用Multiple Annotation Fusion Loss和Intersection-Union Constraining Module时，网络注意力转移到结节边界，勾画出更加合理完整的结节区域（UGMCS-Net，Nodule A-E）。\n如图9所示，在IUCM的帮助下，网络可以针对复杂结节获得更语义化、更合理的分割结果。然而，如表IV所示，与UGMCS-$Φ_a$+$Φ_b$相比，UGMCS-Net在DSC、IoU和NSD上的性能增益较弱。我们认为造成这种现象的原因有3个：（1）IUCM专注于提高复杂结节的分割性能，与测量上的改进相比，IUCM使得模型对分割结果的性能提升更加显着（进一步验证在第 IV-E 节）。\n（2）复杂结节仅占结节总数的一小部分，因此IUCM无法显着提高模型在各项指标上的得分。 (3)数据集中仍然存在一些失败案例。如图10所示，在这些情况下，UGMCS-IUCM和UGMCS-Net获得的分割掩模包含更多的结节组织并且是更准确的病变区域，但它们的DSC分数较低。\n由于不同医生领域的知识偏差会影响groundtruth，因此对于分割任务来说，获得更准确、更合理的分割掩模通常比更高的度量分数更有意义。\n表V显示了加入UAM和IUCM后模型复杂度的增加。显然，UAM 和 IUCM 可以使模型以很少的计算成本获得更好的性能。\nBackbone 的消融研究：我们测试 U-Net 和 R2U-Net 作为三个模块的骨干。如表六所示，以U-Net为骨干的模型在DSC、IoU和NSD上分别获得了87.04%、78.07%和94.50%的分数。\n以R2U-Net为骨干的模型在DSC、IoU和NSD上分别获得了86.20%、76.82%和93.75%的结果。实验结果表明，所提出的特征提取模块、不确定性感知模块和交集并集约束模块是即插即用的。\n我们之前的工作评估了 nnU-Net [22] 作为骨干网络。\n这个网络在这个任务中有两个缺点：（1）它占用了太多的计算资源，（2）我们只有 1860 个结节，这可能会导致过度拟合。为了平衡计算资源和性能增益，我们在本工作中选择 Attention U-Net。\n交叉点联合约束模块中滤波器的消融研究：在第 III-C 节中，我们讨论了 Otsu 对密度特征的敏感性，使模型能够准确识别高密度组织。因此，我们利用 Otsu 的方法来提取 $R_{HC}$ 的特征。相反，Gabor对图像边缘敏感并提供有效的方向和尺度选择特征，被选择用于 $R_{LC}$的特征提取。在这些部分中，我们进行了涉及 Fold1 上 IntersectionUnion 约束模块内的五个过滤器设置的实验。表 VII 概述了这些设置。如表 VII 所示，我们的最终配置产生了最高的 DSC 分数。\n我们在图 11 中提供了 $R_{LC}^{\\prime}$ 和 $R_{HC}^{\\prime}$ 的特征可视化。可以看出， $R_{LC}^{\\prime}$ 的可视化更多地集中在结节的边缘，其中包含更多的低置信度区域。相比之下， $R_{HC}^{\\prime}$ 的可视化更关注结节的核心，具有更高的分割置信度。这些可视化结果重新证明了我们过滤器设计的有效性。\n参数消融研究：在方程 4 中，存在三个手动设置的参数：α1 指定为 0.5，α2 指定为 0.5，α3 指定为 1。在本节中，我们进行五重验证并说明这些参数选择背后的基本原理。\n如表VIII所示，当α1设置为0.5，α2设置为0.5，α3设置为1时，所提出的方法达到其峰值性能。值得注意的是，α3代表最终分割的权重，这意味着XS在训练过程中发挥着重要作用。\n此外，我们对三个分支的概率图加权平均融合进行了实验，希望网络能够为IUCM中的每个分支选择合适的权重。然而，我们观察到与 $R_{Uni}$ 对应的分支可以为结节分割提供更通用的特征，并且比其他两个分支显得“更强”。因此，其他两个分支的权重往往会减少到 0。根据这些观察结果，我们选择直接融合概率图。\n4.5 Complex-Nodule Validation UGMCS-Net 从可能导致分割不确定性的区域学习特征。因此，它可以更好地分割具有大的低密度区域或复杂结构的结节。为了更好地证明其对 U-Net 难以分割的结节的改进，我们设计了一个 Complex Nodule Validation。基于五重验证U-Net，我们进一步选择了DSC分数低于60％、70％和80％的三组结节。然后使用相同的数据设置训练 Attention U-Net、UGMCS-$Φ_a$+$Φ_b$、UGMCS-IUCM 和 UGMCS-Net，以再次测试这些结节并比较 DSC 和 IoU 分数。\nUGMCS-Net 在复杂结节上的性能提升是显而易见的。与Attention U-Net相比，对于U-Net上DSC分数低于60%的结节，UGMCS-$Φ_a$+$Φ_b$导致平均DSC分数提高1.58%，UGMCS-IUCM使平均DSC分数提高5.12%，UGMCS-平均 DSC 得分净产量增加了 5.45%。对于 U-Net 上 DSC 得分在 60% 到 70% 之间的结节，UGMCS-$Φ_a$+$Φ_b$、UGMCS-IUCM 和 UGMCS-Net 的平均 DSC 得分分别提高了 0.69%、3.11% 和 5.07%。同样，对于 U-Net 上 DSC 分数在 70% 至 80% 之间的结节，UGMCS-$Φ_a$+$Φ_b$、UGMCS-IUCM 和 UGMCS-Net 的平均 DSC 分数相应提高了 0.14%、1.52% 和 1.64%。从上述差异可以看出，UGMCS-IUCM对于复杂结节有很大程度的性能提升。根据表一，我们的网络在整个数据集上仅将 DSC 提高了 0.89%，但相对于 U-Net 上 DSC 分数低于 60% 的结节而言，相对于 Attention U-Net 具有很大的性能提升。这是因为具有复杂结构的结节仅占所有数据的一小部分。\n图12显示了一些复杂结节的分割结果。红色下标是UGMCS-Net的分段DSC，黑色下标是UNet的DSC。可以看出，U-Net分割DSC得分低于60%的结节是一些低密度或毛玻璃组织。 UGMCS-Net在这些结节中的显着改进表明UGMCS-Net可以更好地学习结节低密度组织的特征并更准确地分割低密度结节病变区域。当U-Net分割DSC得分低于70%时，可以观察到除了一些低密度结节外，一些结节还存在不规则空洞、毛刺、组织内突然出现亮点或肺壁过亮。 UGMCS-Net在这些结节上令人信服的分割性能反映了UGMCS-Net对边界特征、密度差异的学习能力以及良好的抗噪声能力。当U-Net分割DSC得分低于80%时，我们观察到许多新结节具有更多的实体组织。在这种情况下，UGMCS-Net可以准确地确定结节区域。此外，对于大多数结节，UGMCS-Net的分割结果反映了更多的语义特征，具有更强的可解释性。\n复杂结节验证中的分割性能分析。 UGMCS-$Φ_a$+$Φ_b$、UGMCS-IUCM 和 UGMCS-Net 平均 DSC 和 IoU 后面是与 Attention U-Net 相应度量的差值（绿色数字）。所有指标均以百分比表示。\n（复杂结节验证：该验证测试了 UGMCS-Net 对 U-Net 难以分割的肺结节进行三个级别的分割性能。每张CT图像的最后两个掩模分别是UGMCS-Net和U-Net的分割结果。U-Net的分割结果以黑色显示，UGMCS-Net以红色显示。所有指标均以百分比表示。）\nDISCUSSIONS 长期以来，肺结节分割的任务一直致力于实现高精度，其中 DSC 或 IoU 是主要目标。然而，考虑到肺结节尺寸小且结构复杂，如果分割结果以不同置信度突出显示区域，可能对放射科医生更有帮助。高置信度区域提供了结节或肿瘤组织的主要部分，而低置信度区域则包含重要的低密度特征，例如毛玻璃状和毛刺征，放射科医生也应注意这些特征。\n所提出的方法旨在提供对临床诊断更有用的信息，而不是简单地改进 DSC。它并不寻求取代医生的临床作用，而是通过允许他们利用人工智能方法的优势来补充医生的临床作用。我们相信，这是将人工智能融入临床实践的更好方法。\n5.1 Data Requirement 我们的方法并不需要每个放射科医生都对所有结节进行注释。如 [11] 所示，项目期间共有 12 名放射科医生参与了所有五个站点的图像注释程序。鉴于大多数结节由 1-4 名放射科医生进行注释，可以想象结节可能由不同的放射科医生进行注释。\n尽管如此，不同放射科医生参与注释结节不会妨碍我们方法的适用性。尽管不同放射科医生之间的注释风格可能存在差异，但值得注意的是，训练有素的放射科医生遵循既定的结节注释标准，例如[38]。这些标准确保不同组的放射科医生提供多样化但基本一致的注释。\n5.2 Limitation 我们研究的一个局限性是我们仅在 LIDC-IDRI 数据集上测试我们提出的方法，该数据集是目前唯一公开可用的肺结节完整注释数据集。尽管已有十多年的历史，该数据集仍然提供了许多研究机会。然而，对多个注释的需求可能会限制我们的方法在现实临床环境中的实用性，其中获得多个注释可能并不总是可行。为了解决这个限制，我们计划探索能够基于单个注释自动识别高置信度和低置信度区域的技术，从而提高我们方法的可行性和适用性。\nCONCLUSIONS 多个注释之间的协议，以改进分割并识别分割置信度较低的区域。UAAM 从多置信度模板 (MCM) 中捕获特征，多置信度模板是低置信度 (LC) 模板和高置信度 (HC) 模板的组合。基于UAAM，我们进一步设计了不确定性引导分割网络（UGMCS-Net），其中包含特征提取模块、不确定性感知模块和交集并集约束模块。这些模块共同从多个注释之间的共识或分歧中学习有价值的信息，提供具有高和低分割置信度的区域，以及可以平衡所有可能性的分割结果。除了传统的验证方法之外，我们还提出了 LIDC-IDRI 上的复杂结节验证，测试 UGMCS-Net 对 U-Net 难以分割的肺结节的分割性能。\n实验结果表明，我们的方法可以显着提高 U-Net 分割效果不佳的结节的分割性能。\n总结：牛逼牛逼牛逼！！！ 确实牛逼！ 不愧是一区顶刊\n","permalink":"https://swimmingliu.cn/posts/papernotes/2023-uncertainty-aware-attentionmechanism/","summary":"\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e放射科医生拥有不同的培训和临床经验，导致\u003cstrong\u003e肺结节的分割注释\u003c/strong\u003e存在\u003cstrong\u003e差异\u003c/strong\u003e，从而导\u003cstrong\u003e致分割的不确定性\u003c/strong\u003e。传统方法通常选择\u003cstrong\u003e单个注释\u003c/strong\u003e作为学习目标或尝试学习包含\u003cstrong\u003e多个注释\u003c/strong\u003e的\u003cstrong\u003e潜在空间\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e然而，这些方法无法\u003cstrong\u003e利用多个注释之间的共识和分歧所固有的有价值的信息\u003c/strong\u003e。在本文中，我们提出了一种\u003cstrong\u003e不确定性感知注意机制\u003c/strong\u003e（UAAM），它利用多个\u003cstrong\u003e注释之间的共识\u003c/strong\u003e和分歧来促进更好的分割。为此，我们引入了\u003cstrong\u003e多置信度掩模\u003c/strong\u003e（MCM），它结合了\u003cstrong\u003e低置信度（LC）掩模\u003c/strong\u003e和高置信度（HC）掩模。 \u003cstrong\u003eLC 掩模\u003c/strong\u003e表示\u003cstrong\u003e分割置信度较低的区域\u003c/strong\u003e，\u003cstrong\u003e放射科医生可能有不同的分割选择\u003c/strong\u003e。继\u003cstrong\u003eUAAM\u003c/strong\u003e之后，我们进一步设计了一个\u003cstrong\u003e不确定性引导多置信分割网络\u003c/strong\u003e（UGMCS-Net），它包含三个模块：\u003cstrong\u003e一个捕获肺结节一般特征的特征提取模块\u003c/strong\u003e，\u003cstrong\u003e一个为肺结节产生三个特征的不确定性感知模块\u003c/strong\u003e。\u003cstrong\u003e注释的并集、交集和注释集，以及一个交集并集约束模块\u003c/strong\u003e，该模块使用\u003cstrong\u003e三个特征之间的距离来平衡最终分割和 MCM 的预测\u003c/strong\u003e。为了全面展示我们方法的性能，我们提出了 LIDC-IDRI 上的复杂结节验证，它测试了 UGMCS-Net 对使用常规方法难以分割的肺结节的分割性能。实验结果表明，我们的方法可以显着提高传统方法难以分割的结节的分割性能。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"introduction\"\u003eINTRODUCTION\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e肺结节分割\u003c/strong\u003e在\u003cstrong\u003e肺癌计算机辅助诊断 (CAD)\u003c/strong\u003e 系统中至关重要 [1]，可提供\u003cstrong\u003e结节大小、形状和其他重要医学特征\u003c/strong\u003e等关键信息。然而，对于深度学习方法的\u003cstrong\u003e一般训练和测试范例\u003c/strong\u003e，每个结节图像数据只有一个由\u003cstrong\u003e一名放射科医生\u003c/strong\u003e描绘的注释掩模[2]-[6]。因此，\u003cstrong\u003e网络每次只能提供结节区域\u003c/strong\u003e的单个预测。\u003c/p\u003e\n\u003cp\u003e然而，在临床实践中，不同的放射科医生\u003cstrong\u003e由于其不同的培训和临床经验\u003c/strong\u003e可能会为肺结节提供\u003cstrong\u003e不同的分割注释\u003c/strong\u003e[7]-[9]。\u003c/p\u003e\n\u003cp\u003e因此，基于\u003cstrong\u003e单一注释的传统方法\u003c/strong\u003e无法反映\u003cstrong\u003e临床经验的多样性\u003c/strong\u003e，限制了深度学习方法的应用。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e解决放射科医生之间注释不同问题\u003c/strong\u003e的一个直接解决方案是为\u003cstrong\u003e每个肺结节图像合并多个注释\u003c/strong\u003e。这导致了另一个问题：\u003cstrong\u003e多个注释不可避免地会带来不确定性和冲突\u003c/strong\u003e，因为放射科医生\u003cstrong\u003e可能会对同一区域进行不同的注释\u003c/strong\u003e。为了克服这个问题，Kohl 等人在 2018 年提出了一种概率 U-Net，它\u003cstrong\u003e利用条件变分自动编码器\u003c/strong\u003e将\u003cstrong\u003e多个分割变体编码\u003c/strong\u003e到\u003cstrong\u003e低维潜在空间\u003c/strong\u003e中 [8]、[10]。通过从该空间采样，网络可以影响相应的分割图。基于这项研究，Hu等人提出将\u003cstrong\u003e真实不确定性\u003c/strong\u003e与\u003cstrong\u003e概率UNet\u003c/strong\u003e相结合，这可以\u003cstrong\u003e提高预测不确定性估计\u003c/strong\u003e、\u003cstrong\u003e样本准确性和样本多样性\u003c/strong\u003e[7]。这些方法依赖于\u003cstrong\u003e潜在空间和该空间中的随机样本\u003c/strong\u003e。因此，这些方法只能通过多次预测来提供不确定区域。\u003c/p\u003e\n\u003cp\u003e在本文中，我们提出了一个论点，即\u003cstrong\u003e多个注释之间的不确定性遵循特定的模式\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e为了演示这种现象，我们引入了\u003cstrong\u003e多重置信掩码\u003c/strong\u003e (MCM)，它结合了\u003cstrong\u003e高置信度 (HC) 掩码\u003c/strong\u003e和低置信度 (LC) 掩码，如图 1 所示。 A. 交叉掩码等于 \u003cstrong\u003eHC mask\u003c/strong\u003e，代表\u003cstrong\u003e所有注释的交集\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e联合掩码是所有注释的联合\u003c/strong\u003e。 \u003cstrong\u003eLC掩模是交集掩模和并集掩模之间的差异\u003c/strong\u003e。当在 LIDC-IDRI 数据集 [11] 上计算 HC 和 LC 的 Hounsfield 单位 (HU) 核估计时，\u003cstrong\u003e如图 1.B 所示，我们可以观察到 LC 和 HC 掩模之间的 HU 分布存在明显区别\u003c/strong\u003e。具体地，LC区域具有比HC区域更低的HU值。从像素分布来看，\u003cstrong\u003eHU值越低，对应区域的密度越低\u003c/strong\u003e。就CT图像特征而言，LC区域\u003cstrong\u003e主要由结节边缘、毛刺和磨玻璃特征等边界相关特征组成\u003c/strong\u003e，而\u003cstrong\u003eHC区域主要分布在结节核心内\u003c/strong\u003e。因此，我们提出了这样的假设：导致放射科医生之间差异的区域主要与\u003cstrong\u003e低密度组织和边界相关特征\u003c/strong\u003e有关。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cimg alt=\"image-20231130203343980\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/327b2.png\"\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e与其他方法不同，我们建议利用 \u003cstrong\u003eMCM (多重置信掩码) ** 和注释集作为具有\u003c/strong\u003e不同分割确定性的特征的学习指导**，有助于更好的分割性能。我们将这种训练称为\u003cstrong\u003eUncertaintyAware Attention Mechanism\u003c/strong\u003e，如图2所示。按照这种机制，我们进一步设计了用于肺结节分割的\u003cstrong\u003eUncertainty-Guide Multi-Confidence Segmentation Network\u003c/strong\u003e（UGMCS-Net）。\u003c/p\u003e","title":"Uncertainty-Aware Attention Mechanism:利用不确定性感知注意机制进行肺结节分割和不确定区域预测"},{"content":"程序设计作业接口文档 统一返回格式\n{ code: ...,\t# 状态码 msg: ...,\t# 描述信息 data: { # 数据 ... } } code = { 200 == 成功, 500 == 失败, } msg = { success == 成功 fail == 失败 ... } data = { key : value } 前端 虚拟换衣功能 @请求格式 （请求后端） # 前后端需统一样例图片id { userId: ...\u0026lt;int\u0026gt;,\t# 标识哪个用户的请求 isUploadCloth: ...\u0026lt;bool\u0026gt;, # 若上传衣服图片使用base64，否则用id isUploadPerson: ...\u0026lt;bool\u0026gt;, # 若上传人物图片使用base64，否则用id clothData: ...\u0026lt;base64||null\u0026gt;, # 衣服图片base64编码 personData: ...\u0026lt;base64||null\u0026gt;,\t# 人物图片base64编码 exampleClothId: ...\u0026lt;int\u0026gt;,\t# 衣服样例图片id examplePersonId: ...\u0026lt;int\u0026gt;\t# 任务样例图片id } 动漫头像功能 @请求格式 （请求后端） { userId: ...\u0026lt;int\u0026gt;, # 标识哪个用户的请求 imgData: ...\u0026lt;base64\u0026gt; # 需要动漫化的图片 } 后端 虚拟换衣功能 前端请求API: https://talented-civet-separately.ngrok-free.app/tryon/ @返回格式 (返回前端) { code: ...\u0026lt;int\u0026gt;, # 状态码 (200表示成功, 500表示失败) msg: ...\u0026lt;string\u0026gt;,\t# 消息 (success / fail) data: { tryon_result : ...\u0026lt;url\u0026gt;, # 处理后的图片url } } 动漫头像功能 前端请求API: https://talented-civet-separately.ngrok-free.app/anime/ @返回格式 (返回前端) { code: ...\u0026lt;int\u0026gt;, # 状态码 (200表示成功, 500表示失败) msg : ...\u0026lt;string\u0026gt;, # 消息 (success / fail) data: { anime_result : ...\u0026lt;url\u0026gt;, # 处理后的图片url } } 模型端 虚拟换衣功能 后端请求API: https://certain-ideally-foal.ngrok-free.app/tryon/predict/ @请求格式\t(后端发出请求) { userid : ...\u0026lt;int\u0026gt;, # 用户id cloth : ...\u0026lt;url\u0026gt;, # 衣服图片url链接 person : ...\u0026lt;url\u0026gt;\t# 人物图片url链接 } @返回格式\t（返回后端） { code: ...\u0026lt;int\u0026gt;, # 状态码 (200表示成功, 500表示失败) msg: ...\u0026lt;string\u0026gt;,\t# 消息 (success / fail) data: { image_value : ...\u0026lt;base64\u0026gt;, # 处理后的图片base64编码 } } 动漫头像功能 后端请求API: https://certain-ideally-foal.ngrok-free.app/anime/predict/ @请求格式 { userid : ...\u0026lt;int\u0026gt;, # 用户id origin_image : ...\u0026lt;url\u0026gt;, # 原图片url链接 } @返回格式 { code: ...\u0026lt;int\u0026gt;, # 状态码 (200表示成功, 500表示失败) msg: ...\u0026lt;string\u0026gt;,\t# 消息 (success / fail) data: { image_value : ...\u0026lt;base64\u0026gt;, # 处理后的图片base64编码 } } ","permalink":"https://swimmingliu.cn/posts/diary/2023-%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E4%BD%9C%E4%B8%9A%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/","summary":"\u003ch1 id=\"程序设计作业接口文档\"\u003e程序设计作业接口文档\u003c/h1\u003e\n\u003cp\u003e统一返回格式\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003ecode:\u003c/span\u003e \u003cspan class=\"err\"\u003e...,\u003c/span\u003e\t\u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e状态码\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003emsg:\u003c/span\u003e \u003cspan class=\"err\"\u003e...,\u003c/span\u003e\t\u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e描述信息\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003edata:\u003c/span\u003e \u003cspan class=\"err\"\u003e{\u003c/span\u003e     \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e数据\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \t\u003cspan class=\"err\"\u003e...\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003ecode\u003c/span\u003e \u003cspan class=\"err\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003e200\u003c/span\u003e \u003cspan class=\"err\"\u003e==\u003c/span\u003e \u003cspan class=\"err\"\u003e成功,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003e500\u003c/span\u003e \u003cspan class=\"err\"\u003e==\u003c/span\u003e \u003cspan class=\"err\"\u003e失败,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003emsg\u003c/span\u003e \u003cspan class=\"err\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003esuccess\u003c/span\u003e \u003cspan class=\"err\"\u003e==\u003c/span\u003e \u003cspan class=\"err\"\u003e成功\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003efail\u003c/span\u003e    \u003cspan class=\"err\"\u003e==\u003c/span\u003e \u003cspan class=\"err\"\u003e失败\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003e...\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003edata\u003c/span\u003e \u003cspan class=\"err\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003ekey\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003evalue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"前端\"\u003e前端\u003c/h2\u003e\n\u003ch3 id=\"虚拟换衣功能\"\u003e虚拟换衣功能\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e@请求格式\u003c/span\u003e  \u003cspan class=\"err\"\u003e（请求后端）\u003c/span\u003e  \t \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e前后端需统一样例图片id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003euserId:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;,\u003c/span\u003e\t\t\t\u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e标识哪个用户的请求\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003eisUploadCloth:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;bool\u0026gt;,\u003c/span\u003e           \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e若上传衣服图片使用base64，否则用id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003eisUploadPerson:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;bool\u0026gt;,\u003c/span\u003e          \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e若上传人物图片使用base64，否则用id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003eclothData:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;base64||null\u0026gt;,\u003c/span\u003e \t\u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e衣服图片base64编码\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003epersonData:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;base64||null\u0026gt;,\u003c/span\u003e\t\u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e人物图片base64编码\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003eexampleClothId:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;,\u003c/span\u003e\t\t\u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e衣服样例图片id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003eexamplePersonId:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;\u003c/span\u003e\t\t\u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e任务样例图片id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"动漫头像功能\"\u003e动漫头像功能\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e@请求格式\u003c/span\u003e \u003cspan class=\"err\"\u003e（请求后端）\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003euserId:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;,\u003c/span\u003e    \t        \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e标识哪个用户的请求\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003eimgData:\u003c/span\u003e  \u003cspan class=\"err\"\u003e...\u0026lt;base64\u0026gt;\u003c/span\u003e \t        \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e需要动漫化的图片\u003c/span\u003e \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"后端\"\u003e后端\u003c/h2\u003e\n\u003ch3 id=\"虚拟换衣功能-1\"\u003e虚拟换衣功能\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e前端请求API:\u003c/span\u003e \u003cspan class=\"err\"\u003ehttps:\u003c/span\u003e\u003cspan class=\"c1\"\u003e//talented-civet-separately.ngrok-free.app/tryon/\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"err\"\u003e@返回格式\u003c/span\u003e \u003cspan class=\"err\"\u003e(返回前端)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003ecode:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;,\u003c/span\u003e \t                \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e状态码\u003c/span\u003e \u003cspan class=\"err\"\u003e(200表示成功,\u003c/span\u003e \u003cspan class=\"err\"\u003e500表示失败)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003emsg:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;string\u0026gt;,\u003c/span\u003e\t                \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e消息\u003c/span\u003e \u003cspan class=\"err\"\u003e(success\u003c/span\u003e \u003cspan class=\"err\"\u003e/\u003c/span\u003e \u003cspan class=\"err\"\u003efail)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003edata:\u003c/span\u003e \u003cspan class=\"err\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"err\"\u003etryon_result\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;url\u0026gt;,\u003c/span\u003e  \t\u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e处理后的图片url\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"动漫头像功能-1\"\u003e动漫头像功能\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e前端请求API:\u003c/span\u003e \u003cspan class=\"err\"\u003ehttps:\u003c/span\u003e\u003cspan class=\"c1\"\u003e//talented-civet-separately.ngrok-free.app/anime/\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"err\"\u003e@返回格式\u003c/span\u003e \u003cspan class=\"err\"\u003e(返回前端)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003ecode:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;,\u003c/span\u003e  \t                \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e状态码\u003c/span\u003e \u003cspan class=\"err\"\u003e(200表示成功,\u003c/span\u003e \u003cspan class=\"err\"\u003e500表示失败)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003emsg\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;string\u0026gt;,\u003c/span\u003e \t                \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e消息\u003c/span\u003e \u003cspan class=\"err\"\u003e(success\u003c/span\u003e \u003cspan class=\"err\"\u003e/\u003c/span\u003e \u003cspan class=\"err\"\u003efail)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003edata:\u003c/span\u003e \u003cspan class=\"err\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \t\u003cspan class=\"err\"\u003eanime_result\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e  \u003cspan class=\"err\"\u003e...\u0026lt;url\u0026gt;,\u003c/span\u003e \t\u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e处理后的图片url\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"模型端\"\u003e模型端\u003c/h2\u003e\n\u003ch3 id=\"虚拟换衣功能-2\"\u003e虚拟换衣功能\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e后端请求API:\u003c/span\u003e \u003cspan class=\"err\"\u003ehttps:\u003c/span\u003e\u003cspan class=\"c1\"\u003e//certain-ideally-foal.ngrok-free.app/tryon/predict/\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"err\"\u003e@请求格式\u003c/span\u003e\t\u003cspan class=\"err\"\u003e(后端发出请求)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003euserid\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;,\u003c/span\u003e              \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e用户id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003ecloth\u003c/span\u003e  \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;url\u0026gt;,\u003c/span\u003e \t            \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e衣服图片url链接\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003eperson\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;url\u0026gt;\u003c/span\u003e\t            \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e人物图片url链接\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e@返回格式\u003c/span\u003e\t\u003cspan class=\"err\"\u003e（返回后端）\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003ecode:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;,\u003c/span\u003e \t            \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e状态码\u003c/span\u003e \u003cspan class=\"err\"\u003e(200表示成功,\u003c/span\u003e \u003cspan class=\"err\"\u003e500表示失败)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003emsg:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;string\u0026gt;,\u003c/span\u003e\t            \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e消息\u003c/span\u003e \u003cspan class=\"err\"\u003e(success\u003c/span\u003e \u003cspan class=\"err\"\u003e/\u003c/span\u003e \u003cspan class=\"err\"\u003efail)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003edata:\u003c/span\u003e \u003cspan class=\"err\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"err\"\u003eimage_value\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;base64\u0026gt;,\u003c/span\u003e  \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e处理后的图片base64编码\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"动漫头像功能-2\"\u003e动漫头像功能\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e后端请求API:\u003c/span\u003e \u003cspan class=\"err\"\u003ehttps:\u003c/span\u003e\u003cspan class=\"c1\"\u003e//certain-ideally-foal.ngrok-free.app/anime/predict/\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"err\"\u003e@请求格式\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003euserid\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;,\u003c/span\u003e  \t   \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e用户id\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003eorigin_image\u003c/span\u003e  \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;url\u0026gt;,\u003c/span\u003e \t   \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e原图片url链接\u003c/span\u003e \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e@返回格式\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003ecode:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;int\u0026gt;,\u003c/span\u003e \t            \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e状态码\u003c/span\u003e \u003cspan class=\"err\"\u003e(200表示成功,\u003c/span\u003e \u003cspan class=\"err\"\u003e500表示失败)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003emsg:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;string\u0026gt;,\u003c/span\u003e\t            \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e消息\u003c/span\u003e \u003cspan class=\"err\"\u003e(success\u003c/span\u003e \u003cspan class=\"err\"\u003e/\u003c/span\u003e \u003cspan class=\"err\"\u003efail)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003edata:\u003c/span\u003e \u003cspan class=\"err\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"err\"\u003eimage_value\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"err\"\u003e...\u0026lt;base64\u0026gt;,\u003c/span\u003e  \u003cspan class=\"err\"\u003e#\u003c/span\u003e \u003cspan class=\"err\"\u003e处理后的图片base64编码\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"程序设计作业接口文档"},{"content":"Prior Attention Network: 用于医学图像中多病灶分割的预先注意网络 Abstract 医学图像中邻近组织的多种类型病变的准确分割在临床实践中具有重要意义。基于从粗到精策略的卷积神经网络（CNN）已广泛应用于该领域。然而，由于组织的大小、对比度和高类间相似性的不确定性，多病灶分割仍然具有挑战性。此外，普遍采用的级联策略对硬件要求较高，限制了临床部署的潜力。为了解决上述问题，我们提出了一种新颖的先验注意网络（PANet），它遵循从粗到细的策略来在医学图像中执行多病灶分割。所提出的网络通过在网络中插入与病变相关的空间注意机制，在单个网络中实现了两个步骤的分割。此外，我们还提出了中间监督策略，用于生成与病变相关的注意力来获取感兴趣区域（ROI），这加速了收敛并明显提高了分割性能。我们在两个应用中研究了所提出的分割框架：肺部 CT 切片中多发性肺部感染的 2D 分割和脑 MRI 中多发性病变的 3D 分割。实验结果表明，与级联网络相比，在 2D 和 3D 分割任务中，我们提出的网络以更少的计算成本实现了更好的性能。所提出的网络可以被视为 2D 和 3D 任务中多病灶分割的通用解决方案。源代码可在 https://github.com/hsiangyuzhao/PANet 获取\n问题导向：\n①组织的大小、对比度和高类间相似性的不确定性\n②多类别病灶分割\n③普遍采用的级联策略对硬件要求较高\nIntroduction 医学图像分割对于疾病的准确筛查和患者的预后具有重要意义。基于病灶分割的病灶评估提供了疾病进展的信息，帮助医生提高临床诊断和治疗的质量。然而，手动病变分割相当主观且费力，这限制了其潜在的临床应用。近年来，随着人工智能的快速发展，基于深度学习的算法得到了广泛的应用，并在医学图像分割方面取得了最先进的性能[1]。卷积神经网络（CNN）由于其高分割质量而在医学图像中的病变分割中很受欢迎。此类算法通常具有深度编码器，可从输入图像中自动提取特征，并通过以下操作生成密集预测。例如，Long等人[2]提出了一种用于图像语义分割的全卷积网络，该网络颇具影响力，并启发了后来的医学分割中的端到端框架。 Ronneberger等人[3]提出了一种用于医学图像分割的U形网络（U-Net），该网络在医学分割的许多领域都显示出了可喜的结果，并已成为许多医学分割任务的虚拟基准。\n这一段都可以当成经典医学图像分割的背景引入\n然而，尽管医学分割取得了这些突破，但目前的医学分割方法主要集中在病灶的二元分割上，即区分病灶（前景）和其他一切（背景）。尽管二元分割确实有助于隔离某些感兴趣区域并允许对医学图像进行精确分析，但在某些需要对病变进行多类分割的场景中，二元分割还不够。与二元分割相比，由于组织的类间相似性，这种情况要困难得多，因为不同类型的病变在纹理、大小和形状上可能相似。具有从粗到细策略的级联网络已广泛应用于此类场景，例如肝脏和病变的分割、脑肿瘤分割[4]、[5][6]、[7]。\n此类网络通常由两个独立的网络组成，其中第一个网络执行粗分割，第二个网络基于从第一个网络分割的 ROI 细化分割。然而，尽管级联网络已广泛应用于医学图像的多病灶分割，但级联策略也有其缺点。由于级联网络由两个独立的网络组成，参数量和显存占用通常是单个网络的两倍，这对硬件要求较高，限制了其在临床使用的潜力。更重要的是，由于级联网络中的两个网络通常是独立的，因此级联网络的训练过程有时比单个网络更困难，这可能导致欠拟合。\n级联网络：参数量大、容易欠拟合。\n在本文中，我们提出了一种名为先验注意网络（PANet）的新型网络结构，用于在医学图像中执行多病灶分割。所提出的网络由一个用于特征提取的编码器和两个分别生成病变区域注意力和最终预测的解码器组成。该网络与注意力机制结合在一起。为了减少参数大小和硬件占用，我们使用网络编码器的深层、语义丰富的特征来生成病变区域的空间注意力。\n然后，编码器生成的特征表示通过空间注意力进行细化，并将其发送到解码器以进行最终的多类预测。为了提高分割性能并加速收敛，我们还在网络结构中引入了中间监督和深度监督。通过这些改进，与传统的级联网络相比，所提出的网络以显着降低的参数大小和计算成本实现了有竞争力的结果。\n利用网络编码器的深层、特征信息来生成空间注意力（WTF ???）\n中间监督、深度监督 （不错不错， 好多一区和顶会的文章都用深度监督）\n这项工作的贡献体现在三个方面。首先，我们提出了一种新颖的网络架构，通过将传统级联网络中的两个分割步骤结合在单个网络中，遵循 2D 和 3D 医学图像中多病灶分割的从粗到细的策略。与级联网络相比，所提出的架构以更少的额外计算成本实现了有竞争力的分割性能，更容易训练和部署到生产环境。其次，我们提出了一种监督空间注意力机制，将病变区域的注意力与网络提取的特征相结合，将多病变分割分解为两个更容易的阶段，并且与当前基于注意力的方法相比具有更好的可解释性。第三，所提出的网络已在两个实际应用中得到验证，包括肺部 CT 切片中的 COVID-19 病变的 2D 分割和多模态 MRI 中的脑肿瘤的 3D 分割。所提出的网络在 2D 和 3D 任务中都优于前沿方法，并且在参数和计算成本方面比当前网络更高效。\n一个网络、监督空间注意力机制、参数和计算成本方面比当前网络更高效。\nRelated Work 1）图像分割的网络结构：用于图像分割的典型卷积神经网络通常由一个卷积特征提取器组成，其拓扑类似于常见的分类网络，自动从输入图像中提取特征，并进行基于卷积的操作以生成最终的密集预测。在自然图像分割领域，FCN [2]、DeepLab [8]、PSPNet [9] 和 SegNet [10] 因其性能和效率而颇受欢迎。对于医学分割，U-Net [3] 在许多任务中相当流行，并且已被修改为许多改进版本，例如 Attention U-Net [11]、U-Net++ [12]、V-Net [13] 和H-DenseUNet [14]在某些领域获得更好的性能。\n2）级联网络在医学分割中的应用：级联网络已广泛应用于正常组织和病变的分割以及不同类型病变的分割，包括肝脏病变、脑肿瘤、硬化病变和前列腺癌的分割[4] ，[15][5]，[16]。例如，Awad 等人[17]提出了一个名为 CU-Net 的级联框架，用于在 CT 扫描中对肝脏和病变进行自动分割。他们还提供了可以指导临床治疗的有用信息和解释。 Xi等人[18]提出了一种级联U-ResNets，它遵循一种新颖的垂直级联策略，并在他们的工作中评估了不同类型的损失函数。除了肝脏病灶分割之外，级联策略在 BraTS 挑战中也很流行。例如，BraTS 2019挑战赛的Top-2解决方案[6]、[7]都是具有不同级联策略的级联网络。\n3）神经网络中的注意力：注意力机制受到人类感知和视觉认知的启发，并已普遍应用于计算机视觉任务中[19]，[20][11]，[21]。计算机视觉任务中的注意力机制是在神经网络提取的特征表示上生成空间或通道权重图。例如，Woo等人[20]开发了一个卷积块注意力模块（CBAM）来引入一种融合注意力机制，其中包括通道注意力和空间注意力。这种注意力模块可以插入到常用的分类或分割网络中。Oktay等人[11]在Attention U-Net中提出了一种新颖的注意力门，用于细化网络编码器提取的特征表示，以促进网络专注于ROI。最近，首先在自然语言处理任务中提出的变压器[22]已被引入到医学分割任务中。例如，Wang 等人 [23] 提出了一种 TransBTS，用于从多模态脑 MRI 中执行脑肿瘤分割。\n综上所述，注意力机制已被广泛用于突出ROI并抑制不相关信息，但目前基于注意力的方法的研究并没有对注意力如何产生以及网络为何关注某些区域提供清晰的解释，这使得限制了注意力机制的可解释性。\nMethod 在本节中，我们将详细介绍所提出的先验注意网络架构。在第一部分中，我们将概述所提议的网络。然后，我们相应地提供有关具有中间监督、参数化跳跃连接和具有深度监督的多类解码器的所提出的注意引导解码器的详细信息。\n3.1 . Overview of Network Architecture 基本上，我们提出的网络是基于 U-Net [3] 架构进行修改的，该架构具有 U 形拓扑以及编码器和解码器之间的跳跃连接。在提出的先验注意网络中，一种新颖的注意引导解码器模块被集成到网络的跳跃连接中，以通过空间注意来细化特征表示。网络中还引入了一种新颖的参数化跳跃连接，以指导网络学习普通特征图和精炼特征图之间的比率。注意力引导解码器从编码器获取丰富的语义特征并生成空间注意力图来指导接下来的多类分割。为了产生与投资回报率相关的注意力，框架中使用了中间监督策略。然后将细化的特征图发送到多类解码器以进行最终的密集预测。\n多类解码器采用深度监督策略以获得更好的收敛性并提高分割性能。这种网络拓扑通过注意力引导解码器生成的注意力图在单个网络中实现了传统级联网络的两个步骤。组网方案如图2所示。\n3.2 Attention Guiding Decoder 在典型的级联网络中，分割的第一步是执行粗分割并找到输入图像中的 ROI。在提出的先验注意网络中，我们提出了一个注意引导解码器来执行该过程。所提出的注意力引导解码器被集成到网络中以生成与 ROI 相关的注意力图，然后利用这些图来细化特征表示并提高多类分割性能。\n1）模块拓扑：所提出的注意力引导解码器的基本拓扑基于FCN [2]中提出的特征融合。从网络解码器最深三层提取的特征表示被馈送到该模块。由于特征图的空间大小不同，因此首先执行线性插值以对特征图进行上采样。然后对特征进行压缩，抑制通道维度中的不相关信息，降低计算成本。然后将压缩后的特征分别在通道维度上连接起来以进行特征融合。(torch.cat) 最后，融合三个特征图以获得最终的预测。\n为了简单起见，我们使用 2D 分割来说明注意力图的计算。我们使用 Xi ∈ R Ci × Hi × Wi,i ∈ (3, 4, 5) 表示从网络编码器提取的特征图，其中 X5 表示最深的特征。特征压缩和融合计算如下：\n其中Z5 ∈ R C4 × H4 × W4表示X5和X4的融合特征，Z4 ∈ R C3 × H3 × W3表示X4和X3的融合特征，Wc5 ∈RC5×C4和Wc4 ∈RC4×C3表示相应的压缩卷积， W4 ∈ RC4×C4 表示融合 X5 和 X4 的融合卷积，⊕ 表示特征串联。\n注意力引导解码器的输出计算如下：\n其中 W3 ∈ R C3×C3 表示融合 X4 和 X3 的融合卷积，Wout ∈ R C3 × 1 表示输出卷积，σ 分别表示 Sigmoid 激活。\n2）中间监督：计算机视觉中的传统注意力机制自动生成注意力图，但注意力生成的过程通常是人类无法解释的，并且网络关注的区域可能与人类关注的区域不同。\n这种差距会限制注意力机制的性能和可解释性，有时还会导致网络容量的恶化。为了解决这些问题，我们在网络中引入了中间监督策略。在遵循从粗到细的方式的多病灶分割任务中，我们首先生成一个二元Ground Truth，其中前景表示所有类型的病灶，背景表示其他一切。在具有 C 种病变的多病变分割任务中，我们使用 Gi,i ∈ (1,\u0026hellip;,C) 表示第 i 类病变的二元基本事实，其中前景表示特定病变背景代表其他一切。二进制真实值 Gb 计算如下：\n然后利用二元损失函数来计算二元真实值 yb 和注意力引导解码器生成的注意力图 Y 之间的二元损失 l：\n其中 Lb 表示二元损失函数。然后利用计算出的损失 l 来监督注意力引导解码器的参数更新。\n这个地方的中间监督主要是 要让中间的注意力机制起作用，不能随便生成。\n通过引入中间监督，生成的注意力由输入图像的二元真实值进行监督。这样，网络被迫学习多病灶分割任务的分解，即首先提取病灶区域，然后对病灶区域进行细粒度分类。这种分解降低了多病灶分割的难度，并且与当前在“黑匣子”中生成注意力的基于注意力的医学分割方法相比，具有更好的可解释性。\n3.3 Parameterized Skip Connections 跳跃连接已广泛应用于流行的卷积网络中，包括U-Net [3]、ResNet [24]等。受[11]的启发，我们建议将注意力图集成到连接网络编码器和多网络的跳跃连接中，形成多级解码器。在跳跃连接中，我们还引入了额外的残差路径来恢复普通特征图并进一步提高分割性能。与传统的残差路径相比，残差路径的幅值因子αi,i ∈ (1, 2,…, 5)被设置为网络的可学习参数，并在反向传播过程中更新。我们相信这样的设置可以为网络增加额外的非线性能力并增强跳过连接的有效性。\n我们使用 Fi,i ∈ (1, 2,\u0026hellip;, 5) 表示来自网络编码器的普通特征图，Y 表示注意力图，精炼后的特征图 Fri,i ∈ (1, 2,. .., 5) 多类解码器接收的信息计算如下：\n然后将细化的特征图发送到多类解码器以进行最终的多类预测。\n3.4 Multi-Class Decoder With Deep Supervision U形分割网络中的解码器用于接收编码器发送的特征图，随着解码器中的特征通道数量的减少和空间分辨率的增加，分割性能逐步细化。然而，随着网络变深，最深的解码器块变得难以训练，这可能会限制最终的分割性能。深度监督策略已经被提出来训练深度卷积网络[25]、[26]。在所提出的先验注意网络中，辅助预测是从不同级别的解码器块中提取的，并使用相同的基本事实进行监督。我们使用 Pi,i ∈ (1, 2, 3) 表示来自多类解码器的辅助预测，Pm 表示最终的多类预测，g 表示真实值，Lm 表示多类损失函数。最终的多类损失计算如下：\n所提出的多类解码器的解码器块也与当前网络设置具有共同的设置，即卷积层、归一化层和非线性激活单元的堆栈。\n总结一下：\n① 注意力机制 + 中间监督：最后三层特征融合 + 这一部分做深度监督（原来这样也叫创新）\n② 跳跃连接的部分加了一个α因子 （感觉像权重一样的东西 ）\n③ 多阶段的深度监督 （这个就算一个trick吧，大家都在用）， 不过这里变成了多类别\nExperiments 4.1 Strong Baselines and Evaluation Metrics 为了研究网络架构的性能差异，我们将所提出的先验注意网络与医学分割中最流行的方法进行了比较，包括 U-Net [3]、Attention U-Net [11] 和级联 U-Net，在两个 2D 中和 3D 分割任务。值得注意的是，与他们论文中提出的原始版本相比，基线方法根据网络拓扑方面的某些任务进行了修改和优化，以获得性能提升。我们将残差连接[24]、批量归一化[30]和来自 ImageNet 的预训练编码器引入到 2D COVIDlesion 分割任务的基线方法中，并且我们还将残差连接、实例归一化和 PReLU 激活引入到 3D 脑肿瘤分割任务中。除了网络拓扑之外，基线方法与所提出的先验注意网络共享相同的数据增强和训练配置。\n对于 COVID-19 病变的 2D 分割，我们使用 Dice 指数、精度分数和召回分数来评估所提出的网络的性能。 Dice指数是一种用来衡量两个样本相似度的统计量，已广泛用于分割算法的评估。精确率衡量的是实际正确的阳性识别的比例，召回率衡量的是算法对阳性样本的敏感度。对于 BraTS 2020 挑战赛的 3D 分割，在在线门户上进行评估，并根据 Dice 指数和 95% Hausdorff 距离（HD）对算法进行排名。\n我们使用 G 表示ground truth，P 表示密集预测，TP 表示正确预测的正样本，FP 表示错误预测的正样本，TN 表示正确预测的副样本，FN 表示错误预测的副样本。这些指标的计算方式如下：\n这个HD（Hausdorff ）也是一种评估分割结果的方式 （alright 又多了一种指标）\n4.2 肺部 CT 切片中的 COVID-19 病灶的 2D 多病灶分割 1）数据：由于可用的开源COVID-19 CT分割数据集通常很小，因此利用两个独立的公开可用数据集，即COVID-19 CT分割数据集[27]和CC-CCII数据集[28]来验证所提出的方法二维分割任务中的方法。第一个数据集包含来自 40 多名患者的 100 个轴向 CT 切片，这些切片已重新缩放至 512 × 512 像素并进行灰度化。所有切片均由放射科医生用不同的标签进行分割，以识别不同类型的肺部感染。第二个数据集由 150 名 COVID-19 患者的 750 张 CT 切片组成，这些切片被手动分割为背景、肺野、毛玻璃混浊和实变。由于并非所有 750 个切片都包含病变，我们最终使用了 150 名患者的 549 个带注释的切片。对于这两个数据集，利用 5 倍交叉验证来评估所提出模型的性能。\n折叠之间的数据根据患者进行分割，以避免潜在的数据泄漏。最终的标签和分割图包含 3 个类别，包括背景、毛玻璃不透明度 (GGO) 和合并 (CON.)。\n2）实现细节：a）模型设置和损失函数：对于预训练网络编码器，我们采用来自ImageNet的预训练ResNeXt-50（32 × 4d）[31]作为基线方法和所提出的先验注意网络的编码器。对于解码器中的上采样，采用双线性插值，比例因子为2。对于中间监督和级联U-Net第一阶段的二元损失函数，我们采用Dice Loss [13]和Focal的线性组合损失[32]作为损失函数。对于最终输出的多类损失函数，我们采用Focal Tversky Loss [33]作为损失函数。\nb) 训练细节：我们的模型是在 Ubuntu 16.04 服务器上使用 PyTorch 1.7.1 框架实现的。我们使用 NVIDIA RTX 2080 Ti GPU 来加速我们的训练过程。在我们的训练过程中使用Albumentations [34] 进行数据增强，以减少过度拟合并提高泛化能力。首先，将所有输入图像重新缩放为 560 × 560，然后进行随机亮度和对比度偏移以及随机仿射变换。然后将图像随机裁剪为 512 × 512，然后进行随机弹性变换，最后输入网络。该模型由 Adam 优化器优化，β1 = 0.9、β2 = 0.999、γ = 1e − 8。L2 正则化也用于减少过度拟合。我们将模型权重衰减设置为 1e − 5。初始学习率设置为 1e −4 并降低，然后采用余弦退火策略。批量大小设置为 4，模型训练 40 轮。该模型使用 5 倍交叉验证进行评估。\n3）定量结果：我们在两个数据集上的实验中不同模型的详细比较分别如表一和表二所示。如图所示，我们提出的网络在毛玻璃不透明度和固结的 Dice 分数方面优于 U-Net、Attention U-Net。所提出的 PANet 以更少的参数和计算成本实现了与级联 U-Net 竞争的结果。由于这些模型在模型主干和训练策略上是相同的，很明显，所提出的注意力引导解码器、中间监督和深度监督的组合对分割性能有很大贡献。注意力引导解码器的利用有助于模型更准确地检测感染组织并生成与感染相关的注意力图，从而有利于解码器中的多类分割。\n此外，中间监督和深度监督的引入促进了网络的收敛，这也有助于提高性能。\n好好好，这哥们儿，睁着眼睛说瞎话是吧（这Unet明明比你低啊，精度也没差多少啊）\n4）定性结果：不同模型在 2D COVID-19 切片上的视觉比较如图 4 所示。由于模型在 Dice 分数方面非常接近，因此乍一看这些模型的表现相似。但与 U-Net 和 Attention U-Net 相比，所提出的 PANet 在实变和微小病变的分割上表现更好。\n与 U-Net 和 Attention U-Net 相比，PANet 产生更准确的分割掩模，并且与 Cascaded U-Net 相比，所提出的网络以更少的计算成本实现了有竞争力的结果。\n额 只要定量结果上去了，好像定性结果都是挑好的说吧？\n) 消融实验：进行了几次消融实验来评估我们模型中组件的性能，如表 III 所示。 a）具有深度监督的多类解码器的有效性：为了探索深度监督策略的贡献，我们建立了两个实验：No.1（U-Net）和No.2（U-Net + DS）。表三的结果表明，深度监督在一定程度上对绩效有所贡献。\nb）注意力引导解码器的有效性：我们通过构建实验 3（U-Net + AGD w/o IS）来研究所提出的网络中所提出的注意力引导解码器的有效性。如表III所示，与实验1相比，注意力引导解码器的引入提供了显着的性能提升。这表明注意力引导解码器在所提出的网络中提供了有效的注意力图，从而指导解码器中的多类分割。\nc）参数化跳跃连接的有效性：为了探索所提出的参数化跳跃连接的有效性，我们建立了两个实验4（U-Net + AGD*）和5（U-Net + AGD）。引入参数化跳跃连接后，分割性能得到了提高，几乎没有额外的参数或计算成本。\nd）中间监督的有效性：为了研究所提出的 PANet 中中间监督策略的有效性，我们比较了第 3 号（U-Net + AGD w/o IS）和第 5 号（U-Net + AGD）。如表 III 所示，与第 3 种相比，具有中间监督的网络获得了额外的改进。此外，在比较第 6 种（U-Net + DS + AGD w/o IS）和第 7 种（PANet）时也可以观察到改进。 ）尽管改进相对较小。可以看出，深度监管的引入也对绩效产生了提升，因此中级监管对绩效的提升并不像以前那么显着。\n4.3 3D Multi-Lesion Segmentation of Brain Tumor From Multi-Modality Brain MRIs 1）数据：我们使用来自 BraTS 2020 挑战赛的开源多模态 MRI 数据集 [29]、[36] [37]。训练集由 369 个多对比 MRI 扫描组成，其中每个扫描包含四种模式，即原生 T1 加权、对比后 T1 加权 (T1Gd)、T2 加权 (T2) 和 T2 流体衰减反转恢复 (FLAIR) ）。\n每次扫描都有相应的 4 类标签：背景（标签 0）、GD 增强肿瘤（ET，标签 4）、瘤周水肿（ED，标签 2）以及坏死和非增强肿瘤核心（NET/ NCR，标签 1)。验证集由 125 个多重对比 MRI 扫描组成，其模式与训练集和隐藏的基本事实相同。所有 MRI 扫描均去除颅骨，与相同的大脑模板 (SRI24) 对齐，并插值至 1mm3 分辨率。验证阶段通过在线门户进行，算法根据 3 个重叠肿瘤区域的性能进行排名，即增强肿瘤 (ET)、肿瘤核心 (ET + NET/NCR) 和整个肿瘤 (ET) + NET/NCR + ED）\n2）实现细节：a）模型设置和损失函数：对于3D分割，由于缺乏开源预训练编码器，所有模型都是从头开始训练的。下采样通过跨步 3 × 3 × 3 填充卷积执行，上采样通过三线性插值实现。为了进一步提高在BraTS数据集上的性能，我们采用基于区域的训练策略（直接在重叠区域而不是独立标签上优化）并增强肿瘤抑制（如果增强肿瘤的预测体积为，则用坏死替换预测的增强肿瘤）小于某个阈值）在训练过程中。对于损失函数，我们采用 Dice Loss [13] 和 Cross Entropy Loss 的线性组合作为网络中二分类和多分类阶段的损失函数。\nb) 训练细节：我们的模型是在 Ubuntu 服务器上使用 PyTorch 1.7.1 框架实现的。由于3D分割的训练，尤其是级联U-Net对显存的要求较高，因此我们使用NVIDIA RTX 2080 Ti GPU和NVIDIA RTX 3090 GPU分别训练单个模型和级联模型。\n由于训练过程的显存占用大于11Gb，我们采用PyTorch框架提供的原生混合精度训练程序来节省显存使用并加速训练过程。人工智能医学开放网络（MONAI）项目[38]和TorchIO[39]分别用于训练和推理阶段的数据加载过程。数据增强是在训练过程中通过 MONAI 项目进行的。\n首先，分别使用 z 分数标准化对所有模态进行标准化。然后通过随机翻转、随机强度偏移、随机强度缩放和弹性变换来增强图像。最后，我们将图像块随机裁剪为 128 × 128 × 128 并将其输入网络。对于推理，我们还采用基于补丁的推理管道来生成 BraTS 2020 验证集的预测。面片大小设置为 128 × 128 × 128，面片之间的重叠设置为 75%。重叠区域中的预测是重叠块的平均值。这种重叠配置可以被视为自集成并产生更好的分割性能。对于模型评估，我们进行了 2 个单独的评估程序来比较分割模型的性能。首先，我们对 BraTS 2020 训练集进行 5 倍交叉验证，以比较离散区域（增强肿瘤、瘤周水肿和非增强肿瘤核心）上的分割性能。然后，我们对 BraTS 2020 验证集进行评估，以比较重叠区域（增强肿瘤、肿瘤核心和整个肿瘤）的分割性能，其中我们可以将所提出的方法与最先进的方法进行比较BraTS 挑战。\n3）定量结果：BraTS 2020 训练集的交叉验证性能已在表 IV 中报告。\n所提出的 PANet 在 Dice 分数和 Hausdorff 距离方面优于所有其他网络。此外，我们还在 BraTS 2020 验证集上对训练后的模型进行了验证。通过这种方式，我们还将所提出的网络与模态配对学习（BraTS 2020 中的 Top-2 解决方案）[35] 和研究中的 Transformer TransBTS [23] 进行了比较，除了基于 U 的常用网络之外-网。\n性能列于表五中。我们提出的 PANet 在 BraTS 2020 验证集上优于 U-Net、Attention U-Net、级联 U-Net 和 TransBTS。此外，所提出的 PANet 在 BraTS 2020 上实现了与 Top2 解决方案类似的 Dice 分数，并且具有更好的 Hausdorff 距离。另外，值得注意的是，与 U-Net 相比，所提出的 PANet 仅增加了 3.9% 的额外 GFlops，并且以更少的计算成本实现了比级联 U-Net 更好的性能。这些结果表明，所提出的先验注意网络在 BraTS 2020 数据集上的分割性能和计算效率之间取得了复杂的平衡。\n4）定性结果：我们可视化具有不同分割难度的 3 幅 MRI 图像，以展示不同模型的性能。对于最简单的情况（BraTS20_Validation_077），所有模型都能够分割病变，而所提出的 PANet 获得最高的分割 Dice 分数。对于有一定难度的病例（BraTS20_Validation_028），Attention U-Net和级联U-Net在水肿分割方面都产生了严重的误报，导致整个肿瘤的Dice评分较低。对于最难的情况（BraTS20_Validation_076），由于增强肿瘤的假阳性分割，U-Net、Attention U-Net 和级联 U-Net 的性能并不乐观，而所提出的 PANet 产生了最好的分割性能。所提出的 PANet 的成功归功于具有中间监督的注意力引导解码器，特征图通过空间注意力图进行细化，这可以防止潜在的误报预测。\n关于医学影像中的轴位面（横断面）、冠状面、矢状面的解释\n1.冠状面 （Coronal），又称额状面。即从左右方向，沿人体的长轴将人体纵切为前、后两部分的切面。这种提法只是为了在临床中将器官位置描述的更具体，英文名称是：Coronal section；\n2.矢状面 (Sagittal)就是把人体分成左右两面的解剖面，于这个面平行的也是矢状面。出于这个位置的叫矢状位。矢状位的英文名称是：Median sagittal section；\n3.水平位 (Axial)又称横断位，即左右、前后构成的面为水平位，英文名称是:Transverse section。\n5）消融分析：在 BraTS 2020 验证数据集上也进行了与 2D 分割类似的消融实验，以评估我们模型中呈现的组件的有效性，如表六所示。\na）具有深度监督的多类解码器的有效性：我们通过向网络解码器引入深度监督来构建实验2（U-Net + DS）。与基线（No.1）相比，实验No.2在增强肿瘤、肿瘤核心和整个肿瘤的分割性能方面提供了一定程度的性能提升。此外，当引入注意力引导解码器时，可以观察到性能的提高（第3和第6）。\nb) 注意力引导解码器的有效性：我们构建实验 3（U-Net + AGD w/o IS）来研究所提出的网络中注意力引导解码器的有效性。与基线相比，注意力引导解码器在增强肿瘤和肿瘤核心的分割性能方面产生了显着的改善。这表明注意力引导解码器对从编码器提取的特征图产生有效的注意力，从而更容易区分病变。\nc）参数化跳跃连接的有效性：我们建立了两个实验No.4（U-Net + AGD*）和No.5（UNet + AGD）来探索所提出的参数化跳跃连接的有效性。引入参数化跳跃连接后，在增强肿瘤和肿瘤核心方面分割性能有所提高，但整个肿瘤的分割性能略有下降。\nd）中间监督的有效性：我们通过比较表六中的第3号和第5号来调查中间监督策略的有效性。在No.5（U-Net + AGD）中，通过引入中间监督，增强肿瘤和肿瘤核心的Dice得分显着提高。但是当引入深度监督时，中间监督的性能提升并不像以前那么显着（第6和第7），这与2D分割情况类似。\nDISCUSSION AND CONCLUSION 多病灶分割在临床场景中具有重要意义，因为某种疾病可能同时发生多种类型的感染，不同感染阶段的患者可能会出现不同类型的病灶。例如，磨玻璃样混浊（GGO）和实变（CON.）是COVID-19患者典型的肺部病变，前者通常发生在早期患者，而后者的增加可能表明病情恶化。胶质瘤可分为低级别胶质瘤（LGG）和胶质母细胞瘤，即高级别胶质瘤（GBM/HGG），并且在发生HGG的患者中更有可能发现强化肿瘤。因此，多病灶分割在患者的筛查和预后方面具有巨大的潜力。\n多病灶分割问题可以分解为粗分割和细分割，粗分割是对病灶进行粗略分割，而细分割则基于前一分割，以产生最终的分割图。级联网络广泛用于多病变分割任务，因为这些算法背后的逻辑非常自然。然而，级联网络在潜在的临床部署中受到限制，因为它们缺乏灵活性并且对计算资源的要求很高。与现有的级联网络相比，我们开发了一种先验注意网络，它将粗分割和细分割集成到一个网络中。我们提出的网络架构的优点是分割性能和计算效率的平衡。通过将分割的两个步骤结合在一个网络中，所提出的先验注意网络能够实现多病灶分割的端到端训练，在训练和推理方面都具有更大的灵活性，并且在临床部署中具有更大的潜力。此外，我们设法保持所提出的先验注意网络的性能，在分割性能和运行效率之间实现复杂的平衡。\n与级联 U-Net 相比，我们提出的先验注意力网络在 2D 和 3D 任务中都实现了更好的性能和效率，如图 6 所示。\n总之，我们提出了一种新颖的分割网络，即先验注意网络，用于医学图像中的多病灶分割。受流行的从粗到细策略的启发，我们通过空间注意机制将级联网络的两个步骤聚合成一个网络。此外，我们引入了一种新颖的中间监督机制来指导与病变相关的注意图的生成，这可以指导解码器中的后续多类分割。所提出的网络在 2D 和 3D 医学图像（包括 CT 扫描和多模态 MRI）上进行评估。对于 2D 分割，与级联 U-Net 相比，所提出的先验注意力网络以更少的计算成本获得了有竞争力的结果。对于 3D 脑肿瘤分割，所提出的先验注意网络在 BraTS 2020 验证数据集上产生了最先进的性能，并且优于基于 U-Net 的其他基线方法。实验结果表明，该方法在医学影像中的许多多病灶分割任务中具有巨大的应用潜力，与二元分割相比可以提供更多信息，并有助于医生未来的临床诊断。\n","permalink":"https://swimmingliu.cn/posts/papernotes/2022-priorattentionnetwork/","summary":"\u003ch1 id=\"prior-attention-network-用于医学图像中多病灶分割的预先注意网络\"\u003ePrior Attention Network: 用于医学图像中多病灶分割的预先注意网络\u003c/h1\u003e\n\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e医学图像中邻近组织的多种类型病变的准确分割在临床实践中具有重要意义。基于从\u003cstrong\u003e粗到精策略的卷积神经网络（CNN）\u003cstrong\u003e已广泛应用于该领域。然而，由于\u003c/strong\u003e组织的大小、对比度和高类间相似性的不确定性\u003c/strong\u003e，多病灶分割仍然具有挑战性。此外，\u003cstrong\u003e普遍采用的级联策略\u003c/strong\u003e对\u003cstrong\u003e硬件要求较高\u003c/strong\u003e，限制了临床部署的潜力。为了解决上述问题，我们提出了一种新颖的先验注意网络（PANet），它\u003cstrong\u003e遵循从粗到细的策略\u003c/strong\u003e来在医学图像中执行多病灶分割。所提出的网络通过在网络中\u003cstrong\u003e插入与病变相关的空间注意机制\u003c/strong\u003e，在单个网络中实现了\u003cstrong\u003e两个步骤的分割\u003c/strong\u003e。此外，我们还提出了\u003cstrong\u003e中间监督策略\u003c/strong\u003e，用于\u003cstrong\u003e生成与病变相关的注意力\u003c/strong\u003e来获取\u003cstrong\u003e感兴趣区域（ROI）\u003c/strong\u003e，这加速了收敛并明显提高了分割性能。我们在两个应用中研究了所提出的分割框架：\u003cstrong\u003e肺部 CT 切片\u003c/strong\u003e中多发性\u003cstrong\u003e肺部感染的 2D 分割\u003c/strong\u003e和\u003cstrong\u003e脑 MRI 中多发性病变的 3D 分割\u003c/strong\u003e。实验结果表明，与级联网络相比，在 2D 和 3D 分割任务中，我们提出的网络以更少的计算成本实现了更好的性能。所提出的网络可以被视为 2D 和 3D 任务中多病灶分割的通用解决方案。源代码可在 \u003ca href=\"https://github.com/hsiangyuzhao/PANet\"\u003ehttps://github.com/hsiangyuzhao/PANet\u003c/a\u003e 获取\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e问题导向：\u003c/p\u003e\n\u003cp\u003e①\u003cstrong\u003e组织的大小、对比度和高类间相似性的不确定性\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e②多类别病灶分割\u003c/p\u003e\n\u003cp\u003e③\u003cstrong\u003e普遍采用的级联策略\u003c/strong\u003e对\u003cstrong\u003e硬件要求较高\u003c/strong\u003e\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e医学图像分割对于疾病的准确筛查和患者的预后具有重要意义。基于病灶分割的病灶评估提供了疾病进展的信息，帮助医生提高临床诊断和治疗的质量。然而，手动病变分割相当主观且费力，这限制了其潜在的临床应用。近年来，随着人工智能的快速发展，基于深度学习的算法得到了广泛的应用，并在医学图像分割方面取得了最先进的性能[1]\u003c/strong\u003e。卷积神经网络（CNN）由于其高分割质量而在医学图像中的病变分割中很受欢迎。此类算法通常具有\u003cstrong\u003e深度编码器\u003c/strong\u003e，可从输入图像中自动提取特征，并通过以下操作\u003cstrong\u003e生成密集预测\u003c/strong\u003e。例如，Long等人[2]提出了一种用于图像语义分割的全卷积网络，该网络颇具影响力，并启发了后来的医学分割中的端到端框架。 Ronneberger等人[3]提出了一种用于医学图像分割的U形网络（U-Net），该网络在医学分割的许多领域都显示出了可喜的结果，并已成为许多医学分割任务的虚拟基准。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e这一段都可以当成经典医学图像分割的背景引入\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e然而，尽管医学分割取得了这些突破，但目前的\u003cstrong\u003e医学分割方法主要集中在病灶的二元分割上\u003c/strong\u003e，即\u003cstrong\u003e区分病灶（前景）和其他一切（背景）\u003c/strong\u003e。尽管二元分割确实有助于\u003cstrong\u003e隔离某些感兴趣区域\u003c/strong\u003e并允许对\u003cstrong\u003e医学图像进行精确分析\u003c/strong\u003e，但在某些需要\u003cstrong\u003e对病变进行多类分割的场景中，二元分割还不够\u003c/strong\u003e。与二元分割相比，由于\u003cstrong\u003e组织的类间相似性，这种情况要困难得多\u003c/strong\u003e，因为\u003cstrong\u003e不同类型的病变在纹理、大小和形状上可能相似\u003c/strong\u003e。具有从粗到细策略的级联网络已广泛应用于此类场景，例如\u003cstrong\u003e肝脏和病变的分割、脑肿瘤分割\u003c/strong\u003e[4]、[5][6]、[7]。\u003c/p\u003e\n\u003cp\u003e此类网络通常由两个独立的网络组成，其中第一个\u003cstrong\u003e网络执行粗分割，第二个网络基于从第一个网络分割的 ROI 细化分割\u003c/strong\u003e。然而，尽管\u003cstrong\u003e级联网络\u003c/strong\u003e已广泛应用于医学图像的\u003cstrong\u003e多病灶分割\u003c/strong\u003e，但级联策略也有其缺点。由于\u003cstrong\u003e级联网络由两个独立的网络组成\u003c/strong\u003e，\u003cstrong\u003e参数量和显存占用通常是单个网络的两倍\u003c/strong\u003e，这对硬件要求较高，限制了其在临床使用的潜力。更重要的是，由于级联网络中的两个网络通常是独立的，因此\u003cstrong\u003e级联网络的训练过程有时比单个网络更困难\u003c/strong\u003e，这可能导致欠拟合。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e级联网络：参数量大、容易欠拟合。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e在本文中，我们提出了一种名为先验注意网络（PANet）的新型网络结构，用于在医学图像中执行\u003cstrong\u003e多病灶分割\u003c/strong\u003e。所提出的网络由\u003cstrong\u003e一个\u003c/strong\u003e用于\u003cstrong\u003e特征提取的编码器\u003c/strong\u003e和\u003cstrong\u003e两个分别生成病变区域注意力和最终预测的解码器组成\u003c/strong\u003e。该网络与\u003cstrong\u003e注意力机制\u003c/strong\u003e结合在一起。为了\u003cstrong\u003e减少参数大小和硬件\u003c/strong\u003e占用，我们使用\u003cstrong\u003e网络编码器的深层、语义丰富的特征\u003c/strong\u003e来\u003cstrong\u003e生成病变区域的空间注意力\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e然后，\u003cstrong\u003e编码器生成的特征\u003c/strong\u003e表示通过\u003cstrong\u003e空间注意力\u003c/strong\u003e进行细化，并将其发送到解码器以进行\u003cstrong\u003e最终的多类预测\u003c/strong\u003e。为了\u003cstrong\u003e提高分割性能并加速收敛\u003c/strong\u003e，我们还在网络结构中引入了\u003cstrong\u003e中间监督和深度监督\u003c/strong\u003e。通过这些改进，与传统的级联网络相比，所提出的网络以\u003cstrong\u003e显着降低的参数大小和计算成本\u003c/strong\u003e实现了有竞争力的结果。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e利用网络编码器的深层、特征信息来生成空间注意力（WTF ???）\u003c/p\u003e\n\u003cp\u003e中间监督、深度监督 （不错不错， 好多一区和顶会的文章都用深度监督）\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e这项工作的贡献体现在三个方面。\u003cstrong\u003e首先\u003c/strong\u003e，我们提出了一种新颖的网络架构，通过将传统级联网络中的两个分割步骤结合在\u003cstrong\u003e单个网络\u003c/strong\u003e中，遵循 2D 和 3D 医学图像中多病灶分割的\u003cstrong\u003e从粗到细的策略\u003c/strong\u003e。与级联网络相比，所提出的架构以更少的额外计算成本实现了有竞争力的分割性能，更容易训练和部署到生产环境。\u003cstrong\u003e其次\u003c/strong\u003e，我们提出了一种\u003cstrong\u003e监督空间注意力机制\u003c/strong\u003e，将\u003cstrong\u003e病变区域的注意力与网络提取的特征相结合\u003c/strong\u003e，将多病变分割分解为\u003cstrong\u003e两个更容易的阶段\u003c/strong\u003e，并且与当前\u003cstrong\u003e基于注意力的方法相比具有更好的可解释性\u003c/strong\u003e。\u003cstrong\u003e第三\u003c/strong\u003e，所提出的网络已在两个实际应用中得到验证，\u003cstrong\u003e包括肺部 CT 切片中的 COVID-19 病变的 2D 分割和多模态 MRI 中的脑肿瘤的 3D 分割\u003c/strong\u003e。所提出的网络在 2D 和 3D 任务中都优于前沿方法，并且在参数和计算成本方面比当前网络更高效。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e一个网络、监督空间注意力机制、参数和计算成本方面比当前网络更高效。\u003c/p\u003e\n\u003ch2 id=\"related-work\"\u003eRelated Work\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e1）图像分割的网络结构：用于图像分割的典型卷积神经网络通常由一个卷积特征提取器组成，其拓扑类似于常见的分类网络，自动从输入图像中提取特征，并进行基于卷积的操作以生成最终的密集预测。在自然图像分割领域，FCN [2]、DeepLab [8]、PSPNet [9] 和 SegNet [10] 因其性能和效率而颇受欢迎。对于医学分割，U-Net [3] 在许多任务中相当流行，并且已被修改为许多改进版本，例如 Attention U-Net [11]、U-Net++ [12]、V-Net [13] 和H-DenseUNet [14]在某些领域获得更好的性能。\u003c/p\u003e","title":"Prior Attention Network: 用于医学图像中多病灶分割的预先注意网络"},{"content":"地大服务器使用教程 1. 服务器环境介绍 NVIDIA RTX 3090 (24GB) NVIDIA RTX 2080 Ti (11GB) 2. 配置实验环境 2.1 Conda环境安装 每位同学都会分配个人用户，大家在自己的用户上使用Conda进行环境配置。\nConda安装教程：https://blog.csdn.net/JineD/article/details/129507719\n大家按照教程步骤安装即可, 由于安装时间较长, 视频中暂不进行演示。\n2.2 Conda环境配置 （以YOLOv8为例） # 创建conda环境 名为yolov8_lyj python版本为3.9 conda create -n yolov8_lyj python=3.9 # 激活环境 conda activate yolov8_lyj # 选择合适的路径，克隆github项目代码 git clone https://github.com/ultralytics/ultralytics # 进入到项目路径下 cd ultralytics/ # 安装相关依赖包 pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple 2.3 准备数据集 下载需要训练的数据集 （最好找顶刊/顶会论文中的公开数据集）\n按照算法指定的数据集格式，对数据集格式进行调整。\n​\t目标检测中数据集格式之间的相互转换：（VOC、COCO、YOLO格式）\n​\thttps://zhuanlan.zhihu.com/p/461488682\n2.4 开始实验 在算法中指定数据集的存放路径 （相对/绝对路径均可）\n初始化算法的参数\nbatch-size 批处理大小：每一次处理图片的个数，根据显卡内存进行调整\repochs\t迭代次数：算法总共需要训练的轮次\rworkers 载入数据进程数：每一次调用多少个进程来载入数据\rdevice 选择显卡设备： \u0026#39;0\u0026#39;使用3090，\u0026#39;1\u0026#39;使用2080ti，\u0026#39;0,1\u0026#39;使用两张卡 开始训练 # 运行训练代码 python mian.py (注：使用向日葵的同学，可以直接在Pycharm当中运行)\n3. 注意事项 1. 查看显卡使用情况 两种办法：\n# 第一种 使用nivida驱动直接查看\rnvidia-smi\r# 第二种 使用第三方库 gpustat动态查看\r# 先安装第三方库\rpip install gpustat -i https://pypi.tuna.tsinghua.edu.cn/simple\r# 每两秒刷新一次 动态查看显存使用情况\rwatch -n2 gpustat 2. Magic Network 使用向日葵的同学，可以使用Magic Network进行github仓库克隆、google网盘数据集下载等\n使用方法：\nexport http_proxy=http://127.0.0.1:7890\rexport https_proxy=http://127.0.0.1:7890 预祝大家科研顺利，硕果累累，offer拿到手软！！！\n博客地址： SwimmingLiu.cn\n","permalink":"https://swimmingliu.cn/posts/diary/2023-%E5%9C%B0%E5%A4%A7%E6%9C%8D%E5%8A%A1%E5%99%A8/","summary":"\u003ch1 id=\"地大服务器使用教程\"\u003e地大服务器使用教程\u003c/h1\u003e\n\u003ch2 id=\"1-服务器环境介绍\"\u003e1. 服务器环境介绍\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eNVIDIA RTX \u003cspan class=\"m\"\u003e3090\u003c/span\u003e \u003cspan class=\"o\"\u003e(\u003c/span\u003e24GB\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eNVIDIA RTX \u003cspan class=\"m\"\u003e2080\u003c/span\u003e Ti \u003cspan class=\"o\"\u003e(\u003c/span\u003e11GB\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cimg alt=\"image-20231120113601423\" loading=\"lazy\" src=\"https://oss.swimmingliu.cn/HoBnO.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"2-配置实验环境\"\u003e2. 配置实验环境\u003c/h2\u003e\n\u003ch3 id=\"21-conda环境安装\"\u003e2.1 Conda环境安装\u003c/h3\u003e\n\u003cp\u003e每位同学都会分配个人用户，大家在自己的用户上使用Conda进行环境配置。\u003c/p\u003e\n\u003cp\u003eConda安装教程：https://blog.csdn.net/JineD/article/details/129507719\u003c/p\u003e\n\u003cp\u003e大家按照教程步骤安装即可, 由于安装时间较长, 视频中暂不进行演示。\u003c/p\u003e\n\u003ch3 id=\"22-conda环境配置-以yolov8为例\"\u003e2.2 Conda环境配置 （以YOLOv8为例）\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 创建conda环境 名为yolov8_lyj python版本为3.9\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003econda create -n yolov8_lyj \u003cspan class=\"nv\"\u003epython\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e3.9\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 激活环境\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003econda activate yolov8_lyj\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 选择合适的路径，克隆github项目代码\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003egit clone https://github.com/ultralytics/ultralytics\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 进入到项目路径下\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003ecd\u003c/span\u003e ultralytics/\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 安装相关依赖包\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003epip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"23-准备数据集\"\u003e2.3 准备数据集\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e下载需要训练的数据集 （最好找顶刊/顶会论文中的公开数据集）\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e按照算法指定的数据集格式，对数据集格式进行调整。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e​\t\t目标检测中数据集格式之间的相互转换：（VOC、COCO、YOLO格式）\u003c/p\u003e\n\u003cp\u003e​\t\thttps://zhuanlan.zhihu.com/p/461488682\u003c/p\u003e\n\u003ch3 id=\"24-开始实验\"\u003e2.4 开始实验\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e在算法中指定数据集的存放路径 （相对/绝对路径均可）\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e初始化算法的参数\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ebatch-size  批处理大小：每一次处理图片的个数，根据显卡内存进行调整\r\nepochs\t   迭代次数：算法总共需要训练的轮次\r\nworkers     载入数据进程数：每一次调用多少个进程来载入数据\r\ndevice      选择显卡设备： \u0026#39;0\u0026#39;使用3090，\u0026#39;1\u0026#39;使用2080ti，\u0026#39;0,1\u0026#39;使用两张卡\n\u003c/code\u003e\u003c/pre\u003e\u003col start=\"3\"\u003e\n\u003cli\u003e开始训练\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 运行训练代码\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003epython mian.py\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e(注：使用向日葵的同学，可以直接在Pycharm当中运行)\u003c/p\u003e","title":"地大服务器使用教程"},{"content":"ACC-UNet: A Completely Convolutional UNet model for the 2020s (MICCAI2023) 1. Abstract 由于ViT （Vision Transformer）的引入，UNet和Transformer融合已成为大趋势。最近，又有很多研究人员开始重新思考卷积模型，比如将ConvNext嵌入到ResNet，能够达到Swin Transformer的水平。受此启发，作者提出了一个纯粹的卷积UNET模型 （ACC-UNet），并且超越基于Transfomer的模型(如Swin-UNET或UCTransNet)。 作者研究了基于Transfomer的UNET模型优点：长范围依赖关系和跨级别跳过连接。 ACC-UNet结合了卷积神经网络（ConvNets）的内在归纳偏差和Transformer的设计决策 卷积神经网络（ConvNets）的内在归纳偏差：卷积神经网络具有天生的归纳偏差，这意味着它们在处理图像等数据时具有一些固有的假设和特点。例如，卷积神经网络擅长处理局部特征、平移不变性等，这些特点使它们在图像处理任务中表现出色。 Transformer的设计决策：Transformer是一种不同的神经网络架构，它采用了一些独特的设计决策，例如自注意力机制和位置编码等。这些设计决策使得Transformer在处理长距离依赖性、全局关系等方面表现出色，适合处理序列数据和具有远程依赖的任务。 ACC-UNet 在 5 个不同的医学图像分割基准上进行了评估，并且始终优于卷积网络、Transfomer及其混合网络。\n2.Introduction 语义分割是计算机辅助医学图像分析的重要组成部分，可识别并突出显示各种诊断任务中感兴趣的区域。然而，由于涉及图像模态和采集以及病理和生物变化的各种因素，这通常变得复杂[18]。深度学习在这一领域的应用无疑在这方面受益匪浅。最值得注意的是，自推出以来，UNet 模型 [19] 在医学图像分割方面表现出了惊人的功效。结果，UNet 及其衍生品已成为事实上的标准[25]。\n学习一下这里的背景描述\n原始的 UNet 模型包含对称的编码器-解码器架构（图 1a）并采用跳跃连接，这为解码器提供了在编码器的池化操作期间可能丢失的空间信息。尽管通过简单串联的信息传播提高了性能，但编码器-解码器特征图之间可能存在语义差距。这导致了第二类 UNet 的发展（图 1b）。 U-Net++ [26] 利用密集连接，而 MultiResUNet [11] 在跳过连接上添加了额外的卷积块作为潜在的补救措施。到目前为止，UNet 的历史上所有创新都是使用 CNN 进行的。然而，2020 年的十年给计算机视觉领域带来了根本性的变化。 CNN 在视觉领域的长期主导地位被视觉转换器打破了 [7]。 Swin Transformers [15] 进一步针对一般视觉应用调整了变压器。因此，UNet 模型开始采用 Transformer [5]。 Swin-Unet [9] 用 Swin Transformer 块取代了卷积块，从而开创了一类新的模型（图 1c）。尽管如此，CNN 在图像分割方面仍然具有各种优点，导致了融合这两者的发展[2]。这种混合类 UNet 模型（图 1d）在编码器-解码器中采用卷积块，并沿跳跃连接使用变换器层。 UCTransNet [22]和MCTrans[24]是此类的两个代表性模型。最后，还尝试开发全变压器 UNet 架构（图 1e），例如，SMESwin Unet [27] 在编码器-解码器块和跳跃连接中都使用变压器。\n从 UNet出发，然后逐步介绍他的变体（UNet++等）。随后介绍Transformer和UNet的各种结合体，为后续对比实验做铺垫。最后结合一张发展图，简明扼要描述UNet的创新历程。\n最近，鉴于 Transformer 带来的进步，研究开始重新发现 CNN 的潜力。这方面的开创性工作是“A ConvNet for the 2020s”[16]，它探讨了 Transformer 引入的各种想法及其在卷积网络中的适用性。通过逐渐融合训练协议和微观-宏观设计选择的思想，这项工作使 ResNet 模型的性能优于 Swin Transformer 模型。\n在本文中，我们在 UNet 模型的背景下提出了同样的问题。我们研究仅基于卷积的 UNet 模型是否可以与基于 Transformer 的 UNet 竞争。在此过程中，我们从 Transformer 架构中获得动力并开发了纯卷积 UNet 模型。我们提出了一种基于补丁的上下文聚合，与基于窗口的自注意力相反。此外，我们通过融合来自多个级别编码器的特征图来创新跳跃连接。对 5 个基准数据集的广泛实验表明，我们提出的修改有可能改进 UNet 模型。\n通过介绍CONvNet的重要性，引入本文重点 （纯卷积模块的UNet）。\n3. Method 3.1 A high-level view of transformers in UNet Transformers 显然在两个不同方面改进了 UNet 模型:\n1.利用自注意力的远程依赖性: Transformer 可以通过使用（窗口式）自注意力，从更大的上下文视图中计算特征。此外，他们还通过采用反向瓶颈（即增加 MLP 层中的神经元）来提高表达能力。此外，它们包含快捷连接，这有助于学习。 2.通过通道注意力的自适应多级特征组合: 基于 Transformer 的 UNet 使用通道注意力自适应地融合来自多个编码器级别的特征图。与受当前级别信息限制的简单跳跃连接相比，由于来自不同级别的各种感兴趣区域的组合，这会生成丰富的特征。\n主要就两个点：\n自主注意力在UNet的编码和解码阶段都能够快速、准确地根据上下文信息提取特征。\n自注意力机制可以用来连接encoder阶段不同stage的特征图。\n猜想：把新出的自注意力机制加在ACC-Unet是不是也会有提升呢？\n3.2 Hierarchical Aggregation of Neighborhood Context (HANC) 我们首先探索引入远程依赖性并提高卷积块的表达能力的可能性。我们仅使用逐点和深度卷积来降低计算复杂度。为了增加表达能力，我们建议在卷积块中包含反向瓶颈[16]，这可以通过使用逐点卷积将通道数从 cin 增加到 cinv = cin * inv_f ctr 来实现。由于这些额外的通道会增加模型复杂度，因此我们使用3×3深度卷积来补偿。输入特征图 xin ∈ R cin,n,m 被转换为 x1 ∈ R cinv,n,m （图 2b）\n接下来，我们希望在卷积块中模拟自注意力，其核心是将一个像素与其邻域中的其他像素进行比较[15]。通过将像素值与其邻域的平均值和最大值进行比较可以简化这种比较。因此，我们可以通过附加相邻像素特征的平均值和最大值来提供邻域比较的近似概念。因此，连续逐点卷积可以考虑这些并捕获对比视图。\n由于分层分析对图像有益[23]，我们不是在单个大窗口中计算这种聚合，而是在多个级别中分层计算，例如 2 × 2, 2 ^2 × 2^ 2 , · · · , 2^(k− 1) × 2^(k−1) 个补丁。当 k = 1 时，这将是普通的卷积运算，但是当我们增加 k 的值时，将提供更多的上下文信息，从而绕过对更大卷积核的需要。因此，我们提出的分层邻域上下文聚合通过上下文信息丰富了特征图 x1 ∈ R cinv,n,m 作为 x2 ∈ R cinv*(2k−1),n,m （图 2b），其中 ||对应于沿通道维度的串联。\n下面与Transfomer类似，我们在卷积块中包含一个快捷连接，以实现更好的梯度传播。因此，我们执行另一个逐点卷积以减少 cin 的通道数并与输入特征图相加。因此，x2 ∈ R cinv*(2k−1),n,m 变为 x3 ∈ R cin,n,m （图 2b）\n最后，我们使用逐点卷积将滤波器的数量更改为cout作为输出\n\u0026ldquo;inverted bottlenecks\u0026rdquo;（反向瓶颈） ：将Bottleneck放在卷积块的开始，而不是结束。它先使用1x1卷积来减少通道数，然后才是较大的卷积层。\n3.3 Multi Level Feature Compilation (MLFC) 接下来，我们研究多级特征组合的可行性，这是使用基于 Transformer 的 UNet 的另一个优点。\n基于 Transformer 的跳跃连接已经证明了所有编码器级别的有效特征融合以及各个解码器从编译的特征图中进行的适当过滤[24,22,27]。这是通过连接不同级别的投影令牌来执行的[22]。按照这种方法，我们调整从不同编码器级别获得的卷积特征图的大小，以使它们均衡并连接它们。这为我们提供了跨不同语义级别的特征图的概述。我们应用逐点卷积运算来总结这种表示并与相应的编码器特征图合并。整体信息和个体信息的融合通过另一个卷积传递，我们假设它用来自其他级别特征的信息丰富了当前级别特征。\n对于来自 4 个不同级别的特征 x1、x2、x3、x4，特征图可以通过多级信息来丰富（图 2d）\n这里， resizei(xj ) 是将 xj 的大小调整为 xi 的大小且 ctot = c1 + c2 + c3 + c4 的操作。此操作针对所有不同级别单独完成。因此，我们提出了另一个名为多级特征编译（MLFC）的新颖块，它聚合来自多个编码器级别的信息并丰富各个编码器特征图。该块如图 2d 所示。\n总结： 把各stage的特征联合起来进行逐点卷积，然后各stage得到新的特征信息\n3.4 ACC-UNet 因此，我们提出全卷积ACC-UNet（图2a）。我们从普通的 UNet 模型开始，并将滤波器的数量减少了一半。然后，我们用我们提出的 HANC 块替换了编码器和解码器中的卷积块。我们考虑 inv_f ctr = 3，而不是第 3 级的最后一个解码器块 (inv_f ctr = 34)，以模拟 Swin Transformer 第 3 阶段的扩展。 k = 3，最多考虑 4 × 4 个补丁，被选择用于除瓶颈级别 (k = 1) 及其旁边的级别 (k = 2) 之外的所有级别。接下来，我们通过使用残差块（图 2c）来修改跳跃连接以减少语义间隙 [11] 并堆叠 3 个 MLFC 块。所有卷积层均经过批量归一化 [12]，由 Leaky-RELU [17] 激活，并通过挤压和激励 [10] 重新校准。\n总而言之，在 UNet 模型中，我们用我们提出的 HANC 块替换了经典的卷积块，该 HANC 块执行近似版本的自注意力，并修改了与 MLFC 块的跳跃连接，MLFC 块考虑来自不同编码器级别的特征图。所提出的模型有 16.77 M 个参数，比普通 UNet 模型大约增加了 2M。\n4.Experiments 4.1 Datasets 为了评估 ACC-UNet，我们在 5 个跨不同任务和模式的公共数据集上进行了实验。我们使用 ISIC-2018 [6,21]（皮肤镜检查，2594 张图像）、BUSI [3]（乳腺超声，使用类似于 [13] 的 437 张良性图像和 210 张恶性图像）、CVC-ClinicDB [4]（结肠镜检查，612 张图像） ）、COVID [1]（肺炎病灶分割，100 张图像）和 GlaS [20]（腺体分割，85 张训练图像和 80 张测试图像）。所有图像和掩模的大小都调整为224×224。对于GlaS数据集，我们将原始测试分割作为测试数据，对于其他数据集，我们随机选择20％的图像作为测试数据。\n剩余的 60% 和 20% 图像用于训练和验证，并使用不同的随机改组重复实验 3 次。\nISIC-2018、BUSI、 CVC-ClinicDB、COVID、GlaS 五个数据集\n4.2 Comparison Experiments 4.3 Ablation Study 4.4 Qualitative Results ","permalink":"https://swimmingliu.cn/posts/papernotes/2023-acc-unet/","summary":"\u003ch1 id=\"acc-unet-a-completely-convolutional-unet-model-for-the-2020s-miccai2023\"\u003eACC-UNet: A Completely Convolutional UNet model for the 2020s (MICCAI2023)\u003c/h1\u003e\n\u003ch2 id=\"1-abstract\"\u003e1. Abstract\u003c/h2\u003e\n\u003cp\u003e由于ViT （Vision Transformer）的引入，UNet和Transformer融合已成为大趋势。最近，又有很多研究人员开始重新思考卷积模型，比如将ConvNext嵌入到ResNet，能够达到Swin Transformer的水平。受此启发，作者提出了一个纯粹的卷积UNET模型 （ACC-UNet），并且超越基于Transfomer的模型(如Swin-UNET或UCTransNet)。\n作者研究了基于Transfomer的UNET模型优点：长范围依赖关系和跨级别跳过连接。\nACC-UNet结合了\u003cstrong\u003e卷积神经网络（ConvNets）的内在归纳偏差\u003c/strong\u003e和\u003cstrong\u003eTransformer的设计决策\u003c/strong\u003e\n\u003cstrong\u003e卷积神经网络（ConvNets）的内在归纳偏差\u003c/strong\u003e：卷积神经网络具有天生的归纳偏差，这意味着它们在处理图像等数据时具有一些固有的假设和特点。例如，卷积神经网络擅长处理局部特征、平移不变性等，这些特点使它们在图像处理任务中表现出色。\n\u003cstrong\u003eTransformer的设计决策\u003c/strong\u003e：Transformer是一种不同的神经网络架构，它采用了一些独特的设计决策，例如自注意力机制和位置编码等。这些设计决策使得Transformer在处理长距离依赖性、全局关系等方面表现出色，适合处理序列数据和具有远程依赖的任务。\nACC-UNet 在 5 个不同的医学图像分割基准上进行了评估，并且始终优于卷积网络、Transfomer及其混合网络。\u003c/p\u003e\n\u003ch2 id=\"2introduction\"\u003e2.Introduction\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e语义分割是计算机辅助医学图像分析的重要组成部分，可识别并突出显示各种诊断任务中感兴趣的区域。然而，由于涉及图像模态和采集以及病理和生物变化的各种因素，这通常变得复杂[18]。深度学习在这一领域的应用无疑在这方面受益匪浅。最值得注意的是，自推出以来，UNet 模型 [19] 在医学图像分割方面表现出了惊人的功效。结果，UNet 及其衍生品已成为事实上的标准[25]。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e学习一下这里的背景描述\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e原始的 UNet 模型包含对称的编码器-解码器架构（图 1a）并采用跳跃连接，这为解码器提供了在编码器的池化操作期间可能丢失的空间信息。尽管通过简单串联的信息传播提高了性能，但编码器-解码器特征图之间可能存在语义差距。这导致了第二类 UNet 的发展（图 1b）。 U-Net++ [26] 利用密集连接，而 MultiResUNet [11] 在跳过连接上添加了额外的卷积块作为潜在的补救措施。到目前为止，UNet 的历史上所有创新都是使用 CNN 进行的。然而，2020 年的十年给计算机视觉领域带来了根本性的变化。 CNN 在视觉领域的长期主导地位被视觉转换器打破了 [7]。 Swin Transformers [15] 进一步针对一般视觉应用调整了变压器。因此，UNet 模型开始采用 Transformer [5]。 Swin-Unet [9] 用 Swin Transformer 块取代了卷积块，从而开创了一类新的模型（图 1c）。尽管如此，CNN 在图像分割方面仍然具有各种优点，导致了融合这两者的发展[2]。这种混合类 UNet 模型（图 1d）在编码器-解码器中采用卷积块，并沿跳跃连接使用变换器层。 UCTransNet [22]和MCTrans[24]是此类的两个代表性模型。最后，还尝试开发全变压器 UNet 架构（图 1e），例如，SMESwin Unet [27] 在编码器-解码器块和跳跃连接中都使用变压器。\u003c/p\u003e","title":"ACC-UNet: A Completely Convolutional UNet model for the 2020s (MICCAI2023)"},{"content":"(2023) M2SNet: 新颖多尺度模块 + 智能损失函数 = 通用图像分割SOTA网络 Abstract 准确的医学图像分割对于早期医学诊断至关重要。大多数现有方法基于U形结构，并使用逐元素加法或串联在解码器中逐步融合不同级别的特征。然而，这两种操作都容易产生大量冗余信息，从而削弱不同级别特征之间的互补性，导致病灶定位不准确和边缘模糊。为了应对这一挑战，我们提出了一种通用的多尺度减法网络（M2SNet）来完成医学图像的多样化分割。具体来说，我们首先设计一个基本减法单元（SU）来产生编码器中相邻级别之间的差异特征。接下来，我们将单尺度 SU 扩展到层内多尺度 SU，它可以为解码器提供像素级和结构级差异信息。\n然后，我们金字塔式地为不同层次的多尺度SU配备不同的感受野，从而实现层间多尺度特征聚合并获得丰富的多尺度差异信息。此外，我们构建了一个免训练网络“LossNet”来全面监督从底层到顶层的任务感知特征，这驱动我们的多尺度减法网络同时捕获细节和结构线索。\n没有花里胡哨的东西，我们的方法在不同的评估指标下，在不同图像模态的四种不同医学图像分割任务的 11 个数据集上表现优于大多数最先进的方法，包括彩色结肠镜成像、超声成像、计算机断层扫描 (CT) ）和光学相干断层扫描（OCT）。\n两个主要创新点：多尺度金字塔减法单元 （确实牛逼）+ LossNet（为了创新而创新的损失函数）\nIntroduction 作为计算机辅助诊断系统中的重要作用，精确的医学图像分割技术可以为医生做出临床决策提供重要指导。精确分割存在三个普遍的挑战：首先，U形结构[1]、[2]由于其利用多级信息重建高分辨率特征图的能力而受到了相当多的关注。在UNet [2]中，上采样的特征图与从编码器跳过的特征图连接在一起，并在上采样步骤之间添加卷积和非线性，如图1（a）所示。后续基于UNet的方法通过注意力机制[3]、[4]、门机制[5]、[6]、变压器技术[7]、[8]设计不同的特征增强模块，如图1（b）所示。 UNet++[9]使用嵌套和密集的跳跃连接来减少编码器和解码器的特征图之间的语义差距，如图1（c）所示。\n先说医学分割在医学领域重要\u0026hellip;(balabala) 然后当前领域存在xxx挑战\u0026hellip;(balabala)\n这里是以医学图像分割挑战的视角，介绍UNet发展的情况。然后在描述不同UNet变体发展过程中解决的不同问题（感觉可以借鉴）\n一般来说，编码器中不同级别的特征有不同的特征。高级别具有更多的语义信息，有助于定位对象，而低级别具有更详细的信息，可以捕捉对象的微妙边界。解码器利用特定级别和跨级别特征来生成最终的高分辨率预测。然而，上述方法直接使用逐元素加法或串联来融合来自编码器的任意两级特征并将它们传输到解码器。这些简单的操作并没有更多地关注不同层次之间的差异信息。这一缺点不仅会产生冗余信息来稀释真正有用的特征，还会削弱特定于级别的特征的特性，从而导致网络无法平衡精确定位和微妙的边界细化。其次，由于感受野有限，单尺度卷积核很难捕获大小变化物体的上下文信息。一些方法[1]、[2]、[9]-[11]依赖于层间多尺度特征，并逐步整合来自不同尺度表示的语义上下文和纹理细节。其他人[6]、[12]-[15]专注于基于网络中的空洞空间金字塔池化模块[16]（ASPP）或DenseASPP [17]提取层内多尺度信息。然而，类似ASPP的多尺度卷积模块会产生许多额外的参数和计算。许多方法[5]、[18]-[21]通常将多个ASPP模块安装到不同级别的编码器/解码器块中，而有些方法[13]、[14]、[22]、[23]将其安装在不同级别的编码器/解码器块中。最高级别的编码器块。第三，损失函数的形式直接为网络的梯度优化提供了方向。在分割领域，提出了许多损失函数来监督不同级别的预测，例如像素级别的L1损失、交叉熵损失和加权交叉熵损失[24]，SSIM[25]损失区域层面的不确定性损失[26]，全局层面的IoU损失、Dice损失和一致性增强损失[11]。尽管这些基本损失函数及其变体具有不同的优化特性，但复杂的手动数学形式的设计对于许多研究来说确实非常耗时。为了获得综合性能，模型通常会集成多种损失函数，这对研究人员的训练技能提出了很高的要求。因此，我们认为有必要引入一种无需复杂人工设计的智能损失函数来全面监督分割预测。\n在本文中，我们提出了一种用于一般医学图像分割的新型多尺度减法网络（M2SNet）。首先，我们设计一个减法单元（SU）并将其应用于每对相邻的级别特征。 SU突出了特征之间有用的差异信息，并消除了冗余部分的干扰。其次，我们借助所提出的多尺度减法模块收集极端多尺度信息。\n对于层间多尺度信息，我们以金字塔方式连接多个减法单元来捕获大跨度的跨层信息。然后，我们聚合特定于级别的特征和多路径跨级别差分特征，然后在解码器中生成最终预测。对于层内多尺度信息，我们通过一组不同内核大小的full one滤波器将单尺度减法单元改进为多尺度减法单元，可以自然地实现多尺度减法聚合，而无需引入额外的参数。如图1所示，MSNet配备了层间多尺度减法模块，M2SNet同时具有层间和层内多尺度减法结构。第三，我们提出了一个LossNet来自动监督从底层到顶层提取的特征图，它可以通过简单的L2损失函数优化从细节到结构的分割。\n多尺度减法单元可以去特征之间的差异信息，消除冗余干扰。\n（也就是说可以用这种办法替换注意力机制）\nRELATED WORK Medical Image Segmentation Network 根据不同器官或病变的特点，我们将现有的医学图像分割方法分为两类：医学通用的和医学专用的。随着U-Net[2]在医学图像分割领域取得稳定的性能，带有编码器-解码器的U形结构已成为基本的分割基线。 U-Net++[9]集成了长连接和短连接，可以减少编码器和解码器子网络的特征图之间的语义差距。对于注意力 U-Net [28]，注意力门嵌入在编码器和解码器块之间的每个过渡层中，它可以自动学习关注不同形状和大小的目标结构。最近，Transformer [29]架构在许多自然语言处理任务中取得了成功。一些作品[7]、[8]探讨了其对医学视觉任务的有效性。 UTNet [7] 是一种简单但功能强大的混合变压器架构，它在编码器和解码器中应用自注意力模块，以最小的开销捕获不同规模的远程依赖关系。另一个具有代表性的基于 Transformer 的模型是 TransUNet [8]，它通过将图像特征视为序列来编码强全局上下文，并通过 U 形混合架构设计利用低级 CNN 特征。\n医学特定方法。在息肉分割任务中，SFA [30]和PraNet [4]专注于恢复息肉与其周围粘膜之间的清晰边界。前者提出了共享编码器和两个相互约束的解码器下的选择性特征聚合结构和边界敏感损失函数。后者利用反向注意模块来建立区域和边界线索之间的关系。此外，Ji等人[31]利用时空信息构建视频息肉分割模型。在COVID-19肺部感染任务中，Paluru等人[32]提出了一种基于变形深度嵌入的轻量级CNN来分割COVID-19胸部CT图像中的异常。 Inf-Net [33] 构建隐式反向注意力和显式边缘注意力来对边界进行建模。 BCS-Net [34]具有三个渐进边界上下文语义重建块，可以帮助解码器捕获肺部感染的零散区域。在乳腺分割任务中，Byra等人[35]通过注意力机制开发了选择性核来调整U-Net的感受野，可以进一步提高乳腺肿瘤的分割精度。 Chen 等人 [36] 提出了一种嵌套 U 网，通过利用不同的深度和共享权重来实现乳腺肿瘤的稳健表示。\n我们可以看到，医学通用方法通常针对通用挑战（即丰富的特征表示、多尺度信息提取和跨级别特征聚合）。并且，医学特异性方法根据当前器官或病变的特征提出有针对性的解决方案，例如设计一系列注意力机制、边缘增强模块、不确定性估计等。然而，通用医学模型和医学特异性模型都依赖于通过大量的加法或串联操作来实现特征融合，削弱了互补特征之间的特殊性部分。我们提出的多尺度减法模块自然专注于提取差异信息，从而为解码器提供有效的目标特征。\n主要是说大部分特征融合都是用加法/乘法/串联实现的，但是减法可以削弱互补特征之间的特殊性部分。所以多尺度减法模块提取差异信息，然后再用加法进行特征融合。\nMulti-scale Feature Extraction 尺度线索在捕捉对象的上下文信息中发挥着重要作用。受到被广泛验证为有效且理论上合理的框架的尺度空间理论的启发，越来越多的多尺度方法被提出。与单尺度特征相比，多尺度特征有利于解决自然发生的尺度变化。这一特性可以帮助医学分割模型感知不同尺度的病变。根据形式，当前基于多尺度的方法可以大致分为两类，即层间多尺度结构和层内多尺度结构。前者基于特征编码器提取的不同尺度的特征，并在解码器中逐步聚合它们，例如U形[1]、[2]、[4]、[9]-[11]、[37] ，[38]架构。后者通常配备多尺度可插拔模块，如ASPP [16]、DenseASPP [17]、FoldASPP [6]和PAFEM [12]，构建具有不同扩张率的并行多分支卷积层，以获得丰富的组合感受野。与它们不同的是，我们通过同时引入层间和层内多尺度，提出了具有极端多尺度信息的多尺度减法模块中的多尺度。并且，层内多尺度减法单元专注于挖掘从像素到像素到区域到区域的特征对的自差分性质。与单尺度操作相比，整个过程非常高效，不需要额外的参数。\n多尺度减法模块可以超越其他卷积类办法的多尺度特征信息提取办法\nLoss Method 图像分割中的大多数损失函数都是基于交叉熵或重合度量。传统的交叉熵损失对类别信息一视同仁。 Long等人[24]提出了每个类别的加权交叉熵损失（WCE），以抵消数据中的类别不平衡。 Lin等人[39]引入了困难样本和简单样本的权重来提出焦点损失。 Dice loss[40]被提出作为V-Net中重合测量的损失函数，可以有效抑制类别不平衡带来的问题。 Tversky 损失[41]是 Dice 损失的正则化版本，用于控制准确率和召回率对损失函数的贡献。 Wong等人[42]通过Dice损失和WCE损失的加权求和提出指数对数损失（EL Loss）来提高小结构物体的分割精度。\nTaghanaki等人[43]发现单独使用基于重叠的损失函数存在风险，并提出comomoloss将Dice损失作为正则化项与WCE损失相结合来处理输入输出不平衡的问题。\n虽然这些各种各样的损失函数在不同层次上有不同的效果，但手动设计这些复杂的函数确实费时费力。为此，我们提出了自动且全面的分割损失结构，称为LossNet。\nLossNet权重就0.1 （ 感觉这个是为了创新而创新）\nMETHOD Encoder: Res2Net + Connection: MMSB + Decoder: Plus\nMulti-scale in Multi-scale Subtraction Module 我们使用 FA 和 FB 来表示相邻级别的特征图。\n它们都已被 ReLU 操作激活。我们定义一个基本减法单位（SU）：\n其中是逐元素减法运算，然后计算绝对值，Conv(·) 表示卷积层。直接对元素位置特征进行单尺度减法只是为了建立孤立像素级别上的差异关系，没有考虑病灶可能具有区域聚类的特征。与带有单尺度减法单元的MSNet MICCAI版本[27]相比，我们设计了一个强大的层内多尺度减法单元（MSU），并将MSNet改进为M2SNet。如图3所示，我们利用大小为1×1、3×3和5×5的固定全一权重的多尺度卷积滤波器根据像素-像素和区域区域模式计算细节和结构差异值。使用具有固定参数的多尺度滤波器不仅可以直接捕获匹配空间位置处的初始特征对之间的多尺度差异线索，而且可以在不引入额外参数负担的情况下实现高效训练。因此，M2SNet可以保持与MSNet相同的低计算量，并获得更高精度的性能。整个多尺度减法过程可以表述为：\n其中 Filter(·) n×n 表示大小为 n × n 的完整滤波器（卷积）。 MSU可以捕获FA和FB的互补信息，并突出它们从纹理到结构的差异，从而为解码器提供更丰富的信息。\n为了获得跨多个特征级别的高阶互补信息，我们水平和垂直连接多个MSU来计算一系列具有不同阶数和感受野的差分特征。多尺度减法模块中多尺度的细节可以在图2中找到。我们聚合了相应级别和任意级别之间的特定尺度特征（MSi 1 ）和跨尺度差分特征（MSi n6=1）。其他级别生成互补增强特征（CEi）。这个过程可以表述如下：\n最后，所有CEi参与解码，然后对息肉区域进行分割。\n这里就是介绍一下MSU\nLossNet 在所提出的模型中，总训练损失可以写为：\n其中L w IoU和L w BCE表示加权IoU损失和二元交叉熵（BCE）损失，它们已在分割任务中广泛采用。我们使用与[4]、[44]、[45]中相同的定义，它们的有效性已在这些工作中得到验证。与它们不同的是，我们额外使用LossNet来进一步优化从细节到结构的分割。\n具体来说，我们使用 ImageNet 预训练分类网络，例如 VGG-16，分别提取预测和地面实况的多尺度特征。然后，它们的特征差异计算为损失 Lf ：\n令 F i P 和 F i G 分别表示从预测和地面实况中提取的第 i 层特征图。 l i f 计算为其欧几里德距离（L2-Loss），该距离在像素级别进行监督：\n从图4中可以看出，低层特征图包含丰富的边界信息，高层特征图描述位置信息。因此，LossNet可以在特征层面产生全面的监督。\n","permalink":"https://swimmingliu.cn/posts/papernotes/2023-m2snet/","summary":"\u003ch1 id=\"2023-m2snet-新颖多尺度模块--智能损失函数--通用图像分割sota网络\"\u003e(2023) M2SNet: 新颖多尺度模块 + 智能损失函数 = 通用图像分割SOTA网络\u003c/h1\u003e\n\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e准确的医学图像分割对于早期医学诊断至关重要。大多数现有方法基于U形结构，并使用\u003cstrong\u003e逐元素加法或串联在解码器中逐步融合不同级别的特征\u003c/strong\u003e。然而，这两种操作都\u003cstrong\u003e容易产生大量冗余信息\u003c/strong\u003e，从而\u003cstrong\u003e削弱不同级别特征之间的互补性\u003c/strong\u003e，导致\u003cstrong\u003e病灶定位不准确和边缘模糊\u003c/strong\u003e。为了应对这一挑战，我们提出了一种通用的多尺度减法网络（M2SNet）来完成医学图像的多样化分割。具体来说，我们首先设计一个基本\u003cstrong\u003e减法单元（SU）\u003cstrong\u003e来产生编码器中相邻级别之间的差异特征。接下来，我们将单尺度 SU 扩展到层内多尺度 SU，它可以为解码器\u003c/strong\u003e提供像素级和结构级差异信息\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e然后，我们金字塔式地为不同层次的多尺度SU配备不同的感受野，从而实现层间多尺度特征聚合并获得丰富的多尺度差异信息。此外，我们构建了一个免训练网络“LossNet”来全面监督从底层到顶层的任务感知特征，这驱动我们的多尺度减法网络同时捕获细节和结构线索。\u003c/p\u003e\n\u003cp\u003e没有花里胡哨的东西，我们的方法在不同的评估指标下，在不同图像模态的四种不同医学图像分割任务的 11 个数据集上表现优于大多数最先进的方法，包括彩色结肠镜成像、超声成像、计算机断层扫描 (CT) ）和光学相干断层扫描（OCT）。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e两个主要创新点：多尺度金字塔减法单元 （确实牛逼）+ LossNet（为了创新而创新的损失函数）\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e作为计算机辅助诊断系统中的重要作用，精确的医学图像分割技术可以为医生做出临床决策提供重要指导。精确分割存在三个普遍的挑战：首先，U形结构[1]、[2]由于其利用多级信息重建高分辨率特征图的能力而受到了相当多的关注。在UNet [2]中，上采样的特征图与从编码器跳过的特征图连接在一起，并在上采样步骤之间添加卷积和非线性，如图1（a）所示。后续基于UNet的方法通过注意力机制[3]、[4]、门机制[5]、[6]、变压器技术[7]、[8]设计不同的特征增强模块，如图1（b）所示。 UNet++[9]使用嵌套和密集的跳跃连接来减少编码器和解码器的特征图之间的语义差距，如图1（c）所示。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e先说医学分割在医学领域重要\u0026hellip;(balabala)  然后当前领域存在xxx挑战\u0026hellip;(balabala)\u003c/p\u003e\n\u003cp\u003e这里是以医学图像分割挑战的视角，介绍UNet发展的情况。然后在描述不同UNet变体发展过程中解决的不同问题（感觉可以借鉴）\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e一般来说，编码器中不同级别的特征有不同的特征。\u003cstrong\u003e高级别具有更多的语义信息\u003c/strong\u003e，有助于定位对象，而低级别具有\u003cstrong\u003e更详细的信息\u003c/strong\u003e，可以捕捉对象的\u003cstrong\u003e微妙边界\u003c/strong\u003e。解码器利用特定级别和跨级别特征来生成最终的\u003cstrong\u003e高分辨率预测\u003c/strong\u003e。然而，上述方法\u003cstrong\u003e直接使用逐元素加法或串联来融合来自编码器的任意两级特征\u003c/strong\u003e并将它们传输到解码器。这些简单的操作并没有更多地关注\u003cstrong\u003e不同层次之间的差异信息。\u003cstrong\u003e这一缺点不仅会产生\u003c/strong\u003e冗余信息来稀释真正有用的特征\u003c/strong\u003e，还会\u003cstrong\u003e削弱特定于级别的特征的特性\u003c/strong\u003e，从而导致网络无法平衡精确定位和微妙的边界细化。其次，由于\u003cstrong\u003e感受野有限\u003c/strong\u003e，单尺度卷积核很难捕获大小变化物体的\u003cstrong\u003e上下文信息\u003c/strong\u003e。一些方法[1]、[2]、[9]-[11]依赖于层间多尺度特征，并逐步整合来自不同尺度表示的\u003cstrong\u003e语义上下文和纹理细节\u003c/strong\u003e。其他人[6]、[12]-[15]专注于基于网络中的空洞空间金字塔池化模块[16]（ASPP）或DenseASPP [17]提取\u003cstrong\u003e层内多尺度信息\u003c/strong\u003e。然而，类似ASPP的多尺度卷积模块会产生\u003cstrong\u003e许多额外的参数和计算\u003c/strong\u003e。许多方法[5]、[18]-[21]通常将多个ASPP模块安装到不同级别的编码器/解码器块中，而有些方法[13]、[14]、[22]、[23]将其安装在不同级别的编码器/解码器块中。最高级别的编码器块。第三，损失函数的形式直接为网络的梯度优化提供了方向。在分割领域，提出了许多损失函数来监督不同级别的预测，例如像素级别的L1损失、交叉熵损失和加权交叉熵损失[24]，SSIM[25]损失区域层面的不确定性损失[26]，全局层面的IoU损失、Dice损失和一致性增强损失[11]。尽管这些基本损失函数及其变体具有不同的优化特性，但复杂的手动数学形式的设计对于许多研究来说确实非常耗时。为了获得综合性能，模型通常会集成多种损失函数，这对研究人员的训练技能提出了很高的要求。因此，我们认为有必要引入一种无需复杂人工设计的智能损失函数来全面监督分割预测。\u003c/p\u003e\n\u003cp\u003e在本文中，我们提出了一种用于一般医学图像分割的新型多尺度减法网络（M2SNet）。首先，我们设计一个减法单元（SU）并将其应用于\u003cstrong\u003e每对相邻的级别特征\u003c/strong\u003e。 SU突出了\u003cstrong\u003e特征之间有用的差异信息，并消除了冗余部分的干扰\u003c/strong\u003e。其次，我们借助所提出的\u003cstrong\u003e多尺度减法模块\u003c/strong\u003e收集\u003cstrong\u003e极端多尺度信息\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e对于层间多尺度信息，我们以金字塔方式连接多个减法单元来捕获大跨度的跨层信息。然后，我们\u003cstrong\u003e聚合特定于级别的特征\u003c/strong\u003e和\u003cstrong\u003e多路径跨级别差分特征\u003c/strong\u003e，然后在解码器中生成最终预测。对于层内多尺度信息，我们通过一组不同内核大小的full one滤波器将单尺度减法单元\u003cstrong\u003e改进为多尺度减法单元，可以自然地实现多尺度减法聚合，而无需引入额外的参数\u003c/strong\u003e。如图1所示，MSNet配备了层间多尺度减法模块，M2SNet同时具有层间和层内多尺度减法结构。第三，我们提出了一个LossNet来自动监督从底层到顶层提取的特征图，它可以通过简单的L2损失函数优化从细节到结构的分割。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e多尺度减法单元可以去特征之间的差异信息，消除冗余干扰。\u003c/p\u003e\n\u003cp\u003e（也就是说可以用这种办法替换注意力机制）\u003c/p\u003e\n\u003ch2 id=\"related-work\"\u003eRELATED WORK\u003c/h2\u003e\n\u003ch3 id=\"medical-image-segmentation-network\"\u003eMedical Image Segmentation Network\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e根据不同器官或病变的特点，我们将现有的医学图像分割方法分为两类：医学通用的和医学专用的。随着U-Net[2]在医学图像分割领域取得稳定的性能，带有编码器-解码器的U形结构已成为基本的分割基线。 U-Net++[9]集成了\u003cstrong\u003e长连接和短连接\u003c/strong\u003e，可以减少编码器和解码器子网络的特征图之间的语义差距。对于注意力 U-Net [28]，\u003cstrong\u003e注意力门\u003c/strong\u003e嵌入在编码器和解码器块之间的每个过渡层中，它可以自动学习关注不\u003cstrong\u003e同形状和大小的目标结构\u003c/strong\u003e。最近，Transformer [29]架构在许多自然语言处理任务中取得了成功。一些作品[7]、[8]探讨了其对医学视觉任务的有效性。 UTNet [7] 是一种简单但功能强大的混合变压器架构，它在编码器和解码器中应用自注意力模块，以最小的开销捕获不同规模的远程依赖关系。另一个具有代表性的基于 Transformer 的模型是 TransUNet [8]，它通过将图像特征视为序列来编码强全局上下文，并通过 U 形混合架构设计利用低级 CNN 特征。\u003c/p\u003e\n\u003cp\u003e医学特定方法。在息肉分割任务中，SFA [30]和PraNet [4]专注于恢复息肉与其周围粘膜之间的清晰边界。前者提出了共享编码器和两个相互约束的解码器下的选择性特征聚合结构和边界敏感损失函数。后者利用反向注意模块来建立区域和边界线索之间的关系。此外，Ji等人[31]利用时空信息构建视频息肉分割模型。在COVID-19肺部感染任务中，Paluru等人[32]提出了一种基于变形深度嵌入的轻量级CNN来分割COVID-19胸部CT图像中的异常。 Inf-Net [33] 构建隐式反向注意力和显式边缘注意力来对边界进行建模。 BCS-Net [34]具有三个渐进边界上下文语义重建块，可以帮助解码器捕获肺部感染的零散区域。在乳腺分割任务中，Byra等人[35]通过注意力机制开发了选择性核来调整U-Net的感受野，可以进一步提高乳腺肿瘤的分割精度。 Chen 等人 [36] 提出了一种嵌套 U 网，通过利用不同的深度和共享权重来实现乳腺肿瘤的稳健表示。\u003c/p\u003e","title":"M2SNet: Multi-scale in Multi-scale Subtraction Network for Medical Image Segmentation"},{"content":"EGE-UNet: an Efficient Group Enhanced UNet for skin lesion segmentation 1. Abstract 目前的医学图像分割模型大多是 Transformer + Unet，这些模型的大量参数和计算负载使得它们不适合移动健康应用。\n作者提出的EGE-UNet 模型轻量、高效。（与 TransFuse 相比，参数和计算成本分别降低了 494 倍和 160 倍，模型参数量只有50KB）\n创新点：组多轴哈达玛产品注意力模块（GHPA）和组聚合桥模块（GAB）。\n1.GHPA 对输入特征进行分组，并在不同轴上执行哈达玛产品注意力机制（HPA），以从不同角度提取病理信息。\n2.GAB 通过对低级特征、高级特征以及解码器在每个阶段生成的掩码进行分组，有效地融合了多尺度信息。\n2. Introduction 背景: 恶性黑色素瘤是世界上增长最快的癌症之一。据美国癌症协会估计，2020 年约有 100,350 例新发病例，超过 6,500 例死亡。因此，自动化皮肤病变分割系统势在必行，因为它可以帮助医疗专业人员快速识别病变区域并促进后续治疗过程。\n相同方式可引入脑瘤、肺癌。\n为了提高分割性能，最近的研究倾向于采用具有更大参数和计算复杂度的模块，例如结合视觉变换器（ViT）的自注意力机制[7]。例如，Swin-UNet [4]，基于Swin Transformer [11]，利用自注意力机制的特征提取能力来提高分割性能。 TransUNet [5] 开创了用于医学图像分割的 CNN 和 ViT 的串行融合。 TransFuse [26]采用双路径结构，利用 CNN 和 ViT 分别捕获局部和全局信息。UTNetV2[8]利用混合分层架构、高效的双向注意力和语义图来实现全局多尺度特征融合，结合了CNN和ViT的优点。 TransBTS [23] 将自注意力引入脑肿瘤分割任务中，并用它来聚合高级信息。\nAbstract提到当前医学分割模型大部分是Transformer + Unet，这里做出具体阐述。\n先前的工作通过引入复杂的模块来提高性能，但忽略了实际医疗环境中计算资源的限制。因此，迫切需要为移动医疗中的分割任务设计一种低参数、低计算负载的模型。最近，UNeXt [22] 结合了 UNet [18] 和 MLP [21] 开发了一种轻量级模型，该模型可以获得优异的性能，同时减少参数和计算量。此外，MALUNet [19]通过减少模型通道数并引入多个注意力模块来减小模型大小，从而比 UNeXt 具有更好的皮肤病变分割性能。然而，尽管MALUNet大大减少了参数数量和计算量，但其分割性能仍然低于一些大型模型，例如TransFuse。因此，在本研究中，我们提出了 EGE-UNet，这是一种轻量级皮肤病变分割模型，可实现最先进的效果，同时显着降低参数和计算成本。此外，据我们所知，这是第一个将参数减少到大约 50KB 的工作。\n提出问题：医疗环境中计算资源的限制，复杂模块难以落地 \u0026mdash;\u0026gt; 解决办法：轻量化模型\n当前轻量化发展历程 \u0026mdash;\u0026gt; 轻量化的模型分割效果不好 \u0026mdash;\u0026gt; EGE-Unet 轻量+分割能力强\n具体来说，EGE-UNet 利用两个关键模块：群组多轴 Hadamard 产品注意力模块（GHPA）和群组聚合桥模块（GAB）。\n一方面，由于多头自注意力机制（MHSA），最近基于 ViT [7] 的模型已经显示出前景。 MHSA将输入划分为多个head，并在每个head中计算self-attention，这使得模型能够从不同的角度获取信息，整合不同的知识，提高性能。尽管如此，MHSA 的二次复杂度极大地增加了模型的大小。因此，我们提出了具有线性复杂度的哈达玛产品注意力机制（HPA）。HPA 采用可学习的权重，并使用输入执行哈达玛乘积运算以获得输出。随后，受到 MHSA 中多头模式的启发，我们提出了 GHPA，它将输入分为不同的组，并在每个组中执行 HPA。然而，值得注意的是，我们在不同组的不同轴上进行HPA，这有助于进一步从不同的角度获取信息。\n另一方面，对于GAB，由于医学图像中分割目标的大小和形状不一致，因此获得多尺度信息至关重要[19]。因此，GAB基于组聚合融合不同大小的高层和低层特征，并额外引入掩模信息来辅助特征融合。通过将上述两个模块与UNet相结合，我们提出了EGE-UNet，它以极低的参数和计算量实现了出色的分割性能。与以前仅注重提高性能的方法不同，我们的模型还优先考虑现实环境中的可用性。图 1 显示了 EGEUNet 与其他网络的清晰比较。\n具体介绍为什么引入两个创新模块（GHPA、GAB）、以及模块是基于什么论文。（模块背景+创新方法）\n(1)提出了GHPA和GAB，前者有效地获取和集成多视角信息，后者接受不同尺度的特征，以及用于高效多尺度特征融合的辅助掩模。\n(2)我们提出了EGEUNet，这是一种专为皮肤病变分割而设计的极其轻量级的模型。\n(3) 我们进行了广泛的实验，证明了我们的方法在以显着降低的资源需求实现最先进性能方面的有效性。\n主要贡献：（1）写模块作用 （2）写整体网络优势 （3）实验效果\n3. Method 3.1EGE-Unet网络结构 EGE-UNet由对称编码器-解码器部分组成的 U 形架构之上。\n编码器由六级组成，每级通道数为{8,16,24,32,48,64}。解码器同理\n前三个阶段采用内核大小为 3 的普通卷积，后三个阶段利用提出的 GHPA 从不同的角度提取表示信息。\n与 UNet 中的简单跳跃连接相比，EGE-UNet 在编码器和解码器之间的每个阶段都采用了 GAB。\n利用深度监督生成不同规模的掩模预测，这些预测用于损失函数并作为 GAB 的输入之一。\n通过集成这些高级模块，EGE-UNet 显着减少了参数和计算负载，同时与之前的方法相比增强了分割性能。\n3.2 GHPA (Group multi-axis Hadamard Product Attention module) 为了克服 MHSA 带来的二次复杂度问题，我们提出了具有线性复杂度的 HPA。给定输入 x 和随机初始化的可学习张量 p，首先使用双线性插值来调整 p 的大小以匹配 x 的大小。然后，我们在 p 上采用深度可分离卷积（DW）[10][20]，然后在 x 和 p 之间进行哈达玛乘积运算以获得输出。然而，仅利用简单的HPA不足以从多个角度提取信息，导致结果不理想。受 MHSA 中多头模式的启发，我们引入了基于 HPA 的 GHPA，如算法 1 所示。我们将输入沿通道维度平均分为四组，并在高度-宽度、通道-高度和通道上执行 HPA - 分别为前三组的宽度轴。对于最后一组，我们只在特征图上使用DW。最后，我们沿着通道维度连接四组，并应用另一个数据仓库来整合不同角度的信息。请注意，DW 中使用的所有内核大小均为 3。\n首先对输入的特征分为四组进行处理：高度-宽度、通道-高度、通道-宽度、深度可分离卷积\n然后连接4组特征，进行可分离卷积融合特征。\n具体过程：\n第一步，按通道数将输入张量分为四组。（x1, x2, x3, x4）\n设置初始化三个全一张量，分别为高度-宽度、通道-高度、通道-宽度（Pxy, Pzx, Pzy）。\n第二步，将 x1, x2, x3 的对应切片分别使用双线插值法（bilinear）在Pxy, Pzx, Pzy中进行插值。\n第三步，对插值后的Pxy, Pzx, Pzy，进行深度可分离卷积，然后分别和x1, x2, x3进行哈达玛乘积\n第四步，连接4组特征信息，然后经过深度可分离卷积融合特征。\n3.3 GAB (Group Aggregation Bridge module) 多尺度信息的获取被认为对于密集预测任务（例如医学图像分割）至关重要。因此，如图 3 所示，我们引入了 GAB，它接受三个输入：低级特征、高级特征和掩码。首先，采用深度可分离卷积（DW）和双线性插值来调整高层特征的大小，以匹配低层特征的大小。其次，我们沿通道维度将两个特征映射分为四组，并将一组低级特征与一组高级特征连接起来，以获得四组融合特征。对于每组融合特征，掩码被连接起来。接下来，将内核大小为3和不同扩张率{1,2,5,7}的扩张卷积[25]应用于不同的组，以提取不同尺度的信息。最后，将四组沿通道维度连接起来，然后应用内核大小为 1 的普通卷积，以实现不同尺度的特征之间的交互。\nGAB模块作用： 将高级特征、低级特征、低级特征的预测掩码进行特征融合，作为新的输入特征进行解码。\n具体过程： 高级特征、低级特征、低级特征的预测掩码 (xh、xl 、Mask)\n首先，采用深度可分离卷积（DW）和双线性插值来调整高层特征 (xh) 的大小，以匹配低层特征 (xl) 的大小。\n其次，沿通道维度将两个特征映射分为四组。（对应不同空洞卷积的扩张率：d1 = 1, d2 = 2, d3 = 5, d4 = 7）\n并将每一组的低级特、高级特征和掩码连接起来，总共四组融合特征。\n最后，将四组特征进行连接，并进行1x1卷积得到输出。\n3.4 Loss Function 在本研究中，由于不同的GAB需要不同尺度的掩模信息，因此采用深度监督来计算不同阶段的损失函数，以生成更准确的掩模信息。我们的损失函数可以表示为方程（1）和（2）。其中 Bce 和 Dice 表示二元交叉熵和dice损失。 λi是不同阶段的权重。在本文中，我们默认将i=0到i=5之间的λi设置为1、0.5、0.4、0.3、0.2、0.1。\n分为6个阶段，逐一计算每个阶段的损失。然后按照权重对损失进行求和。\n4.Experiments 4.1 Datasets and Implementation details 为了评估我们模型的有效性，我们选择了两个公共皮肤病变分割数据集，即 ISIC2017 [1][3] 和 ISIC2018 [2][6]，分别包含 2150 个和 2694 个皮肤镜图像。与之前的研究[19]一致，我们以 7:3 的比例将数据集随机划分为训练集和测试集。\nEGE-UNet是由Pytorch[17]框架开发的。所有实验均在单个 NVIDIA RTX A6000 GPU 上执行。图像被归一化并调整大小为 256×256。我们应用各种数据增强，包括水平翻转、垂直翻转和随机旋转。 AdamW [13] 用作优化器，以 0.001 的学习率初始化，CosineAnnealingLR [12] 用作调度器，最大迭代次数为 50，最小学习率为 1e-5。总共训练了 300 个 epoch，批量大小为 8。为了评估我们的方法，我们采用并集平均交集 (mIoU)、Dice 相似度得分 (DSC) 作为指标，并进行 5 次训练\n​\t在公共皮肤病变分割数据集（ISIC2017 和 ISIC2018 ）进行对比实验，在ISIC2018进行消融实验\n采用并集平均交集 (mIoU)、Dice 相似度得分 (DSC) 作为评估指标\n4.2 Comparison Experiments 4.3 Ablation Experiments 4.4 Qualitative Comparisons 5. ConClusions 在本文中，我们提出了两个高级模块。我们的 GHPA 使用一种新颖的 HPA 机制将自注意力的二次复杂度简化为线性复杂度。它还利用分组来充分捕获来自不同角度的信息。我们的 GAB 融合了低级和高级特征，并引入了一个掩模来集成多尺度信息。基于这些模块，我们提出了用于皮肤病变分割任务的 EGE-UNet。实验结果证明了我们的方法在显着降低资源需求的情况下实现最先进的性能的有效性。我们希望我们的工作能够激发医学图像界对轻量级模型的进一步研究。\n作者提出的EGE-UNet实现了轻量、准确的皮肤病变分割任务\n","permalink":"https://swimmingliu.cn/posts/papernotes/2023-ege-unet%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/","summary":"\u003ch1 id=\"ege-unet-an-efficient-group-enhanced-unet-for-skin-lesion-segmentation\"\u003eEGE-UNet: an Efficient Group Enhanced UNet for skin lesion segmentation\u003c/h1\u003e\n\u003ch2 id=\"1-abstract\"\u003e1. Abstract\u003c/h2\u003e\n\u003cp\u003e目前的医学图像分割模型大多是 Transformer + Unet，这些模型的大量参数和计算负载使得它们不适合移动健康应用。\u003c/p\u003e\n\u003cp\u003e作者提出的EGE-UNet 模型轻量、高效。（与 TransFuse 相比，参数和计算成本分别降低了 494 倍和 160 倍，模型参数量只有50KB）\u003c/p\u003e\n\u003cp\u003e创新点：组多轴哈达玛产品注意力模块（GHPA）和组聚合桥模块（GAB）。\u003c/p\u003e\n\u003cp\u003e1.GHPA 对输入特征进行分组，并在不同轴上执行哈达玛产品注意力机制（HPA），以从不同角度提取病理信息。\u003c/p\u003e\n\u003cp\u003e2.GAB 通过对低级特征、高级特征以及解码器在每个阶段生成的掩码进行分组，有效地融合了多尺度信息。\u003c/p\u003e\n\u003ch2 id=\"2-introduction\"\u003e2. Introduction\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e背景: 恶性黑色素瘤是世界上增长最快的癌症之一。据美国癌症协会估计，2020 年约有 100,350 例新发病例，超过 6,500 例死亡。因此，自动化皮肤病变分割系统势在必行，因为它可以帮助医疗专业人员快速识别病变区域并促进后续治疗过程。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e相同方式可引入脑瘤、肺癌。\u003c/strong\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e为了提高分割性能，最近的研究倾向于采用具有更大参数和计算复杂度的模块，例如结合视觉变换器（ViT）的自注意力机制[7]。例如，Swin-UNet [4]，基于Swin Transformer [11]，利用自注意力机制的特征提取能力来提高分割性能。 TransUNet [5] 开创了用于医学图像分割的 CNN 和 ViT 的串行融合。 TransFuse [26]采用双路径结构，利用 CNN 和 ViT 分别捕获局部和全局信息。UTNetV2[8]利用混合分层架构、高效的双向注意力和语义图来实现全局多尺度特征融合，结合了CNN和ViT的优点。 TransBTS [23] 将自注意力引入脑肿瘤分割任务中，并用它来聚合高级信息。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003eAbstract提到当前医学分割模型大部分是Transformer + Unet，这里做出具体阐述。\u003c/strong\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e先前的工作通过引入复杂的模块来提高性能，但忽略了实际医疗环境中计算资源的限制。因此，迫切需要为移动医疗中的分割任务设计一种低参数、低计算负载的模型。最近，UNeXt [22] 结合了 UNet [18] 和 MLP [21] 开发了一种轻量级模型，该模型可以获得优异的性能，同时减少参数和计算量。此外，MALUNet [19]通过减少模型通道数并引入多个注意力模块来减小模型大小，从而比 UNeXt 具有更好的皮肤病变分割性能。然而，尽管MALUNet大大减少了参数数量和计算量，但其分割性能仍然低于一些大型模型，例如TransFuse。因此，在本研究中，我们提出了 EGE-UNet，这是一种轻量级皮肤病变分割模型，可实现最先进的效果，同时显着降低参数和计算成本。此外，据我们所知，这是第一个将参数减少到大约 50KB 的工作。\u003c/p\u003e","title":"EGE-UNet: an Efficient Group Enhanced UNet for skin lesion segmentation"}]