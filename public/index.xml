<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>This is my content on SwimmingLiu&#39;s Blog</title>
    <link>https://swimmingliu.github.io/</link>
    <description>Recent content in This is my content on SwimmingLiu&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 04 Dec 2023 16:28:11 +0800</lastBuildDate><atom:link href="https://swimmingliu.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Uncertainty-Aware Attention Mechanism:利用不确定性感知注意机制进行肺结节分割和不确定区域预测</title>
      <link>https://swimmingliu.github.io/posts/papernotes/2023-uncertainty-aware-attentionmechanism/</link>
      <pubDate>Mon, 04 Dec 2023 16:28:11 +0800</pubDate>
      
      <guid>https://swimmingliu.github.io/posts/papernotes/2023-uncertainty-aware-attentionmechanism/</guid>
      <description>Abstract 放射科医生拥有不同的培训和临床经验，导致肺结节的分割注释存在差异，从而导致分割的不确定性。传统方法通常选择单个注释作为学习目标或尝试学习包含多个注释的潜在空间。
然而，这些方法无法利用多个注释之间的共识和分歧所固有的有价值的信息。在本文中，我们提出了一种不确定性感知注意机制（UAAM），它利用多个注释之间的共识和分歧来促进更好的分割。为此，我们引入了多置信度掩模（MCM），它结合了低置信度（LC）掩模和高置信度（HC）掩模。 LC 掩模表示分割置信度较低的区域，放射科医生可能有不同的分割选择。继UAAM之后，我们进一步设计了一个不确定性引导多置信分割网络（UGMCS-Net），它包含三个模块：一个捕获肺结节一般特征的特征提取模块，一个为肺结节产生三个特征的不确定性感知模块。注释的并集、交集和注释集，以及一个交集并集约束模块，该模块使用三个特征之间的距离来平衡最终分割和 MCM 的预测。为了全面展示我们方法的性能，我们提出了 LIDC-IDRI 上的复杂结节验证，它测试了 UGMCS-Net 对使用常规方法难以分割的肺结节的分割性能。实验结果表明，我们的方法可以显着提高传统方法难以分割的结节的分割性能。
INTRODUCTION 肺结节分割在肺癌计算机辅助诊断 (CAD) 系统中至关重要 [1]，可提供结节大小、形状和其他重要医学特征等关键信息。然而，对于深度学习方法的一般训练和测试范例，每个结节图像数据只有一个由一名放射科医生描绘的注释掩模[2]-[6]。因此，网络每次只能提供结节区域的单个预测。
然而，在临床实践中，不同的放射科医生由于其不同的培训和临床经验可能会为肺结节提供不同的分割注释[7]-[9]。
因此，基于单一注释的传统方法无法反映临床经验的多样性，限制了深度学习方法的应用。
解决放射科医生之间注释不同问题的一个直接解决方案是为每个肺结节图像合并多个注释。这导致了另一个问题：多个注释不可避免地会带来不确定性和冲突，因为放射科医生可能会对同一区域进行不同的注释。为了克服这个问题，Kohl 等人在 2018 年提出了一种概率 U-Net，它利用条件变分自动编码器将多个分割变体编码到低维潜在空间中 [8]、[10]。通过从该空间采样，网络可以影响相应的分割图。基于这项研究，Hu等人提出将真实不确定性与概率UNet相结合，这可以提高预测不确定性估计、样本准确性和样本多样性[7]。这些方法依赖于潜在空间和该空间中的随机样本。因此，这些方法只能通过多次预测来提供不确定区域。
在本文中，我们提出了一个论点，即多个注释之间的不确定性遵循特定的模式。
为了演示这种现象，我们引入了多重置信掩码 (MCM)，它结合了高置信度 (HC) 掩码和低置信度 (LC) 掩码，如图 1 所示。 A. 交叉掩码等于 HC mask，代表所有注释的交集。
联合掩码是所有注释的联合。 LC掩模是交集掩模和并集掩模之间的差异。当在 LIDC-IDRI 数据集 [11] 上计算 HC 和 LC 的 Hounsfield 单位 (HU) 核估计时，如图 1.B 所示，我们可以观察到 LC 和 HC 掩模之间的 HU 分布存在明显区别。具体地，LC区域具有比HC区域更低的HU值。从像素分布来看，HU值越低，对应区域的密度越低。就CT图像特征而言，LC区域主要由结节边缘、毛刺和磨玻璃特征等边界相关特征组成，而HC区域主要分布在结节核心内。因此，我们提出了这样的假设：导致放射科医生之间差异的区域主要与低密度组织和边界相关特征有关。
与其他方法不同，我们建议利用 MCM (多重置信掩码) ** 和注释集作为具有不同分割确定性的特征的学习指导**，有助于更好的分割性能。我们将这种训练称为UncertaintyAware Attention Mechanism，如图2所示。按照这种机制，我们进一步设计了用于肺结节分割的Uncertainty-Guide Multi-Confidence Segmentation Network（UGMCS-Net）。
UGMCS-Net 包含三个模块：基于 U-Net 的特征提取模块、不确定性感知模块和交集并集约束模块。</description>
    </item>
    
    <item>
      <title>程序设计作业接口文档</title>
      <link>https://swimmingliu.github.io/posts/diary/2023-%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E4%BD%9C%E4%B8%9A%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/</link>
      <pubDate>Sat, 02 Dec 2023 21:40:07 +0800</pubDate>
      
      <guid>https://swimmingliu.github.io/posts/diary/2023-%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E4%BD%9C%E4%B8%9A%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/</guid>
      <description>程序设计作业接口文档 统一返回格式
{ code: ...,	# 状态码 msg: ...,	# 描述信息 data: { # 数据 ... } } code = { 200 == 成功, 500 == 失败, } msg = { success == 成功 fail == 失败 ... } data = { key : value } 前端 虚拟换衣功能 @请求格式 （请求后端） # 前后端需统一样例图片id { userId: ...&amp;lt;int&amp;gt;,	# 标识哪个用户的请求 isUploadCloth: ...&amp;lt;bool&amp;gt;, # 若上传衣服图片使用base64，否则用id isUploadPerson: ...&amp;lt;bool&amp;gt;, # 若上传人物图片使用base64，否则用id clothData: ...&amp;lt;base64||null&amp;gt;, # 衣服图片base64编码 personData: .</description>
    </item>
    
    <item>
      <title>Prior Attention Network: 用于医学图像中多病灶分割的预先注意网络</title>
      <link>https://swimmingliu.github.io/posts/papernotes/2022-priorattentionnetwork/</link>
      <pubDate>Tue, 28 Nov 2023 14:55:47 +0800</pubDate>
      
      <guid>https://swimmingliu.github.io/posts/papernotes/2022-priorattentionnetwork/</guid>
      <description>Prior Attention Network: 用于医学图像中多病灶分割的预先注意网络 Abstract 医学图像中邻近组织的多种类型病变的准确分割在临床实践中具有重要意义。基于从粗到精策略的卷积神经网络（CNN）已广泛应用于该领域。然而，由于组织的大小、对比度和高类间相似性的不确定性，多病灶分割仍然具有挑战性。此外，普遍采用的级联策略对硬件要求较高，限制了临床部署的潜力。为了解决上述问题，我们提出了一种新颖的先验注意网络（PANet），它遵循从粗到细的策略来在医学图像中执行多病灶分割。所提出的网络通过在网络中插入与病变相关的空间注意机制，在单个网络中实现了两个步骤的分割。此外，我们还提出了中间监督策略，用于生成与病变相关的注意力来获取感兴趣区域（ROI），这加速了收敛并明显提高了分割性能。我们在两个应用中研究了所提出的分割框架：肺部 CT 切片中多发性肺部感染的 2D 分割和脑 MRI 中多发性病变的 3D 分割。实验结果表明，与级联网络相比，在 2D 和 3D 分割任务中，我们提出的网络以更少的计算成本实现了更好的性能。所提出的网络可以被视为 2D 和 3D 任务中多病灶分割的通用解决方案。源代码可在 https://github.com/hsiangyuzhao/PANet 获取
问题导向：
①组织的大小、对比度和高类间相似性的不确定性
②多类别病灶分割
③普遍采用的级联策略对硬件要求较高
Introduction 医学图像分割对于疾病的准确筛查和患者的预后具有重要意义。基于病灶分割的病灶评估提供了疾病进展的信息，帮助医生提高临床诊断和治疗的质量。然而，手动病变分割相当主观且费力，这限制了其潜在的临床应用。近年来，随着人工智能的快速发展，基于深度学习的算法得到了广泛的应用，并在医学图像分割方面取得了最先进的性能[1]。卷积神经网络（CNN）由于其高分割质量而在医学图像中的病变分割中很受欢迎。此类算法通常具有深度编码器，可从输入图像中自动提取特征，并通过以下操作生成密集预测。例如，Long等人[2]提出了一种用于图像语义分割的全卷积网络，该网络颇具影响力，并启发了后来的医学分割中的端到端框架。 Ronneberger等人[3]提出了一种用于医学图像分割的U形网络（U-Net），该网络在医学分割的许多领域都显示出了可喜的结果，并已成为许多医学分割任务的虚拟基准。
这一段都可以当成经典医学图像分割的背景引入
然而，尽管医学分割取得了这些突破，但目前的医学分割方法主要集中在病灶的二元分割上，即区分病灶（前景）和其他一切（背景）。尽管二元分割确实有助于隔离某些感兴趣区域并允许对医学图像进行精确分析，但在某些需要对病变进行多类分割的场景中，二元分割还不够。与二元分割相比，由于组织的类间相似性，这种情况要困难得多，因为不同类型的病变在纹理、大小和形状上可能相似。具有从粗到细策略的级联网络已广泛应用于此类场景，例如肝脏和病变的分割、脑肿瘤分割[4]、[5][6]、[7]。
此类网络通常由两个独立的网络组成，其中第一个网络执行粗分割，第二个网络基于从第一个网络分割的 ROI 细化分割。然而，尽管级联网络已广泛应用于医学图像的多病灶分割，但级联策略也有其缺点。由于级联网络由两个独立的网络组成，参数量和显存占用通常是单个网络的两倍，这对硬件要求较高，限制了其在临床使用的潜力。更重要的是，由于级联网络中的两个网络通常是独立的，因此级联网络的训练过程有时比单个网络更困难，这可能导致欠拟合。
级联网络：参数量大、容易欠拟合。
在本文中，我们提出了一种名为先验注意网络（PANet）的新型网络结构，用于在医学图像中执行多病灶分割。所提出的网络由一个用于特征提取的编码器和两个分别生成病变区域注意力和最终预测的解码器组成。该网络与注意力机制结合在一起。为了减少参数大小和硬件占用，我们使用网络编码器的深层、语义丰富的特征来生成病变区域的空间注意力。
然后，编码器生成的特征表示通过空间注意力进行细化，并将其发送到解码器以进行最终的多类预测。为了提高分割性能并加速收敛，我们还在网络结构中引入了中间监督和深度监督。通过这些改进，与传统的级联网络相比，所提出的网络以显着降低的参数大小和计算成本实现了有竞争力的结果。
利用网络编码器的深层、特征信息来生成空间注意力（WTF ???）
中间监督、深度监督 （不错不错， 好多一区和顶会的文章都用深度监督）
这项工作的贡献体现在三个方面。首先，我们提出了一种新颖的网络架构，通过将传统级联网络中的两个分割步骤结合在单个网络中，遵循 2D 和 3D 医学图像中多病灶分割的从粗到细的策略。与级联网络相比，所提出的架构以更少的额外计算成本实现了有竞争力的分割性能，更容易训练和部署到生产环境。其次，我们提出了一种监督空间注意力机制，将病变区域的注意力与网络提取的特征相结合，将多病变分割分解为两个更容易的阶段，并且与当前基于注意力的方法相比具有更好的可解释性。第三，所提出的网络已在两个实际应用中得到验证，包括肺部 CT 切片中的 COVID-19 病变的 2D 分割和多模态 MRI 中的脑肿瘤的 3D 分割。所提出的网络在 2D 和 3D 任务中都优于前沿方法，并且在参数和计算成本方面比当前网络更高效。
一个网络、监督空间注意力机制、参数和计算成本方面比当前网络更高效。
Related Work 1）图像分割的网络结构：用于图像分割的典型卷积神经网络通常由一个卷积特征提取器组成，其拓扑类似于常见的分类网络，自动从输入图像中提取特征，并进行基于卷积的操作以生成最终的密集预测。在自然图像分割领域，FCN [2]、DeepLab [8]、PSPNet [9] 和 SegNet [10] 因其性能和效率而颇受欢迎。对于医学分割，U-Net [3] 在许多任务中相当流行，并且已被修改为许多改进版本，例如 Attention U-Net [11]、U-Net++ [12]、V-Net [13] 和H-DenseUNet [14]在某些领域获得更好的性能。</description>
    </item>
    
    <item>
      <title>地大服务器使用教程</title>
      <link>https://swimmingliu.github.io/posts/diary/2023-%E5%9C%B0%E5%A4%A7%E6%9C%8D%E5%8A%A1%E5%99%A8/</link>
      <pubDate>Mon, 20 Nov 2023 12:25:57 +0800</pubDate>
      
      <guid>https://swimmingliu.github.io/posts/diary/2023-%E5%9C%B0%E5%A4%A7%E6%9C%8D%E5%8A%A1%E5%99%A8/</guid>
      <description>地大服务器使用教程 1. 服务器环境介绍 NVIDIA RTX 3090 (24GB) NVIDIA RTX 2080 Ti (11GB) 2. 配置实验环境 2.1 Conda环境安装 每位同学都会分配个人用户，大家在自己的用户上使用Conda进行环境配置。
Conda安装教程：https://blog.csdn.net/JineD/article/details/129507719
大家按照教程步骤安装即可, 由于安装时间较长, 视频中暂不进行演示。
2.2 Conda环境配置 （以YOLOv8为例） # 创建conda环境 名为yolov8_lyj python版本为3.9 conda create -n yolov8_lyj python=3.9 # 激活环境 conda activate yolov8_lyj # 选择合适的路径，克隆github项目代码 git clone https://github.com/ultralytics/ultralytics # 进入到项目路径下 cd ultralytics/ # 安装相关依赖包 pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple 2.3 准备数据集 下载需要训练的数据集 （最好找顶刊/顶会论文中的公开数据集）
按照算法指定的数据集格式，对数据集格式进行调整。
​	目标检测中数据集格式之间的相互转换：（VOC、COCO、YOLO格式）
​	https://zhuanlan.zhihu.com/p/461488682
2.4 开始实验 在算法中指定数据集的存放路径 （相对/绝对路径均可）
初始化算法的参数
batch-size 批处理大小：每一次处理图片的个数，根据显卡内存进行调整 epochs	迭代次数：算法总共需要训练的轮次 workers 载入数据进程数：每一次调用多少个进程来载入数据 device 选择显卡设备： &amp;#39;0&amp;#39;使用3090，&amp;#39;1&amp;#39;使用2080ti，&amp;#39;0,1&amp;#39;使用两张卡 开始训练 # 运行训练代码 python mian.</description>
    </item>
    
    <item>
      <title>ACC-UNet: A Completely Convolutional UNet model for the 2020s (MICCAI2023)</title>
      <link>https://swimmingliu.github.io/posts/papernotes/2023-acc-unet/</link>
      <pubDate>Sun, 12 Nov 2023 16:32:06 +0800</pubDate>
      
      <guid>https://swimmingliu.github.io/posts/papernotes/2023-acc-unet/</guid>
      <description>ACC-UNet: A Completely Convolutional UNet model for the 2020s (MICCAI2023) 1. Abstract 由于ViT （Vision Transformer）的引入，UNet和Transformer融合已成为大趋势。最近，又有很多研究人员开始重新思考卷积模型，比如将ConvNext嵌入到ResNet，能够达到Swin Transformer的水平。受此启发，作者提出了一个纯粹的卷积UNET模型 （ACC-UNet），并且超越基于Transfomer的模型(如Swin-UNET或UCTransNet)。 作者研究了基于Transfomer的UNET模型优点：长范围依赖关系和跨级别跳过连接。 ACC-UNet结合了卷积神经网络（ConvNets）的内在归纳偏差和Transformer的设计决策 卷积神经网络（ConvNets）的内在归纳偏差：卷积神经网络具有天生的归纳偏差，这意味着它们在处理图像等数据时具有一些固有的假设和特点。例如，卷积神经网络擅长处理局部特征、平移不变性等，这些特点使它们在图像处理任务中表现出色。 Transformer的设计决策：Transformer是一种不同的神经网络架构，它采用了一些独特的设计决策，例如自注意力机制和位置编码等。这些设计决策使得Transformer在处理长距离依赖性、全局关系等方面表现出色，适合处理序列数据和具有远程依赖的任务。 ACC-UNet 在 5 个不同的医学图像分割基准上进行了评估，并且始终优于卷积网络、Transfomer及其混合网络。
2.Introduction 语义分割是计算机辅助医学图像分析的重要组成部分，可识别并突出显示各种诊断任务中感兴趣的区域。然而，由于涉及图像模态和采集以及病理和生物变化的各种因素，这通常变得复杂[18]。深度学习在这一领域的应用无疑在这方面受益匪浅。最值得注意的是，自推出以来，UNet 模型 [19] 在医学图像分割方面表现出了惊人的功效。结果，UNet 及其衍生品已成为事实上的标准[25]。
学习一下这里的背景描述
原始的 UNet 模型包含对称的编码器-解码器架构（图 1a）并采用跳跃连接，这为解码器提供了在编码器的池化操作期间可能丢失的空间信息。尽管通过简单串联的信息传播提高了性能，但编码器-解码器特征图之间可能存在语义差距。这导致了第二类 UNet 的发展（图 1b）。 U-Net++ [26] 利用密集连接，而 MultiResUNet [11] 在跳过连接上添加了额外的卷积块作为潜在的补救措施。到目前为止，UNet 的历史上所有创新都是使用 CNN 进行的。然而，2020 年的十年给计算机视觉领域带来了根本性的变化。 CNN 在视觉领域的长期主导地位被视觉转换器打破了 [7]。 Swin Transformers [15] 进一步针对一般视觉应用调整了变压器。因此，UNet 模型开始采用 Transformer [5]。 Swin-Unet [9] 用 Swin Transformer 块取代了卷积块，从而开创了一类新的模型（图 1c）。尽管如此，CNN 在图像分割方面仍然具有各种优点，导致了融合这两者的发展[2]。这种混合类 UNet 模型（图 1d）在编码器-解码器中采用卷积块，并沿跳跃连接使用变换器层。 UCTransNet [22]和MCTrans[24]是此类的两个代表性模型。最后，还尝试开发全变压器 UNet 架构（图 1e），例如，SMESwin Unet [27] 在编码器-解码器块和跳跃连接中都使用变压器。</description>
    </item>
    
    <item>
      <title>M2SNet: Multi-scale in Multi-scale Subtraction Network for Medical Image Segmentation</title>
      <link>https://swimmingliu.github.io/posts/papernotes/2023-m2snet/</link>
      <pubDate>Sun, 12 Nov 2023 16:25:03 +0800</pubDate>
      
      <guid>https://swimmingliu.github.io/posts/papernotes/2023-m2snet/</guid>
      <description>(2023) M2SNet: 新颖多尺度模块 + 智能损失函数 = 通用图像分割SOTA网络 Abstract 准确的医学图像分割对于早期医学诊断至关重要。大多数现有方法基于U形结构，并使用逐元素加法或串联在解码器中逐步融合不同级别的特征。然而，这两种操作都容易产生大量冗余信息，从而削弱不同级别特征之间的互补性，导致病灶定位不准确和边缘模糊。为了应对这一挑战，我们提出了一种通用的多尺度减法网络（M2SNet）来完成医学图像的多样化分割。具体来说，我们首先设计一个基本减法单元（SU）来产生编码器中相邻级别之间的差异特征。接下来，我们将单尺度 SU 扩展到层内多尺度 SU，它可以为解码器提供像素级和结构级差异信息。
然后，我们金字塔式地为不同层次的多尺度SU配备不同的感受野，从而实现层间多尺度特征聚合并获得丰富的多尺度差异信息。此外，我们构建了一个免训练网络“LossNet”来全面监督从底层到顶层的任务感知特征，这驱动我们的多尺度减法网络同时捕获细节和结构线索。
没有花里胡哨的东西，我们的方法在不同的评估指标下，在不同图像模态的四种不同医学图像分割任务的 11 个数据集上表现优于大多数最先进的方法，包括彩色结肠镜成像、超声成像、计算机断层扫描 (CT) ）和光学相干断层扫描（OCT）。
两个主要创新点：多尺度金字塔减法单元 （确实牛逼）+ LossNet（为了创新而创新的损失函数）
Introduction 作为计算机辅助诊断系统中的重要作用，精确的医学图像分割技术可以为医生做出临床决策提供重要指导。精确分割存在三个普遍的挑战：首先，U形结构[1]、[2]由于其利用多级信息重建高分辨率特征图的能力而受到了相当多的关注。在UNet [2]中，上采样的特征图与从编码器跳过的特征图连接在一起，并在上采样步骤之间添加卷积和非线性，如图1（a）所示。后续基于UNet的方法通过注意力机制[3]、[4]、门机制[5]、[6]、变压器技术[7]、[8]设计不同的特征增强模块，如图1（b）所示。 UNet++[9]使用嵌套和密集的跳跃连接来减少编码器和解码器的特征图之间的语义差距，如图1（c）所示。
先说医学分割在医学领域重要&amp;hellip;(balabala) 然后当前领域存在xxx挑战&amp;hellip;(balabala)
这里是以医学图像分割挑战的视角，介绍UNet发展的情况。然后在描述不同UNet变体发展过程中解决的不同问题（感觉可以借鉴）
一般来说，编码器中不同级别的特征有不同的特征。高级别具有更多的语义信息，有助于定位对象，而低级别具有更详细的信息，可以捕捉对象的微妙边界。解码器利用特定级别和跨级别特征来生成最终的高分辨率预测。然而，上述方法直接使用逐元素加法或串联来融合来自编码器的任意两级特征并将它们传输到解码器。这些简单的操作并没有更多地关注不同层次之间的差异信息。这一缺点不仅会产生冗余信息来稀释真正有用的特征，还会削弱特定于级别的特征的特性，从而导致网络无法平衡精确定位和微妙的边界细化。其次，由于感受野有限，单尺度卷积核很难捕获大小变化物体的上下文信息。一些方法[1]、[2]、[9]-[11]依赖于层间多尺度特征，并逐步整合来自不同尺度表示的语义上下文和纹理细节。其他人[6]、[12]-[15]专注于基于网络中的空洞空间金字塔池化模块[16]（ASPP）或DenseASPP [17]提取层内多尺度信息。然而，类似ASPP的多尺度卷积模块会产生许多额外的参数和计算。许多方法[5]、[18]-[21]通常将多个ASPP模块安装到不同级别的编码器/解码器块中，而有些方法[13]、[14]、[22]、[23]将其安装在不同级别的编码器/解码器块中。最高级别的编码器块。第三，损失函数的形式直接为网络的梯度优化提供了方向。在分割领域，提出了许多损失函数来监督不同级别的预测，例如像素级别的L1损失、交叉熵损失和加权交叉熵损失[24]，SSIM[25]损失区域层面的不确定性损失[26]，全局层面的IoU损失、Dice损失和一致性增强损失[11]。尽管这些基本损失函数及其变体具有不同的优化特性，但复杂的手动数学形式的设计对于许多研究来说确实非常耗时。为了获得综合性能，模型通常会集成多种损失函数，这对研究人员的训练技能提出了很高的要求。因此，我们认为有必要引入一种无需复杂人工设计的智能损失函数来全面监督分割预测。
在本文中，我们提出了一种用于一般医学图像分割的新型多尺度减法网络（M2SNet）。首先，我们设计一个减法单元（SU）并将其应用于每对相邻的级别特征。 SU突出了特征之间有用的差异信息，并消除了冗余部分的干扰。其次，我们借助所提出的多尺度减法模块收集极端多尺度信息。
对于层间多尺度信息，我们以金字塔方式连接多个减法单元来捕获大跨度的跨层信息。然后，我们聚合特定于级别的特征和多路径跨级别差分特征，然后在解码器中生成最终预测。对于层内多尺度信息，我们通过一组不同内核大小的full one滤波器将单尺度减法单元改进为多尺度减法单元，可以自然地实现多尺度减法聚合，而无需引入额外的参数。如图1所示，MSNet配备了层间多尺度减法模块，M2SNet同时具有层间和层内多尺度减法结构。第三，我们提出了一个LossNet来自动监督从底层到顶层提取的特征图，它可以通过简单的L2损失函数优化从细节到结构的分割。
多尺度减法单元可以去特征之间的差异信息，消除冗余干扰。
（也就是说可以用这种办法替换注意力机制）
RELATED WORK Medical Image Segmentation Network 根据不同器官或病变的特点，我们将现有的医学图像分割方法分为两类：医学通用的和医学专用的。随着U-Net[2]在医学图像分割领域取得稳定的性能，带有编码器-解码器的U形结构已成为基本的分割基线。 U-Net++[9]集成了长连接和短连接，可以减少编码器和解码器子网络的特征图之间的语义差距。对于注意力 U-Net [28]，注意力门嵌入在编码器和解码器块之间的每个过渡层中，它可以自动学习关注不同形状和大小的目标结构。最近，Transformer [29]架构在许多自然语言处理任务中取得了成功。一些作品[7]、[8]探讨了其对医学视觉任务的有效性。 UTNet [7] 是一种简单但功能强大的混合变压器架构，它在编码器和解码器中应用自注意力模块，以最小的开销捕获不同规模的远程依赖关系。另一个具有代表性的基于 Transformer 的模型是 TransUNet [8]，它通过将图像特征视为序列来编码强全局上下文，并通过 U 形混合架构设计利用低级 CNN 特征。
医学特定方法。在息肉分割任务中，SFA [30]和PraNet [4]专注于恢复息肉与其周围粘膜之间的清晰边界。前者提出了共享编码器和两个相互约束的解码器下的选择性特征聚合结构和边界敏感损失函数。后者利用反向注意模块来建立区域和边界线索之间的关系。此外，Ji等人[31]利用时空信息构建视频息肉分割模型。在COVID-19肺部感染任务中，Paluru等人[32]提出了一种基于变形深度嵌入的轻量级CNN来分割COVID-19胸部CT图像中的异常。 Inf-Net [33] 构建隐式反向注意力和显式边缘注意力来对边界进行建模。 BCS-Net [34]具有三个渐进边界上下文语义重建块，可以帮助解码器捕获肺部感染的零散区域。在乳腺分割任务中，Byra等人[35]通过注意力机制开发了选择性核来调整U-Net的感受野，可以进一步提高乳腺肿瘤的分割精度。 Chen 等人 [36] 提出了一种嵌套 U 网，通过利用不同的深度和共享权重来实现乳腺肿瘤的稳健表示。</description>
    </item>
    
    <item>
      <title>EGE-UNet: an Efficient Group Enhanced UNet for skin lesion segmentation</title>
      <link>https://swimmingliu.github.io/posts/papernotes/2023-ege-unet%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Sat, 11 Nov 2023 19:51:21 +0800</pubDate>
      
      <guid>https://swimmingliu.github.io/posts/papernotes/2023-ege-unet%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</guid>
      <description>EGE-UNet: an Efficient Group Enhanced UNet for skin lesion segmentation 1. Abstract 目前的医学图像分割模型大多是 Transformer + Unet，这些模型的大量参数和计算负载使得它们不适合移动健康应用。
作者提出的EGE-UNet 模型轻量、高效。（与 TransFuse 相比，参数和计算成本分别降低了 494 倍和 160 倍，模型参数量只有50KB）
创新点：组多轴哈达玛产品注意力模块（GHPA）和组聚合桥模块（GAB）。
1.GHPA 对输入特征进行分组，并在不同轴上执行哈达玛产品注意力机制（HPA），以从不同角度提取病理信息。
2.GAB 通过对低级特征、高级特征以及解码器在每个阶段生成的掩码进行分组，有效地融合了多尺度信息。
2. Introduction 背景: 恶性黑色素瘤是世界上增长最快的癌症之一。据美国癌症协会估计，2020 年约有 100,350 例新发病例，超过 6,500 例死亡。因此，自动化皮肤病变分割系统势在必行，因为它可以帮助医疗专业人员快速识别病变区域并促进后续治疗过程。
相同方式可引入脑瘤、肺癌。
为了提高分割性能，最近的研究倾向于采用具有更大参数和计算复杂度的模块，例如结合视觉变换器（ViT）的自注意力机制[7]。例如，Swin-UNet [4]，基于Swin Transformer [11]，利用自注意力机制的特征提取能力来提高分割性能。 TransUNet [5] 开创了用于医学图像分割的 CNN 和 ViT 的串行融合。 TransFuse [26]采用双路径结构，利用 CNN 和 ViT 分别捕获局部和全局信息。UTNetV2[8]利用混合分层架构、高效的双向注意力和语义图来实现全局多尺度特征融合，结合了CNN和ViT的优点。 TransBTS [23] 将自注意力引入脑肿瘤分割任务中，并用它来聚合高级信息。
Abstract提到当前医学分割模型大部分是Transformer + Unet，这里做出具体阐述。
先前的工作通过引入复杂的模块来提高性能，但忽略了实际医疗环境中计算资源的限制。因此，迫切需要为移动医疗中的分割任务设计一种低参数、低计算负载的模型。最近，UNeXt [22] 结合了 UNet [18] 和 MLP [21] 开发了一种轻量级模型，该模型可以获得优异的性能，同时减少参数和计算量。此外，MALUNet [19]通过减少模型通道数并引入多个注意力模块来减小模型大小，从而比 UNeXt 具有更好的皮肤病变分割性能。然而，尽管MALUNet大大减少了参数数量和计算量，但其分割性能仍然低于一些大型模型，例如TransFuse。因此，在本研究中，我们提出了 EGE-UNet，这是一种轻量级皮肤病变分割模型，可实现最先进的效果，同时显着降低参数和计算成本。此外，据我们所知，这是第一个将参数减少到大约 50KB 的工作。</description>
    </item>
    
    <item>
      <title>⏱ timeline</title>
      <link>https://swimmingliu.github.io/archives/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://swimmingliu.github.io/archives/</guid>
      <description>archives</description>
    </item>
    
    <item>
      <title>🔍 Search</title>
      <link>https://swimmingliu.github.io/search/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://swimmingliu.github.io/search/</guid>
      <description>search</description>
    </item>
    
  </channel>
</rss>
