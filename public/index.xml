<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>This is my content on SwimmingLiu&#39;s Blog</title>
    <link>https://swimmingliu.cn/</link>
    <description>Recent content in This is my content on SwimmingLiu&#39;s Blog</description>
    <image>
      <title>SwimmingLiu&#39;s Blog</title>
      <url>https://swimmingliu.cn/papermod-cover.png</url>
      <link>https://swimmingliu.cn/papermod-cover.png</link>
    </image>
    <generator>Hugo -- 0.136.0</generator>
    <language>en</language>
    <lastBuildDate>Wed, 05 Mar 2025 21:45:49 +0800</lastBuildDate>
    <atom:link href="https://swimmingliu.cn/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>(JUC) Java并发面试题笔记</title>
      <link>https://swimmingliu.cn/posts/job/java-juc-interview-questions/</link>
      <pubDate>Wed, 05 Mar 2025 21:45:49 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/job/java-juc-interview-questions/</guid>
      <description>&lt;h2 id=&#34;1-什么是-java-内存模型jmm&#34;&gt;1. 什么是 Java 内存模型（JMM）？&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;JMM&lt;/code&gt; 是 Java内存模型 ， 它是Java虚拟机 &lt;code&gt;JVM&lt;/code&gt; 定义的一种规范，用于描述多线程程序中的变量，像实例字段、静态字段和数组元素，他们如何在内存中存储和传递的规则。也就是规定线程啥时候从住内存里面读数据，啥时候把数据写回到住内存。&lt;code&gt;JMM&lt;/code&gt; 的核心目标是确保多线程环境下的&lt;strong&gt;可见性&lt;/strong&gt;、&lt;strong&gt;有序性&lt;/strong&gt;和&lt;strong&gt;原子性&lt;/strong&gt;, 避免硬件和编译器优化带来的不一致问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;【可见性、有序性、原子性定义】&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;可见性&lt;/strong&gt;：确保一个线程对共享变量的修改，能够及时被另外一个线程看到。 &lt;code&gt;volatile&lt;/code&gt;就是用来保证可见性的，强制线程每次读写的时候，直接从主内存当中获取最新值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;有序性&lt;/strong&gt;：指线程执行操作的顺序。JMM允许某些指令重排序之后再提高性能，但会保证线程内的操作顺序不会被破坏。通过&lt;code&gt;happens-before&lt;/code&gt; (线程A发生在线程B之前)的关系来保证跨线程的有序性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;原子性&lt;/strong&gt;：操作不可分割，线程不会在执行的过程当中被打断。例如, &lt;code&gt;synchronize&lt;/code&gt; 关键字能确保方法或代码块的原子性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;【JMM作用】&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因为不同的操作系统都有一套独立的内存模型，但是Java为了满足跨平台的特性，它需要定义一套内存模型屏蔽个操作系统之间的差异。我们可以利用JMM当中定义好的从Java源码到CPU指令的执行规范，也就是使用&lt;code&gt;synchronized&lt;/code&gt; 、&lt;code&gt;volatile&lt;/code&gt; 等关键字，还有&lt;code&gt;happens-before&lt;/code&gt;原则，就可以写出并发安全的代码了。
比如说，线程A和线程B同时操作 &lt;code&gt;变量-1&lt;/code&gt;，假如最开始&lt;code&gt;变量-1&lt;/code&gt; 是 &lt;code&gt;0&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先，线程A和线程B都读取了&lt;code&gt;变量-1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;然后，线程B对取到的&lt;code&gt;变量-1&lt;/code&gt;自增为&lt;code&gt;1&lt;/code&gt;，并写回主内存&lt;/li&gt;
&lt;li&gt;此时，线程A对读取到的&lt;code&gt;变量-1&lt;/code&gt;也自增&lt;code&gt;1&lt;/code&gt;，并写回主内存。这就会导致线程B的操作失效了，出现并发安全问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果有JMM，我们就可以在线程A要修改数据之前,让它采用CAS乐观锁的方式进行修改。再次去读主内存当中的值，然后修改之后，再判断一下主内存的值是否发生变化。如果没有发生变化，就写回主内存。如果发生变化，就要进行自旋。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;【注意】&lt;/strong&gt; 工作内存是每个线程独立的内存空间，其他线程都是看不到的。主内存是Java堆内存的一部分，所有的实例变量、静态变量和数组元素都存储在主内存当中。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;JMM架构图&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/49ddf552-f9c8-11ef-99c5-c858c0c1deba&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;【内存间交互操作类型 (8种原子操作)】&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;lock 上锁&lt;/strong&gt;：把一个变量表示为一条线程独占的状态&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;unlock 解锁&lt;/strong&gt;： 把一个变量从独占状态中释放出来，释放后的变量才能被其他线程锁定&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;read 读取&lt;/strong&gt;： 从主内存当中读取一个变量到工作内存中&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;load 载入&lt;/strong&gt;：把&lt;code&gt;read&lt;/code&gt;操作从主内存中得到的变量值放入工作内存的变量副本当中&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;use 使用&lt;/strong&gt;：把工作内存当中的一个变量值传递给执行引擎&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;assign 赋值&lt;/strong&gt;：把一个从执行引擎接收到的值赋给工作内存中的变量&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;store 存储&lt;/strong&gt;：把工作内存中的一个变量的值传送给主内存中&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;write 写入&lt;/strong&gt;：把store操作从工作内存中得到的变量值放入主内存的变量中&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;【volatile 特殊规则】&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;可见性&lt;/strong&gt;：对于 &lt;code&gt;volatile&lt;/code&gt; 修饰的变量的写操作会立即刷新到内存中，任何线程对这个&lt;code&gt;volatile&lt;/code&gt; 变量的读操作都能立即看到最新的值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;禁止指令重排序&lt;/strong&gt;： 在对 &lt;code&gt;volatile&lt;/code&gt; 变量进行读/写操作的时候，会插入内存屏障，禁止指令重排序。也就是该变量的写操作不能与之前的读/写操作重排序，它的都操作不能与之后的读/写操作重排序。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;【Happens-Before 原则】&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;见下一个问题&lt;/p&gt;
&lt;h2 id=&#34;2-什么是java的-happens-before-规则&#34;&gt;2. 什么是Java的 happens-before 规则?&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;happens-before&lt;/code&gt; 原则就是 &lt;code&gt;JMM&lt;/code&gt; 当中定义操作间顺序的规则，确保操作的有序性和可见性。&lt;/p&gt;</description>
    </item>
    <item>
      <title>操作系统面试题笔记</title>
      <link>https://swimmingliu.cn/posts/job/operation-system-interview-questions/</link>
      <pubDate>Sat, 01 Mar 2025 09:49:44 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/job/operation-system-interview-questions/</guid>
      <description>&lt;h2 id=&#34;1-说说你知道的几种-io-模型&#34;&gt;1. 说说你知道的几种 I/O 模型&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;【常见的五大I/O模型】&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;常见的五大I/O模式分别为: 同步阻塞I/O (Blocking I/O) &lt;code&gt;BIO&lt;/code&gt;、非阻塞I/O (Non-blocking I/O) &lt;code&gt;NIO&lt;/code&gt;、I/O多路复用、信号量驱动I/O、异步I/O &lt;code&gt;AIO&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;我们假如要烧水喝，看不同模型是怎么烧的水喝&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;&lt;strong&gt;I/O 模型&lt;/strong&gt;&lt;/th&gt;
          &lt;th&gt;特性&lt;/th&gt;
          &lt;th&gt;烧水案例&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;同步阻塞I/O &lt;code&gt;BIO&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;数据从网卡到内核，再从内核到用户空间，都是阻塞操作。&lt;/td&gt;
          &lt;td&gt;自己动手烧水，一直盯着，等水烧开了，倒在杯子里喝。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;非阻塞I/O &lt;code&gt;NIO&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;数据从网卡到内核不阻塞，&lt;code&gt;read&lt;/code&gt;不到数据直接返回，但是从内核到用户空间会阻塞 (用户轮询&lt;code&gt;read&lt;/code&gt;)&lt;/td&gt;
          &lt;td&gt;自己动手烧水，隔两分钟看一下，水烧开没有。等水烧开了，倒在杯子里喝。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;I/O多路复用&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;只有一个线程查看多个连接是否有数据准备就绪 (看从网卡能不能&lt;code&gt;read&lt;/code&gt;到数据到内核)&lt;/td&gt;
          &lt;td&gt;找专门烧水的领居帮忙，他把水烧好了之后，会喊你来拿。但是你要自己倒在杯子里喝。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;信号驱动I/O&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;数据从网卡到内核之后会自动通知用户程序，然后让他&lt;code&gt;read&lt;/code&gt;读取数据&lt;/td&gt;
          &lt;td&gt;去烧水房烧水，全自动的，有个通知灯。水烧完了之后会按你家的门铃，但是有客人来了，也会按门铃&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;异步I/O &lt;code&gt;AIO&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;全程不阻塞，拷贝到用户空间之后直接回调。&lt;/td&gt;
          &lt;td&gt;和多路复用类似，但是烧完水之后不用自己倒水，他帮你倒好了，还吹凉了，你过来喝就行。&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;img alt=&#34;IO五种模型&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/3bbe065d-f63f-11ef-a797-c858c0c1deba&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>个人简历常问问题</title>
      <link>https://swimmingliu.cn/posts/job/personal-interview-hot-question/</link>
      <pubDate>Thu, 27 Feb 2025 10:52:54 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/job/personal-interview-hot-question/</guid>
      <description>&lt;p&gt;个人简历详情查看 -&amp;gt; &lt;a href=&#34;https://rxresu.me/dashboard/resumes&#34;&gt;个人简历页&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;1-异步秒杀机制的异步是如何实现的&#34;&gt;1. 异步秒杀机制的异步是如何实现的?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;【正常秒杀的顺序】&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;查询优惠券 -&amp;gt; 判断秒杀库存 -&amp;gt; 查询订单 -&amp;gt; 校验是否一人一单 -&amp;gt; 扣减库存 -&amp;gt; 创建订单&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;【异步秒杀】&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为了实现用户异步下单，其实就是把是否能够下单的判断逻辑和下单的操作拆分开。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;采用Redis来判断是否有足够的库存和校验一人一单
&lt;ul&gt;
&lt;li&gt;如果满足条件，把用户、订单id、商品id保存到阻塞队列，直接给用户返回秒杀成功。&lt;/li&gt;
&lt;li&gt;如果不满足条件，直接返回秒杀失败。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;后台线程会去执行queue里边的消息&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这样就可以实现异步的秒杀下单了，那么如果实现判断秒杀库存和校验一人一单呢？&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;1653561657295&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/8f260a35-f4b5-11ef-a915-c858c0c1deba&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;【秒杀库存 + 一人一单】&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用户下单之后，判断redis当中的库存key的value是否大于&lt;code&gt;0&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;value &amp;gt; 0&lt;/code&gt; -&amp;gt; 第2步&lt;/li&gt;
&lt;li&gt;&lt;code&gt;value &amp;lt;= 0&lt;/code&gt; -&amp;gt; 直接返回库存不足 （返回&lt;code&gt;1&lt;/code&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;如果库存充足，判断redis当中的秒杀商品key的 &lt;code&gt;set&lt;/code&gt; 集合是否已包含&lt;code&gt;userid&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;包含&lt;code&gt;userid&lt;/code&gt;， 说明用户已经下单了，直接返回当前用户已下单 (返回&lt;code&gt;2&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;不包含 &lt;code&gt;userid&lt;/code&gt; -&amp;gt; 第3步&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;如果用户没有下单，将用户的 &lt;code&gt;userid&lt;/code&gt; 存入 &lt;code&gt;set&lt;/code&gt; 里面 (返回&lt;code&gt;0&lt;/code&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;【注意】&lt;/strong&gt; 整个操作是原子性的，这样就确保了不会出现&lt;strong&gt;超卖现象和一人多单现象&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;-- 1.参数列表&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;-- 1.1.秒杀商品id&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;local&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;voucherId&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ARGV&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;-- 1.2.用户id&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;local&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;userId&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ARGV&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;-- 1.3.订单id&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;local&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;orderId&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ARGV&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;-- 2.数据key&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;-- 2.1.库存key&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;local&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stockKey&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;seckill:stock:&amp;#39;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;..&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;voucherId&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;-- 2.2.秒杀商品订单key&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;local&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;orderKey&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;seckill:order:&amp;#39;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;..&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;voucherId&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;-- 3.脚本业务&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;-- 3.1.判断库存是否充足 get stockKey&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kr&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tonumber&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;redis.call&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;get&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stockKey&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;then&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;-- 3.2.库存不足，返回1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kr&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kr&#34;&gt;end&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;-- 3.2.判断用户是否下单 SISMEMBER orderKey userId&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kr&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;redis.call&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;sismember&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;orderKey&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;userId&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;then&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;-- 3.3.存在，说明是重复下单，返回2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kr&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kr&#34;&gt;end&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kr&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;【阻塞队列实现下单】&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Redis面试题笔记</title>
      <link>https://swimmingliu.cn/posts/job/redis-interview-questions/</link>
      <pubDate>Thu, 20 Feb 2025 21:21:45 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/job/redis-interview-questions/</guid>
      <description>&lt;h2 id=&#34;1-redis主从复制的原理&#34;&gt;1. Redis主从复制的原理&lt;/h2&gt;
&lt;p&gt;【&lt;strong&gt;主从复制的原理&lt;/strong&gt;】&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;同步：从节点向主节点发送&lt;code&gt;psync&lt;/code&gt;命令进行同步，从节点保存主节点返回的 &lt;code&gt;runid&lt;/code&gt; 和 &lt;code&gt; offset&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;全量复制：如果是第一次连接或者连接失败且&lt;code&gt;repl_backlog_buffer&lt;/code&gt; 缓存区不包含&lt;code&gt;slave_repl_offset&lt;/code&gt;， 则生成主节点的数据快照(RDB文件)发给从节点&lt;/li&gt;
&lt;li&gt;增量复制：全量复制完毕后，主从节点之间会保持长连接。如果连接没有断开或者&lt;code&gt;slave_repl_offset&lt;/code&gt;仍然在&lt;code&gt;repl_backlog_buffer&lt;/code&gt;中，则将后续的写操作传递给从节点，让数据保持一致。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;【全量复制细节】&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;全量复制的过程是基于TCP长连接的，主要流程如下&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;从节点发送&lt;code&gt;psync ? -1&lt;/code&gt;表示需要建立连接进行同步，主节点返回主节点ID &lt;code&gt;runid&lt;/code&gt; 和 复制进度&lt;code&gt;offset&lt;/code&gt; (第一次同步用 -1 表示)。从节点接受之后，保存主节点的信息。&lt;/li&gt;
&lt;li&gt;主节点执行&lt;code&gt;bgsave&lt;/code&gt;命令生成数据快照RDB文件，然后将RDB文件发送给从节点。从节点接受文件后，清除现有的所有数据，然后加载RDB文件&lt;/li&gt;
&lt;li&gt;如果在制作数据快照RDB文件的过程当中，主节点接收到了新的写操作，主节点会将其记录在&lt;code&gt;repl buffer&lt;/code&gt; 里面。然后将&lt;code&gt;repl buffer&lt;/code&gt;当中的写操作发给从节点，让其数据保持一致。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt=&#34;Redis主从全量复制&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/ac630d4c-ef8d-11ef-a882-c858c0c1deba&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;【增量复制细节】&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果主从节点意外断开连接，为了保持数据的一致性，必须重新同步数据。如果使用全量复制来保持一致性的话，开销太大，所以采用增量复制。&lt;/p&gt;
&lt;p&gt;增量复制的具体流程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;连接恢复后，从节点会发送&lt;code&gt;psync {runid} {offset}&lt;/code&gt;， 其中主节点ID &lt;code&gt;runid&lt;/code&gt; 和 复制进度&lt;code&gt;offset&lt;/code&gt;用于标识是哪一个服务器主机和复制进度。&lt;/li&gt;
&lt;li&gt;主节点收到&lt;code&gt;psync&lt;/code&gt; 命令之后，会用&lt;code&gt;conitnue&lt;/code&gt;响应告知从节点，采用增量复制同步数据&lt;/li&gt;
&lt;li&gt;最后，主节点根据&lt;code&gt;offset&lt;/code&gt;查找对应的进度，将断线期间未同步的写命令，发送给从节点。同时，主节点将所有的写命令写入&lt;code&gt;repl_backlog_buffer&lt;/code&gt;， 用于后续判断是采用增量复制还是全量复制。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;【注意】从节点 &lt;code&gt;psync&lt;/code&gt; 携带的 &lt;code&gt;offset&lt;/code&gt; 为 &lt;code&gt;slave_repl_offset&lt;/code&gt;。如果 &lt;code&gt;repl_backlog_buffer&lt;/code&gt;包含&lt;code&gt;slave_repl_offset&lt;/code&gt; 对应的部分，则采用增量复制，否则采用全量复制。&lt;code&gt;repl_backlog_buffer&lt;/code&gt;的默认缓冲区大小为&lt;code&gt;1M&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;Redis主从增量复制&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/ac9f21a3-ef8d-11ef-9016-c858c0c1deba&#34;&gt;&lt;/p&gt;
&lt;p&gt;【&lt;strong&gt;为什么要主从复制&lt;/strong&gt;】&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;备份数据&lt;/strong&gt;：主从复制实现了数据的热备份，是持久化之外的数据冗余方式&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;故障恢复&lt;/strong&gt;：当主节点宕机之后，可以采用从节点提供服务。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;负载均衡&lt;/strong&gt;:  主从复制实现了读写分离，只有主节点支持读写操作，从节点只有读操作。在读多写少的场景下，可以提高Redis服务器的并发量。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&#34;Redis主从读写分离&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/acad0d12-ef8d-11ef-b17f-c858c0c1deba&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;2-redis集群的实现原理是什么&#34;&gt;2. Redis集群的实现原理是什么?&lt;/h2&gt;
&lt;p&gt;【&lt;strong&gt;Redis集群基本知识&lt;/strong&gt;】&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;: Redis集群由多个实例组成，每个实例存储部分数据 (每个实例之间的数据不重复) 。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;【注】集群和主从节点不是一个东西，集群的某一个实例当中可能包含一个主节点 + 多个从节点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;为什么用&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;问题&lt;/th&gt;
          &lt;th&gt;解决方案&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;容量不足&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;数据分片，将数据分散不存到不同的主节点&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;高并发写入&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;数据分片，将写入请求分摊到多个主节点&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;主机宕机问题&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;自动切换主从节点，避免影响服务， 不需要手动修改客户端配置&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;节点通信协议&lt;/strong&gt;：Redis集群采用Gossip协议, 支持分布式信息传播、延迟低、效率高。采用去中心化思想，任意实例(主节点)都可以作为请求入口，节点间相互通信。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分片原理&lt;/strong&gt;： 采用哈希槽(Hash Slot)机制来分配数据，整个空间可以划分为&lt;strong&gt;16384&lt;/strong&gt; (16 * 1024)个槽。 每个Redis负责一定范围的哈希槽,数据的key经过哈希函数计算之后对&lt;strong&gt;16384&lt;/strong&gt;取余可定位到对应的节点。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&#34;Redis集群架构图&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/acc54635-ef8d-11ef-971e-c858c0c1deba&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Java集合面试题笔记</title>
      <link>https://swimmingliu.cn/posts/job/java-set-interview-questions/</link>
      <pubDate>Thu, 20 Feb 2025 21:20:50 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/job/java-set-interview-questions/</guid>
      <description>&lt;h2 id=&#34;1-说说-java-中-hashmap-的原理&#34;&gt;1. 说说 Java 中 HashMap 的原理？&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;【HashMap定义】&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;结构：数组 + 链表 + 红黑树 (&lt;code&gt;JDK 1.8&lt;/code&gt; 之后)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;默认值：初始容量为16 (数组长度)，负载因子为 0.75。当存储的元素为 16 * 0.75 = 12个时，会触发&lt;code&gt;Resize()&lt;/code&gt; 扩容操作，容量 x 2 并重新分配位置。但是扩容是有一定开销的，频繁扩容会影响性能。另外，&lt;code&gt;TREEIFY_THRESHOLD&lt;/code&gt; 转换为红黑树的默认链表长度阈值为 8, &lt;code&gt;UNTREEIFY_THRESHOLD&lt;/code&gt; 从红黑树转换为链表的阈值为 6。 两个阈值采用不同值的原因是防止刚转换为红黑树，又变成链表，反复横跳，消耗资源。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数组下标位置计算方法：首先使用key的&lt;code&gt;hashCode()&lt;/code&gt;方法计算下标位置，然后通过  &lt;code&gt;indexFor()&lt;/code&gt; (&lt;code&gt;JDK 1.7&lt;/code&gt; 以前) 计算下标值。 &lt;code&gt;JDK 1.7&lt;/code&gt;后，为了提高计算效率采用 &lt;code&gt;(len - 1) &amp;amp; hash&lt;/code&gt; 来确定下标值。&lt;/p&gt;
&lt;p&gt;【注】数组的长度&lt;code&gt;len&lt;/code&gt; 是2的幂次方时，&lt;code&gt;(len - 1) &amp;amp; hash&lt;/code&gt; 等价于 &lt;code&gt;hash % len&lt;/code&gt;。 这也是为什么数组长度必须是2的幂次方。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&#34;HashMap底层结构&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/65f25922-ef8d-11ef-827a-c858c0c1deba&#34;&gt;&lt;/p&gt;
&lt;p&gt;【&lt;strong&gt;HashMap线程不安全&lt;/strong&gt;】&lt;/p&gt;
&lt;p&gt;为了保证HashMap的读写效率高，它的操作是非同步的，也就是说读写操作没有锁保护。所以多线程场景下是线程不安全的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;【HashMap不同版本区别】&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;JDK 1.7: 数组 + 链表，链表部分采用头插法，多线程会导致出现环形链表。扩容会计算每个元素hash值，并分配到新的位置，开销大。&lt;/li&gt;
&lt;li&gt;JDK 1.8：数组 + 链表 + 红黑树，采用高低位置来分配位置，即判断&lt;code&gt;(e.hash &amp;amp; oldCap) == 0&lt;/code&gt;， 减少了计算hash的次数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;【HashMap的PUT方法】&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Java基础题面试笔记</title>
      <link>https://swimmingliu.cn/posts/job/java-basic-interview-questions/</link>
      <pubDate>Wed, 19 Feb 2025 15:18:58 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/job/java-basic-interview-questions/</guid>
      <description>&lt;h2 id=&#34;1-序列化和反序列化&#34;&gt;1. 序列化和反序列化&lt;/h2&gt;
&lt;p&gt;1.序列化和反序列化：把对象转换为字节流，用于存储和传输；读取字节流数据，重新创建对象。
2.序列化不包括静态对象：序列化和反序列化的本质是调用对象的&lt;code&gt;writeObject&lt;/code&gt;和&lt;code&gt;readObject&lt;/code&gt;方法,来实现将对象写入输出流和读取输入流。但是，静态变量不属于对象，所以调用这两个方法就没法儿让静态变量参与。&lt;/p&gt;
&lt;h2 id=&#34;2-什么是不可变类&#34;&gt;2. 什么是不可变类？&lt;/h2&gt;
&lt;p&gt;1.不可变类：初始化之后，就不能修改的类。
2.修饰方法：final 和 private 修饰所有类和变量
3.不可修改：不暴露set方法，只能通过重新创建对象替代修改功能(&lt;code&gt;String&lt;/code&gt;的replace方法)
4.优缺点：
优点：线程安全，缓存友好
缺点：频繁拼接和修改会浪费资源&lt;/p&gt;
&lt;h2 id=&#34;3-exception和error区别&#34;&gt;3. Exception和Error区别?&lt;/h2&gt;
&lt;p&gt;1.Exception和Error定义区别：Exception是可处理程序异常，Error是系统级不可回复错误
2.try-catch建议：
1.范围能小则小
2.Exception最好要写清楚具体是哪一个Exception(IOException)
3.null值等能用if判断的，不要用try-catch,因为异常比条件语句低效
4.finally不要直接return和处理返回值&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;Exception和Error区别&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/946b73cc-ef5d-11ef-95ab-c858c0c1deba&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;4-java-中的-hashcode-和-equals-方法之间有什么关系&#34;&gt;4. Java 中的 hashCode 和 equals 方法之间有什么关系？&lt;/h2&gt;
&lt;p&gt;1、&lt;code&gt;equals()&lt;/code&gt; 和 &lt;code&gt;hashCode()&lt;/code&gt; 的关系&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果两个对象&lt;code&gt;euqals()&lt;/code&gt; 为 &lt;code&gt;true&lt;/code&gt;， 则其 &lt;code&gt;hashCode()&lt;/code&gt;一定相同&lt;/li&gt;
&lt;li&gt;如果两个对象&lt;code&gt;hashCode()&lt;/code&gt; 相同，其&lt;code&gt;equals()&lt;/code&gt;结果不一定为&lt;code&gt;true&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2、为什么重写&lt;code&gt;equals()&lt;/code&gt;之后，一定要重写&lt;code&gt;hashCode()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;当重写&lt;code&gt;equals()&lt;/code&gt; 之后，通常是重新定义了两个对象相等的逻辑。如果不重写&lt;code&gt;hashCode()&lt;/code&gt;方法， 则在散列集合（&lt;code&gt;HashMap&lt;/code&gt; 和 &lt;code&gt;HashSet&lt;/code&gt;）中，可能无法正确存储和检索，因为两个相同的对象可能有不同的&lt;code&gt;hash&lt;/code&gt;值。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;例如，下方Person类重写了&lt;code&gt;equals()&lt;/code&gt; 方法，但是没有重新&lt;code&gt;hashCode()&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Java&#34; data-lang=&#34;Java&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Person&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;private&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;private&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;age&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;boolean&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;equals&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Object&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;obj&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;obj&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;obj&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;null&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;||&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;getClass&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;obj&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getClass&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Person&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;person&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Person&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;obj&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;age&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;person&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;age&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Objects&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;equals&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;person&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;创建相同的对象，并添加到&lt;code&gt;HashSet&lt;/code&gt;中&lt;/p&gt;</description>
    </item>
    <item>
      <title>MySQL面试题笔记</title>
      <link>https://swimmingliu.cn/posts/job/mysql-interview-questions/</link>
      <pubDate>Wed, 19 Feb 2025 15:16:42 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/job/mysql-interview-questions/</guid>
      <description>&lt;h2 id=&#34;1mysql-中的数据排序是怎么实现的&#34;&gt;1.MySQL 中的数据排序是怎么实现的？&lt;/h2&gt;
&lt;p&gt;1.&lt;strong&gt;排序方法&lt;/strong&gt;：索引排序和文件排序 (filesort)&lt;/p&gt;
&lt;p&gt;2.&lt;strong&gt;索引排序&lt;/strong&gt;：如果&lt;code&gt;order by xxx&lt;/code&gt;的字段为索引字段，则利用索引进行排序。效率最高，索引默认有序。&lt;/p&gt;
&lt;p&gt;3.&lt;strong&gt;文件排序 (filesort)&lt;/strong&gt;：内存排序(单路排序和双路排序)和磁盘排序，具体取决于排序数据的大小。其中，内存排序使用单路排序或双路排序，取决于&lt;code&gt;max_length_for_sort_data&lt;/code&gt;(默认为4096个字节)&lt;/p&gt;
&lt;p&gt;4.&lt;strong&gt;双路排序&lt;/strong&gt;：取&lt;code&gt;row_id&lt;/code&gt;(如果有主键，则为主键)和&lt;code&gt;select a,b,c order by xxx&lt;/code&gt;的&lt;code&gt;xxx&lt;/code&gt;字段放入&lt;code&gt;sort_buffer&lt;/code&gt;(排序缓存)中，将排序后的&lt;code&gt;row_id&lt;/code&gt;回表查询&lt;code&gt;a,b,c&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;5.&lt;strong&gt;单路排序&lt;/strong&gt;: 直接把要查的所有字段放入&lt;code&gt;sort_buffer&lt;/code&gt;里，排序后直接得到结果集合&lt;/p&gt;
&lt;p&gt;6.&lt;strong&gt;磁盘排序&lt;/strong&gt;（归并排序）:将数据分为多份文件，单独对文件进行排序，然后合并成一个有序的大文件&lt;/p&gt;
&lt;h2 id=&#34;2-mysql-的-change-buffer-是什么它有什么作用&#34;&gt;2. MySQL 的 Change Buffer 是什么？它有什么作用？&lt;/h2&gt;
&lt;p&gt;1.ChangeBuffer定义：Change Buffer是InnoDB缓冲当中的一块缓存区，用于暂存二级索引的修改，避免二级索引页修改产生的随机IO
2.ChangeBuffer注意事项：只能用于二级索引，不能用于其他任何索引，包括主键索引和唯一索引都不行。
3.如果ChangeBuffer挂了，更改操作未执行，是否会出现脏数据？
首先，ChangeBuffer也会保存在磁盘空间里面，redo log会记录Change Buffer当中的修改操作，确保数据一致性。&lt;/p&gt;
&lt;p&gt;知识拓展1：一级索引和二级索引区别&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;一级索引（聚簇索引）&lt;/strong&gt;：数据表的主键索引，数据和索引存储在同一B+树的叶子节点中。每个表只能有一个一级索引。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;二级索引（非聚簇索引）&lt;/strong&gt;：除主键外的其他索引，叶子节点存储索引列的值和对应的主键值。通过二级索引查询时，需要先通过二级索引获取主键值，再通过主键值查询数据，这个过程称为“回表”。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;知识拓展2:  MySQL中有哪些常见索引？都有什么区别？&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在MySQL中，索引是提高查询效率的关键工具。常见的索引类型包括主键索引、唯一索引、普通索引、全文索引和空间索引。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. 主键索引（Primary Key Index）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：主键索引是一种特殊的唯一索引，用于唯一标识表中的每一行数据。每个表只能有一个主键索引，且主键列的值不能为空。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt;：主键索引的叶子节点存储完整的数据行，因此查询效率高。在InnoDB存储引擎中，主键索引是聚簇索引，数据存储与索引结构合并。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2. 唯一索引（Unique Index）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：唯一索引确保索引列的每个值都是唯一的，但允许有空值。与主键索引类似，不同之处在于唯一索引允许列值为NULL。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt;：唯一索引的叶子节点存储索引列的值和对应的主键值。在InnoDB中，唯一索引是非聚簇索引，数据存储与索引结构分开。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3. 普通索引（Index）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：普通索引是最基本的索引类型，没有任何限制。索引列的值可以重复，也可以为NULL。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt;：普通索引的叶子节点存储索引列的值和对应的主键值。在InnoDB中，普通索引是非聚簇索引，数据存储与索引结构分开。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;4. 全文索引（Fulltext Index）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：全文索引用于对文本数据进行全文搜索，适用于MyISAM存储引擎。它允许对文本字段进行复杂的搜索，如查找包含特定单词的记录。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt;：全文索引的叶子节点存储文档的词项信息。在MyISAM中，全文索引是非聚簇索引，数据存储与索引结构分开。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;5. 空间索引（Spatial Index）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：空间索引用于对地理空间数据进行索引，支持空间数据类型的快速查询。它适用于存储地理位置、地图等空间数据的表。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt;：空间索引的叶子节点存储空间数据的索引信息。在MyISAM中，空间索引是非聚簇索引，数据存储与索引结构分开。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;主键索引&lt;/strong&gt;：用于唯一标识每一行数据，值不能为空。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;唯一索引&lt;/strong&gt;：确保索引列的值唯一，但允许有空值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;普通索引&lt;/strong&gt;：最基本的索引类型，允许重复和空值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;全文索引&lt;/strong&gt;：用于对文本数据进行全文搜索，适用于MyISAM存储引擎。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;空间索引&lt;/strong&gt;：用于对地理空间数据进行索引，支持空间数据类型的快速查询。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;3-详细描述一条-sql-语句在-mysql-中的执行过程&#34;&gt;3. 详细描述一条 SQL 语句在 MySQL 中的执行过程。&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;连接器判断用户是否成功建立连接，数据库连接的权限校验&lt;/li&gt;
&lt;li&gt;连接器会查询缓存，&lt;code&gt;key&lt;/code&gt; 是 SQL 语句，&lt;code&gt;value&lt;/code&gt; 是查询结果。如果命中，直接返回查询结果。(MySQL 8.0之后，就移除这个功能了)。&lt;/li&gt;
&lt;li&gt;分析器分析SQL语法和词法是否有误&lt;/li&gt;
&lt;li&gt;优化器生成SQL的执行计划，确定使用的索引和调整where的执行顺序（包括连表顺序）&lt;/li&gt;
&lt;li&gt;执行器判断当前用户是否有权限查询该表，然后执行该SQL语句&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt=&#34;MySQL架构图&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/7457976c-ef5d-11ef-b738-c858c0c1deba&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Java面试题-随手记</title>
      <link>https://swimmingliu.cn/posts/job/java-interview-questions-notes/</link>
      <pubDate>Fri, 27 Dec 2024 17:27:35 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/job/java-interview-questions-notes/</guid>
      <description>&lt;h2 id=&#34;-和-equals-区别&#34;&gt;== 和 equals 区别&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;==&lt;/code&gt; 基本类型(int, long, float, char, boolean) 值比较， 引用类型(String，List) 进行地址比较&lt;/p&gt;
&lt;p&gt;&lt;code&gt;equals&lt;/code&gt; 默认就是 &lt;code&gt;==&lt;/code&gt; ，但是部分引用类型(String，List)重写了该方法，进行值比较&lt;/p&gt;
&lt;h2 id=&#34;get-和-post-区别&#34;&gt;get 和 post 区别&lt;/h2&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;特性&lt;/th&gt;
          &lt;th&gt;GET&lt;/th&gt;
          &lt;th&gt;POST&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;目的&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;获取资源，查询数据&lt;/td&gt;
          &lt;td&gt;提交数据，创建或更新资源&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;请求数据方式&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;参数通过 URL 查询字符串传递&lt;/td&gt;
          &lt;td&gt;数据通过请求体传递&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;数据暴露&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;数据暴露在 URL 中，较不安全&lt;/td&gt;
          &lt;td&gt;数据存储在请求体中，相对安全&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;数据大小限制&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;URL 长度有限制（约 2048 个字符）&lt;/td&gt;
          &lt;td&gt;没有数据大小限制&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;适用场景&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;获取数据，查询，展示资源&lt;/td&gt;
          &lt;td&gt;提交表单，上传文件，修改资源，发送敏感数据等&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;springmvc中reponsebodypathvariablerequestparameters在什么情况下使用&#34;&gt;SpringMVC中@ReponseBody、@PathVariable、@RequestParameters在什么情况下使用?&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;@ReponseBody&lt;/code&gt; 用于接受请求体数据，一般用于POST请求&lt;/p&gt;
&lt;p&gt;&lt;code&gt;@PathVariable&lt;/code&gt; 用于接受路径参数，一般用户接受 &lt;code&gt;id&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;@RequestParameters&lt;/code&gt; 用于接受请求参数，一般用于GET请求&lt;/p&gt;
&lt;h2 id=&#34;jvm堆的结构gc介绍和作用&#34;&gt;JVM堆的结构、GC介绍和作用&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.51cto.com/article/710705.html&#34;&gt;JVM堆结构的参考文章&lt;/a&gt; 、 &lt;a href=&#34;https://www.bilibili.com/video/BV1dt411u7wi&#34;&gt;GC垃圾回收过程&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;区域&lt;/th&gt;
          &lt;th&gt;主要用途&lt;/th&gt;
          &lt;th&gt;特点&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;新生代（Young Generation）&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;存储新创建的对象，快速垃圾回收&lt;/td&gt;
          &lt;td&gt;包含 Eden 区和两个 Survivor 区，采用复制算法进行回收&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;老年代（Old Generation）&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;存储长期存活的对象&lt;/td&gt;
          &lt;td&gt;回收频率较低，垃圾回收较耗时&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;永久代（Permanent Generation) (jdk 1.7）&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;存储类的元数据、方法字节码等&lt;/td&gt;
          &lt;td&gt;在 jdk 1.8 被 Metaspace 替代&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;元空间（jdk 1.8）&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;存储类的元数据&lt;/td&gt;
          &lt;td&gt;不再属于堆，使用本地内存，大小由系统限制&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;code&gt;GC&lt;/code&gt; 是垃圾回收器， 作用是自动内存管理和避免内存泄漏&lt;/p&gt;</description>
    </item>
    <item>
      <title>A Dual-Branch Framework with Prior Knowledge for Precise Segmentation of Lung Nodules in Challenging CT Scans</title>
      <link>https://swimmingliu.cn/posts/papernotes/2023-dbnet/</link>
      <pubDate>Sun, 03 Mar 2024 15:37:07 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/papernotes/2023-dbnet/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;肺癌是全球最致命的癌症之一，早期诊断对于患者的生存至关重要。&lt;strong&gt;肺结节&lt;/strong&gt;是&lt;strong&gt;早期肺癌的主要表现&lt;/strong&gt;，通常通过 &lt;strong&gt;CT 扫描&lt;/strong&gt;进行评估。如今，计算机辅助诊断系统被广泛用于辅助医生进行疾病诊断。&lt;strong&gt;肺结节的准确分割&lt;/strong&gt;受到&lt;strong&gt;内部异质性和外部数据&lt;/strong&gt;因素的影响。为了克服&lt;strong&gt;结节的细微、混合、粘附型、良性和不确定类别&lt;/strong&gt;的分割挑战，提出了一种新的&lt;strong&gt;混合手动特征网络&lt;/strong&gt;，可&lt;strong&gt;增强灵敏度和准确性&lt;/strong&gt;。该方法通过&lt;strong&gt;双分支网络框架和多维融合模块&lt;/strong&gt;集成&lt;strong&gt;特征信息&lt;/strong&gt;。通过使用&lt;strong&gt;多个数据源和不同数据质量&lt;/strong&gt;进行训练和验证，我们的方法在 &lt;strong&gt;LUNA16&lt;/strong&gt;、&lt;strong&gt;多厚度切片图像数据集 (Multi-thickness Slice Image dataset)&lt;/strong&gt;、&lt;strong&gt;LIDC&lt;/strong&gt; 和 &lt;strong&gt;UniToChest&lt;/strong&gt; 上表现出领先的性能，Dice 相似系数达到 86.89%、75.72%、84.12% 和 80.74分别超过了当前大多数肺结节分割方法。我们的方法进一步提高了肺结节分割任务的&lt;strong&gt;准确性、可靠性和稳定性&lt;/strong&gt;，即使是在具有挑战性的 CT 扫描中也是如此。本研究中使用的代码发布在 GitHub 上，可通过以下 URL (&lt;a href=&#34;https://github.com/BITEWKRER/DBNet&#34;&gt;https://github.com/BITEWKRER/DBNet&lt;/a&gt;) 获取。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;肺癌是全球癌症相关死亡的主要原因[1]。仅在美国，预计 2023 年将有 127,070 人死于肺癌，占所有癌症死亡的 21% [2]。不幸的是，超过 50% 的肺癌病例发生在发展中国家或不发达国家，与发达国家相比，这些国家的医疗资源有限[3]。&lt;/p&gt;
&lt;p&gt;为了增加生存机会，早期诊断和治疗肺癌仍然至关重要。在中国，研究表明，&lt;strong&gt;小于1厘米的I期肺癌的5年生存率为92%&lt;/strong&gt;。然而，&lt;strong&gt;晚期肺癌的5年生存率低得多&lt;/strong&gt;，仅为&lt;strong&gt;7.0%&lt;/strong&gt;[4]。&lt;strong&gt;利用计算机断层扫描 (CT) 进行肺癌筛查已显示出可大幅降低死亡率的潜力&lt;/strong&gt; [5]、[6]。低剂量CT是目前肺癌筛查最常用的方法。此外，移动CT的引入有助于解决欠发达国家和偏远地区缺乏CT扫描仪的问题[6]。由于可能没有明显的症状，检测早期肺癌的存在可能会带来重大挑战。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;这种医学背景数据可以直接借鉴，Chatgpt润色改写就完事儿&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在 &lt;strong&gt;CT 图像上识别肺结节提供了疾病的关键指标&lt;/strong&gt; [1], [3]。这些结节代表&lt;strong&gt;圆形异常&lt;/strong&gt;，其&lt;strong&gt;大小各异&lt;/strong&gt;，直径范围为 &lt;strong&gt;3 至 30 毫米&lt;/strong&gt; [7]。为了进一步研究肺结节，美国国家癌症研究所组装了“肺部图像数据库联盟和图像数据库资源计划（LIDC）”数据集[8]。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;欠发达地区设备不足、人员不足，导致医生的诊断和治疗时间有限&lt;/strong&gt;[9]。在这种情况下，&lt;strong&gt;医生的工作量很大、重复且耗时&lt;/strong&gt;[10]、[5]。此外，由于与CT切片相比，&lt;strong&gt;肺部结节性病变&lt;/strong&gt;占据相对&lt;strong&gt;较小的面积&lt;/strong&gt;，&lt;strong&gt;长时间和密集的CT筛查&lt;/strong&gt;可能会导致&lt;strong&gt;漏检小的、细微的或 GGO&lt;/strong&gt; (肺磨玻璃结节) [3]，[6]。为了解决这些问题，计算机辅助诊断系统（CAD）出现并得到了快速发展，特别是随着基于深度学习技术的诊断方法的进步。 &lt;strong&gt;CAD系统大大减轻了医生的工作量，最大限度地降低了未发现结节的风险，并提高了肺结节诊断的效率和可靠性&lt;/strong&gt;。然而，当前用于肺结节分割的 CAD 系统仍然面临一些挑战。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;下面详细阐述了肺结节分割的几个现有挑战，可以从这些挑战入手&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;首先，&lt;strong&gt;放射科医生标记的肺结节&lt;/strong&gt;包含&lt;strong&gt;九个诊断特征&lt;/strong&gt;[11]，&lt;strong&gt;异质性表型&lt;/strong&gt;阻碍了&lt;strong&gt;肺结节分割的发展&lt;/strong&gt;。如图1所示，&lt;strong&gt;实心结节（a，b）具有清晰的形状和边界&lt;/strong&gt;，而&lt;strong&gt;微妙的GGO结节（e）具有低对比度和模糊的边界&lt;/strong&gt;[4]，使得网络很容易将&lt;strong&gt;它们分类为背景区域&lt;/strong&gt;。&lt;strong&gt;空洞（g）结节降低了网络分割的敏感性&lt;/strong&gt;，并且由于&lt;strong&gt;背景和分割目标之间的极度不平衡，小结节很容易被遗漏&lt;/strong&gt;[12]。&lt;/p&gt;
&lt;p&gt;由于周围多余的组织结构，&lt;strong&gt;血管旁或胸膜旁（c、d、f）可能会导致网络分类错误&lt;/strong&gt;[13]。此外，&lt;strong&gt;部分实性结节（h）比纯GGO更致密&lt;/strong&gt;，产生更&lt;strong&gt;复杂的异质纹理，更容易发展成恶性结节&lt;/strong&gt;[14]。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt=&#34;image-20240303102609243&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/262f8e71-d931-11ee-b68c-c858c0c1debd&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;其次，肺结节内部因素造成的分割困难在于&lt;strong&gt;医生注释、层厚、数据来源和数据质量&lt;/strong&gt;。&lt;strong&gt;数据质量差&lt;/strong&gt;或&lt;strong&gt;不同医生的经验&lt;/strong&gt;可能会导致&lt;strong&gt;不同的注释和注释者数量&lt;/strong&gt;。由&lt;strong&gt;多名医生注释的病变区域&lt;/strong&gt;通常更&lt;strong&gt;可靠&lt;/strong&gt;，减少了潜在的临床风险。&lt;strong&gt;在资源有限的地区&lt;/strong&gt;，由于 &lt;strong&gt;CT 扫描仪短缺和成像设备陈旧&lt;/strong&gt;，&lt;strong&gt;CT 扫描质量差的情况很常见&lt;/strong&gt;。&lt;strong&gt;较厚的切片&lt;/strong&gt;更有可能产生“&lt;strong&gt;体积平均效应”和伪影&lt;/strong&gt;，使医生&lt;strong&gt;难以达成一致的诊断&lt;/strong&gt;。即使使用&lt;strong&gt;移动 CT 扫描仪&lt;/strong&gt;也可能&lt;strong&gt;无法提供完整的诊断详细信息&lt;/strong&gt;。最后，目前&lt;strong&gt;大多数肺结节分割方法&lt;/strong&gt;都是基于&lt;strong&gt;2D图像&lt;/strong&gt;，但这些方法忽略了&lt;strong&gt;空间关系&lt;/strong&gt;，因此提出一种有效的&lt;strong&gt;3D肺结节分割模型&lt;/strong&gt;来&lt;strong&gt;捕获肺结节的空间位置&lt;/strong&gt;、&lt;strong&gt;纹理和其他详细信息变得越来越重要以避免误诊和漏诊&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Challenge&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;异质性: 肺结节的形状多异 （实心结节、磨玻璃结节 (GGO) 、空洞结节、血管和胸膜旁边的结节）&lt;/p&gt;</description>
    </item>
    <item>
      <title>YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information</title>
      <link>https://swimmingliu.cn/posts/papernotes/2024-yolov9/</link>
      <pubDate>Fri, 01 Mar 2024 15:26:23 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/papernotes/2024-yolov9/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;如今的深度学习方法主要关注如何设计&lt;strong&gt;最合适的目标函数&lt;/strong&gt;，使模型的预测结果能够最接近真实情况。同时，必须设计一个&lt;strong&gt;适当的架构&lt;/strong&gt;，可以帮助&lt;strong&gt;获取足够的信息进行预测&lt;/strong&gt;。现有方法忽略了一个事实，即&lt;strong&gt;当输入数据经过逐层特征提取和空间变换时&lt;/strong&gt;，&lt;strong&gt;大量信息将会丢失&lt;/strong&gt;。本文将深入研究数据通过&lt;strong&gt;深度网络传输时数据丢失的重要问题&lt;/strong&gt;，即&lt;strong&gt;信息瓶颈和可逆函数&lt;/strong&gt;。我们提出了&lt;strong&gt;可编程梯度信息（PGI）&lt;strong&gt;的概念来应对深度网络实现&lt;/strong&gt;多个目标所需的各种变化&lt;/strong&gt;。
PGI可以为&lt;strong&gt;目标任务计算目标函数&lt;/strong&gt;提供&lt;strong&gt;完整的输入信息&lt;/strong&gt;，从而获得&lt;strong&gt;可靠的梯度信息来更新网络权值&lt;/strong&gt;。此外，还设计了一种基于&lt;strong&gt;梯度路径规划的新型轻量级网络架构&lt;/strong&gt;——&lt;strong&gt;通用高效层聚合网络（GELAN）&lt;/strong&gt;。GELAN的架构证实了PGI在轻量级模型上取得了优异的结果。我们在基于 MS COCO 数据集的目标检测上验证了所提出的 GELAN 和 PGI。结果表明，与基于深度卷积开发的最先进方法相比，GELAN 仅使用&lt;strong&gt;传统的卷积算子&lt;/strong&gt;即可实现更好的参数利用率。 PGI 可用于从轻型到大型的各种模型。它可以用来获取完整的信息，使得&lt;strong&gt;train-from-scratch (从零开始训练) 模型能够比使用大数据集预训练&lt;/strong&gt;的state-of-theart模型获得更好的结果，对比结果如图1所示。源代码位于：https： //github.com/WongKinYiu/yolov9。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;核心创新点:  依然是网络结构的创新&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Programmable Gradient Information (PGI)&lt;/li&gt;
&lt;li&gt;Generalized Efficient Layer Aggregation Network（GELAN）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt=&#34;image-20240301113226341&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/f6b3ea45-d79d-11ee-a66b-c858c0c1debd&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;基于深度学习的模型在计算机视觉、语言处理和语音识别等各个领域都表现出了比过去的人工智能系统更好的性能。近年来，深度学习领域的研究人员主要关注如何开发更强大的系统架构和学习方法，例如CNN，Transformers[8,9,40] 、41、60、69、70]，Perceivers[26、26、32、52、56、81、81]和Mambas[17、38、80]。此外，一些研究人员尝试开发更通用的目标函数，例如损失函数[5,45,46,50,77,78]，标签分配[10,12,33,67,79]和辅助监督[18] 、20、24、28、29、51、54、68、76]。上述研究都试图精确地找到&lt;strong&gt;输入和目标任务之间的映射&lt;/strong&gt;。然而，大多数过去的方法都忽略了&lt;strong&gt;输入数据在前馈过程中可能会产生不可忽略的信息丢失量&lt;/strong&gt;。这种&lt;strong&gt;信息丢失&lt;/strong&gt;可能会导致&lt;strong&gt;有偏差的梯度流&lt;/strong&gt;，随后用于更新模型。上述问题可能导致深度网络&lt;strong&gt;在目标和输入之间建立不正确的关联&lt;/strong&gt;，导致训练后的模型产生不正确的预测。&lt;/p&gt;
&lt;p&gt;在深度网络中，&lt;strong&gt;输入数据在前馈过程中丢失信息的现象&lt;/strong&gt;俗称&lt;strong&gt;信息瓶颈&lt;/strong&gt;[59]，其示意图如图2所示。目前可以缓解这种现象的主要方法有：（1）&lt;strong&gt;可逆架构&lt;/strong&gt;的使用[3,16,19]：该方法主要&lt;strong&gt;使用重复的输入数据，并以显式的方式维护输入数据的信息&lt;/strong&gt;； （2）使用&lt;strong&gt;Masked建模&lt;/strong&gt;[1,6,9,27,71,73]：主要利用重构损失，采用&lt;strong&gt;隐式方式最大化提取特征并保留输入信息&lt;/strong&gt;； （3）引入&lt;strong&gt;深度监督&lt;/strong&gt;概念[28,51,54,68]：它利用&lt;strong&gt;没有丢失太多重要信息的浅层特征来预先建立从特征到目标的映射&lt;/strong&gt;，以确保&lt;strong&gt;重要信息能够被传递到更深的层次&lt;/strong&gt;。然而，上述方法在训练过程和推理过程中都存在不同的缺点。例如，&lt;strong&gt;可逆架构需要额外的层来组合重复馈送的输入数据&lt;/strong&gt;，这将显着增加推理成本。另外，由于&lt;strong&gt;输入数据层到输出层不能有太深的路径&lt;/strong&gt;，这种限制将导致&lt;strong&gt;在训练过程中难以对高阶语义信息进行建模&lt;/strong&gt;。对于 &lt;strong&gt;Masked 建模&lt;/strong&gt;，其&lt;strong&gt;重建损失有时与目标损失相冲突&lt;/strong&gt;。此外，大多数&lt;strong&gt;掩码机制还会产生与数据的不正确关联&lt;/strong&gt;。 对于&lt;strong&gt;深层监督&lt;/strong&gt;机制来说，会产生&lt;strong&gt;误差累积&lt;/strong&gt;，如果&lt;strong&gt;浅层监督在训练过程中丢失信息&lt;/strong&gt;，&lt;strong&gt;后续层将无法检索到所需信息&lt;/strong&gt;。上述现象在&lt;strong&gt;困难任务&lt;/strong&gt;和&lt;strong&gt;小模型上&lt;/strong&gt;会更加&lt;strong&gt;显着&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;针对上述问题，我们提出了一个新的概念，即&lt;strong&gt;可编程梯度信息（PGI）&lt;/strong&gt;。其概念是通过&lt;strong&gt;辅助可逆分支生成可靠的梯度&lt;/strong&gt;，使得&lt;strong&gt;深层特征仍然能够保持执行目标任务的关键特征&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;辅助可逆分支的设计&lt;/strong&gt;可以避免传统的&lt;strong&gt;融合多路径特征的深度监督过程&lt;/strong&gt;可能造成的&lt;strong&gt;语义损失&lt;/strong&gt;。换句话说，我们在&lt;strong&gt;不同语义层面上编程梯度信息传播&lt;/strong&gt;，从而达到最佳的训练结果。 PGI的&lt;strong&gt;可逆架构建立在辅助分支上&lt;/strong&gt;，因此&lt;strong&gt;没有额外的成本&lt;/strong&gt;。由于PGI可以&lt;strong&gt;自由选择适合目标任务的损失函数&lt;/strong&gt;，因此也克服了&lt;strong&gt;Masked建模&lt;/strong&gt;遇到的问题。所提出的&lt;strong&gt;PGI机制&lt;/strong&gt;可以应用于各种规模的&lt;strong&gt;深度神经网络&lt;/strong&gt;，并且比仅适用于&lt;strong&gt;非常深的神经网络&lt;/strong&gt;的&lt;strong&gt;深度监督机制更通用&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在本文中，我们还基于ELAN[65]设计了&lt;strong&gt;广义ELAN（GELAN）&lt;/strong&gt;，GELAN的设计同时&lt;strong&gt;考虑了参数量、计算复杂度、准确性和推理速度&lt;/strong&gt;。这种设计允许用户&lt;strong&gt;针对不同的推理设备任意选择合适的计算块&lt;/strong&gt;。我们将提出的PGI和GELAN结合起来，然后设计了新一代YOLO系列物体检测系统，我们称之为YOLOv9。我们使用MS COCO数据集进行实验，实验结果验证了我们提出的YOLOv9在所有比较中都取得了顶尖的性能。&lt;/p&gt;
&lt;p&gt;我们总结本文的贡献如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;我们从&lt;strong&gt;可逆函数的角度&lt;/strong&gt;对&lt;strong&gt;现有的深度神经网络架构进行了理论分析&lt;/strong&gt;，通过这个过程&lt;strong&gt;我们成功地解释了许多过去难以解释的现象&lt;/strong&gt;。我们还基于此分析&lt;strong&gt;设计了PGI和辅助可逆分支&lt;/strong&gt;，并取得了优异的结果。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;我们设计的PGI解决了&lt;strong&gt;深度监督&lt;/strong&gt;只能用于&lt;strong&gt;极深的神经网络架构的问题&lt;/strong&gt;，从而让&lt;strong&gt;新的轻量级架构真正应用于日常生活中&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;我们设计的GELAN仅使用&lt;strong&gt;常规卷积&lt;/strong&gt;来实现比基于最先进技术的&lt;strong&gt;深度卷积设计更高的参数利用率&lt;/strong&gt;，同时表现出&lt;strong&gt;轻、快速、准确&lt;/strong&gt;的巨大优势。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;结合所提出的PGI和GELAN，YOLOv9在MS COCO数据集上的目标检测性能在各个方面都大大超过了现有的实时目标检测器。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;Programmable Gradient Information (PGI)：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;自由选择适合目标任务的损失函数&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;可逆结构建立辅助分支，不增加推理成本&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;适用于各种规模的深度神经网络&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;GELAN：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;轻、快速、准确&lt;/li&gt;
&lt;li&gt;采用常规卷积吊打其他新颖卷积&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related work&lt;/h2&gt;
&lt;h3 id=&#34;21-real-time-object-detectors&#34;&gt;2.1 Real-time Object Detectors&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;目前主流的实时目标检测器是YOLO系列[2,7,13–15,25,30,31,47–49,61–63,74,75]，这些模型大多数使用CSPNet[64]或 ELAN [65] 及其变体作为主要计算单元。在特征集成方面，通常使用改进的PAN[37]或FPN[35]作为工具，然后使用改进的YOLOv3头[49]或FCOS头[57, 58]作为预测头。最近也提出了一些实时目标检测器，例如 RT DETR [43]，其基础是 DETR [4]。然而，由于DETR系列目标检测器在没有相应领域预训练模型的情况下很难应用于新领域，因此目前应用最广泛的实时目标检测器仍然是YOLO系列。本文选择 YOLOv7 [63] 作为开发该方法的基础，该方法已在各种计算机视觉任务和各种场景中被证明有效。&lt;/p&gt;</description>
    </item>
    <item>
      <title>YOLOSHOW - YOLOv5/YOLOv7/YOLOv8/YOLOv9/RTDETR GUI based on Pyside6</title>
      <link>https://swimmingliu.cn/posts/diary/yoloshow/</link>
      <pubDate>Sun, 18 Feb 2024 19:30:06 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/diary/yoloshow/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;YOLOSHOW&lt;/strong&gt;&lt;/em&gt; is a graphical user interface (GUI) application embed with &lt;code&gt;YOLOv5&lt;/code&gt; &lt;code&gt;YOLOv7&lt;/code&gt; &lt;code&gt;YOLOv8&lt;/code&gt; &lt;code&gt;YOLOv9&lt;/code&gt; &lt;code&gt;YOLOv10&lt;/code&gt; &lt;code&gt;YOLOv11&lt;/code&gt;  &lt;code&gt;RT-DETR&lt;/code&gt; &lt;code&gt;SAM&lt;/code&gt; &lt;code&gt;MobileSAM&lt;/code&gt; &lt;code&gt;FastSAM&lt;/code&gt; algorithm.&lt;/p&gt;
 &lt;p align=&#34;center&#34;&gt; 
  English &amp;nbsp; | &amp;nbsp; &lt;a href=&#34;https://github.com/SwimmingLiu/YOLOSHOW/blob/master/README_cn.md&#34;&gt;简体中文&lt;/a&gt;
 &lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;YOLOSHOW-Screen&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/YOLOSHOW-SNAPSHOT.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;demo-video&#34;&gt;Demo Video&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;YOLOSHOW v1.x&lt;/code&gt; : &lt;a href=&#34;https://www.bilibili.com/video/BV1BC411x7fW&#34;&gt;YOLOSHOW-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;YOLOSHOW v2.x&lt;/code&gt; : &lt;a href=&#34;https://www.bilibili.com/video/BV1ZD421E7m3&#34;&gt;YOLOSHOWv2.0-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;todo-list&#34;&gt;Todo List&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Add &lt;code&gt;YOLOv9&lt;/code&gt; &lt;code&gt;YOLOv10&lt;/code&gt;  &lt;code&gt;RT-DETR&lt;/code&gt;  &lt;code&gt;YOLOv11&lt;/code&gt;  &lt;code&gt;SAM&lt;/code&gt;  &lt;code&gt;MobileSAM&lt;/code&gt;  &lt;code&gt;FastSAM&lt;/code&gt; Algorithm&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Support Instance Segmentation （ &lt;code&gt;YOLOv5&lt;/code&gt;  &lt;code&gt;YOLOv8&lt;/code&gt;  &lt;code&gt;YOLOv11&lt;/code&gt; &lt;code&gt;SAM&lt;/code&gt;  &lt;code&gt;MobileSAM&lt;/code&gt;  &lt;code&gt;FastSAM&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Support Pose Estimation （ &lt;code&gt;YOLOv8&lt;/code&gt;  &lt;code&gt;YOLOv11&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Support Oriented Bounding Boxes ( &lt;code&gt;YOLOv8&lt;/code&gt;  &lt;code&gt;YOLOv11&lt;/code&gt; )&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Support Http Protocol in &lt;code&gt;RTSP&lt;/code&gt; Function ( &lt;code&gt;Single&lt;/code&gt; Mode )&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Add Model Comparison Mode（VS Mode）&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Support Dragging File Input&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Tracking &amp;amp; Counting ( &lt;code&gt;Industrialization&lt;/code&gt; )&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;functions&#34;&gt;Functions&lt;/h2&gt;
&lt;h3 id=&#34;1-support-image--video--webcam--folder-batch--ipcam-object-detection&#34;&gt;1. Support Image / Video / Webcam / Folder (Batch) / IPCam Object Detection&lt;/h3&gt;
&lt;p&gt;Choose Image / Video / Webcam / Folder (Batch) / IPCam in the menu bar on the left to detect objects.&lt;/p&gt;</description>
    </item>
    <item>
      <title>YOLOSHOW 中文版 - YOLOv5/YOLOv7/YOLOv8/YOLOv9/RTDETR GUI based on Pyside6</title>
      <link>https://swimmingliu.cn/posts/diary/yoloshow-cn/</link>
      <pubDate>Sun, 18 Feb 2024 19:30:06 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/diary/yoloshow-cn/</guid>
      <description>&lt;h2 id=&#34;介绍&#34;&gt;介绍&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;YOLOSHOW&lt;/strong&gt;&lt;/em&gt; 是一款集合了 &lt;code&gt;YOLOv5&lt;/code&gt; &lt;code&gt;YOLOv7&lt;/code&gt; &lt;code&gt;YOLOv8&lt;/code&gt; &lt;code&gt;YOLOv9&lt;/code&gt; &lt;code&gt;YOLOv10&lt;/code&gt; &lt;code&gt;YOLOv11&lt;/code&gt;  &lt;code&gt;RT-DETR&lt;/code&gt; &lt;code&gt;SAM&lt;/code&gt; &lt;code&gt;MobileSAM&lt;/code&gt; &lt;code&gt;FastSAM&lt;/code&gt; 的图形化界面程序&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt; 
  &lt;a href=&#34;https://github.com/SwimmingLiu/YOLOSHOW/blob/master/README.md&#34;&gt; English&lt;/a&gt; &amp;nbsp; | &amp;nbsp; 简体中文&lt;/a&gt;
 &lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;YOLOSHOW-Screen&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/YOLOSHOW-SNAPSHOT.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;演示视频&#34;&gt;演示视频&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;YOLOSHOW v1.x&lt;/code&gt; : &lt;a href=&#34;https://www.bilibili.com/video/BV1BC411x7fW&#34;&gt;YOLOSHOW-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;YOLOSHOW v2.x&lt;/code&gt; : &lt;a href=&#34;https://www.bilibili.com/video/BV1ZD421E7m3&#34;&gt;YOLOSHOWv2.0-YOLOv9/YOLOv8/YOLOv7/YOLOv5/RTDETR GUI&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;待做清单&#34;&gt;待做清单&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 加入 &lt;code&gt;YOLOv9&lt;/code&gt; &lt;code&gt;YOLOv10&lt;/code&gt;  &lt;code&gt;RT-DETR&lt;/code&gt;  &lt;code&gt;YOLOv11&lt;/code&gt;  &lt;code&gt;SAM&lt;/code&gt;  &lt;code&gt;MobileSAM&lt;/code&gt;  &lt;code&gt;FastSAM&lt;/code&gt;算法&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 支持实例分割 （ &lt;code&gt;YOLOv5&lt;/code&gt;  &lt;code&gt;YOLOv8&lt;/code&gt;  &lt;code&gt;YOLOv11&lt;/code&gt; &lt;code&gt;SAM&lt;/code&gt;  &lt;code&gt;MobileSAM&lt;/code&gt;  &lt;code&gt;FastSAM&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 支持姿态估计 （&lt;code&gt;YOLOv8&lt;/code&gt; &lt;code&gt;YOLOv11&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 支持旋转框 (&lt;code&gt;YOLOv8&lt;/code&gt; &lt;code&gt;YOLOv11&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;code&gt;RTSP&lt;/code&gt; 功能 支持 Http 协议 ( Single Mode )&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 支持模型对比模式（VS Mode）&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 支持拖拽文件输入&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 追踪和计数模型 ( &lt;code&gt;工业化&lt;/code&gt; )&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;功能&#34;&gt;功能&lt;/h2&gt;
&lt;h3 id=&#34;1-支持-图片--视频--摄像头--文件夹批量-网络摄像头-目标检测&#34;&gt;1. 支持 图片 / 视频 / 摄像头 / 文件夹（批量）/ 网络摄像头 目标检测&lt;/h3&gt;
&lt;p&gt;选择左侧菜单栏的图片 / 视频 / 摄像头 / 文件夹（批量）/ 网络摄像头 进行目标检测&lt;/p&gt;</description>
    </item>
    <item>
      <title>ZSTU服务器使用教程 (Yang Li Lab)</title>
      <link>https://swimmingliu.cn/posts/diary/zstu_server_manuscript/</link>
      <pubDate>Fri, 05 Jan 2024 13:47:03 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/diary/zstu_server_manuscript/</guid>
      <description>&lt;h2 id=&#34;安装-xshell-和-xftp&#34;&gt;安装 Xshell 和 Xftp&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;https://www.netsarang.com/en/xshell-download/ &lt;span class=&#34;c1&#34;&gt;# Xshell下载连接&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;https://blog.csdn.net/m0_67400972/article/details/125346023 &lt;span class=&#34;c1&#34;&gt;# 安装教程&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;添加xshell连接&#34;&gt;添加Xshell连接&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&#34;image-20240105113129928&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/B6xRW.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;其中 &lt;code&gt;server.ip&lt;/code&gt; 为服务器公网ip地址，端口为 &lt;code&gt;6969&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;安装anaconda3&#34;&gt;安装Anaconda3&lt;/h2&gt;
&lt;p&gt;每个用户均被分配 &lt;code&gt;AnacondaAnaconda3-2023.07-1-Linux-x86_64.sh &lt;/code&gt; 于主目录&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;bash AnacondaAnaconda3-2023.07-1-Linux-x86_64.sh &lt;span class=&#34;c1&#34;&gt;# 安装anaconda3&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img alt=&#34;image-20240105113942737&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/B6KTv.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;输入 &lt;code&gt;yes&lt;/code&gt; 后， 再按回车键 即可&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;image-20240105114146047&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/B6one.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;初始化anaconda3&#34;&gt;初始化Anaconda3&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda init bash	&lt;span class=&#34;c1&#34;&gt;# 初始化conda&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后重新使用Xshell 连接即可&lt;/p&gt;
&lt;h2 id=&#34;magic-network&#34;&gt;Magic Network&lt;/h2&gt;
&lt;p&gt;下载外网文件、克隆Github项目等操作，必须使用Magic Network&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;http_proxy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;http://127.0.0.1:7890
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;https_proxy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;http://127.0.0.1:7890
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;取消Magic Network&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;unset&lt;/span&gt; http_proxy
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;unset&lt;/span&gt; https_proxy
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果使用上面的命令，不能连接Google. 需要远程桌面连接，打开CFW (默认是打开的)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;nohup bash /home/dell/LYJ/Clash/cfw &amp;gt; cfw.out
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img alt=&#34;image-20240105115600487&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/B6So3.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;国内镜像下载&#34;&gt;国内镜像下载&lt;/h2&gt;
&lt;p&gt;pip 清华源下载&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install -i https://pypi.tuna.tsinghua.edu.cn/simple packge      &lt;span class=&#34;c1&#34;&gt;# packge为包名&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;conda 配置镜像&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 以上两条是Anaconda官方库的镜像&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 以上是Anaconda第三方库 Conda Forge的镜像&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 以上是Pytorch的Anaconda第三方镜像&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;远程桌面连接&#34;&gt;远程桌面连接&lt;/h2&gt;
&lt;p&gt;远程连接直接找师兄问 向日葵 和 Teamviewer 密码，连接即可&lt;/p&gt;</description>
    </item>
    <item>
      <title>ZSTU Server Management</title>
      <link>https://swimmingliu.cn/posts/diary/zstu_server_management/</link>
      <pubDate>Thu, 04 Jan 2024 21:36:25 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/diary/zstu_server_management/</guid>
      <description>&lt;h2 id=&#34;frp配置&#34;&gt;FRP配置&lt;/h2&gt;
&lt;h3 id=&#34;跳板机&#34;&gt;跳板机&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# frps.ini 配置&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;common&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;bind_port&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;7000&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#frps服务监听的端口&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;token&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;123&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 链接口令&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;./frps -c frps.ini &lt;span class=&#34;c1&#34;&gt;# 启动frps&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;服务器&#34;&gt;服务器&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# frpc.ini&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;common&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;server_addr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; x.x.x.x &lt;span class=&#34;c1&#34;&gt;# 此处为 跳板机 的公网ip&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;server_port&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;7000&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 跳板机上frps服务监听的端口&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;token&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;123&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 链接口令&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;ssh&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; tcp
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;local_ip&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; 127.0.0.1 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;local_port&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;22&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 需要暴露的内网机器的端口&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;remote_port&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;6000&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 暴露的内网机器的端口在vps上的端口&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;ssh连接&#34;&gt;SSH连接&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ssh -p &lt;span class=&#34;m&#34;&gt;6000&lt;/span&gt; swimmingliu@server.ip &lt;span class=&#34;c1&#34;&gt;# 普通ssh 连接&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ssh swimmingliu@server.ip 6000	  &lt;span class=&#34;c1&#34;&gt;# xshell ssh连接&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;用户管理&#34;&gt;用户管理&lt;/h2&gt;
&lt;h3 id=&#34;添加用户&#34;&gt;添加用户&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo adduser xxx
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;删除用户&#34;&gt;删除用户&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo deluser xxx
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;magic-network&#34;&gt;Magic Network&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;http_proxy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;http://127.0.0.1:7890
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;https_proxy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;http://127.0.0.1:7890
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;anaconda3-安装和配置&#34;&gt;Anaconda3 安装和配置&lt;/h2&gt;
&lt;h3 id=&#34;安装anaconda3&#34;&gt;安装Anaconda3&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget --user-agent&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Mozilla&amp;#34;&lt;/span&gt; https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2023.07-1-Linux-x86_64.sh
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;bash Anaconda3-2023.07-1-Linux-x86_64.sh
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive 清华源&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;配置之前的envs&#34;&gt;配置之前的envs&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cp -r old_envs_path anaconda/envs/		&lt;span class=&#34;c1&#34;&gt;#迁移之前的envs环境&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;完结撒花&#34;&gt;完结撒花❀❀❀&lt;/h2&gt;</description>
    </item>
    <item>
      <title>MovieKGQA: 基于知识图谱和neo4j图数据库的电影知识问答系统</title>
      <link>https://swimmingliu.cn/posts/diary/2023-moviekgqa/</link>
      <pubDate>Tue, 12 Dec 2023 12:18:57 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/diary/2023-moviekgqa/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;基于知识图谱和neo4j图数据库的电影知识问答系统&lt;/p&gt;
&lt;div style=&#34;display:flex; justify-content: space-around; &#34;&gt;
&lt;img src=&#34;https://i.imgs.ovh/2023/12/12/mM4uR.png&#34; alt=&#34;image-20231212102658908&#34; style=&#34;box-shadow: 0 0 10px rgba(200, 200, 200);&#34; width=30% height:300px/&gt;
&lt;img src=&#34;https://i.imgs.ovh/2023/12/12/mM58p.png&#34; alt=&#34;image-20231212102738360&#34; style=&#34;box-shadow: 0 0 10px rgba(200, 200, 200);&#34; width=30% height:300px/&gt;
&lt;img src=&#34;https://i.imgs.ovh/2023/12/12/mMdFT.png&#34; alt=&#34;image-20231212103113278&#34; style=&#34;&#34; width=30% height:300px/&gt;
&lt;/div&gt;
&lt;h2 id=&#34;workflow&#34;&gt;Workflow&lt;/h2&gt;
&lt;h3 id=&#34;database&#34;&gt;DataBase&lt;/h3&gt;
&lt;p&gt;爬取豆瓣TOP1000电影信息数据&lt;/p&gt;
&lt;h3 id=&#34;frontend&#34;&gt;Frontend&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;获取用户输入的信息 （语音输入 / 文本输入）&lt;/li&gt;
&lt;li&gt;向电影知识问答后端服务器发送请求&lt;/li&gt;
&lt;li&gt;获取返回结果  (成功 -&amp;gt; 4 / 失败 -&amp;gt; 5)&lt;/li&gt;
&lt;li&gt;如果返回结果包含image信息，则显示图片和文字，否则只显示文字&lt;/li&gt;
&lt;li&gt;请求基于gpt的AI模型服务器，并显示返回结果&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;backend&#34;&gt;Backend&lt;/h3&gt;
&lt;p&gt;​	[准备工作]  训练 TF-IDF 向量算法和朴素贝叶斯分类器，用于预测用户文本所属的问题类别&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;接受前端请求，获取用户输入信息&lt;/li&gt;
&lt;li&gt;使用分词库解析用户输入的文本词性，提取关键词&lt;/li&gt;
&lt;li&gt;根据贝叶斯分类器，分类出用户文本的问题类型&lt;/li&gt;
&lt;li&gt;结合关键词与问题类别，在 Neo4j 中查询问题的答案&lt;/li&gt;
&lt;li&gt;返回查询结果 （若问题类型为 演员信息 / 电影介绍，则附加图片url）&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;workflow-graph&#34;&gt;WorkFlow Graph&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&#34;workflow graph&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/0IEuW.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;frame&#34;&gt;Frame&lt;/h2&gt;
&lt;h3 id=&#34;database-1&#34;&gt;DataBase&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://neo4j.com/&#34;&gt;&lt;img alt=&#34;Neo4j&#34; loading=&#34;lazy&#34; src=&#34;https://img.shields.io/badge/neo4j-test?style=for-the-badge&amp;logo=neo4j&amp;logoColor=white&amp;color=blue&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;frontend-1&#34;&gt;Frontend&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://developers.weixin.qq.com/&#34;&gt;&lt;img alt=&#34;wechat mini programs&#34; loading=&#34;lazy&#34; src=&#34;https://img.shields.io/badge/wechat%20mini%20programs-test?style=for-the-badge&amp;logo=wechat&amp;logoColor=white&amp;color=%2320B2AA&#34;&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>U-NET V2: RETHINKING THE SKIP CONNECTIONS OF U-NET FOR MEDICAL IMAGE SEGMENTATION</title>
      <link>https://swimmingliu.cn/posts/papernotes/2023-unet_v2/</link>
      <pubDate>Mon, 11 Dec 2023 20:49:32 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/papernotes/2023-unet_v2/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;在本文中，我们介绍了 U-Net v2，这是一种用于医学图像分割的新的稳健且高效的 U-Net 变体。它的目的是&lt;strong&gt;增强语义信息在低级特征中的注入&lt;/strong&gt;，同时&lt;strong&gt;用更精细的细节来细化高级特征&lt;/strong&gt;。对于输入图像，我们首先使用&lt;strong&gt;深度神经网络编码器提取多级特征&lt;/strong&gt;。接下来，我们通过&lt;strong&gt;注入来自更高级别特征的语义信息&lt;/strong&gt;并通过 &lt;strong&gt;Hadamard 乘积&lt;/strong&gt;集成来自&lt;strong&gt;较低级别特征的更精细的细节&lt;/strong&gt;来&lt;strong&gt;增强每个级别的特征图&lt;/strong&gt;。我们新颖的&lt;strong&gt;跳跃连接&lt;/strong&gt;赋予&lt;strong&gt;所有级别的功能&lt;/strong&gt;以&lt;strong&gt;丰富的语义特征和复杂的细节&lt;/strong&gt;。&lt;strong&gt;改进后的特征随后被传输到解码器&lt;/strong&gt;以进行&lt;strong&gt;进一步处理和分割&lt;/strong&gt;。我们的方法可以&lt;strong&gt;无缝集成到任何编码器-解码器网络中&lt;/strong&gt;。我们在几个公共医学图像分割数据集上评估了我们的方法，用于皮肤病变分割和息肉分割，实验结果证明了我们的新方法相对于最先进的方法的分割准确性，同时&lt;strong&gt;保留了内存和计算效率&lt;/strong&gt;。代码位于：https://github.com/yaoppeng/U-Net_v2。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;主要工作就在于中间的skip-connection&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;随着现代深度神经网络的进步，语义图像分割取得了重大进展。语义图像分割的典型范例涉及具有&lt;strong&gt;跳跃连接的编码器-解码器网络[&lt;strong&gt;1]。在此框架中，编码器从&lt;/strong&gt;输入图像中提取层次和抽象特征&lt;/strong&gt;，而解码器获取&lt;strong&gt;编码器生成的特征图并重建像素级分割掩模或图&lt;/strong&gt;，&lt;strong&gt;为输入图像中的每个像素分配类标签&lt;/strong&gt;。人们进行了一系列研究[2, 3]，&lt;strong&gt;将全局信息纳入特征图&lt;/strong&gt;中并增强多尺度特征，从而大大提高了分割性能。
在医学图像分析领域，&lt;strong&gt;精确的图像分割&lt;/strong&gt;在计算机辅助诊断和分析中起着至关重要的作用。 U-Net [4] 最初是为了&lt;strong&gt;医学图像分割&lt;/strong&gt;而引入的，利用&lt;strong&gt;跳跃连接&lt;/strong&gt;来连接每个级别的&lt;strong&gt;编码器和解码器阶段&lt;/strong&gt;。&lt;strong&gt;跳跃连接&lt;/strong&gt;使解码器能够访问&lt;strong&gt;早期编码器阶段&lt;/strong&gt;的特征，从而保留&lt;strong&gt;高级语义信息&lt;/strong&gt;和&lt;strong&gt;细粒度空间细节&lt;/strong&gt;。这种方法有助于&lt;strong&gt;精确描绘对象边界&lt;/strong&gt;并提取&lt;strong&gt;医学图像中的小结构&lt;/strong&gt;。此外，还应用了&lt;strong&gt;密集连接机制&lt;/strong&gt;，通过&lt;strong&gt;连接所有级别&lt;/strong&gt;和&lt;strong&gt;所有阶段的特征&lt;/strong&gt;来减少&lt;strong&gt;编码器和解码器中特征之间的差异&lt;/strong&gt;[5]。设计了一种机制来&lt;strong&gt;通过连接较高和较低级别&lt;/strong&gt;的&lt;strong&gt;不同尺度的特征&lt;/strong&gt;来&lt;strong&gt;增强特征&lt;/strong&gt;[6]。
然而，基于 U-Net 的模型中的这些连接在&lt;strong&gt;集成低级和高级特征方面&lt;/strong&gt;可能&lt;strong&gt;不够有效&lt;/strong&gt;。例如，在 ResNet [7] 中，深度神经网络是作为&lt;strong&gt;多个浅层网络的集合&lt;/strong&gt;而形成的，并且&lt;strong&gt;显式添加的残差连接&lt;/strong&gt;表明，即使在百万规模的训练中，网络也很难学习&lt;strong&gt;恒等映射函数图像&lt;/strong&gt;数据集。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;对于编码器提取的特征，低级特征通常保留更多细节，但缺乏足够的语义信息，并且可能包含不需要的噪声&lt;/strong&gt;。相反，&lt;strong&gt;高级特征包含更多语义信息，但由于分辨率显着降低而缺乏精确的细节（例如对象边界）&lt;/strong&gt;。通过&lt;strong&gt;串联简单地融合特征&lt;/strong&gt;将在&lt;strong&gt;很大程度上依赖于网络的学习能力&lt;/strong&gt;，这&lt;strong&gt;通常与训练数据集的大小成正比&lt;/strong&gt;。这是一个具有挑战性的问题，特别是在医学成像领域，&lt;strong&gt;通常受到有限数据的限制&lt;/strong&gt;。这种信息融合是&lt;strong&gt;通过密集连接跨多个级别连接低级和高级特征&lt;/strong&gt;来实现的，可能会限制来自&lt;strong&gt;不同级别的信息的贡献&lt;/strong&gt;并可能引入噪声。另一方面，尽管&lt;strong&gt;引入的额外卷积并没有显着增加参数数量&lt;/strong&gt;，但 &lt;strong&gt;GPU 内存消耗将会增加&lt;/strong&gt;，因为必须&lt;strong&gt;存储所有中间特征图和相应的梯度&lt;/strong&gt;以进行前向传递和后向梯度计算。这会导致 &lt;strong&gt;GPU 内存使用量&lt;/strong&gt;和&lt;strong&gt;浮点运算 (FLOP) 增加&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt=&#34;image-20231211193109745&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/mCdvu.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;(a) U-Net v2 模型的整体架构，由&lt;strong&gt;编码器、SDI（语义和细节注入）模块和解码器&lt;/strong&gt;组成。 (b) SDI模块的架构。为简单起见，我们仅显示第三级特征的细化（l = 3）。 &lt;strong&gt;SmoothConv 表示用于特征平滑的 3 × 3 卷积&lt;/strong&gt;。$\bigotimes$ 表示哈达玛积。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在[8]中，利用&lt;strong&gt;反向注意力&lt;/strong&gt;来明确地建立&lt;strong&gt;多尺度特征之间&lt;/strong&gt;的联系。在[9]中，ReLU激活应用于&lt;strong&gt;较高级别&lt;/strong&gt;的特征，并&lt;strong&gt;将激活的特征与较低级别的特征相乘&lt;/strong&gt;。此外，在[10]中，作者提出分别从 &lt;strong&gt;CNN 和 Transformer 模型&lt;/strong&gt;中提取特征，在多个级别上组合&lt;strong&gt;来自 CNN 和 Transformer 分支&lt;/strong&gt;的特征来&lt;strong&gt;增强特征图&lt;/strong&gt;。然而，这些方法&lt;strong&gt;都很复杂&lt;/strong&gt;，而且它们的&lt;strong&gt;性能仍然不是很令人满意&lt;/strong&gt;，因此需要进一步改进。&lt;/p&gt;
&lt;p&gt;在本文中，我们提出了 U-Net v2，这是一种基于 U-Net 的新分割框架，具有&lt;strong&gt;简单且高效的跳跃连接&lt;/strong&gt;。我们的模型首先&lt;strong&gt;使用 CNN 或 Transformer 编码器&lt;/strong&gt;提取&lt;strong&gt;多级特征图&lt;/strong&gt;。接下来，&lt;strong&gt;对于第 i 层的特征图&lt;/strong&gt;，我们通过&lt;strong&gt;简单的哈达玛乘积操作&lt;/strong&gt;显式地注入&lt;strong&gt;高层特征（包含更多语义信息）&lt;strong&gt;和&lt;/strong&gt;低层特征（捕获更精细的细节）&lt;/strong&gt;，从而&lt;strong&gt;增强语义和细节第 i 级特征&lt;/strong&gt;。随后，&lt;strong&gt;细化的特征&lt;/strong&gt;被传输到解码器进行&lt;strong&gt;分辨率重建和分割&lt;/strong&gt;。我们的方法可以无缝集成到任何编码器-解码器网络中。&lt;/p&gt;
&lt;p&gt;我们使用公开的数据集在两个医学图像分割任务（皮肤病变分割和息肉分割）上评估我们的新方法。实验结果表明，我们的 U-Net v2 在这些分割任务中始终优于最先进的方法，&lt;strong&gt;同时保持 FLOP 和 GPU 内存效率&lt;/strong&gt;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Uncertainty-Aware Attention Mechanism:利用不确定性感知注意机制进行肺结节分割和不确定区域预测</title>
      <link>https://swimmingliu.cn/posts/papernotes/2023-uncertainty-aware-attentionmechanism/</link>
      <pubDate>Mon, 04 Dec 2023 16:28:11 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/papernotes/2023-uncertainty-aware-attentionmechanism/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;放射科医生拥有不同的培训和临床经验，导致&lt;strong&gt;肺结节的分割注释&lt;/strong&gt;存在&lt;strong&gt;差异&lt;/strong&gt;，从而导&lt;strong&gt;致分割的不确定性&lt;/strong&gt;。传统方法通常选择&lt;strong&gt;单个注释&lt;/strong&gt;作为学习目标或尝试学习包含&lt;strong&gt;多个注释&lt;/strong&gt;的&lt;strong&gt;潜在空间&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;然而，这些方法无法&lt;strong&gt;利用多个注释之间的共识和分歧所固有的有价值的信息&lt;/strong&gt;。在本文中，我们提出了一种&lt;strong&gt;不确定性感知注意机制&lt;/strong&gt;（UAAM），它利用多个&lt;strong&gt;注释之间的共识&lt;/strong&gt;和分歧来促进更好的分割。为此，我们引入了&lt;strong&gt;多置信度掩模&lt;/strong&gt;（MCM），它结合了&lt;strong&gt;低置信度（LC）掩模&lt;/strong&gt;和高置信度（HC）掩模。 &lt;strong&gt;LC 掩模&lt;/strong&gt;表示&lt;strong&gt;分割置信度较低的区域&lt;/strong&gt;，&lt;strong&gt;放射科医生可能有不同的分割选择&lt;/strong&gt;。继&lt;strong&gt;UAAM&lt;/strong&gt;之后，我们进一步设计了一个&lt;strong&gt;不确定性引导多置信分割网络&lt;/strong&gt;（UGMCS-Net），它包含三个模块：&lt;strong&gt;一个捕获肺结节一般特征的特征提取模块&lt;/strong&gt;，&lt;strong&gt;一个为肺结节产生三个特征的不确定性感知模块&lt;/strong&gt;。&lt;strong&gt;注释的并集、交集和注释集，以及一个交集并集约束模块&lt;/strong&gt;，该模块使用&lt;strong&gt;三个特征之间的距离来平衡最终分割和 MCM 的预测&lt;/strong&gt;。为了全面展示我们方法的性能，我们提出了 LIDC-IDRI 上的复杂结节验证，它测试了 UGMCS-Net 对使用常规方法难以分割的肺结节的分割性能。实验结果表明，我们的方法可以显着提高传统方法难以分割的结节的分割性能。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;introduction&#34;&gt;INTRODUCTION&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;肺结节分割&lt;/strong&gt;在&lt;strong&gt;肺癌计算机辅助诊断 (CAD)&lt;/strong&gt; 系统中至关重要 [1]，可提供&lt;strong&gt;结节大小、形状和其他重要医学特征&lt;/strong&gt;等关键信息。然而，对于深度学习方法的&lt;strong&gt;一般训练和测试范例&lt;/strong&gt;，每个结节图像数据只有一个由&lt;strong&gt;一名放射科医生&lt;/strong&gt;描绘的注释掩模[2]-[6]。因此，&lt;strong&gt;网络每次只能提供结节区域&lt;/strong&gt;的单个预测。&lt;/p&gt;
&lt;p&gt;然而，在临床实践中，不同的放射科医生&lt;strong&gt;由于其不同的培训和临床经验&lt;/strong&gt;可能会为肺结节提供&lt;strong&gt;不同的分割注释&lt;/strong&gt;[7]-[9]。&lt;/p&gt;
&lt;p&gt;因此，基于&lt;strong&gt;单一注释的传统方法&lt;/strong&gt;无法反映&lt;strong&gt;临床经验的多样性&lt;/strong&gt;，限制了深度学习方法的应用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决放射科医生之间注释不同问题&lt;/strong&gt;的一个直接解决方案是为&lt;strong&gt;每个肺结节图像合并多个注释&lt;/strong&gt;。这导致了另一个问题：&lt;strong&gt;多个注释不可避免地会带来不确定性和冲突&lt;/strong&gt;，因为放射科医生&lt;strong&gt;可能会对同一区域进行不同的注释&lt;/strong&gt;。为了克服这个问题，Kohl 等人在 2018 年提出了一种概率 U-Net，它&lt;strong&gt;利用条件变分自动编码器&lt;/strong&gt;将&lt;strong&gt;多个分割变体编码&lt;/strong&gt;到&lt;strong&gt;低维潜在空间&lt;/strong&gt;中 [8]、[10]。通过从该空间采样，网络可以影响相应的分割图。基于这项研究，Hu等人提出将&lt;strong&gt;真实不确定性&lt;/strong&gt;与&lt;strong&gt;概率UNet&lt;/strong&gt;相结合，这可以&lt;strong&gt;提高预测不确定性估计&lt;/strong&gt;、&lt;strong&gt;样本准确性和样本多样性&lt;/strong&gt;[7]。这些方法依赖于&lt;strong&gt;潜在空间和该空间中的随机样本&lt;/strong&gt;。因此，这些方法只能通过多次预测来提供不确定区域。&lt;/p&gt;
&lt;p&gt;在本文中，我们提出了一个论点，即&lt;strong&gt;多个注释之间的不确定性遵循特定的模式&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;为了演示这种现象，我们引入了&lt;strong&gt;多重置信掩码&lt;/strong&gt; (MCM)，它结合了&lt;strong&gt;高置信度 (HC) 掩码&lt;/strong&gt;和低置信度 (LC) 掩码，如图 1 所示。 A. 交叉掩码等于 &lt;strong&gt;HC mask&lt;/strong&gt;，代表&lt;strong&gt;所有注释的交集&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;联合掩码是所有注释的联合&lt;/strong&gt;。 &lt;strong&gt;LC掩模是交集掩模和并集掩模之间的差异&lt;/strong&gt;。当在 LIDC-IDRI 数据集 [11] 上计算 HC 和 LC 的 Hounsfield 单位 (HU) 核估计时，&lt;strong&gt;如图 1.B 所示，我们可以观察到 LC 和 HC 掩模之间的 HU 分布存在明显区别&lt;/strong&gt;。具体地，LC区域具有比HC区域更低的HU值。从像素分布来看，&lt;strong&gt;HU值越低，对应区域的密度越低&lt;/strong&gt;。就CT图像特征而言，LC区域&lt;strong&gt;主要由结节边缘、毛刺和磨玻璃特征等边界相关特征组成&lt;/strong&gt;，而&lt;strong&gt;HC区域主要分布在结节核心内&lt;/strong&gt;。因此，我们提出了这样的假设：导致放射科医生之间差异的区域主要与&lt;strong&gt;低密度组织和边界相关特征&lt;/strong&gt;有关。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt=&#34;image-20231130203343980&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/327b2.png&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;与其他方法不同，我们建议利用 &lt;strong&gt;MCM (多重置信掩码) ** 和注释集作为具有&lt;/strong&gt;不同分割确定性的特征的学习指导**，有助于更好的分割性能。我们将这种训练称为&lt;strong&gt;UncertaintyAware Attention Mechanism&lt;/strong&gt;，如图2所示。按照这种机制，我们进一步设计了用于肺结节分割的&lt;strong&gt;Uncertainty-Guide Multi-Confidence Segmentation Network&lt;/strong&gt;（UGMCS-Net）。&lt;/p&gt;</description>
    </item>
    <item>
      <title>程序设计作业接口文档</title>
      <link>https://swimmingliu.cn/posts/diary/2023-%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E4%BD%9C%E4%B8%9A%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/</link>
      <pubDate>Sat, 02 Dec 2023 21:40:07 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/diary/2023-%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E4%BD%9C%E4%B8%9A%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/</guid>
      <description>&lt;h1 id=&#34;程序设计作业接口文档&#34;&gt;程序设计作业接口文档&lt;/h1&gt;
&lt;p&gt;统一返回格式&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;code:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...,&lt;/span&gt;	&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;状态码&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;msg:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...,&lt;/span&gt;	&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;描述信息&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;data:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;{&lt;/span&gt;     &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;数据&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    	&lt;span class=&#34;err&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;code&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;200&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;成功,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;500&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;失败,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;msg&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;success&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;成功&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;fail&lt;/span&gt;    &lt;span class=&#34;err&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;失败&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;key&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;value&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;前端&#34;&gt;前端&lt;/h2&gt;
&lt;h3 id=&#34;虚拟换衣功能&#34;&gt;虚拟换衣功能&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;@请求格式&lt;/span&gt;  &lt;span class=&#34;err&#34;&gt;（请求后端）&lt;/span&gt;  	 &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;前后端需统一样例图片id&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;userId:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;int&amp;gt;,&lt;/span&gt;			&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;标识哪个用户的请求&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;isUploadCloth:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;bool&amp;gt;,&lt;/span&gt;           &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;若上传衣服图片使用base64，否则用id&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;isUploadPerson:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;bool&amp;gt;,&lt;/span&gt;          &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;若上传人物图片使用base64，否则用id&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;clothData:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;base64||null&amp;gt;,&lt;/span&gt; 	&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;衣服图片base64编码&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;personData:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;base64||null&amp;gt;,&lt;/span&gt;	&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;人物图片base64编码&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;exampleClothId:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;int&amp;gt;,&lt;/span&gt;		&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;衣服样例图片id&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;examplePersonId:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;int&amp;gt;&lt;/span&gt;		&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;任务样例图片id&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;动漫头像功能&#34;&gt;动漫头像功能&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;@请求格式&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;（请求后端）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;userId:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;int&amp;gt;,&lt;/span&gt;    	        &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;标识哪个用户的请求&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;imgData:&lt;/span&gt;  &lt;span class=&#34;err&#34;&gt;...&amp;lt;base64&amp;gt;&lt;/span&gt; 	        &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;需要动漫化的图片&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;后端&#34;&gt;后端&lt;/h2&gt;
&lt;h3 id=&#34;虚拟换衣功能-1&#34;&gt;虚拟换衣功能&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;前端请求API:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;https:&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//talented-civet-separately.ngrok-free.app/tryon/
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;@返回格式&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;(返回前端)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;code:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;int&amp;gt;,&lt;/span&gt; 	                &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;状态码&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;(200表示成功,&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;500表示失败)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;msg:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;string&amp;gt;,&lt;/span&gt;	                &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;消息&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;(success&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;fail)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;data:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;err&#34;&gt;tryon_result&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;url&amp;gt;,&lt;/span&gt;  	&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;处理后的图片url&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;动漫头像功能-1&#34;&gt;动漫头像功能&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;前端请求API:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;https:&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//talented-civet-separately.ngrok-free.app/anime/
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;@返回格式&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;(返回前端)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;code:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;int&amp;gt;,&lt;/span&gt;  	                &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;状态码&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;(200表示成功,&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;500表示失败)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;msg&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;string&amp;gt;,&lt;/span&gt; 	                &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;消息&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;(success&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;fail)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;data:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    	&lt;span class=&#34;err&#34;&gt;anime_result&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;:&lt;/span&gt;  &lt;span class=&#34;err&#34;&gt;...&amp;lt;url&amp;gt;,&lt;/span&gt; 	&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;处理后的图片url&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;模型端&#34;&gt;模型端&lt;/h2&gt;
&lt;h3 id=&#34;虚拟换衣功能-2&#34;&gt;虚拟换衣功能&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;后端请求API:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;https:&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//certain-ideally-foal.ngrok-free.app/tryon/predict/
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;@请求格式&lt;/span&gt;	&lt;span class=&#34;err&#34;&gt;(后端发出请求)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;userid&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;int&amp;gt;,&lt;/span&gt;              &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;用户id&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;cloth&lt;/span&gt;  &lt;span class=&#34;err&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;url&amp;gt;,&lt;/span&gt; 	            &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;衣服图片url链接&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;person&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;url&amp;gt;&lt;/span&gt;	            &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;人物图片url链接&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;@返回格式&lt;/span&gt;	&lt;span class=&#34;err&#34;&gt;（返回后端）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;code:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;int&amp;gt;,&lt;/span&gt; 	            &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;状态码&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;(200表示成功,&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;500表示失败)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;msg:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;string&amp;gt;,&lt;/span&gt;	            &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;消息&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;(success&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;fail)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;data:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;err&#34;&gt;image_value&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;base64&amp;gt;,&lt;/span&gt;  &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;处理后的图片base64编码&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;动漫头像功能-2&#34;&gt;动漫头像功能&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;后端请求API:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;https:&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//certain-ideally-foal.ngrok-free.app/anime/predict/
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;@请求格式&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;userid&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;int&amp;gt;,&lt;/span&gt;  	   &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;用户id&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;origin_image&lt;/span&gt;  &lt;span class=&#34;err&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;url&amp;gt;,&lt;/span&gt; 	   &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;原图片url链接&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;@返回格式&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;code:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;int&amp;gt;,&lt;/span&gt; 	            &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;状态码&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;(200表示成功,&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;500表示失败)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;msg:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;string&amp;gt;,&lt;/span&gt;	            &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;消息&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;(success&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;fail)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;data:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;err&#34;&gt;image_value&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;...&amp;lt;base64&amp;gt;,&lt;/span&gt;  &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;处理后的图片base64编码&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Prior Attention Network: 用于医学图像中多病灶分割的预先注意网络</title>
      <link>https://swimmingliu.cn/posts/papernotes/2022-priorattentionnetwork/</link>
      <pubDate>Tue, 28 Nov 2023 14:55:47 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/papernotes/2022-priorattentionnetwork/</guid>
      <description>&lt;h1 id=&#34;prior-attention-network-用于医学图像中多病灶分割的预先注意网络&#34;&gt;Prior Attention Network: 用于医学图像中多病灶分割的预先注意网络&lt;/h1&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;医学图像中邻近组织的多种类型病变的准确分割在临床实践中具有重要意义。基于从&lt;strong&gt;粗到精策略的卷积神经网络（CNN）&lt;strong&gt;已广泛应用于该领域。然而，由于&lt;/strong&gt;组织的大小、对比度和高类间相似性的不确定性&lt;/strong&gt;，多病灶分割仍然具有挑战性。此外，&lt;strong&gt;普遍采用的级联策略&lt;/strong&gt;对&lt;strong&gt;硬件要求较高&lt;/strong&gt;，限制了临床部署的潜力。为了解决上述问题，我们提出了一种新颖的先验注意网络（PANet），它&lt;strong&gt;遵循从粗到细的策略&lt;/strong&gt;来在医学图像中执行多病灶分割。所提出的网络通过在网络中&lt;strong&gt;插入与病变相关的空间注意机制&lt;/strong&gt;，在单个网络中实现了&lt;strong&gt;两个步骤的分割&lt;/strong&gt;。此外，我们还提出了&lt;strong&gt;中间监督策略&lt;/strong&gt;，用于&lt;strong&gt;生成与病变相关的注意力&lt;/strong&gt;来获取&lt;strong&gt;感兴趣区域（ROI）&lt;/strong&gt;，这加速了收敛并明显提高了分割性能。我们在两个应用中研究了所提出的分割框架：&lt;strong&gt;肺部 CT 切片&lt;/strong&gt;中多发性&lt;strong&gt;肺部感染的 2D 分割&lt;/strong&gt;和&lt;strong&gt;脑 MRI 中多发性病变的 3D 分割&lt;/strong&gt;。实验结果表明，与级联网络相比，在 2D 和 3D 分割任务中，我们提出的网络以更少的计算成本实现了更好的性能。所提出的网络可以被视为 2D 和 3D 任务中多病灶分割的通用解决方案。源代码可在 &lt;a href=&#34;https://github.com/hsiangyuzhao/PANet&#34;&gt;https://github.com/hsiangyuzhao/PANet&lt;/a&gt; 获取&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;问题导向：&lt;/p&gt;
&lt;p&gt;①&lt;strong&gt;组织的大小、对比度和高类间相似性的不确定性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;②多类别病灶分割&lt;/p&gt;
&lt;p&gt;③&lt;strong&gt;普遍采用的级联策略&lt;/strong&gt;对&lt;strong&gt;硬件要求较高&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;医学图像分割对于疾病的准确筛查和患者的预后具有重要意义。基于病灶分割的病灶评估提供了疾病进展的信息，帮助医生提高临床诊断和治疗的质量。然而，手动病变分割相当主观且费力，这限制了其潜在的临床应用。近年来，随着人工智能的快速发展，基于深度学习的算法得到了广泛的应用，并在医学图像分割方面取得了最先进的性能[1]&lt;/strong&gt;。卷积神经网络（CNN）由于其高分割质量而在医学图像中的病变分割中很受欢迎。此类算法通常具有&lt;strong&gt;深度编码器&lt;/strong&gt;，可从输入图像中自动提取特征，并通过以下操作&lt;strong&gt;生成密集预测&lt;/strong&gt;。例如，Long等人[2]提出了一种用于图像语义分割的全卷积网络，该网络颇具影响力，并启发了后来的医学分割中的端到端框架。 Ronneberger等人[3]提出了一种用于医学图像分割的U形网络（U-Net），该网络在医学分割的许多领域都显示出了可喜的结果，并已成为许多医学分割任务的虚拟基准。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这一段都可以当成经典医学图像分割的背景引入&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;然而，尽管医学分割取得了这些突破，但目前的&lt;strong&gt;医学分割方法主要集中在病灶的二元分割上&lt;/strong&gt;，即&lt;strong&gt;区分病灶（前景）和其他一切（背景）&lt;/strong&gt;。尽管二元分割确实有助于&lt;strong&gt;隔离某些感兴趣区域&lt;/strong&gt;并允许对&lt;strong&gt;医学图像进行精确分析&lt;/strong&gt;，但在某些需要&lt;strong&gt;对病变进行多类分割的场景中，二元分割还不够&lt;/strong&gt;。与二元分割相比，由于&lt;strong&gt;组织的类间相似性，这种情况要困难得多&lt;/strong&gt;，因为&lt;strong&gt;不同类型的病变在纹理、大小和形状上可能相似&lt;/strong&gt;。具有从粗到细策略的级联网络已广泛应用于此类场景，例如&lt;strong&gt;肝脏和病变的分割、脑肿瘤分割&lt;/strong&gt;[4]、[5][6]、[7]。&lt;/p&gt;
&lt;p&gt;此类网络通常由两个独立的网络组成，其中第一个&lt;strong&gt;网络执行粗分割，第二个网络基于从第一个网络分割的 ROI 细化分割&lt;/strong&gt;。然而，尽管&lt;strong&gt;级联网络&lt;/strong&gt;已广泛应用于医学图像的&lt;strong&gt;多病灶分割&lt;/strong&gt;，但级联策略也有其缺点。由于&lt;strong&gt;级联网络由两个独立的网络组成&lt;/strong&gt;，&lt;strong&gt;参数量和显存占用通常是单个网络的两倍&lt;/strong&gt;，这对硬件要求较高，限制了其在临床使用的潜力。更重要的是，由于级联网络中的两个网络通常是独立的，因此&lt;strong&gt;级联网络的训练过程有时比单个网络更困难&lt;/strong&gt;，这可能导致欠拟合。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;级联网络：参数量大、容易欠拟合。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在本文中，我们提出了一种名为先验注意网络（PANet）的新型网络结构，用于在医学图像中执行&lt;strong&gt;多病灶分割&lt;/strong&gt;。所提出的网络由&lt;strong&gt;一个&lt;/strong&gt;用于&lt;strong&gt;特征提取的编码器&lt;/strong&gt;和&lt;strong&gt;两个分别生成病变区域注意力和最终预测的解码器组成&lt;/strong&gt;。该网络与&lt;strong&gt;注意力机制&lt;/strong&gt;结合在一起。为了&lt;strong&gt;减少参数大小和硬件&lt;/strong&gt;占用，我们使用&lt;strong&gt;网络编码器的深层、语义丰富的特征&lt;/strong&gt;来&lt;strong&gt;生成病变区域的空间注意力&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;然后，&lt;strong&gt;编码器生成的特征&lt;/strong&gt;表示通过&lt;strong&gt;空间注意力&lt;/strong&gt;进行细化，并将其发送到解码器以进行&lt;strong&gt;最终的多类预测&lt;/strong&gt;。为了&lt;strong&gt;提高分割性能并加速收敛&lt;/strong&gt;，我们还在网络结构中引入了&lt;strong&gt;中间监督和深度监督&lt;/strong&gt;。通过这些改进，与传统的级联网络相比，所提出的网络以&lt;strong&gt;显着降低的参数大小和计算成本&lt;/strong&gt;实现了有竞争力的结果。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;利用网络编码器的深层、特征信息来生成空间注意力（WTF ???）&lt;/p&gt;
&lt;p&gt;中间监督、深度监督 （不错不错， 好多一区和顶会的文章都用深度监督）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这项工作的贡献体现在三个方面。&lt;strong&gt;首先&lt;/strong&gt;，我们提出了一种新颖的网络架构，通过将传统级联网络中的两个分割步骤结合在&lt;strong&gt;单个网络&lt;/strong&gt;中，遵循 2D 和 3D 医学图像中多病灶分割的&lt;strong&gt;从粗到细的策略&lt;/strong&gt;。与级联网络相比，所提出的架构以更少的额外计算成本实现了有竞争力的分割性能，更容易训练和部署到生产环境。&lt;strong&gt;其次&lt;/strong&gt;，我们提出了一种&lt;strong&gt;监督空间注意力机制&lt;/strong&gt;，将&lt;strong&gt;病变区域的注意力与网络提取的特征相结合&lt;/strong&gt;，将多病变分割分解为&lt;strong&gt;两个更容易的阶段&lt;/strong&gt;，并且与当前&lt;strong&gt;基于注意力的方法相比具有更好的可解释性&lt;/strong&gt;。&lt;strong&gt;第三&lt;/strong&gt;，所提出的网络已在两个实际应用中得到验证，&lt;strong&gt;包括肺部 CT 切片中的 COVID-19 病变的 2D 分割和多模态 MRI 中的脑肿瘤的 3D 分割&lt;/strong&gt;。所提出的网络在 2D 和 3D 任务中都优于前沿方法，并且在参数和计算成本方面比当前网络更高效。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一个网络、监督空间注意力机制、参数和计算成本方面比当前网络更高效。&lt;/p&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;1）图像分割的网络结构：用于图像分割的典型卷积神经网络通常由一个卷积特征提取器组成，其拓扑类似于常见的分类网络，自动从输入图像中提取特征，并进行基于卷积的操作以生成最终的密集预测。在自然图像分割领域，FCN [2]、DeepLab [8]、PSPNet [9] 和 SegNet [10] 因其性能和效率而颇受欢迎。对于医学分割，U-Net [3] 在许多任务中相当流行，并且已被修改为许多改进版本，例如 Attention U-Net [11]、U-Net++ [12]、V-Net [13] 和H-DenseUNet [14]在某些领域获得更好的性能。&lt;/p&gt;</description>
    </item>
    <item>
      <title>地大服务器使用教程</title>
      <link>https://swimmingliu.cn/posts/diary/2023-%E5%9C%B0%E5%A4%A7%E6%9C%8D%E5%8A%A1%E5%99%A8/</link>
      <pubDate>Mon, 20 Nov 2023 12:25:57 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/diary/2023-%E5%9C%B0%E5%A4%A7%E6%9C%8D%E5%8A%A1%E5%99%A8/</guid>
      <description>&lt;h1 id=&#34;地大服务器使用教程&#34;&gt;地大服务器使用教程&lt;/h1&gt;
&lt;h2 id=&#34;1-服务器环境介绍&#34;&gt;1. 服务器环境介绍&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;NVIDIA RTX &lt;span class=&#34;m&#34;&gt;3090&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;24GB&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;NVIDIA RTX &lt;span class=&#34;m&#34;&gt;2080&lt;/span&gt; Ti &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;11GB&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img alt=&#34;image-20231120113601423&#34; loading=&#34;lazy&#34; src=&#34;https://oss.swimmingliu.cn/HoBnO.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;2-配置实验环境&#34;&gt;2. 配置实验环境&lt;/h2&gt;
&lt;h3 id=&#34;21-conda环境安装&#34;&gt;2.1 Conda环境安装&lt;/h3&gt;
&lt;p&gt;每位同学都会分配个人用户，大家在自己的用户上使用Conda进行环境配置。&lt;/p&gt;
&lt;p&gt;Conda安装教程：https://blog.csdn.net/JineD/article/details/129507719&lt;/p&gt;
&lt;p&gt;大家按照教程步骤安装即可, 由于安装时间较长, 视频中暂不进行演示。&lt;/p&gt;
&lt;h3 id=&#34;22-conda环境配置-以yolov8为例&#34;&gt;2.2 Conda环境配置 （以YOLOv8为例）&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 创建conda环境 名为yolov8_lyj python版本为3.9&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda create -n yolov8_lyj &lt;span class=&#34;nv&#34;&gt;python&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;3.9
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 激活环境&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda activate yolov8_lyj
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 选择合适的路径，克隆github项目代码&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/ultralytics/ultralytics
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 进入到项目路径下&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ultralytics/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 安装相关依赖包&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;23-准备数据集&#34;&gt;2.3 准备数据集&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;下载需要训练的数据集 （最好找顶刊/顶会论文中的公开数据集）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;按照算法指定的数据集格式，对数据集格式进行调整。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​		目标检测中数据集格式之间的相互转换：（VOC、COCO、YOLO格式）&lt;/p&gt;
&lt;p&gt;​		https://zhuanlan.zhihu.com/p/461488682&lt;/p&gt;
&lt;h3 id=&#34;24-开始实验&#34;&gt;2.4 开始实验&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;在算法中指定数据集的存放路径 （相对/绝对路径均可）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;初始化算法的参数&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;batch-size  批处理大小：每一次处理图片的个数，根据显卡内存进行调整
epochs	   迭代次数：算法总共需要训练的轮次
workers     载入数据进程数：每一次调用多少个进程来载入数据
device      选择显卡设备： &amp;#39;0&amp;#39;使用3090，&amp;#39;1&amp;#39;使用2080ti，&amp;#39;0,1&amp;#39;使用两张卡
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;开始训练&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 运行训练代码&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python mian.py
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;(注：使用向日葵的同学，可以直接在Pycharm当中运行)&lt;/p&gt;</description>
    </item>
    <item>
      <title>ACC-UNet: A Completely Convolutional UNet model for the 2020s (MICCAI2023)</title>
      <link>https://swimmingliu.cn/posts/papernotes/2023-acc-unet/</link>
      <pubDate>Sun, 12 Nov 2023 16:32:06 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/papernotes/2023-acc-unet/</guid>
      <description>&lt;h1 id=&#34;acc-unet-a-completely-convolutional-unet-model-for-the-2020s-miccai2023&#34;&gt;ACC-UNet: A Completely Convolutional UNet model for the 2020s (MICCAI2023)&lt;/h1&gt;
&lt;h2 id=&#34;1-abstract&#34;&gt;1. Abstract&lt;/h2&gt;
&lt;p&gt;由于ViT （Vision Transformer）的引入，UNet和Transformer融合已成为大趋势。最近，又有很多研究人员开始重新思考卷积模型，比如将ConvNext嵌入到ResNet，能够达到Swin Transformer的水平。受此启发，作者提出了一个纯粹的卷积UNET模型 （ACC-UNet），并且超越基于Transfomer的模型(如Swin-UNET或UCTransNet)。
作者研究了基于Transfomer的UNET模型优点：长范围依赖关系和跨级别跳过连接。
ACC-UNet结合了&lt;strong&gt;卷积神经网络（ConvNets）的内在归纳偏差&lt;/strong&gt;和&lt;strong&gt;Transformer的设计决策&lt;/strong&gt;
&lt;strong&gt;卷积神经网络（ConvNets）的内在归纳偏差&lt;/strong&gt;：卷积神经网络具有天生的归纳偏差，这意味着它们在处理图像等数据时具有一些固有的假设和特点。例如，卷积神经网络擅长处理局部特征、平移不变性等，这些特点使它们在图像处理任务中表现出色。
&lt;strong&gt;Transformer的设计决策&lt;/strong&gt;：Transformer是一种不同的神经网络架构，它采用了一些独特的设计决策，例如自注意力机制和位置编码等。这些设计决策使得Transformer在处理长距离依赖性、全局关系等方面表现出色，适合处理序列数据和具有远程依赖的任务。
ACC-UNet 在 5 个不同的医学图像分割基准上进行了评估，并且始终优于卷积网络、Transfomer及其混合网络。&lt;/p&gt;
&lt;h2 id=&#34;2introduction&#34;&gt;2.Introduction&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;语义分割是计算机辅助医学图像分析的重要组成部分，可识别并突出显示各种诊断任务中感兴趣的区域。然而，由于涉及图像模态和采集以及病理和生物变化的各种因素，这通常变得复杂[18]。深度学习在这一领域的应用无疑在这方面受益匪浅。最值得注意的是，自推出以来，UNet 模型 [19] 在医学图像分割方面表现出了惊人的功效。结果，UNet 及其衍生品已成为事实上的标准[25]。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;学习一下这里的背景描述&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;原始的 UNet 模型包含对称的编码器-解码器架构（图 1a）并采用跳跃连接，这为解码器提供了在编码器的池化操作期间可能丢失的空间信息。尽管通过简单串联的信息传播提高了性能，但编码器-解码器特征图之间可能存在语义差距。这导致了第二类 UNet 的发展（图 1b）。 U-Net++ [26] 利用密集连接，而 MultiResUNet [11] 在跳过连接上添加了额外的卷积块作为潜在的补救措施。到目前为止，UNet 的历史上所有创新都是使用 CNN 进行的。然而，2020 年的十年给计算机视觉领域带来了根本性的变化。 CNN 在视觉领域的长期主导地位被视觉转换器打破了 [7]。 Swin Transformers [15] 进一步针对一般视觉应用调整了变压器。因此，UNet 模型开始采用 Transformer [5]。 Swin-Unet [9] 用 Swin Transformer 块取代了卷积块，从而开创了一类新的模型（图 1c）。尽管如此，CNN 在图像分割方面仍然具有各种优点，导致了融合这两者的发展[2]。这种混合类 UNet 模型（图 1d）在编码器-解码器中采用卷积块，并沿跳跃连接使用变换器层。 UCTransNet [22]和MCTrans[24]是此类的两个代表性模型。最后，还尝试开发全变压器 UNet 架构（图 1e），例如，SMESwin Unet [27] 在编码器-解码器块和跳跃连接中都使用变压器。&lt;/p&gt;</description>
    </item>
    <item>
      <title>M2SNet: Multi-scale in Multi-scale Subtraction Network for Medical Image Segmentation</title>
      <link>https://swimmingliu.cn/posts/papernotes/2023-m2snet/</link>
      <pubDate>Sun, 12 Nov 2023 16:25:03 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/papernotes/2023-m2snet/</guid>
      <description>&lt;h1 id=&#34;2023-m2snet-新颖多尺度模块--智能损失函数--通用图像分割sota网络&#34;&gt;(2023) M2SNet: 新颖多尺度模块 + 智能损失函数 = 通用图像分割SOTA网络&lt;/h1&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;准确的医学图像分割对于早期医学诊断至关重要。大多数现有方法基于U形结构，并使用&lt;strong&gt;逐元素加法或串联在解码器中逐步融合不同级别的特征&lt;/strong&gt;。然而，这两种操作都&lt;strong&gt;容易产生大量冗余信息&lt;/strong&gt;，从而&lt;strong&gt;削弱不同级别特征之间的互补性&lt;/strong&gt;，导致&lt;strong&gt;病灶定位不准确和边缘模糊&lt;/strong&gt;。为了应对这一挑战，我们提出了一种通用的多尺度减法网络（M2SNet）来完成医学图像的多样化分割。具体来说，我们首先设计一个基本&lt;strong&gt;减法单元（SU）&lt;strong&gt;来产生编码器中相邻级别之间的差异特征。接下来，我们将单尺度 SU 扩展到层内多尺度 SU，它可以为解码器&lt;/strong&gt;提供像素级和结构级差异信息&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;然后，我们金字塔式地为不同层次的多尺度SU配备不同的感受野，从而实现层间多尺度特征聚合并获得丰富的多尺度差异信息。此外，我们构建了一个免训练网络“LossNet”来全面监督从底层到顶层的任务感知特征，这驱动我们的多尺度减法网络同时捕获细节和结构线索。&lt;/p&gt;
&lt;p&gt;没有花里胡哨的东西，我们的方法在不同的评估指标下，在不同图像模态的四种不同医学图像分割任务的 11 个数据集上表现优于大多数最先进的方法，包括彩色结肠镜成像、超声成像、计算机断层扫描 (CT) ）和光学相干断层扫描（OCT）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;两个主要创新点：多尺度金字塔减法单元 （确实牛逼）+ LossNet（为了创新而创新的损失函数）&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;作为计算机辅助诊断系统中的重要作用，精确的医学图像分割技术可以为医生做出临床决策提供重要指导。精确分割存在三个普遍的挑战：首先，U形结构[1]、[2]由于其利用多级信息重建高分辨率特征图的能力而受到了相当多的关注。在UNet [2]中，上采样的特征图与从编码器跳过的特征图连接在一起，并在上采样步骤之间添加卷积和非线性，如图1（a）所示。后续基于UNet的方法通过注意力机制[3]、[4]、门机制[5]、[6]、变压器技术[7]、[8]设计不同的特征增强模块，如图1（b）所示。 UNet++[9]使用嵌套和密集的跳跃连接来减少编码器和解码器的特征图之间的语义差距，如图1（c）所示。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;先说医学分割在医学领域重要&amp;hellip;(balabala)  然后当前领域存在xxx挑战&amp;hellip;(balabala)&lt;/p&gt;
&lt;p&gt;这里是以医学图像分割挑战的视角，介绍UNet发展的情况。然后在描述不同UNet变体发展过程中解决的不同问题（感觉可以借鉴）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一般来说，编码器中不同级别的特征有不同的特征。&lt;strong&gt;高级别具有更多的语义信息&lt;/strong&gt;，有助于定位对象，而低级别具有&lt;strong&gt;更详细的信息&lt;/strong&gt;，可以捕捉对象的&lt;strong&gt;微妙边界&lt;/strong&gt;。解码器利用特定级别和跨级别特征来生成最终的&lt;strong&gt;高分辨率预测&lt;/strong&gt;。然而，上述方法&lt;strong&gt;直接使用逐元素加法或串联来融合来自编码器的任意两级特征&lt;/strong&gt;并将它们传输到解码器。这些简单的操作并没有更多地关注&lt;strong&gt;不同层次之间的差异信息。&lt;strong&gt;这一缺点不仅会产生&lt;/strong&gt;冗余信息来稀释真正有用的特征&lt;/strong&gt;，还会&lt;strong&gt;削弱特定于级别的特征的特性&lt;/strong&gt;，从而导致网络无法平衡精确定位和微妙的边界细化。其次，由于&lt;strong&gt;感受野有限&lt;/strong&gt;，单尺度卷积核很难捕获大小变化物体的&lt;strong&gt;上下文信息&lt;/strong&gt;。一些方法[1]、[2]、[9]-[11]依赖于层间多尺度特征，并逐步整合来自不同尺度表示的&lt;strong&gt;语义上下文和纹理细节&lt;/strong&gt;。其他人[6]、[12]-[15]专注于基于网络中的空洞空间金字塔池化模块[16]（ASPP）或DenseASPP [17]提取&lt;strong&gt;层内多尺度信息&lt;/strong&gt;。然而，类似ASPP的多尺度卷积模块会产生&lt;strong&gt;许多额外的参数和计算&lt;/strong&gt;。许多方法[5]、[18]-[21]通常将多个ASPP模块安装到不同级别的编码器/解码器块中，而有些方法[13]、[14]、[22]、[23]将其安装在不同级别的编码器/解码器块中。最高级别的编码器块。第三，损失函数的形式直接为网络的梯度优化提供了方向。在分割领域，提出了许多损失函数来监督不同级别的预测，例如像素级别的L1损失、交叉熵损失和加权交叉熵损失[24]，SSIM[25]损失区域层面的不确定性损失[26]，全局层面的IoU损失、Dice损失和一致性增强损失[11]。尽管这些基本损失函数及其变体具有不同的优化特性，但复杂的手动数学形式的设计对于许多研究来说确实非常耗时。为了获得综合性能，模型通常会集成多种损失函数，这对研究人员的训练技能提出了很高的要求。因此，我们认为有必要引入一种无需复杂人工设计的智能损失函数来全面监督分割预测。&lt;/p&gt;
&lt;p&gt;在本文中，我们提出了一种用于一般医学图像分割的新型多尺度减法网络（M2SNet）。首先，我们设计一个减法单元（SU）并将其应用于&lt;strong&gt;每对相邻的级别特征&lt;/strong&gt;。 SU突出了&lt;strong&gt;特征之间有用的差异信息，并消除了冗余部分的干扰&lt;/strong&gt;。其次，我们借助所提出的&lt;strong&gt;多尺度减法模块&lt;/strong&gt;收集&lt;strong&gt;极端多尺度信息&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;对于层间多尺度信息，我们以金字塔方式连接多个减法单元来捕获大跨度的跨层信息。然后，我们&lt;strong&gt;聚合特定于级别的特征&lt;/strong&gt;和&lt;strong&gt;多路径跨级别差分特征&lt;/strong&gt;，然后在解码器中生成最终预测。对于层内多尺度信息，我们通过一组不同内核大小的full one滤波器将单尺度减法单元&lt;strong&gt;改进为多尺度减法单元，可以自然地实现多尺度减法聚合，而无需引入额外的参数&lt;/strong&gt;。如图1所示，MSNet配备了层间多尺度减法模块，M2SNet同时具有层间和层内多尺度减法结构。第三，我们提出了一个LossNet来自动监督从底层到顶层提取的特征图，它可以通过简单的L2损失函数优化从细节到结构的分割。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;多尺度减法单元可以去特征之间的差异信息，消除冗余干扰。&lt;/p&gt;
&lt;p&gt;（也就是说可以用这种办法替换注意力机制）&lt;/p&gt;
&lt;h2 id=&#34;related-work&#34;&gt;RELATED WORK&lt;/h2&gt;
&lt;h3 id=&#34;medical-image-segmentation-network&#34;&gt;Medical Image Segmentation Network&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;根据不同器官或病变的特点，我们将现有的医学图像分割方法分为两类：医学通用的和医学专用的。随着U-Net[2]在医学图像分割领域取得稳定的性能，带有编码器-解码器的U形结构已成为基本的分割基线。 U-Net++[9]集成了&lt;strong&gt;长连接和短连接&lt;/strong&gt;，可以减少编码器和解码器子网络的特征图之间的语义差距。对于注意力 U-Net [28]，&lt;strong&gt;注意力门&lt;/strong&gt;嵌入在编码器和解码器块之间的每个过渡层中，它可以自动学习关注不&lt;strong&gt;同形状和大小的目标结构&lt;/strong&gt;。最近，Transformer [29]架构在许多自然语言处理任务中取得了成功。一些作品[7]、[8]探讨了其对医学视觉任务的有效性。 UTNet [7] 是一种简单但功能强大的混合变压器架构，它在编码器和解码器中应用自注意力模块，以最小的开销捕获不同规模的远程依赖关系。另一个具有代表性的基于 Transformer 的模型是 TransUNet [8]，它通过将图像特征视为序列来编码强全局上下文，并通过 U 形混合架构设计利用低级 CNN 特征。&lt;/p&gt;
&lt;p&gt;医学特定方法。在息肉分割任务中，SFA [30]和PraNet [4]专注于恢复息肉与其周围粘膜之间的清晰边界。前者提出了共享编码器和两个相互约束的解码器下的选择性特征聚合结构和边界敏感损失函数。后者利用反向注意模块来建立区域和边界线索之间的关系。此外，Ji等人[31]利用时空信息构建视频息肉分割模型。在COVID-19肺部感染任务中，Paluru等人[32]提出了一种基于变形深度嵌入的轻量级CNN来分割COVID-19胸部CT图像中的异常。 Inf-Net [33] 构建隐式反向注意力和显式边缘注意力来对边界进行建模。 BCS-Net [34]具有三个渐进边界上下文语义重建块，可以帮助解码器捕获肺部感染的零散区域。在乳腺分割任务中，Byra等人[35]通过注意力机制开发了选择性核来调整U-Net的感受野，可以进一步提高乳腺肿瘤的分割精度。 Chen 等人 [36] 提出了一种嵌套 U 网，通过利用不同的深度和共享权重来实现乳腺肿瘤的稳健表示。&lt;/p&gt;</description>
    </item>
    <item>
      <title>EGE-UNet: an Efficient Group Enhanced UNet for skin lesion segmentation</title>
      <link>https://swimmingliu.cn/posts/papernotes/2023-ege-unet%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Sat, 11 Nov 2023 19:51:21 +0800</pubDate>
      <guid>https://swimmingliu.cn/posts/papernotes/2023-ege-unet%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</guid>
      <description>&lt;h1 id=&#34;ege-unet-an-efficient-group-enhanced-unet-for-skin-lesion-segmentation&#34;&gt;EGE-UNet: an Efficient Group Enhanced UNet for skin lesion segmentation&lt;/h1&gt;
&lt;h2 id=&#34;1-abstract&#34;&gt;1. Abstract&lt;/h2&gt;
&lt;p&gt;目前的医学图像分割模型大多是 Transformer + Unet，这些模型的大量参数和计算负载使得它们不适合移动健康应用。&lt;/p&gt;
&lt;p&gt;作者提出的EGE-UNet 模型轻量、高效。（与 TransFuse 相比，参数和计算成本分别降低了 494 倍和 160 倍，模型参数量只有50KB）&lt;/p&gt;
&lt;p&gt;创新点：组多轴哈达玛产品注意力模块（GHPA）和组聚合桥模块（GAB）。&lt;/p&gt;
&lt;p&gt;1.GHPA 对输入特征进行分组，并在不同轴上执行哈达玛产品注意力机制（HPA），以从不同角度提取病理信息。&lt;/p&gt;
&lt;p&gt;2.GAB 通过对低级特征、高级特征以及解码器在每个阶段生成的掩码进行分组，有效地融合了多尺度信息。&lt;/p&gt;
&lt;h2 id=&#34;2-introduction&#34;&gt;2. Introduction&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;背景: 恶性黑色素瘤是世界上增长最快的癌症之一。据美国癌症协会估计，2020 年约有 100,350 例新发病例，超过 6,500 例死亡。因此，自动化皮肤病变分割系统势在必行，因为它可以帮助医疗专业人员快速识别病变区域并促进后续治疗过程。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;相同方式可引入脑瘤、肺癌。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;为了提高分割性能，最近的研究倾向于采用具有更大参数和计算复杂度的模块，例如结合视觉变换器（ViT）的自注意力机制[7]。例如，Swin-UNet [4]，基于Swin Transformer [11]，利用自注意力机制的特征提取能力来提高分割性能。 TransUNet [5] 开创了用于医学图像分割的 CNN 和 ViT 的串行融合。 TransFuse [26]采用双路径结构，利用 CNN 和 ViT 分别捕获局部和全局信息。UTNetV2[8]利用混合分层架构、高效的双向注意力和语义图来实现全局多尺度特征融合，结合了CNN和ViT的优点。 TransBTS [23] 将自注意力引入脑肿瘤分割任务中，并用它来聚合高级信息。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Abstract提到当前医学分割模型大部分是Transformer + Unet，这里做出具体阐述。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;先前的工作通过引入复杂的模块来提高性能，但忽略了实际医疗环境中计算资源的限制。因此，迫切需要为移动医疗中的分割任务设计一种低参数、低计算负载的模型。最近，UNeXt [22] 结合了 UNet [18] 和 MLP [21] 开发了一种轻量级模型，该模型可以获得优异的性能，同时减少参数和计算量。此外，MALUNet [19]通过减少模型通道数并引入多个注意力模块来减小模型大小，从而比 UNeXt 具有更好的皮肤病变分割性能。然而，尽管MALUNet大大减少了参数数量和计算量，但其分割性能仍然低于一些大型模型，例如TransFuse。因此，在本研究中，我们提出了 EGE-UNet，这是一种轻量级皮肤病变分割模型，可实现最先进的效果，同时显着降低参数和计算成本。此外，据我们所知，这是第一个将参数减少到大约 50KB 的工作。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
