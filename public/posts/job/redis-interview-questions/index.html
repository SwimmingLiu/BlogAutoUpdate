<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Redis面试题笔记 | SwimmingLiu&#39;s Blog</title>
<meta name="keywords" content="Java, Redis">
<meta name="description" content="1. Redis主从复制的原理
【主从复制的原理】

同步：从节点向主节点发送psync命令进行同步，从节点保存主节点返回的 runid 和  offset
全量复制：如果是第一次连接或者连接失败且repl_backlog_buffer 缓存区不包含slave_repl_offset， 则生成主节点的数据快照(RDB文件)发给从节点
增量复制：全量复制完毕后，主从节点之间会保持长连接。如果连接没有断开或者slave_repl_offset仍然在repl_backlog_buffer中，则将后续的写操作传递给从节点，让数据保持一致。

【全量复制细节】
全量复制的过程是基于TCP长连接的，主要流程如下

从节点发送psync ? -1表示需要建立连接进行同步，主节点返回主节点ID runid 和 复制进度offset (第一次同步用 -1 表示)。从节点接受之后，保存主节点的信息。
主节点执行bgsave命令生成数据快照RDB文件，然后将RDB文件发送给从节点。从节点接受文件后，清除现有的所有数据，然后加载RDB文件
如果在制作数据快照RDB文件的过程当中，主节点接收到了新的写操作，主节点会将其记录在repl buffer 里面。然后将repl buffer当中的写操作发给从节点，让其数据保持一致。


【增量复制细节】
如果主从节点意外断开连接，为了保持数据的一致性，必须重新同步数据。如果使用全量复制来保持一致性的话，开销太大，所以采用增量复制。
增量复制的具体流程如下：

连接恢复后，从节点会发送psync {runid} {offset}， 其中主节点ID runid 和 复制进度offset用于标识是哪一个服务器主机和复制进度。
主节点收到psync 命令之后，会用conitnue响应告知从节点，采用增量复制同步数据
最后，主节点根据offset查找对应的进度，将短线期间未同步的写命令，发送给从节点。同时，主节点将所有的写命令写入repl_backlog_buffer， 用于后续判断是采用增量复制还是全量复制。

【注意】从节点 psync 携带的 offset 为 slave_repl_offset。如果 repl_backlog_buffer包含slave_repl_offset 对应的部分，则采用增量复制，否则采用全量复制。repl_backlog_buffer的默认缓冲区大小为1M

【为什么要主从复制】

备份数据：主从复制实现了数据的热备份，是持久化之外的数据冗余方式
故障恢复：当主节点宕机之后，可以采用从节点提供服务。
负载均衡:  主从复制实现了读写分离，只有主节点支持读写操作，从节点只有都操作。在读多写少的场景下，可以提高Redis服务器的并发量。


2. Redis集群的实现原理是什么?
【Redis集群基本知识】

定义: Redis集群由多个实例组成，每个实例存储部分数据 (每个实例之间的数据不重复) 。

【注】集群和主从节点不是一个东西，集群的某一个实例当中可能包含一个主节点 &#43; 多个从节点

为什么用


  
      
          问题
          解决方案
      
  
  
      
          容量不足
          数据分片，将数据分散不存到不同的主节点
      
      
          高并发写入
          数据分片，将写入请求分摊到多个主节点
      
      
          主机宕机问题
          自动切换主从节点，避免影响服务， 不需要手动修改客户端配置
      
  


节点通信协议：Redis集群采用Gossip协议, 支持分布式信息传播、延迟低、效率高。采用去中心化思想，任意实例(主节点)都可以作为请求入口，节点间相互通信。
分片原理： 采用哈希槽(Hash Slot)机制来分配数据，整个空间可以划分为16384 (16 * 1024)个槽。 每个Redis负责一定范围的哈希槽,数据的key经过哈希函数计算之后对16384取余可定位到对应的节点。

">
<meta name="author" content="SwimmingLiu">
<link rel="canonical" href="https://swimmingliu.cn/posts/job/redis-interview-questions/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.6ecbb0040febd20e47edd88a662c19f1ea945bf7427774b86594271d18f88faf.css" integrity="sha256-bsuwBA/r0g5H7diKZiwZ8eqUW/dCd3S4ZZQnHRj4j68=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://swimmingliu.cn/images/swimmingliu_icon.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://swimmingliu.cn/images/swimmingliu_icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://swimmingliu.cn/images/swimmingliu_icon.png">
<link rel="apple-touch-icon" href="https://swimmingliu.cn/images/swimmingliu_icon.png">
<link rel="mask-icon" href="https://swimmingliu.cn/images/swimmingliu_icon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://swimmingliu.cn/posts/job/redis-interview-questions/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            
            
            delimiters: [
                { left: '$$', right: '$$', display: true },
                { left: '$', right: '$', display: false },
                { left: '\\(', right: '\\)', display: false },
                { left: '\\[', right: '\\]', display: true }
            ],
            
            throwOnError: false
        });
    });
</script>

<meta property="og:url" content="https://swimmingliu.cn/posts/job/redis-interview-questions/">
  <meta property="og:site_name" content="SwimmingLiu&#39;s Blog">
  <meta property="og:title" content="Redis面试题笔记">
  <meta property="og:description" content="1. Redis主从复制的原理 【主从复制的原理】
同步：从节点向主节点发送psync命令进行同步，从节点保存主节点返回的 runid 和 offset 全量复制：如果是第一次连接或者连接失败且repl_backlog_buffer 缓存区不包含slave_repl_offset， 则生成主节点的数据快照(RDB文件)发给从节点 增量复制：全量复制完毕后，主从节点之间会保持长连接。如果连接没有断开或者slave_repl_offset仍然在repl_backlog_buffer中，则将后续的写操作传递给从节点，让数据保持一致。 【全量复制细节】
全量复制的过程是基于TCP长连接的，主要流程如下
从节点发送psync ? -1表示需要建立连接进行同步，主节点返回主节点ID runid 和 复制进度offset (第一次同步用 -1 表示)。从节点接受之后，保存主节点的信息。 主节点执行bgsave命令生成数据快照RDB文件，然后将RDB文件发送给从节点。从节点接受文件后，清除现有的所有数据，然后加载RDB文件 如果在制作数据快照RDB文件的过程当中，主节点接收到了新的写操作，主节点会将其记录在repl buffer 里面。然后将repl buffer当中的写操作发给从节点，让其数据保持一致。 【增量复制细节】
如果主从节点意外断开连接，为了保持数据的一致性，必须重新同步数据。如果使用全量复制来保持一致性的话，开销太大，所以采用增量复制。
增量复制的具体流程如下：
连接恢复后，从节点会发送psync {runid} {offset}， 其中主节点ID runid 和 复制进度offset用于标识是哪一个服务器主机和复制进度。 主节点收到psync 命令之后，会用conitnue响应告知从节点，采用增量复制同步数据 最后，主节点根据offset查找对应的进度，将短线期间未同步的写命令，发送给从节点。同时，主节点将所有的写命令写入repl_backlog_buffer， 用于后续判断是采用增量复制还是全量复制。 【注意】从节点 psync 携带的 offset 为 slave_repl_offset。如果 repl_backlog_buffer包含slave_repl_offset 对应的部分，则采用增量复制，否则采用全量复制。repl_backlog_buffer的默认缓冲区大小为1M
【为什么要主从复制】
备份数据：主从复制实现了数据的热备份，是持久化之外的数据冗余方式 故障恢复：当主节点宕机之后，可以采用从节点提供服务。 负载均衡: 主从复制实现了读写分离，只有主节点支持读写操作，从节点只有都操作。在读多写少的场景下，可以提高Redis服务器的并发量。 2. Redis集群的实现原理是什么? 【Redis集群基本知识】
定义: Redis集群由多个实例组成，每个实例存储部分数据 (每个实例之间的数据不重复) 。 【注】集群和主从节点不是一个东西，集群的某一个实例当中可能包含一个主节点 &#43; 多个从节点
为什么用 问题 解决方案 容量不足 数据分片，将数据分散不存到不同的主节点 高并发写入 数据分片，将写入请求分摊到多个主节点 主机宕机问题 自动切换主从节点，避免影响服务， 不需要手动修改客户端配置 节点通信协议：Redis集群采用Gossip协议, 支持分布式信息传播、延迟低、效率高。采用去中心化思想，任意实例(主节点)都可以作为请求入口，节点间相互通信。 分片原理： 采用哈希槽(Hash Slot)机制来分配数据，整个空间可以划分为16384 (16 * 1024)个槽。 每个Redis负责一定范围的哈希槽,数据的key经过哈希函数计算之后对16384取余可定位到对应的节点。 ">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-02-20T21:21:45+08:00">
    <meta property="article:modified_time" content="2025-02-20T21:21:45+08:00">
    <meta property="article:tag" content="Java">
    <meta property="article:tag" content="Redis">
      <meta property="og:image" content="https://swimmingliu.cn/papermod-cover.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://swimmingliu.cn/papermod-cover.png">
<meta name="twitter:title" content="Redis面试题笔记">
<meta name="twitter:description" content="1. Redis主从复制的原理
【主从复制的原理】

同步：从节点向主节点发送psync命令进行同步，从节点保存主节点返回的 runid 和  offset
全量复制：如果是第一次连接或者连接失败且repl_backlog_buffer 缓存区不包含slave_repl_offset， 则生成主节点的数据快照(RDB文件)发给从节点
增量复制：全量复制完毕后，主从节点之间会保持长连接。如果连接没有断开或者slave_repl_offset仍然在repl_backlog_buffer中，则将后续的写操作传递给从节点，让数据保持一致。

【全量复制细节】
全量复制的过程是基于TCP长连接的，主要流程如下

从节点发送psync ? -1表示需要建立连接进行同步，主节点返回主节点ID runid 和 复制进度offset (第一次同步用 -1 表示)。从节点接受之后，保存主节点的信息。
主节点执行bgsave命令生成数据快照RDB文件，然后将RDB文件发送给从节点。从节点接受文件后，清除现有的所有数据，然后加载RDB文件
如果在制作数据快照RDB文件的过程当中，主节点接收到了新的写操作，主节点会将其记录在repl buffer 里面。然后将repl buffer当中的写操作发给从节点，让其数据保持一致。


【增量复制细节】
如果主从节点意外断开连接，为了保持数据的一致性，必须重新同步数据。如果使用全量复制来保持一致性的话，开销太大，所以采用增量复制。
增量复制的具体流程如下：

连接恢复后，从节点会发送psync {runid} {offset}， 其中主节点ID runid 和 复制进度offset用于标识是哪一个服务器主机和复制进度。
主节点收到psync 命令之后，会用conitnue响应告知从节点，采用增量复制同步数据
最后，主节点根据offset查找对应的进度，将短线期间未同步的写命令，发送给从节点。同时，主节点将所有的写命令写入repl_backlog_buffer， 用于后续判断是采用增量复制还是全量复制。

【注意】从节点 psync 携带的 offset 为 slave_repl_offset。如果 repl_backlog_buffer包含slave_repl_offset 对应的部分，则采用增量复制，否则采用全量复制。repl_backlog_buffer的默认缓冲区大小为1M

【为什么要主从复制】

备份数据：主从复制实现了数据的热备份，是持久化之外的数据冗余方式
故障恢复：当主节点宕机之后，可以采用从节点提供服务。
负载均衡:  主从复制实现了读写分离，只有主节点支持读写操作，从节点只有都操作。在读多写少的场景下，可以提高Redis服务器的并发量。


2. Redis集群的实现原理是什么?
【Redis集群基本知识】

定义: Redis集群由多个实例组成，每个实例存储部分数据 (每个实例之间的数据不重复) 。

【注】集群和主从节点不是一个东西，集群的某一个实例当中可能包含一个主节点 &#43; 多个从节点

为什么用


  
      
          问题
          解决方案
      
  
  
      
          容量不足
          数据分片，将数据分散不存到不同的主节点
      
      
          高并发写入
          数据分片，将写入请求分摊到多个主节点
      
      
          主机宕机问题
          自动切换主从节点，避免影响服务， 不需要手动修改客户端配置
      
  


节点通信协议：Redis集群采用Gossip协议, 支持分布式信息传播、延迟低、效率高。采用去中心化思想，任意实例(主节点)都可以作为请求入口，节点间相互通信。
分片原理： 采用哈希槽(Hash Slot)机制来分配数据，整个空间可以划分为16384 (16 * 1024)个槽。 每个Redis负责一定范围的哈希槽,数据的key经过哈希函数计算之后对16384取余可定位到对应的节点。

">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "📚 Posts",
      "item": "https://swimmingliu.cn/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "💻 Job",
      "item": "https://swimmingliu.cn/posts/job/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Redis面试题笔记",
      "item": "https://swimmingliu.cn/posts/job/redis-interview-questions/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Redis面试题笔记",
  "name": "Redis面试题笔记",
  "description": "1. Redis主从复制的原理 【主从复制的原理】\n同步：从节点向主节点发送psync命令进行同步，从节点保存主节点返回的 runid 和 offset 全量复制：如果是第一次连接或者连接失败且repl_backlog_buffer 缓存区不包含slave_repl_offset， 则生成主节点的数据快照(RDB文件)发给从节点 增量复制：全量复制完毕后，主从节点之间会保持长连接。如果连接没有断开或者slave_repl_offset仍然在repl_backlog_buffer中，则将后续的写操作传递给从节点，让数据保持一致。 【全量复制细节】\n全量复制的过程是基于TCP长连接的，主要流程如下\n从节点发送psync ? -1表示需要建立连接进行同步，主节点返回主节点ID runid 和 复制进度offset (第一次同步用 -1 表示)。从节点接受之后，保存主节点的信息。 主节点执行bgsave命令生成数据快照RDB文件，然后将RDB文件发送给从节点。从节点接受文件后，清除现有的所有数据，然后加载RDB文件 如果在制作数据快照RDB文件的过程当中，主节点接收到了新的写操作，主节点会将其记录在repl buffer 里面。然后将repl buffer当中的写操作发给从节点，让其数据保持一致。 【增量复制细节】\n如果主从节点意外断开连接，为了保持数据的一致性，必须重新同步数据。如果使用全量复制来保持一致性的话，开销太大，所以采用增量复制。\n增量复制的具体流程如下：\n连接恢复后，从节点会发送psync {runid} {offset}， 其中主节点ID runid 和 复制进度offset用于标识是哪一个服务器主机和复制进度。 主节点收到psync 命令之后，会用conitnue响应告知从节点，采用增量复制同步数据 最后，主节点根据offset查找对应的进度，将短线期间未同步的写命令，发送给从节点。同时，主节点将所有的写命令写入repl_backlog_buffer， 用于后续判断是采用增量复制还是全量复制。 【注意】从节点 psync 携带的 offset 为 slave_repl_offset。如果 repl_backlog_buffer包含slave_repl_offset 对应的部分，则采用增量复制，否则采用全量复制。repl_backlog_buffer的默认缓冲区大小为1M\n【为什么要主从复制】\n备份数据：主从复制实现了数据的热备份，是持久化之外的数据冗余方式 故障恢复：当主节点宕机之后，可以采用从节点提供服务。 负载均衡: 主从复制实现了读写分离，只有主节点支持读写操作，从节点只有都操作。在读多写少的场景下，可以提高Redis服务器的并发量。 2. Redis集群的实现原理是什么? 【Redis集群基本知识】\n定义: Redis集群由多个实例组成，每个实例存储部分数据 (每个实例之间的数据不重复) 。 【注】集群和主从节点不是一个东西，集群的某一个实例当中可能包含一个主节点 + 多个从节点\n为什么用 问题 解决方案 容量不足 数据分片，将数据分散不存到不同的主节点 高并发写入 数据分片，将写入请求分摊到多个主节点 主机宕机问题 自动切换主从节点，避免影响服务， 不需要手动修改客户端配置 节点通信协议：Redis集群采用Gossip协议, 支持分布式信息传播、延迟低、效率高。采用去中心化思想，任意实例(主节点)都可以作为请求入口，节点间相互通信。 分片原理： 采用哈希槽(Hash Slot)机制来分配数据，整个空间可以划分为16384 (16 * 1024)个槽。 每个Redis负责一定范围的哈希槽,数据的key经过哈希函数计算之后对16384取余可定位到对应的节点。 ",
  "keywords": [
    "Java", "Redis"
  ],
  "articleBody": "1. Redis主从复制的原理 【主从复制的原理】\n同步：从节点向主节点发送psync命令进行同步，从节点保存主节点返回的 runid 和 offset 全量复制：如果是第一次连接或者连接失败且repl_backlog_buffer 缓存区不包含slave_repl_offset， 则生成主节点的数据快照(RDB文件)发给从节点 增量复制：全量复制完毕后，主从节点之间会保持长连接。如果连接没有断开或者slave_repl_offset仍然在repl_backlog_buffer中，则将后续的写操作传递给从节点，让数据保持一致。 【全量复制细节】\n全量复制的过程是基于TCP长连接的，主要流程如下\n从节点发送psync ? -1表示需要建立连接进行同步，主节点返回主节点ID runid 和 复制进度offset (第一次同步用 -1 表示)。从节点接受之后，保存主节点的信息。 主节点执行bgsave命令生成数据快照RDB文件，然后将RDB文件发送给从节点。从节点接受文件后，清除现有的所有数据，然后加载RDB文件 如果在制作数据快照RDB文件的过程当中，主节点接收到了新的写操作，主节点会将其记录在repl buffer 里面。然后将repl buffer当中的写操作发给从节点，让其数据保持一致。 【增量复制细节】\n如果主从节点意外断开连接，为了保持数据的一致性，必须重新同步数据。如果使用全量复制来保持一致性的话，开销太大，所以采用增量复制。\n增量复制的具体流程如下：\n连接恢复后，从节点会发送psync {runid} {offset}， 其中主节点ID runid 和 复制进度offset用于标识是哪一个服务器主机和复制进度。 主节点收到psync 命令之后，会用conitnue响应告知从节点，采用增量复制同步数据 最后，主节点根据offset查找对应的进度，将短线期间未同步的写命令，发送给从节点。同时，主节点将所有的写命令写入repl_backlog_buffer， 用于后续判断是采用增量复制还是全量复制。 【注意】从节点 psync 携带的 offset 为 slave_repl_offset。如果 repl_backlog_buffer包含slave_repl_offset 对应的部分，则采用增量复制，否则采用全量复制。repl_backlog_buffer的默认缓冲区大小为1M\n【为什么要主从复制】\n备份数据：主从复制实现了数据的热备份，是持久化之外的数据冗余方式 故障恢复：当主节点宕机之后，可以采用从节点提供服务。 负载均衡: 主从复制实现了读写分离，只有主节点支持读写操作，从节点只有都操作。在读多写少的场景下，可以提高Redis服务器的并发量。 2. Redis集群的实现原理是什么? 【Redis集群基本知识】\n定义: Redis集群由多个实例组成，每个实例存储部分数据 (每个实例之间的数据不重复) 。 【注】集群和主从节点不是一个东西，集群的某一个实例当中可能包含一个主节点 + 多个从节点\n为什么用 问题 解决方案 容量不足 数据分片，将数据分散不存到不同的主节点 高并发写入 数据分片，将写入请求分摊到多个主节点 主机宕机问题 自动切换主从节点，避免影响服务， 不需要手动修改客户端配置 节点通信协议：Redis集群采用Gossip协议, 支持分布式信息传播、延迟低、效率高。采用去中心化思想，任意实例(主节点)都可以作为请求入口，节点间相互通信。 分片原理： 采用哈希槽(Hash Slot)机制来分配数据，整个空间可以划分为16384 (16 * 1024)个槽。 每个Redis负责一定范围的哈希槽,数据的key经过哈希函数计算之后对16384取余可定位到对应的节点。 【集群节点之间的交互协议】\n为什么用Gossip协议 分布式信息传播：每个节点定期向其他节点传播状态信息，确保所有节点对集群的状态有一致视图 (采用ping 发送 和 pong 接受，就像检查心跳一样 ) 低延迟、高效率：轻量级通信方式，传递信息很快 去中心化：没有中心节点，任意实例(主节点)都可以作为请求入口，节点间相互通信。 Gossip协议工作原理 状态报告和信息更新：特定时间间隔内，向随机的其他节点报告自身情况 （主从关系、槽位分布）。其他节点接收到之后，会相应的更新对应的节点状态信息 节点检测：通过周期性交换状态信息，可以检测到其他节点的存活状态。预定时间内未响应，则标记为故障节点。 容错处理：如果某个节点故障之后，集群中的其他节点可以重新分配槽位，保持系统的可用性 【哈希槽的相关机制】\n假定集群中有三个节点，Node1 (0 - 5460)、Node2(5461-10922)、Node3(10923-16383)\n集群使用哈希槽的流程如下：\n计算哈希槽 使用CRC16哈希算法计算user:0001的CRC16的值 将CRC16的值对16384进行取余 (哈希槽 = CRC16 % 16383) 假如CRC16为12345，哈希槽 = 12345 % 16383 = 12345 确定目标节点 ：查询到12345为Node3的存储的键，向该节点发送请求 当前非对应节点 ：假设当前连接的节点为Node1，Node1将返回MOVED错误到客户端，并让客户端根据MOVED携带的Node3的信息(ip和端口)重新进行连接，最后从新发送GET user:0001请求，获得结果。 3. Redis的哨兵机制（Sentinel）是什么？ 【哨兵作用】\n监控：哨兵不断监控主从节点的运行状态,定时发送ping进行检测 故障转移: 当主节点发生故障时, 哨兵会先踢出所有失效的节点, 然后选择一个有效的从节点作为新的主节点, 并通知客户端更新主节点的地址 通知: 哨兵可以发送服务各个节点的状态通知，方便观察Redis实例的状态变化。（比如主节点g了，已经更换为新的主节点） 【哨兵机制的主观下线和客观下线】\n主观下线：哨兵在监控的过程中，每隔1s会发送 ping 命令给所有的节点。如果哨兵超过down-after-milliseconds 所配置的时间，没有收到 pong 的响应，就会认为节点主观下线。\n客观下线：某个哨兵发现节点主线下线后，不能确认节点是否真的下线了（可能是网络不稳定），就询问其他的哨兵是否主观下线了。等待其他哨兵的确认，进行投票，如果超过半数+1 (总哨兵数/2 + 1)，就认定为客观下线。\n【注】客观下线只对主节点适用，因为从节点也没必要这样子判断，g了就g了呗。\n【哨兵leader如何选举】\n哨兵leader是采用分布式算法raft选出来的。具体流程如下：\n候选人：当哨兵判断为主观下线，则可以当选候选人 投票：每个哨兵都可以投票，但是只能投一票。候选者会优先投给自己。 选举：选取投票结果半数以上的候选人作为leader (哨兵一般设置为奇数，防止平票) 【主节点如何选举】\n哨兵判断主节点客观下线之后，会踢出所有下线的节点，然后从有效的从节点选新的主节点。选取依据如下：\n优先级：按照从节点的优先级 slave-priority，优先级的值越小越高。 主从复制offset值：如果优先级相同，则判断主从复制的offset值哪一个大，表明其同步的数据越多，优先级就越高。 从节点ID：如果上述条件均相同，则选取ID较小的从节点作为主节点。 4. Redis Cluster 集群模式与 Sentinel 哨兵模式的区别是什么？ Cluster集群模式：集群模式用于对数据进行分片，主要用于解决大数据、高吞吐量的场景。将数据自动分不到多个Redis实例上，支持自动故障转移（如果某个实例失效，集群会自动重写配置和平衡，不需要手动进行调整，因为内置了哨兵逻辑） Sentinel哨兵模式: 哨兵模式用于保证主从节点的高可用，读写分离场景。如果主节点宕机，哨兵会将从节点升为主节点。 5. Redis 在生成 RDB 文件时如何处理请求？ 首先，Redis生成RDB文件的操作是异步的，由fork子线程进行，主线程用于处理客户端的请求。下面具体说明生成RDB文件的流程\n【生成RDB文件原理】\n使用bgsave命令，开启fork子线程进行操作 fork子线程会复制主线程对应的页表（里面包含了需要操作数据的物理地址） 如果过程中，主线程接收到写命令，需要修改数据。主线程会将对应数据的所在页面复制一份，子线程仍然指向老的页面。（老的数据才叫数据快照） 【注意事项】\nRDB处理的时间比较长，过程中会发生大量的磁盘I/O和CPU负载。如果RDB生成的时间过长，并且Redis的写并发高，就可能出现系统抖动的现象，应该选取Redis使用频率较低的时间段生成RDB文件。\n6. Redis集群会出现脑裂问题吗？ 脑裂定义: 在网络分区的情况下，Redis同一个集群的实例当中出现多个主节点，导致数据不一致。\n脑裂发生的原因：比如当前集群实例是一主+两从的模式，当网络发送分区，分为A区和B区。主节点(原)被分到A区,其他节点和哨兵集群都在B区。哨兵机制无法检测到A区的原主节点, 只能重新选取新的主节点(新)。此时，集群当中就有两个主节点，A区的主节点(原)被写入的新数据不会同步到B区的节点上。会出现数据不一致的情况。\n如何避免脑裂：min-slaves-to-write 主节点写操作所要求有效从节点个数、min-slaves-max-lag 从节点的最大延迟。比如 min-slaves-to-write = 3 和min-slaves-max-lag = 10 表明需要至少3个延时低于10s的从节点才可以接受写操作。\n【注意】脑裂并不能够完全避免，比如说在选举主节点的过程中，主节点(原)突然恢复了，然后发现主节点和从节点的延迟都不超过10s，客户端正常在主节点(原)进行写操作。等选举完毕，选出新的主节点，让主节点(原) slaveof 为从节点。选举时间写入的数据会被覆盖，就出现了数据不一致的现象。\n7. Redis如何实现分布式锁？ 分布式锁原理：Redis分布式锁由set ex nx 和 lua 脚本组成，分别对应加锁和解锁操作\n为什么用 set ex nx：某个进程对指定key执行 set nx 之后， 返回值为1，其他进程想要对相同的key获取锁，会发现key已存在，返回值为0。这样就是实现了上锁的操作。但是，如果A进程上完锁突然挂了，其他进程就永远不可能拿到锁。所以，设置一个ex过期时间，让其不要一直占用着锁。\n【注意】set ex nx设置value的时候，必须采用唯一值，比如uuid。 不然可能出现如下情况:\nA进程正常申请锁，值设为1。 A进程上锁后, 执行过程时间比较长, 以至于锁已经过期了, A进程还没执行完. 此时，B进程申请锁，值也设为1. 同时，A进程执行完毕, 使用lua脚本把锁删除了 B进程此时还在执行程序，一脸懵逼。（不是，哥们儿，我锁呢？谁偷了我的锁！！！） 为什么用 lua 进行解锁：如上述注意事项所说的一样，A进程执行完毕之后, 会删除锁. 假如他们的值都采用了uuid保证了唯一性。可能会出现下面的情况\nA进程先判断key和其值是否为对应的uuid，然后再删除锁. A进程准备删除锁之前, 锁过期了. B进程同时获取了锁 A进程再删除了该锁 (B进程申请的锁)，发生了误删的现象 所以需要用lua脚本保证解锁的原子性，就可以避免上述问题\n8. Redis的Red Lock是什么？你了解吗? 1. **Red Lock定义**: 一种分布式锁的实现方案，主要用于解决分布式环境中使用Redis分布式锁的安全性问题 2. **为什么用Red Lock**: 假如我们采用一主+两从+哨兵方式部署Redis，如果有A进程在使用分布式锁的过程当中，主节点发送了主从更换，但是原主节点的锁信息不一定同步到新主节点上。所以当前新主节点可能没有锁信息，此时另外的B进程去获取锁，发现锁没被占，成功拿到锁并执行业务逻辑。此时两个竞争者（A和B进程）会同时操作临界资源，会出现数据不一致的情况。 3. **Red Lock实现原理** : 假如当前有五个实例，不需要部署从节点和哨兵，只需要主节点。注意当前的五个实例之间没有任何关系，不进行任何的信息交互 (不同于Redis Cluster集群模式)。对五个实例依次申请上锁，如果最终申请成功的数量超过半数(大于总数/2 + 1)，则表明红锁申请成功。按照下面的流程进行操作： 1. 客户端获取当前时间 `t1` 2. 客户端依次对五个实例进行`set ex nx` 操作，锁的过期时间为 `t_lock` (远小于锁的总过期事件)。如果当前节点请求超时，则立马请求下一个节点。 3. 当获取的锁超过半数，则获取当前的时间 `t2`。获取锁的过程总耗时`t = t2 - t1`。如果`t`小于锁的过期时间 `t_lock`，则可以判断为加锁成功，否则加锁失败。 4. 加锁成功，则执行业务逻辑。若加锁失败，则依次释放所有节点的锁。 Red Lock是否安全：先说结论，不一定安全\n当前有两个客户端(Client1 和 Client2)，首先Client1 正常获取锁，然后突然被GC执行垃圾回收机制了。在GC的过程当中，Client1 的锁超时释放了，Client2开始申请并获得锁。然后Client2 写入数据并释放锁。 后面Client1 在GC 结束之后又写入数据， 此时就出现了数据不一致的情况。\n9. 说说 Redisson 分布式锁的原理? 【Redisson分布式锁定义】\nRedisson分布式锁是一种基于Redis实现的分布式锁，利用Redis的原子性操作来确保多线程、多进程或多节点系统中，只有一个线程能够获得锁。避免并发操作导致的数据不一致问题。\n主要可以分为四个部分来讲：锁的获取、锁的续期、可重入锁、锁的释放\n【锁的获取】\n执行 exist ，判断锁是否存在 若存在 -\u003e 第 2 步 若不存在 ，说明当前锁别其他进程占用 -\u003e 使用pttl查询锁剩余的过期时间，后续可以再次获取， 执行hincrby，设置重入计数为1 （可重入锁才有这一步操作） 执行pexpire， 设置锁的过期时间 （为了防止任务还没执行完，锁就过期了。Redisson实现了用看门狗机制来为锁进行自动续期） 【可重入锁】\n一般是在线程已经获取锁的基础上，为了后续还能拿到锁。因为假如increment()和anotherMethod都需要用到Counter锁。当increment()拿到锁之后，又调用anotherMethod()又需要获取锁。如果不能二次获取锁，那就陷入死锁了。所以，Redisson才搞了可重入锁\npublic class Counter { private int count = 0; public synchronized void increment() { count++; anotherMethod(); } public synchronized void anotherMethod() { // 可以再次获取相同的锁 count++; } } 可重入锁是在获取锁的基础上，多了一层逻辑。具体实现如下：\n实现锁的获取的所有功能 执行hexist 判断是否锁已经存在，且唯一标识匹配(线程id相关)，所以不能直接用exist判断锁是否存在 如果自己的锁存在，用hincrby把重入次数加一 用pexpire，设置锁的过期时间 如果没有获取成功锁，就和上面一样，用pttl查询锁的过期剩余时间 【锁的释放】\n用hexist判断线程自己的锁是否存在，需要判断唯一标识 如果存在 -\u003e 第2步 如果不存在 -\u003e 直接返回，不需要做解锁操作，因为是别人的锁 用hincry减少一次锁的可重入次数 (增加-1 就是减少一次) 判断锁的可重入次数是否大于 0 如果大于 0， 说明还有函数在使用这个锁，则重新设置过期时间 如果等于 0 -\u003e 第4步 用 del 删除对应的key 用 publish 广播通知其他等待锁的进程，此时释放锁了 【Redisson锁的类型】\n公平锁：和可重入锁类似，确保多个线程按请求顺序获得锁 读写锁: 支持读写分离，多个线程同时获得读锁，而且锁是独占的 信号量与可数锁: 允许多个线程同时持有锁，适用于资源的限流和控制。 10. Redisson 看门狗（watch dog）机制了解吗？ 【为什么用看门狗机制】\n因为如果进程获取锁之后，用户的业务逻辑还没有执行完成，锁就过期了。此时，其他进程抢占临界资源，会导致数据不一致的问题。\n【看门口机制的执行流程】\n判断用户是否设置过期时间 (判断 leaseTime \u003e 0 ，默认 leaseTime 为 -1 ) 如果设置了过期时间，不启用看门狗机制，等到指定的过期时间，锁自动释放。 如果没有设置过期时间 -\u003e 第2步 Redssion会启动一个定时任务，用于自动续期锁的过期时间。 定时任务中，设置锁的超时时间默认为30s， 每间隔总时长的1/3，也就是10s。定时任务会自动锁进行续期，续期时间为30s 当客户端主动释放锁，那么Redisson就会取消看门狗机制。 【注意】 如果客户端主动释放锁之前，服务器突然宕机了，定时任务没法儿继续执行。等看门狗机制设置的过期时间到了，锁就自动释放了。所以，不会出现一直占用锁的情况。\n11. Redis 实现分布式锁时可能遇到的问题有哪些？ 前面锁提前过期, 后续锁被误释放：用户的业务逻辑还没执行完毕，锁提前过期了。被其他的进程获取了锁，同时抢占临界资源，可能出现数据不一致的情况。\n【解决方法】\n通常要保证用户的业务逻辑需要在锁过期之前执行完，因此需要把锁的过期时间稍微设大一些。也不能太大，这样其他程序就拿不到锁，就会降低系统的整体性能。或者使用Redisson分布式锁，会自动调用看门狗机制，定时续期锁，直到任务执行完毕，就不续期锁了。\n单点故障问题：如果只部署了一个Redis节点，当实例宕机或者不可用的时候。整个分布式锁服务将无法完成工作，阻塞业务的正常执行。\n【解决方法】\n可以利用Redis Cluster集群机制，部署多个Redis实例，采用一主+两从的哨兵机制。当某个实例宕机时, 哨兵会自动选举新的有效节点作为主节点。\n主从同步但锁未同步问题：主从复制的过程是异步实现的，如果Redis主节点获取到锁，但是还没同步到从节点。此时，主节点突然宕机，然后哨兵选择新的主节点。但是，由于主从同步没有完成，现在其他客户端可以正常获取锁。就会导致多个应用同时获取锁，会出现数据不一致的问题。\n网络分区问题：在网络不稳定的情况下，客户端和Redis可能会中断再重连。如果没有设置锁的过期时间，那么可能导致锁无法正常释放。如果有多个锁，可能还会引发死锁的现象。\n【多锁死锁现象】\n有两个资源A和B，分别由锁LockA和LockB保护。\n客户端1先获取LockA，然后尝试获取LockB。\n客户端2先获取LockB，然后尝试获取LockA\n如果客户端1拿到了LockA，客户端2拿到了LockB。突然网络不稳定，锁无法正常释放。然后客户端1等待LockB，客户端2等待LockA，就会形成死锁。\n时钟漂移问题：因为Redis分布式锁依赖锁的过期时间来判断是否过期，如果出现时钟漂移，很可能导致锁直接失效。\n【解决方法】\n让所有节点的系统时钟从NTP服务进行同步，减少时钟漂移的影响。\n可重入问题：某个进程可能有多次调用锁，如果锁不能重入的话。当进程获取到锁后，再次申请获取锁，获取不到就死锁了。\n12. Redis为什么这么快? 基于内存: Redis存储的所有数据都存在内存里面，内存的访问速度比硬盘快，提升了读写速度 单线程模型 + I/O多路复用： Redis采用单线程+I/O多路复用的方式，避免了线程上下文切换和竞争条件，提高了并发处理效率 高效数据结构：提供String、List、Hash、Set、Sorted Set 五种数据结构，他们的操作复杂度大部分为O(1) 异步持久化: 持久化操作由子线程异步完成，减少了持久化对主线程的影响，提升了整体性能。 【注意】Redis从6.0开始对网络处理引入了多线程机制，提高I/O性能。网络请求可以并发处理，减少网络I/O等待的影响。但是，Redis 仍然保持了核心命令处理逻辑的单线程特性。\n【I/O多路复用技术】\nLinux多路复用技术允许多个进程的I/O注册到同一管道和内核交互，准备好数据之后再copy到用户空间，实现一个线程处理多个I/O流。 Linux下I/O多路复用有select、poll、epoll 三种，功能类似，细节不同 13. 如何使用Redis快速实现布隆过滤器? Redis可以使用位图Bitmap或者用Redis模块RedisBloom来实现布隆过滤器\n位图 bitmap 实现 bitmap 本质是一个位数组，提供了setbit和getbit来设置和获取某个值，可以用来标识某个元素是否存在 对应给定的key，可以用哈希函数来计算位置索引。如果位图中的值为1， 表示该元素可能存在 RedisBloom 模块实现：封装了哈希函数和位图大小，可以直接用于创建和管理布隆过滤器 【布隆过滤器原理】\n布隆过滤器是由一个位数组+k个独立的哈希函数组成。每次验证某个key对应的数据是否存在的时候，需要k个哈希函数都对其进行运算，如果位数组中的值都为1，说明该key对应的数据可能存在。只要有一个位置不为1， 就说明key对应的数据一定不存在。\n为什么k个函数查到的值都为1， 也不能说明key对应的数据一定存在呢？\n因为可能存在哈希冲突，比如key 和 key1 的k个hash函数的值都为1。但是key对应的数据在数据库里面，但是key1的数据不在数据库里面。\n",
  "wordCount" : "476",
  "inLanguage": "en",
  "image": "https://swimmingliu.cn/papermod-cover.png","datePublished": "2025-02-20T21:21:45+08:00",
  "dateModified": "2025-02-20T21:21:45+08:00",
  "author":[{
    "@type": "Person",
    "name": "SwimmingLiu"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://swimmingliu.cn/posts/job/redis-interview-questions/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "SwimmingLiu's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://swimmingliu.cn/images/swimmingliu_icon.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://swimmingliu.cn/" accesskey="h" title="𝓢𝔀𝓲𝓶𝓶𝓲𝓷𝓰𝓛𝓲𝓾&#39;𝓼 𝓑𝓵𝓸𝓰 (Alt + H)">
                <img src="https://swimmingliu.cn/images/swimmingliu_icon.png" alt="" aria-label="logo"
                    height="30">𝓢𝔀𝓲𝓶𝓶𝓲𝓷𝓰𝓛𝓲𝓾&#39;𝓼 𝓑𝓵𝓸𝓰</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://swimmingliu.cn/index.html" title="🏡 Home">
                    <span>🏡 Home</span>
                </a>
            </li>
            <li>
                <a href="https://swimmingliu.cn/search/" title="🔍 Search">
                    <span>🔍 Search</span>
                </a>
            </li>
            <li>
                <a href="https://swimmingliu.cn/posts/" title="🗒️ Posts">
                    <span>🗒️ Posts</span>
                </a>
            </li>
            <li>
                <a href="https://swimmingliu.cn/archives/" title="📃 Archive">
                    <span>📃 Archive</span>
                </a>
            </li>
            <li>
                <a href="https://swimmingliu.cn/tags/" title="📑 Tags">
                    <span>📑 Tags</span>
                </a>
            </li>
            <li>
                <a href="https://bento.me/swimmingliu" title="👨🏻‍🎓 About Me">
                    <span>👨🏻‍🎓 About Me</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
            <li>
                <a href="https://www.emojisearch.app/" title="Emoji">
                    <span>Emoji</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://swimmingliu.cn/">Home</a>&nbsp;»&nbsp;<a href="https://swimmingliu.cn/posts/">📚 Posts</a>&nbsp;»&nbsp;<a href="https://swimmingliu.cn/posts/job/">💻 Job</a></div>
    <h1 class="post-title entry-hint-parent">
      Redis面试题笔记
    </h1>
    <div class="post-meta"><span title='2025-02-20 21:21:45 +0800 CST'>February 20, 2025</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;SwimmingLiu

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#1-redis%e4%b8%bb%e4%bb%8e%e5%a4%8d%e5%88%b6%e7%9a%84%e5%8e%9f%e7%90%86" aria-label="1. Redis主从复制的原理">1. Redis主从复制的原理</a></li>
                <li>
                    <a href="#2-redis%e9%9b%86%e7%be%a4%e7%9a%84%e5%ae%9e%e7%8e%b0%e5%8e%9f%e7%90%86%e6%98%af%e4%bb%80%e4%b9%88" aria-label="2. Redis集群的实现原理是什么?">2. Redis集群的实现原理是什么?</a></li>
                <li>
                    <a href="#3-redis%e7%9a%84%e5%93%a8%e5%85%b5%e6%9c%ba%e5%88%b6sentinel%e6%98%af%e4%bb%80%e4%b9%88" aria-label="3. Redis的哨兵机制（Sentinel）是什么？">3. Redis的哨兵机制（Sentinel）是什么？</a></li>
                <li>
                    <a href="#4--redis-cluster-%e9%9b%86%e7%be%a4%e6%a8%a1%e5%bc%8f%e4%b8%8e-sentinel-%e5%93%a8%e5%85%b5%e6%a8%a1%e5%bc%8f%e7%9a%84%e5%8c%ba%e5%88%ab%e6%98%af%e4%bb%80%e4%b9%88" aria-label="4.  Redis Cluster 集群模式与 Sentinel 哨兵模式的区别是什么？">4.  Redis Cluster 集群模式与 Sentinel 哨兵模式的区别是什么？</a></li>
                <li>
                    <a href="#5-redis-%e5%9c%a8%e7%94%9f%e6%88%90-rdb-%e6%96%87%e4%bb%b6%e6%97%b6%e5%a6%82%e4%bd%95%e5%a4%84%e7%90%86%e8%af%b7%e6%b1%82" aria-label="5. Redis 在生成 RDB 文件时如何处理请求？">5. Redis 在生成 RDB 文件时如何处理请求？</a></li>
                <li>
                    <a href="#6-redis%e9%9b%86%e7%be%a4%e4%bc%9a%e5%87%ba%e7%8e%b0%e8%84%91%e8%a3%82%e9%97%ae%e9%a2%98%e5%90%97" aria-label="6. Redis集群会出现脑裂问题吗？">6. Redis集群会出现脑裂问题吗？</a></li>
                <li>
                    <a href="#7-redis%e5%a6%82%e4%bd%95%e5%ae%9e%e7%8e%b0%e5%88%86%e5%b8%83%e5%bc%8f%e9%94%81" aria-label="7. Redis如何实现分布式锁？">7. Redis如何实现分布式锁？</a></li>
                <li>
                    <a href="#8-redis%e7%9a%84red-lock%e6%98%af%e4%bb%80%e4%b9%88%e4%bd%a0%e4%ba%86%e8%a7%a3%e5%90%97" aria-label="8. Redis的Red Lock是什么？你了解吗?">8. Redis的Red Lock是什么？你了解吗?</a></li>
                <li>
                    <a href="#9-%e8%af%b4%e8%af%b4-redisson-%e5%88%86%e5%b8%83%e5%bc%8f%e9%94%81%e7%9a%84%e5%8e%9f%e7%90%86" aria-label="9. 说说 Redisson 分布式锁的原理?">9. 说说 Redisson 分布式锁的原理?</a></li>
                <li>
                    <a href="#10-redisson-%e7%9c%8b%e9%97%a8%e7%8b%97watch-dog%e6%9c%ba%e5%88%b6%e4%ba%86%e8%a7%a3%e5%90%97" aria-label="10. Redisson 看门狗（watch dog）机制了解吗？">10. Redisson 看门狗（watch dog）机制了解吗？</a></li>
                <li>
                    <a href="#11-redis-%e5%ae%9e%e7%8e%b0%e5%88%86%e5%b8%83%e5%bc%8f%e9%94%81%e6%97%b6%e5%8f%af%e8%83%bd%e9%81%87%e5%88%b0%e7%9a%84%e9%97%ae%e9%a2%98%e6%9c%89%e5%93%aa%e4%ba%9b" aria-label="11. Redis 实现分布式锁时可能遇到的问题有哪些？">11. Redis 实现分布式锁时可能遇到的问题有哪些？</a></li>
                <li>
                    <a href="#12-redis%e4%b8%ba%e4%bb%80%e4%b9%88%e8%bf%99%e4%b9%88%e5%bf%ab" aria-label="12. Redis为什么这么快?">12. Redis为什么这么快?</a></li>
                <li>
                    <a href="#13-%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8redis%e5%bf%ab%e9%80%9f%e5%ae%9e%e7%8e%b0%e5%b8%83%e9%9a%86%e8%bf%87%e6%bb%a4%e5%99%a8" aria-label="13. 如何使用Redis快速实现布隆过滤器?">13. 如何使用Redis快速实现布隆过滤器?</a>
                </li>
            </ul>
        </div>
    </details>
</div>
  <div class="post-content"><h2 id="1-redis主从复制的原理">1. Redis主从复制的原理<a hidden class="anchor" aria-hidden="true" href="#1-redis主从复制的原理">#</a></h2>
<p>【<strong>主从复制的原理</strong>】</p>
<ol>
<li>同步：从节点向主节点发送<code>psync</code>命令进行同步，从节点保存主节点返回的 <code>runid</code> 和 <code> offset</code></li>
<li>全量复制：如果是第一次连接或者连接失败且<code>repl_backlog_buffer</code> 缓存区不包含<code>slave_repl_offset</code>， 则生成主节点的数据快照(RDB文件)发给从节点</li>
<li>增量复制：全量复制完毕后，主从节点之间会保持长连接。如果连接没有断开或者<code>slave_repl_offset</code>仍然在<code>repl_backlog_buffer</code>中，则将后续的写操作传递给从节点，让数据保持一致。</li>
</ol>
<p><strong>【全量复制细节】</strong></p>
<p>全量复制的过程是基于TCP长连接的，主要流程如下</p>
<ol>
<li>从节点发送<code>psync ? -1</code>表示需要建立连接进行同步，主节点返回主节点ID <code>runid</code> 和 复制进度<code>offset</code> (第一次同步用 -1 表示)。从节点接受之后，保存主节点的信息。</li>
<li>主节点执行<code>bgsave</code>命令生成数据快照RDB文件，然后将RDB文件发送给从节点。从节点接受文件后，清除现有的所有数据，然后加载RDB文件</li>
<li>如果在制作数据快照RDB文件的过程当中，主节点接收到了新的写操作，主节点会将其记录在<code>repl buffer</code> 里面。然后将<code>repl buffer</code>当中的写操作发给从节点，让其数据保持一致。</li>
</ol>
<p><img alt="Redis主从全量复制" loading="lazy" src="https://oss.swimmingliu.cn/ac630d4c-ef8d-11ef-a882-c858c0c1deba"></p>
<p><strong>【增量复制细节】</strong></p>
<p>如果主从节点意外断开连接，为了保持数据的一致性，必须重新同步数据。如果使用全量复制来保持一致性的话，开销太大，所以采用增量复制。</p>
<p>增量复制的具体流程如下：</p>
<ol>
<li>连接恢复后，从节点会发送<code>psync {runid} {offset}</code>， 其中主节点ID <code>runid</code> 和 复制进度<code>offset</code>用于标识是哪一个服务器主机和复制进度。</li>
<li>主节点收到<code>psync</code> 命令之后，会用<code>conitnue</code>响应告知从节点，采用增量复制同步数据</li>
<li>最后，主节点根据<code>offset</code>查找对应的进度，将短线期间未同步的写命令，发送给从节点。同时，主节点将所有的写命令写入<code>repl_backlog_buffer</code>， 用于后续判断是采用增量复制还是全量复制。</li>
</ol>
<p>【注意】从节点 <code>psync</code> 携带的 <code>offset</code> 为 <code>slave_repl_offset</code>。如果 <code>repl_backlog_buffer</code>包含<code>slave_repl_offset</code> 对应的部分，则采用增量复制，否则采用全量复制。<code>repl_backlog_buffer</code>的默认缓冲区大小为<code>1M</code></p>
<p><img alt="Redis主从增量复制" loading="lazy" src="https://oss.swimmingliu.cn/ac9f21a3-ef8d-11ef-9016-c858c0c1deba"></p>
<p>【<strong>为什么要主从复制</strong>】</p>
<ul>
<li><strong>备份数据</strong>：主从复制实现了数据的热备份，是持久化之外的数据冗余方式</li>
<li><strong>故障恢复</strong>：当主节点宕机之后，可以采用从节点提供服务。</li>
<li><strong>负载均衡</strong>:  主从复制实现了读写分离，只有主节点支持读写操作，从节点只有都操作。在读多写少的场景下，可以提高Redis服务器的并发量。</li>
</ul>
<p><img alt="Redis主从读写分离" loading="lazy" src="https://oss.swimmingliu.cn/acad0d12-ef8d-11ef-b17f-c858c0c1deba"></p>
<h2 id="2-redis集群的实现原理是什么">2. Redis集群的实现原理是什么?<a hidden class="anchor" aria-hidden="true" href="#2-redis集群的实现原理是什么">#</a></h2>
<p>【<strong>Redis集群基本知识</strong>】</p>
<ul>
<li><strong>定义</strong>: Redis集群由多个实例组成，每个实例存储部分数据 (每个实例之间的数据不重复) 。</li>
</ul>
<p>【注】集群和主从节点不是一个东西，集群的某一个实例当中可能包含一个主节点 + 多个从节点</p>
<ul>
<li><strong>为什么用</strong></li>
</ul>
<table>
  <thead>
      <tr>
          <th>问题</th>
          <th>解决方案</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>容量不足</strong></td>
          <td>数据分片，将数据分散不存到不同的主节点</td>
      </tr>
      <tr>
          <td><strong>高并发写入</strong></td>
          <td>数据分片，将写入请求分摊到多个主节点</td>
      </tr>
      <tr>
          <td><strong>主机宕机问题</strong></td>
          <td>自动切换主从节点，避免影响服务， 不需要手动修改客户端配置</td>
      </tr>
  </tbody>
</table>
<ul>
<li><strong>节点通信协议</strong>：Redis集群采用Gossip协议, 支持分布式信息传播、延迟低、效率高。采用去中心化思想，任意实例(主节点)都可以作为请求入口，节点间相互通信。</li>
<li><strong>分片原理</strong>： 采用哈希槽(Hash Slot)机制来分配数据，整个空间可以划分为<strong>16384</strong> (16 * 1024)个槽。 每个Redis负责一定范围的哈希槽,数据的key经过哈希函数计算之后对<strong>16384</strong>取余可定位到对应的节点。</li>
</ul>
<p><img alt="Redis集群架构图" loading="lazy" src="https://oss.swimmingliu.cn/acc54635-ef8d-11ef-971e-c858c0c1deba"></p>
<p>【<strong>集群节点之间的交互协议</strong>】</p>
<ul>
<li><strong>为什么用Gossip协议</strong></li>
</ul>
<ol>
<li>分布式信息传播：每个节点定期向其他节点传播状态信息，确保所有节点对集群的状态有一致视图 (采用<code>ping</code> 发送 和 <code>pong</code> 接受，就像检查心跳一样 )</li>
<li>低延迟、高效率：轻量级通信方式，传递信息很快</li>
<li>去中心化：没有中心节点，任意实例(主节点)都可以作为请求入口，节点间相互通信。</li>
</ol>
<ul>
<li><strong>Gossip协议工作原理</strong></li>
</ul>
<ol>
<li>状态报告和信息更新：特定时间间隔内，向随机的其他节点报告自身情况 （主从关系、槽位分布）。其他节点接收到之后，会相应的更新对应的节点状态信息</li>
<li>节点检测：通过周期性交换状态信息，可以检测到其他节点的存活状态。预定时间内未响应，则标记为故障节点。</li>
<li>容错处理：如果某个节点故障之后，集群中的其他节点可以重新分配槽位，保持系统的可用性</li>
</ol>
<p>【<strong>哈希槽的相关机制</strong>】</p>
<p>假定集群中有三个节点，Node1 (0 - 5460)、Node2(5461-10922)、Node3(10923-16383)</p>
<p>集群使用哈希槽的流程如下：</p>
<ul>
<li><strong>计算哈希槽</strong></li>
</ul>
<ol>
<li>使用CRC16哈希算法计算<code>user:0001</code>的CRC16的值</li>
<li>将CRC16的值对16384进行取余 (哈希槽 = CRC16 % 16383)</li>
<li>假如CRC16为12345，哈希槽 = 12345 % 16383 = 12345</li>
</ol>
<ul>
<li><strong>确定目标节点</strong> ：查询到12345为Node3的存储的键，向该节点发送请求</li>
<li><strong>当前非对应节点</strong> ：假设当前连接的节点为Node1，Node1将返回<code>MOVED</code>错误到客户端，并让客户端根据<code>MOVED</code>携带的Node3的信息(<code>ip</code>和端口)重新进行连接，最后从新发送<code>GET user:0001</code>请求，获得结果。</li>
</ul>
<h2 id="3-redis的哨兵机制sentinel是什么">3. Redis的哨兵机制（Sentinel）是什么？<a hidden class="anchor" aria-hidden="true" href="#3-redis的哨兵机制sentinel是什么">#</a></h2>
<p><strong>【哨兵作用】</strong></p>
<ul>
<li>监控：哨兵不断监控主从节点的运行状态,定时发送ping进行检测</li>
<li>故障转移: 当主节点发生故障时, 哨兵会先踢出所有失效的节点, 然后选择一个有效的从节点作为新的主节点, 并通知客户端更新主节点的地址</li>
<li>通知: 哨兵可以发送服务各个节点的状态通知，方便观察Redis实例的状态变化。（比如主节点g了，已经更换为新的主节点）</li>
</ul>
<p><strong>【哨兵机制的主观下线和客观下线】</strong></p>
<ul>
<li>
<p><strong>主观下线</strong>：哨兵在监控的过程中，每隔1s会发送 <code>ping</code> 命令给所有的节点。如果哨兵超过<code>down-after-milliseconds</code> 所配置的时间，没有收到 <code>pong</code> 的响应，就会认为节点主观下线。</p>
</li>
<li>
<p><strong>客观下线</strong>：某个哨兵发现节点主线下线后，不能确认节点是否真的下线了（可能是网络不稳定），就询问其他的哨兵是否主观下线了。等待其他哨兵的确认，进行投票，如果超过半数+1 (总哨兵数/2 + 1)，就认定为客观下线。</p>
</li>
</ul>
<p>【注】客观下线只对主节点适用，因为从节点也没必要这样子判断，g了就g了呗。</p>
<p><strong>【哨兵leader如何选举】</strong></p>
<p>哨兵leader是采用分布式算法raft选出来的。具体流程如下：</p>
<ol>
<li>候选人：当哨兵判断为主观下线，则可以当选候选人</li>
<li>投票：每个哨兵都可以投票，但是只能投一票。候选者会优先投给自己。</li>
<li>选举：选取投票结果半数以上的候选人作为leader (哨兵一般设置为奇数，防止平票)</li>
</ol>
<p><strong>【主节点如何选举】</strong></p>
<p>哨兵判断主节点客观下线之后，会踢出所有下线的节点，然后从有效的从节点选新的主节点。选取依据如下：</p>
<ol>
<li>优先级：按照从节点的优先级 <code>slave-priority</code>，优先级的值越小越高。</li>
<li>主从复制offset值：如果优先级相同，则判断主从复制的offset值哪一个大，表明其同步的数据越多，优先级就越高。</li>
<li>从节点ID：如果上述条件均相同，则选取ID较小的从节点作为主节点。</li>
</ol>
<h2 id="4--redis-cluster-集群模式与-sentinel-哨兵模式的区别是什么">4.  Redis Cluster 集群模式与 Sentinel 哨兵模式的区别是什么？<a hidden class="anchor" aria-hidden="true" href="#4--redis-cluster-集群模式与-sentinel-哨兵模式的区别是什么">#</a></h2>
<ol>
<li><strong>Cluster集群模式</strong>：集群模式用于对数据进行分片，主要用于解决大数据、高吞吐量的场景。将数据自动分不到多个Redis实例上，支持自动故障转移（如果某个实例失效，集群会自动重写配置和平衡，不需要手动进行调整，因为内置了<strong>哨兵逻辑</strong>）</li>
<li><strong>Sentinel哨兵模式</strong>: 哨兵模式用于保证主从节点的高可用，读写分离场景。如果主节点宕机，哨兵会将从节点升为主节点。</li>
</ol>
<h2 id="5-redis-在生成-rdb-文件时如何处理请求">5. Redis 在生成 RDB 文件时如何处理请求？<a hidden class="anchor" aria-hidden="true" href="#5-redis-在生成-rdb-文件时如何处理请求">#</a></h2>
<p>首先，Redis生成RDB文件的操作是异步的，由<code>fork</code>子线程进行，主线程用于处理客户端的请求。下面具体说明生成RDB文件的流程</p>
<p><strong>【生成RDB文件原理】</strong></p>
<ol>
<li>使用<code>bgsave</code>命令，开启<code>fork</code>子线程进行操作</li>
<li><code>fork</code>子线程会复制主线程对应的页表（里面包含了需要操作数据的物理地址）</li>
<li>如果过程中，主线程接收到写命令，需要修改数据。主线程会将对应数据的所在页面复制一份，子线程仍然指向老的页面。（老的数据才叫数据快照）</li>
</ol>
<p><strong>【注意事项】</strong></p>
<p>RDB处理的时间比较长，过程中会发生大量的磁盘I/O和CPU负载。如果RDB生成的时间过长，并且Redis的写并发高，就可能出现系统抖动的现象，应该选取Redis使用频率较低的时间段生成RDB文件。</p>
<h2 id="6-redis集群会出现脑裂问题吗">6. Redis集群会出现脑裂问题吗？<a hidden class="anchor" aria-hidden="true" href="#6-redis集群会出现脑裂问题吗">#</a></h2>
<ol>
<li>
<p><strong>脑裂定义</strong>: 在网络分区的情况下，Redis同一个集群的实例当中出现多个主节点，导致数据不一致。</p>
</li>
<li>
<p><strong>脑裂发生的原因</strong>：比如当前集群实例是一主+两从的模式，当网络发送分区，分为A区和B区。主节点(原)被分到A区,其他节点和哨兵集群都在B区。哨兵机制无法检测到A区的原主节点, 只能重新选取新的主节点(新)。此时，集群当中就有两个主节点，A区的主节点(原)被写入的新数据不会同步到B区的节点上。会出现数据不一致的情况。</p>
</li>
<li>
<p><strong>如何避免脑裂</strong>：<code>min-slaves-to-write</code> 主节点写操作所要求有效从节点个数、<code>min-slaves-max-lag</code> 从节点的最大延迟。比如 <code>min-slaves-to-write = 3</code> 和<code>min-slaves-max-lag = 10</code>  表明需要至少3个延时低于10s的从节点才可以接受写操作。</p>
<p>【注意】脑裂并不能够完全避免，比如说在选举主节点的过程中，主节点(原)突然恢复了，然后发现主节点和从节点的延迟都不超过10s，客户端正常在主节点(原)进行写操作。等选举完毕，选出新的主节点，让主节点(原) slaveof 为从节点。选举时间写入的数据会被覆盖，就出现了数据不一致的现象。</p>
</li>
</ol>
<h2 id="7-redis如何实现分布式锁">7. Redis如何实现分布式锁？<a hidden class="anchor" aria-hidden="true" href="#7-redis如何实现分布式锁">#</a></h2>
<ol>
<li>
<p><strong>分布式锁原理</strong>：Redis分布式锁由<code>set ex nx</code> 和 <code>lua</code> 脚本组成，分别对应加锁和解锁操作</p>
</li>
<li>
<p><strong>为什么用 <code>set ex nx</code></strong>：某个进程对指定key执行 <code>set nx</code> 之后， 返回值为1，其他进程想要对相同的key获取锁，会发现key已存在，返回值为0。这样就是实现了上锁的操作。但是，如果A进程上完锁突然挂了，其他进程就永远不可能拿到锁。所以，设置一个<code>ex</code>过期时间，让其不要一直占用着锁。</p>
<p>【注意】<code>set ex nx</code>设置value的时候，必须采用唯一值，比如<code>uuid</code>。 不然可能出现如下情况:</p>
<ol>
<li>A进程正常申请锁，值设为1。</li>
<li>A进程上锁后, 执行过程时间比较长, 以至于锁已经过期了, A进程还没执行完.</li>
<li>此时，B进程申请锁，值也设为1. 同时，A进程执行完毕, 使用<code>lua</code>脚本把锁删除了</li>
<li>B进程此时还在执行程序，一脸懵逼。（不是，哥们儿，我锁呢？谁偷了我的锁！！！）</li>
</ol>
</li>
<li>
<p><strong>为什么用 <code>lua</code> 进行解锁</strong>：如上述注意事项所说的一样，A进程执行完毕之后, 会删除锁. 假如他们的值都采用了<code>uuid</code>保证了唯一性。可能会出现下面的情况</p>
<ul>
<li>A进程先判断key和其值是否为对应的<code>uuid</code>，然后再删除锁.</li>
<li>A进程准备删除锁之前, 锁过期了. B进程同时获取了锁</li>
<li>A进程再删除了该锁 (B进程申请的锁)，发生了误删的现象</li>
</ul>
<p>所以需要用<code>lua</code>脚本保证解锁的原子性，就可以避免上述问题</p>
</li>
</ol>
<h2 id="8-redis的red-lock是什么你了解吗">8. Redis的Red Lock是什么？你了解吗?<a hidden class="anchor" aria-hidden="true" href="#8-redis的red-lock是什么你了解吗">#</a></h2>
<pre><code>  1. **Red Lock定义**: 一种分布式锁的实现方案，主要用于解决分布式环境中使用Redis分布式锁的安全性问题
  2. **为什么用Red Lock**: 假如我们采用一主+两从+哨兵方式部署Redis，如果有A进程在使用分布式锁的过程当中，主节点发送了主从更换，但是原主节点的锁信息不一定同步到新主节点上。所以当前新主节点可能没有锁信息，此时另外的B进程去获取锁，发现锁没被占，成功拿到锁并执行业务逻辑。此时两个竞争者（A和B进程）会同时操作临界资源，会出现数据不一致的情况。
  3. **Red Lock实现原理** : 假如当前有五个实例，不需要部署从节点和哨兵，只需要主节点。注意当前的五个实例之间没有任何关系，不进行任何的信息交互 (不同于Redis Cluster集群模式)。对五个实例依次申请上锁，如果最终申请成功的数量超过半数(大于总数/2 + 1)，则表明红锁申请成功。按照下面的流程进行操作：
     1. 客户端获取当前时间 `t1`
     2. 客户端依次对五个实例进行`set ex nx` 操作，锁的过期时间为 `t_lock` (远小于锁的总过期事件)。如果当前节点请求超时，则立马请求下一个节点。
     3. 当获取的锁超过半数，则获取当前的时间 `t2`。获取锁的过程总耗时`t = t2 - t1`。如果`t`小于锁的过期时间 `t_lock`，则可以判断为加锁成功，否则加锁失败。
     4. 加锁成功，则执行业务逻辑。若加锁失败，则依次释放所有节点的锁。
</code></pre>
<p><img alt="Redis的RedLock结构图" loading="lazy" src="https://oss.swimmingliu.cn/2bdcd99d-f187-11ef-b6b9-c858c0c1deba"></p>
<ol start="4">
<li>
<p><strong>Red Lock是否安全</strong>：先说结论，不一定安全</p>
<p>当前有两个客户端(<code>Client1</code> 和 <code>Client2</code>)，首先<code>Client1</code> 正常获取锁，然后突然被<code>GC</code>执行垃圾回收机制了。在<code>GC</code>的过程当中，<code>Client1</code> 的锁超时释放了，<code>Client2</code>开始申请并获得锁。然后<code>Client2</code> 写入数据并释放锁。 后面<code>Client1</code> 在<code>GC</code> 结束之后又写入数据， 此时就出现了数据不一致的情况。</p>
</li>
</ol>
<p><img alt="Redis的RedLock安全问题" loading="lazy" src="https://oss.swimmingliu.cn/2c131f31-f187-11ef-8c21-c858c0c1deba"></p>
<h2 id="9-说说-redisson-分布式锁的原理">9. 说说 Redisson 分布式锁的原理?<a hidden class="anchor" aria-hidden="true" href="#9-说说-redisson-分布式锁的原理">#</a></h2>
<p><strong>【Redisson分布式锁定义】</strong></p>
<p>Redisson分布式锁是一种基于Redis实现的分布式锁，利用Redis的原子性操作来确保多线程、多进程或多节点系统中，只有一个线程能够获得锁。避免并发操作导致的数据不一致问题。</p>
<p>主要可以分为四个部分来讲：<strong>锁的获取</strong>、<strong>锁的续期</strong>、<strong>可重入锁</strong>、<strong>锁的释放</strong></p>
<p><strong>【锁的获取】</strong></p>
<ol>
<li>执行 <code>exist</code> ，判断锁是否存在
<ul>
<li>若存在 -&gt; 第 2 步</li>
<li>若不存在 ，说明当前锁别其他进程占用 -&gt;  使用<code>pttl</code>查询锁剩余的过期时间，后续可以再次获取，</li>
</ul>
</li>
<li>执行<code>hincrby</code>，设置重入计数为<code>1</code> （可重入锁才有这一步操作）</li>
<li>执行<code>pexpire</code>， 设置锁的过期时间 （为了防止任务还没执行完，锁就过期了。Redisson实现了用看门狗机制来为锁进行自动续期）</li>
</ol>
<p><strong>【可重入锁】</strong></p>
<p>一般是在线程已经获取锁的基础上，为了后续还能拿到锁。因为假如<code>increment()</code>和<code>anotherMethod</code>都需要用到<code>Counter</code>锁。当<code>increment()</code>拿到锁之后，又调用<code>anotherMethod()</code>又需要获取锁。如果不能二次获取锁，那就陷入死锁了。所以，Redisson才搞了可重入锁</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-java" data-lang="java"><span class="line"><span class="cl"><span class="kd">public</span><span class="w"> </span><span class="kd">class</span> <span class="nc">Counter</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">private</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">count</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">0</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">public</span><span class="w"> </span><span class="kd">synchronized</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">increment</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">count</span><span class="o">++</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">anotherMethod</span><span class="p">();</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">public</span><span class="w"> </span><span class="kd">synchronized</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">anotherMethod</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c1">// 可以再次获取相同的锁</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">count</span><span class="o">++</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></div><p>可重入锁是在获取锁的基础上，多了一层逻辑。具体实现如下：</p>
<ol>
<li>实现锁的获取的所有功能</li>
<li>执行<code>hexist</code> 判断是否锁已经存在，且唯一标识匹配(线程id相关)，所以不能直接用<code>exist</code>判断锁是否存在</li>
<li>如果自己的锁存在，用<code>hincrby</code>把重入次数加一</li>
<li>用<code>pexpire</code>，设置锁的过期时间</li>
<li>如果没有获取成功锁，就和上面一样，用<code>pttl</code>查询锁的过期剩余时间</li>
</ol>
<p><strong>【锁的释放】</strong></p>
<ol>
<li>用<code>hexist</code>判断线程自己的锁是否存在，需要判断唯一标识
<ul>
<li>如果存在 -&gt; 第2步</li>
<li>如果不存在 -&gt; 直接返回，不需要做解锁操作，因为是别人的锁</li>
</ul>
</li>
<li>用<code>hincry</code>减少一次锁的可重入次数 (增加<code>-1</code> 就是减少一次)</li>
<li>判断锁的可重入次数是否大于 <code>0</code>
<ul>
<li>如果大于 <code>0</code>， 说明还有函数在使用这个锁，则重新设置过期时间</li>
<li>如果等于 <code>0</code> -&gt; 第4步</li>
</ul>
</li>
<li>用 <code>del</code> 删除对应的key</li>
<li>用 <code>publish</code> 广播通知其他等待锁的进程，此时释放锁了</li>
</ol>
<p><img alt="Redisson分布式锁" loading="lazy" src="https://oss.swimmingliu.cn/843994be-f4b5-11ef-9fba-c858c0c1deba"></p>
<p><strong>【Redisson锁的类型】</strong></p>
<ul>
<li><strong>公平锁</strong>：和可重入锁类似，确保多个线程按请求顺序获得锁</li>
<li><strong>读写锁</strong>: 支持读写分离，多个线程同时获得读锁，而且锁是独占的</li>
<li><strong>信号量与可数锁</strong>: 允许多个线程同时持有锁，适用于资源的限流和控制。</li>
</ul>
<h2 id="10-redisson-看门狗watch-dog机制了解吗">10. Redisson 看门狗（watch dog）机制了解吗？<a hidden class="anchor" aria-hidden="true" href="#10-redisson-看门狗watch-dog机制了解吗">#</a></h2>
<p><strong>【为什么用看门狗机制】</strong></p>
<p>因为如果进程获取锁之后，用户的业务逻辑还没有执行完成，锁就过期了。此时，其他进程抢占临界资源，会导致数据不一致的问题。</p>
<p><strong>【看门口机制的执行流程】</strong></p>
<ol>
<li>判断用户是否设置过期时间 (判断 <code>leaseTime &gt; 0</code> ，默认 <code>leaseTime</code> 为 <code>-1</code> )
<ul>
<li>如果设置了过期时间，不启用看门狗机制，等到指定的过期时间，锁自动释放。</li>
<li>如果没有设置过期时间 -&gt; 第2步</li>
</ul>
</li>
<li>Redssion会启动一个定时任务，用于自动续期锁的过期时间。</li>
<li>定时任务中，设置锁的超时时间默认为<code>30s</code>， 每间隔总时长的<code>1/3</code>，也就是<code>10s</code>。定时任务会自动锁进行续期，续期时间为<code>30s</code></li>
<li>当客户端主动释放锁，那么Redisson就会取消看门狗机制。</li>
</ol>
<p>【注意】 如果客户端主动释放锁之前，服务器突然宕机了，定时任务没法儿继续执行。等看门狗机制设置的过期时间到了，锁就自动释放了。所以，不会出现一直占用锁的情况。</p>
<p><img alt="Redisson分布式锁执行流程" loading="lazy" src="https://oss.swimmingliu.cn/846a0583-f4b5-11ef-964d-c858c0c1deba"></p>
<h2 id="11-redis-实现分布式锁时可能遇到的问题有哪些">11. Redis 实现分布式锁时可能遇到的问题有哪些？<a hidden class="anchor" aria-hidden="true" href="#11-redis-实现分布式锁时可能遇到的问题有哪些">#</a></h2>
<ol>
<li>
<p><strong>前面锁提前过期, 后续锁被误释放</strong>：用户的业务逻辑还没执行完毕，锁提前过期了。被其他的进程获取了锁，同时抢占临界资源，可能出现数据不一致的情况。</p>
<p>【解决方法】</p>
<p>通常要保证用户的业务逻辑需要在锁过期之前执行完，因此需要把锁的过期时间稍微设大一些。也不能太大，这样其他程序就拿不到锁，就会降低系统的整体性能。或者使用Redisson分布式锁，会自动调用看门狗机制，定时续期锁，直到任务执行完毕，就不续期锁了。</p>
</li>
<li>
<p><strong>单点故障问题</strong>：如果只部署了一个Redis节点，当实例宕机或者不可用的时候。整个分布式锁服务将无法完成工作，阻塞业务的正常执行。</p>
<p>【解决方法】</p>
<p>可以利用Redis Cluster集群机制，部署多个Redis实例，采用一主+两从的哨兵机制。当某个实例宕机时, 哨兵会自动选举新的有效节点作为主节点。</p>
</li>
<li>
<p><strong>主从同步但锁未同步问题</strong>：主从复制的过程是异步实现的，如果Redis主节点获取到锁，但是还没同步到从节点。此时，主节点突然宕机，然后哨兵选择新的主节点。但是，由于主从同步没有完成，现在其他客户端可以正常获取锁。就会导致多个应用同时获取锁，会出现数据不一致的问题。</p>
</li>
<li>
<p><strong>网络分区问题</strong>：在网络不稳定的情况下，客户端和Redis可能会中断再重连。如果没有设置锁的过期时间，那么可能导致锁无法正常释放。如果有多个锁，可能还会引发死锁的现象。</p>
<p>【多锁死锁现象】</p>
<ul>
<li>
<p>有两个资源A和B，分别由锁LockA和LockB保护。</p>
</li>
<li>
<p>客户端1先获取LockA，然后尝试获取LockB。</p>
</li>
<li>
<p>客户端2先获取LockB，然后尝试获取LockA</p>
</li>
</ul>
<p>如果客户端1拿到了LockA，客户端2拿到了LockB。突然网络不稳定，锁无法正常释放。然后客户端1等待LockB，客户端2等待LockA，就会形成死锁。</p>
</li>
<li>
<p><strong>时钟漂移问题</strong>：因为Redis分布式锁依赖锁的过期时间来判断是否过期，如果出现时钟漂移，很可能导致锁直接失效。</p>
<p>【解决方法】</p>
<p>让所有节点的系统时钟从NTP服务进行同步，减少时钟漂移的影响。</p>
</li>
<li>
<p><strong>可重入问题</strong>：某个进程可能有多次调用锁，如果锁不能重入的话。当进程获取到锁后，再次申请获取锁，获取不到就死锁了。</p>
</li>
</ol>
<h2 id="12-redis为什么这么快">12. Redis为什么这么快?<a hidden class="anchor" aria-hidden="true" href="#12-redis为什么这么快">#</a></h2>
<ol>
<li><strong>基于内存</strong>: Redis存储的所有数据都存在内存里面，内存的访问速度比硬盘快，提升了读写速度</li>
<li><strong>单线程模型 + I/O多路复用</strong>： Redis采用单线程+I/O多路复用的方式，避免了线程上下文切换和竞争条件，提高了并发处理效率</li>
<li><strong>高效数据结构</strong>：提供<code>String</code>、<code>List</code>、<code>Hash</code>、<code>Set</code>、<code>Sorted Set</code> 五种数据结构，他们的操作复杂度大部分为O(1)</li>
<li><strong>异步持久化</strong>: 持久化操作由子线程异步完成，减少了持久化对主线程的影响，提升了整体性能。</li>
</ol>
<p>【注意】Redis从6.0开始对网络处理引入了多线程机制，提高I/O性能。网络请求可以并发处理，减少网络I/O等待的影响。但是，Redis 仍然保持了<strong>核心命令处理逻辑的单线程特性</strong>。</p>
<p><strong>【I/O多路复用技术】</strong></p>
<ul>
<li>Linux多路复用技术允许多个进程的I/O注册到同一管道和内核交互，准备好数据之后再copy到用户空间，实现一个线程处理多个I/O流。</li>
<li>Linux下I/O多路复用有<code>select</code>、<code>poll</code>、<code>epoll</code> 三种，功能类似，细节不同</li>
</ul>
<h2 id="13-如何使用redis快速实现布隆过滤器">13. 如何使用Redis快速实现布隆过滤器?<a hidden class="anchor" aria-hidden="true" href="#13-如何使用redis快速实现布隆过滤器">#</a></h2>
<p>Redis可以使用位图<code>Bitmap</code>或者用Redis模块<code>RedisBloom</code>来实现布隆过滤器</p>
<ol>
<li><strong>位图 <code>bitmap</code> 实现</strong>
<ul>
<li>bitmap 本质是一个位数组，提供了<code>setbit</code>和<code>getbit</code>来设置和获取某个值，可以用来标识某个元素是否存在</li>
<li>对应给定的key，可以用哈希函数来计算位置索引。如果位图中的值为<code>1</code>， 表示该元素可能存在</li>
</ul>
</li>
<li><strong><code>RedisBloom</code> 模块实现</strong>：封装了哈希函数和位图大小，可以直接用于创建和管理布隆过滤器</li>
</ol>
<p><strong>【布隆过滤器原理】</strong></p>
<p>布隆过滤器是由<strong>一个位数组+k个独立的哈希函数</strong>组成。每次验证某个key对应的数据是否存在的时候，需要k个哈希函数都对其进行运算，如果位数组中的值都为<code>1</code>，说明该key对应的数据可能存在。只要有一个位置不为<code>1</code>， 就说明key对应的数据一定不存在。</p>
<p>为什么k个函数查到的值都为<code>1</code>， 也不能说明key对应的数据一定存在呢？</p>
<p>因为可能存在哈希冲突，比如<code>key</code> 和 <code>key1</code> 的k个hash函数的值都为<code>1</code>。但是<code>key</code>对应的数据在数据库里面，但是<code>key1</code>的数据不在数据库里面。</p>
<p><img alt="布隆过滤器hash冲突" loading="lazy" src="https://oss.swimmingliu.cn/848e3fbb-f4b5-11ef-80c9-c858c0c1deba"></p>


  </div>



  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://swimmingliu.cn/tags/java/">Java</a></li>
      <li><a href="https://swimmingliu.cn/tags/redis/">Redis</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://swimmingliu.cn/posts/job/personal-interview-hot-question/">
    <span class="title">« Prev</span>
    <br>
    <span>个人简历常问问题</span>
  </a>
  <a class="next" href="https://swimmingliu.cn/posts/job/java-set-interview-questions/">
    <span class="title">Next »</span>
    <br>
    <span>Java集合面试题笔记</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2023-2025 <a href="https://swimmingliu.cn/">SwimmingLiu&#39;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
    <span>
        <a href="https://beian.miit.gov.cn/">浙ICP备2024056260号</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
