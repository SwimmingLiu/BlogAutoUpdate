<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Redis面试题笔记 | SwimmingLiu&#39;s Blog</title>
<meta name="keywords" content="Java, Redis">
<meta name="description" content="1. Redis主从复制的原理
【主从复制的原理】

同步：从节点向主节点发送psync命令进行同步，从节点保存主节点返回的 runid 和  offset
全量复制：如果是第一次连接或者连接失败且repl_backlog_buffer 缓存区不包含slave_repl_offset， 则生成主节点的数据快照(RDB文件)发给从节点
增量复制：全量复制完毕后，主从节点之间会保持长连接。如果连接没有断开或者slave_repl_offset仍然在repl_backlog_buffer中，则将后续的写操作传递给从节点，让数据保持一致。

【全量复制细节】
全量复制的过程是基于TCP长连接的，主要流程如下

从节点发送psync ? -1表示需要建立连接进行同步，主节点返回主节点ID runid 和 复制进度offset (第一次同步用 -1 表示)。从节点接受之后，保存主节点的信息。
主节点执行bgsave命令生成数据快照RDB文件，然后将RDB文件发送给从节点。从节点接受文件后，清除现有的所有数据，然后加载RDB文件
如果在制作数据快照RDB文件的过程当中，主节点接收到了新的写操作，主节点会将其记录在repl buffer 里面。然后将repl buffer当中的写操作发给从节点，让其数据保持一致。


【增量复制细节】
如果主从节点意外断开连接，为了保持数据的一致性，必须重新同步数据。如果使用全量复制来保持一致性的话，开销太大，所以采用增量复制。
增量复制的具体流程如下：

连接恢复后，从节点会发送psync {runid} {offset}， 其中主节点ID runid 和 复制进度offset用于标识是哪一个服务器主机和复制进度。
主节点收到psync 命令之后，会用conitnue响应告知从节点，采用增量复制同步数据
最后，主节点根据offset查找对应的进度，将断线期间未同步的写命令，发送给从节点。同时，主节点将所有的写命令写入repl_backlog_buffer， 用于后续判断是采用增量复制还是全量复制。

【注意】从节点 psync 携带的 offset 为 slave_repl_offset。如果 repl_backlog_buffer包含slave_repl_offset 对应的部分，则采用增量复制，否则采用全量复制。repl_backlog_buffer的默认缓冲区大小为1M

【为什么要主从复制】

备份数据：主从复制实现了数据的热备份，是持久化之外的数据冗余方式
故障恢复：当主节点宕机之后，可以采用从节点提供服务。
负载均衡:  主从复制实现了读写分离，只有主节点支持读写操作，从节点只有读操作。在读多写少的场景下，可以提高Redis服务器的并发量。


2. Redis集群的实现原理是什么?
【Redis集群基本知识】

定义: Redis集群由多个实例组成，每个实例存储部分数据 (每个实例之间的数据不重复) 。

【注】集群和主从节点不是一个东西，集群的某一个实例当中可能包含一个主节点 &#43; 多个从节点

为什么用


  
      
          问题
          解决方案
      
  
  
      
          容量不足
          数据分片，将数据分散不存到不同的主节点
      
      
          高并发写入
          数据分片，将写入请求分摊到多个主节点
      
      
          主机宕机问题
          自动切换主从节点，避免影响服务， 不需要手动修改客户端配置
      
  


节点通信协议：Redis集群采用Gossip协议, 支持分布式信息传播、延迟低、效率高。采用去中心化思想，任意实例(主节点)都可以作为请求入口，节点间相互通信。
分片原理： 采用哈希槽(Hash Slot)机制来分配数据，整个空间可以划分为16384 (16 * 1024)个槽。 每个Redis负责一定范围的哈希槽,数据的key经过哈希函数计算之后对16384取余可定位到对应的节点。

">
<meta name="author" content="SwimmingLiu">
<link rel="canonical" href="https://swimmingliu.cn/posts/job/redis-interview-questions/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.6ecbb0040febd20e47edd88a662c19f1ea945bf7427774b86594271d18f88faf.css" integrity="sha256-bsuwBA/r0g5H7diKZiwZ8eqUW/dCd3S4ZZQnHRj4j68=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://swimmingliu.cn/images/swimmingliu_icon.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://swimmingliu.cn/images/swimmingliu_icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://swimmingliu.cn/images/swimmingliu_icon.png">
<link rel="apple-touch-icon" href="https://swimmingliu.cn/images/swimmingliu_icon.png">
<link rel="mask-icon" href="https://swimmingliu.cn/images/swimmingliu_icon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://swimmingliu.cn/posts/job/redis-interview-questions/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            
            
            delimiters: [
                { left: '$$', right: '$$', display: true },
                { left: '$', right: '$', display: false },
                { left: '\\(', right: '\\)', display: false },
                { left: '\\[', right: '\\]', display: true }
            ],
            
            throwOnError: false
        });
    });
</script>


+
+<meta property="og:url" content="https://swimmingliu.cn/posts/job/redis-interview-questions/">
  <meta property="og:site_name" content="SwimmingLiu&#39;s Blog">
  <meta property="og:title" content="Redis面试题笔记">
  <meta property="og:description" content="1. Redis主从复制的原理 【主从复制的原理】
同步：从节点向主节点发送psync命令进行同步，从节点保存主节点返回的 runid 和 offset 全量复制：如果是第一次连接或者连接失败且repl_backlog_buffer 缓存区不包含slave_repl_offset， 则生成主节点的数据快照(RDB文件)发给从节点 增量复制：全量复制完毕后，主从节点之间会保持长连接。如果连接没有断开或者slave_repl_offset仍然在repl_backlog_buffer中，则将后续的写操作传递给从节点，让数据保持一致。 【全量复制细节】
全量复制的过程是基于TCP长连接的，主要流程如下
从节点发送psync ? -1表示需要建立连接进行同步，主节点返回主节点ID runid 和 复制进度offset (第一次同步用 -1 表示)。从节点接受之后，保存主节点的信息。 主节点执行bgsave命令生成数据快照RDB文件，然后将RDB文件发送给从节点。从节点接受文件后，清除现有的所有数据，然后加载RDB文件 如果在制作数据快照RDB文件的过程当中，主节点接收到了新的写操作，主节点会将其记录在repl buffer 里面。然后将repl buffer当中的写操作发给从节点，让其数据保持一致。 【增量复制细节】
如果主从节点意外断开连接，为了保持数据的一致性，必须重新同步数据。如果使用全量复制来保持一致性的话，开销太大，所以采用增量复制。
增量复制的具体流程如下：
连接恢复后，从节点会发送psync {runid} {offset}， 其中主节点ID runid 和 复制进度offset用于标识是哪一个服务器主机和复制进度。 主节点收到psync 命令之后，会用conitnue响应告知从节点，采用增量复制同步数据 最后，主节点根据offset查找对应的进度，将断线期间未同步的写命令，发送给从节点。同时，主节点将所有的写命令写入repl_backlog_buffer， 用于后续判断是采用增量复制还是全量复制。 【注意】从节点 psync 携带的 offset 为 slave_repl_offset。如果 repl_backlog_buffer包含slave_repl_offset 对应的部分，则采用增量复制，否则采用全量复制。repl_backlog_buffer的默认缓冲区大小为1M
【为什么要主从复制】
备份数据：主从复制实现了数据的热备份，是持久化之外的数据冗余方式 故障恢复：当主节点宕机之后，可以采用从节点提供服务。 负载均衡: 主从复制实现了读写分离，只有主节点支持读写操作，从节点只有读操作。在读多写少的场景下，可以提高Redis服务器的并发量。 2. Redis集群的实现原理是什么? 【Redis集群基本知识】
定义: Redis集群由多个实例组成，每个实例存储部分数据 (每个实例之间的数据不重复) 。 【注】集群和主从节点不是一个东西，集群的某一个实例当中可能包含一个主节点 &#43; 多个从节点
为什么用 问题 解决方案 容量不足 数据分片，将数据分散不存到不同的主节点 高并发写入 数据分片，将写入请求分摊到多个主节点 主机宕机问题 自动切换主从节点，避免影响服务， 不需要手动修改客户端配置 节点通信协议：Redis集群采用Gossip协议, 支持分布式信息传播、延迟低、效率高。采用去中心化思想，任意实例(主节点)都可以作为请求入口，节点间相互通信。 分片原理： 采用哈希槽(Hash Slot)机制来分配数据，整个空间可以划分为16384 (16 * 1024)个槽。 每个Redis负责一定范围的哈希槽,数据的key经过哈希函数计算之后对16384取余可定位到对应的节点。 ">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-02-20T21:21:45+08:00">
    <meta property="article:modified_time" content="2025-02-20T21:21:45+08:00">
    <meta property="article:tag" content="Java">
    <meta property="article:tag" content="Redis">
      <meta property="og:image" content="https://swimmingliu.cn/papermod-cover.png">

+<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://swimmingliu.cn/papermod-cover.png">
<meta name="twitter:title" content="Redis面试题笔记">
<meta name="twitter:description" content="1. Redis主从复制的原理
【主从复制的原理】

同步：从节点向主节点发送psync命令进行同步，从节点保存主节点返回的 runid 和  offset
全量复制：如果是第一次连接或者连接失败且repl_backlog_buffer 缓存区不包含slave_repl_offset， 则生成主节点的数据快照(RDB文件)发给从节点
增量复制：全量复制完毕后，主从节点之间会保持长连接。如果连接没有断开或者slave_repl_offset仍然在repl_backlog_buffer中，则将后续的写操作传递给从节点，让数据保持一致。

【全量复制细节】
全量复制的过程是基于TCP长连接的，主要流程如下

从节点发送psync ? -1表示需要建立连接进行同步，主节点返回主节点ID runid 和 复制进度offset (第一次同步用 -1 表示)。从节点接受之后，保存主节点的信息。
主节点执行bgsave命令生成数据快照RDB文件，然后将RDB文件发送给从节点。从节点接受文件后，清除现有的所有数据，然后加载RDB文件
如果在制作数据快照RDB文件的过程当中，主节点接收到了新的写操作，主节点会将其记录在repl buffer 里面。然后将repl buffer当中的写操作发给从节点，让其数据保持一致。


【增量复制细节】
如果主从节点意外断开连接，为了保持数据的一致性，必须重新同步数据。如果使用全量复制来保持一致性的话，开销太大，所以采用增量复制。
增量复制的具体流程如下：

连接恢复后，从节点会发送psync {runid} {offset}， 其中主节点ID runid 和 复制进度offset用于标识是哪一个服务器主机和复制进度。
主节点收到psync 命令之后，会用conitnue响应告知从节点，采用增量复制同步数据
最后，主节点根据offset查找对应的进度，将断线期间未同步的写命令，发送给从节点。同时，主节点将所有的写命令写入repl_backlog_buffer， 用于后续判断是采用增量复制还是全量复制。

【注意】从节点 psync 携带的 offset 为 slave_repl_offset。如果 repl_backlog_buffer包含slave_repl_offset 对应的部分，则采用增量复制，否则采用全量复制。repl_backlog_buffer的默认缓冲区大小为1M

【为什么要主从复制】

备份数据：主从复制实现了数据的热备份，是持久化之外的数据冗余方式
故障恢复：当主节点宕机之后，可以采用从节点提供服务。
负载均衡:  主从复制实现了读写分离，只有主节点支持读写操作，从节点只有读操作。在读多写少的场景下，可以提高Redis服务器的并发量。


2. Redis集群的实现原理是什么?
【Redis集群基本知识】

定义: Redis集群由多个实例组成，每个实例存储部分数据 (每个实例之间的数据不重复) 。

【注】集群和主从节点不是一个东西，集群的某一个实例当中可能包含一个主节点 &#43; 多个从节点

为什么用


  
      
          问题
          解决方案
      
  
  
      
          容量不足
          数据分片，将数据分散不存到不同的主节点
      
      
          高并发写入
          数据分片，将写入请求分摊到多个主节点
      
      
          主机宕机问题
          自动切换主从节点，避免影响服务， 不需要手动修改客户端配置
      
  


节点通信协议：Redis集群采用Gossip协议, 支持分布式信息传播、延迟低、效率高。采用去中心化思想，任意实例(主节点)都可以作为请求入口，节点间相互通信。
分片原理： 采用哈希槽(Hash Slot)机制来分配数据，整个空间可以划分为16384 (16 * 1024)个槽。 每个Redis负责一定范围的哈希槽,数据的key经过哈希函数计算之后对16384取余可定位到对应的节点。

">

+

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "📚 Posts",
      "item": "https://swimmingliu.cn/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "💻 Job",
      "item": "https://swimmingliu.cn/posts/job/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Redis面试题笔记",
      "item": "https://swimmingliu.cn/posts/job/redis-interview-questions/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Redis面试题笔记",
  "name": "Redis面试题笔记",
  "description": "1. Redis主从复制的原理 【主从复制的原理】\n同步：从节点向主节点发送psync命令进行同步，从节点保存主节点返回的 runid 和 offset 全量复制：如果是第一次连接或者连接失败且repl_backlog_buffer 缓存区不包含slave_repl_offset， 则生成主节点的数据快照(RDB文件)发给从节点 增量复制：全量复制完毕后，主从节点之间会保持长连接。如果连接没有断开或者slave_repl_offset仍然在repl_backlog_buffer中，则将后续的写操作传递给从节点，让数据保持一致。 【全量复制细节】\n全量复制的过程是基于TCP长连接的，主要流程如下\n从节点发送psync ? -1表示需要建立连接进行同步，主节点返回主节点ID runid 和 复制进度offset (第一次同步用 -1 表示)。从节点接受之后，保存主节点的信息。 主节点执行bgsave命令生成数据快照RDB文件，然后将RDB文件发送给从节点。从节点接受文件后，清除现有的所有数据，然后加载RDB文件 如果在制作数据快照RDB文件的过程当中，主节点接收到了新的写操作，主节点会将其记录在repl buffer 里面。然后将repl buffer当中的写操作发给从节点，让其数据保持一致。 【增量复制细节】\n如果主从节点意外断开连接，为了保持数据的一致性，必须重新同步数据。如果使用全量复制来保持一致性的话，开销太大，所以采用增量复制。\n增量复制的具体流程如下：\n连接恢复后，从节点会发送psync {runid} {offset}， 其中主节点ID runid 和 复制进度offset用于标识是哪一个服务器主机和复制进度。 主节点收到psync 命令之后，会用conitnue响应告知从节点，采用增量复制同步数据 最后，主节点根据offset查找对应的进度，将断线期间未同步的写命令，发送给从节点。同时，主节点将所有的写命令写入repl_backlog_buffer， 用于后续判断是采用增量复制还是全量复制。 【注意】从节点 psync 携带的 offset 为 slave_repl_offset。如果 repl_backlog_buffer包含slave_repl_offset 对应的部分，则采用增量复制，否则采用全量复制。repl_backlog_buffer的默认缓冲区大小为1M\n【为什么要主从复制】\n备份数据：主从复制实现了数据的热备份，是持久化之外的数据冗余方式 故障恢复：当主节点宕机之后，可以采用从节点提供服务。 负载均衡: 主从复制实现了读写分离，只有主节点支持读写操作，从节点只有读操作。在读多写少的场景下，可以提高Redis服务器的并发量。 2. Redis集群的实现原理是什么? 【Redis集群基本知识】\n定义: Redis集群由多个实例组成，每个实例存储部分数据 (每个实例之间的数据不重复) 。 【注】集群和主从节点不是一个东西，集群的某一个实例当中可能包含一个主节点 + 多个从节点\n为什么用 问题 解决方案 容量不足 数据分片，将数据分散不存到不同的主节点 高并发写入 数据分片，将写入请求分摊到多个主节点 主机宕机问题 自动切换主从节点，避免影响服务， 不需要手动修改客户端配置 节点通信协议：Redis集群采用Gossip协议, 支持分布式信息传播、延迟低、效率高。采用去中心化思想，任意实例(主节点)都可以作为请求入口，节点间相互通信。 分片原理： 采用哈希槽(Hash Slot)机制来分配数据，整个空间可以划分为16384 (16 * 1024)个槽。 每个Redis负责一定范围的哈希槽,数据的key经过哈希函数计算之后对16384取余可定位到对应的节点。 ",
  "keywords": [
    "Java", "Redis"
  ],
  "articleBody": "1. Redis主从复制的原理 【主从复制的原理】\n同步：从节点向主节点发送psync命令进行同步，从节点保存主节点返回的 runid 和 offset 全量复制：如果是第一次连接或者连接失败且repl_backlog_buffer 缓存区不包含slave_repl_offset， 则生成主节点的数据快照(RDB文件)发给从节点 增量复制：全量复制完毕后，主从节点之间会保持长连接。如果连接没有断开或者slave_repl_offset仍然在repl_backlog_buffer中，则将后续的写操作传递给从节点，让数据保持一致。 【全量复制细节】\n全量复制的过程是基于TCP长连接的，主要流程如下\n从节点发送psync ? -1表示需要建立连接进行同步，主节点返回主节点ID runid 和 复制进度offset (第一次同步用 -1 表示)。从节点接受之后，保存主节点的信息。 主节点执行bgsave命令生成数据快照RDB文件，然后将RDB文件发送给从节点。从节点接受文件后，清除现有的所有数据，然后加载RDB文件 如果在制作数据快照RDB文件的过程当中，主节点接收到了新的写操作，主节点会将其记录在repl buffer 里面。然后将repl buffer当中的写操作发给从节点，让其数据保持一致。 【增量复制细节】\n如果主从节点意外断开连接，为了保持数据的一致性，必须重新同步数据。如果使用全量复制来保持一致性的话，开销太大，所以采用增量复制。\n增量复制的具体流程如下：\n连接恢复后，从节点会发送psync {runid} {offset}， 其中主节点ID runid 和 复制进度offset用于标识是哪一个服务器主机和复制进度。 主节点收到psync 命令之后，会用conitnue响应告知从节点，采用增量复制同步数据 最后，主节点根据offset查找对应的进度，将断线期间未同步的写命令，发送给从节点。同时，主节点将所有的写命令写入repl_backlog_buffer， 用于后续判断是采用增量复制还是全量复制。 【注意】从节点 psync 携带的 offset 为 slave_repl_offset。如果 repl_backlog_buffer包含slave_repl_offset 对应的部分，则采用增量复制，否则采用全量复制。repl_backlog_buffer的默认缓冲区大小为1M\n【为什么要主从复制】\n备份数据：主从复制实现了数据的热备份，是持久化之外的数据冗余方式 故障恢复：当主节点宕机之后，可以采用从节点提供服务。 负载均衡: 主从复制实现了读写分离，只有主节点支持读写操作，从节点只有读操作。在读多写少的场景下，可以提高Redis服务器的并发量。 2. Redis集群的实现原理是什么? 【Redis集群基本知识】\n定义: Redis集群由多个实例组成，每个实例存储部分数据 (每个实例之间的数据不重复) 。 【注】集群和主从节点不是一个东西，集群的某一个实例当中可能包含一个主节点 + 多个从节点\n为什么用 问题 解决方案 容量不足 数据分片，将数据分散不存到不同的主节点 高并发写入 数据分片，将写入请求分摊到多个主节点 主机宕机问题 自动切换主从节点，避免影响服务， 不需要手动修改客户端配置 节点通信协议：Redis集群采用Gossip协议, 支持分布式信息传播、延迟低、效率高。采用去中心化思想，任意实例(主节点)都可以作为请求入口，节点间相互通信。 分片原理： 采用哈希槽(Hash Slot)机制来分配数据，整个空间可以划分为16384 (16 * 1024)个槽。 每个Redis负责一定范围的哈希槽,数据的key经过哈希函数计算之后对16384取余可定位到对应的节点。 【集群节点之间的交互协议】\n为什么用Gossip协议 分布式信息传播：每个节点定期向其他节点传播状态信息，确保所有节点对集群的状态有一致视图 (采用ping 发送 和 pong 接受，就像检查心跳一样 ) 低延迟、高效率：轻量级通信方式，传递信息很快 去中心化：没有中心节点，任意实例(主节点)都可以作为请求入口，节点间相互通信。 Gossip协议工作原理 状态报告和信息更新：特定时间间隔内，向随机的其他节点报告自身情况 （主从关系、槽位分布）。其他节点接收到之后，会相应的更新对应的节点状态信息 节点检测：通过周期性交换状态信息，可以检测到其他节点的存活状态。预定时间内未响应，则标记为故障节点。 容错处理：如果某个节点故障之后，集群中的其他节点可以重新分配槽位，保持系统的可用性 【哈希槽的相关机制】\n假定集群中有三个节点，Node1 (0 - 5460)、Node2(5461-10922)、Node3(10923-16383)\n集群使用哈希槽的流程如下：\n计算哈希槽 使用CRC16哈希算法计算user:0001的CRC16的值 将CRC16的值对16384进行取余 (哈希槽 = CRC16 % 16383) 假如CRC16为12345，哈希槽 = 12345 % 16383 = 12345 确定目标节点 ：查询到12345为Node3的存储的键，向该节点发送请求 当前非对应节点 ：假设当前连接的节点为Node1，Node1将返回MOVED错误到客户端，并让客户端根据MOVED携带的Node3的信息(ip和端口)重新进行连接，最后从新发送GET user:0001请求，获得结果。 3. Redis的哨兵机制（Sentinel）是什么？ 【哨兵作用】\n监控：哨兵不断监控主从节点的运行状态,定时发送ping进行检测 故障转移: 当主节点发生故障时, 哨兵会先踢出所有失效的节点, 然后选择一个有效的从节点作为新的主节点, 并通知客户端更新主节点的地址 通知: 哨兵可以发送服务各个节点的状态通知，方便观察Redis实例的状态变化。（比如主节点g了，已经更换为新的主节点） 【哨兵机制的主观下线和客观下线】\n主观下线：哨兵在监控的过程中，每隔1s会发送 ping 命令给所有的节点。如果哨兵超过down-after-milliseconds 所配置的时间，没有收到 pong 的响应，就会认为节点主观下线。\n客观下线：某个哨兵发现节点主线下线后，不能确认节点是否真的下线了（可能是网络不稳定），就询问其他的哨兵是否主观下线了。等待其他哨兵的确认，进行投票，如果超过半数+1 (总哨兵数/2 + 1)，就认定为客观下线。\n【注】客观下线只对主节点适用，因为从节点也没必要这样子判断，g了就g了呗。\n【哨兵leader如何选举】\n哨兵leader是采用分布式算法raft选出来的。具体流程如下：\n候选人：当哨兵判断为主观下线，则可以当选候选人 投票：每个哨兵都可以投票，但是只能投一票。候选者会优先投给自己。 选举：选取投票结果半数以上的候选人作为leader (哨兵一般设置为奇数，防止平票) 【主节点如何选举】\n哨兵判断主节点客观下线之后，会踢出所有下线的节点，然后从有效的从节点选新的主节点。选取依据如下：\n优先级：按照从节点的优先级 slave-priority，优先级的值越小越高。 主从复制offset值：如果优先级相同，则判断主从复制的offset值哪一个大，表明其同步的数据越多，优先级就越高。 从节点ID：如果上述条件均相同，则选取ID较小的从节点作为主节点。 4. Redis Cluster 集群模式与 Sentinel 哨兵模式的区别是什么？ Cluster集群模式：集群模式用于对数据进行分片，主要用于解决大数据、高吞吐量的场景。将数据自动分不到多个Redis实例上，支持自动故障转移（如果某个实例失效，集群会自动重写配置和平衡，不需要手动进行调整，因为内置了哨兵逻辑） Sentinel哨兵模式: 哨兵模式用于保证主从节点的高可用，读写分离场景。如果主节点宕机，哨兵会将从节点升为主节点。 5. Redis 在生成 RDB 文件时如何处理请求？ 首先，Redis生成RDB文件的操作是异步的，由fork子线程进行，主线程用于处理客户端的请求。下面具体说明生成RDB文件的流程\n【生成RDB文件原理】\n使用bgsave命令，开启fork子线程进行操作 fork子线程会复制主线程对应的页表（里面包含了需要操作数据的物理地址） 如果过程中，主线程接收到写命令，需要修改数据。主线程会将对应数据的所在页面复制一份，子线程仍然指向老的页面。（老的数据才叫数据快照） 【注意事项】\nRDB处理的时间比较长，过程中会发生大量的磁盘I/O和CPU负载。如果RDB生成的时间过长，并且Redis的写并发高，就可能出现系统抖动的现象，应该选取Redis使用频率较低的时间段生成RDB文件。\n[补充] 5. Redis的持久化机制有哪些？ Redis的持久化机制分为三种，RDB 、AOF 和 混合持久化这三种方式。不过 RDB 和 AOF 各有优缺点，所以一般不会单独使用，而是采用混合持久化机制。\n持久化方案 说明 优缺点 适用场景 RDB 数据快照 将内存当中的数据定期保存为dump.rdb， 记录某个时刻的数据快照 文件小，性能高，恢复快。但是数据丢失风险高，fork会阻塞主进程。 适合低频备份的场景，比如冷备份，灾难恢复，全量数据加载(主从复制) AOF 追加日志 将每个写操作记录到日志文件appendonly.aof， 通过重放日志文件恢复数据 数据更安全，文件可读性强。但是文件体积大，恢复速度慢，性能开销大 适合对持久化实时性要求高的场景，例如金融交易，用户数据保存等。 混合持久化 结合RDB 和 AOF 的优点，先生成RDB快照文件，再记录快照之后的写操作到日志文件当中。 适合需要快速恢复且尽量保证减少数据丢失的场景，一般用于生产环境 下面具体说一下不同持久化机制的执行过程\n【RDB 持久化】\n定时生成 RDB：Redis定期根据配置触发 RDB 快照 （或者主动用bgsave命令手动触发） fork 子进程： 主进程判断是否有正在执行的子进程，如果有，直接返回。如果没有，则 fork 创建一个新的子进程用于持久化数据 （fork 的过程，主进程是阻塞等待的） 子进程更新RDB文件： 子进程将数据异步写入临时 RDB 文件，完成后替换旧的 RDB 文件。同时发信号给主进程，主进程更新一下 RDB 数据快照的统计消息 【注意】 采用bgsave 而 不采用save 命令的原因是，save 命令在生成 RDB文件的过程中，会阻塞Redis执行其他操作。\n那么子进程在生成RDB临时文件的过程中，如果客户端对Redis发起新的写操作。Redis同样可以处理这些命令, 这种方式就是写时复制技术。\n【写时复制技术】\nRedis在执行bgsave命令的时候，会通过fork 创建子进程。为了节约内存，父子进程是共享同一片内存数据的。创建子进程的时候，会复制父进程的也表，但是页表指向的物理内存还是同一个。当客户端向Redis发起新的写操作时，物理内存会被复制一份。子进程仍然指向之前的内存地址 (数据快照)，主进程指向复制的物理内存地址，并完成写操作。\n【优缺点】\n优点：写时复制技术可以减少子进程的内存消耗，加快创建速度(fork 子进程，会阻塞父进程)。由于子进程共享内存当中的数据，创建后可以直接读取主进程中的内存做数据，然后把数据写入RDB文件。 缺点：客户端在写时复制操作的时候，不会把新的数据记录到RDB文件中。如果Redis在生成RDB文件后，马上宕机，那么主进程新写入的这些数据都丢失了。另外，如果数据被修改，每次复制的过程都会制造两份内存，内存占用就是之前的两倍了。 【AOF 日志文件生成过程】\nAOF 是通过把Redis的每个写操作追加到日志文件 appendonly.aof 实现持久化的方式。Redis每次重启时,会重放日志文件的命令来恢复数据。口诀：先写内存，再写日志， 过大重写。\n先写内存：每次写操作都会被写入内存的AOF缓冲当中 再写日志：然后从AOF 缓冲中同步到磁盘 (三种写回策略) 过大重写：当AOF 文件过大的时候，Redis会触发AOF 重写，将冗余命令合并，生成新的AOF 文件 【注意】 先写内存，再存日志可以避免额外的检查开销 (只存执行成功的指令)，而且不会阻塞当前操作，指令只想成功后，才将命令记录到AOF日志文件。但是如果还没写完AOF 文件就宕机了，会导致数据丢失。执行写命令和记录到日志都是主线程操作，可能会造成阻塞风险。\n写会策略配置 写回时机 作用 always 同步写回 每次都fsync 同步数据到磁盘，性能最低。如果写入AOF文件期间Redis宕机，则无法通过AOF 进行恢复 everysec 每秒写回 每秒调用一次fsync写回磁盘，安全和性能居中，Redis最多丢1s的数据 no 操作系统决定写回时间 性能高，安全性低 【AOF重写机制】 当Redis检测到AOF 文件过大的时候，会触发AOF 重写机制\n创建子进程：Redis通过BGREWRITEAOF命令创建一个子进程来进行AOF 重写 生成新AOF 文件：子进程基于当前数据库状态，将每个键的最新值转换为写命令，并写入AOF文件 处理新写入的命令：重写期间，把客户端新的写操作同时追加到现有的AOF文件和缓存区的AOF重写缓冲里面 合并新的写入指令：子进程完成AOF文件重写之后，需要确保AOF文件当中的写操作都是最新的。 替换旧的AOF 文件： 最后用新的AOF文件替换旧的AOF文件 **【MP-AOF】**Redis 7.0 采用 Multi-Part Append Only File 解决 AOF 当中的内存开销大(AOF 缓存和AOF 重写缓存包含大量重复数据)、CPU开销大(主进程需要耗时将数据写入AOF 重写缓存，然后传给子进程，子进程要耗时把AOF 重写缓存写入新的AOF 文件)、磁盘开销大(同一份数据会被写入两次，一次写入当前AOF文件，另一次写入新AOF 文件)。其处理过程如下：\n将一个AOF文件拆分成多个文件\n一个基础文件 basefile, 代表数据的初始快照 一个增量文件 incremental files，记录自基础文件创建以来的所有写操作， 可以有多个该文件 基础文件和增量文会放到一个单独的目录中，并且由一个清单文件 manifest file 进行统一跟踪和管理 该方案可以避免写入多个和AOF相关的缓存，子进程独立写基础AOF文件，进程之间无交互，不用切换上下文。\n【为什么Redis需要持久化】 Redis是基于内存的数据库，所有数据存储在内存里面。如果Redis发生了宕机事件，内存中的数据就会全部丢失。为了保证数据的安全，Redis采用持久化机制，让数据保存在磁盘中，方便宕机后进行恢复。如果没有持久化机制，Redis需要从数据库(MySQL)当中恢复数据, 可能会出现下面的问题：\n**性能瓶颈 + 恢复缓慢 **：后端数据库无法向Redis一样快速提供数据。如果数据量比较大，恢复就会变得非常缓慢。 系统压力：恢复的过程比较久，就会给数据库带来很大压力，影响其他的业务。 6. Redis集群会出现脑裂问题吗？ 脑裂定义: 在网络分区的情况下，Redis同一个集群的实例当中出现多个主节点，导致数据不一致。\n脑裂发生的原因：比如当前集群实例是一主+两从的模式，当网络发送分区，分为A区和B区。主节点(原)被分到A区,其他节点和哨兵集群都在B区。哨兵机制无法检测到A区的原主节点, 只能重新选取新的主节点(新)。此时，集群当中就有两个主节点，A区的主节点(原)被写入的新数据不会同步到B区的节点上。会出现数据不一致的情况。\n如何避免脑裂：min-slaves-to-write 主节点写操作所要求有效从节点个数、min-slaves-max-lag 从节点的最大延迟。比如 min-slaves-to-write = 3 和min-slaves-max-lag = 10 表明需要至少3个延时低于10s的从节点才可以接受写操作。\n【注意】脑裂并不能够完全避免，比如说在选举主节点的过程中，主节点(原)突然恢复了，然后发现主节点和从节点的延迟都不超过10s，客户端正常在主节点(原)进行写操作。等选举完毕，选出新的主节点，让主节点(原) slaveof 为从节点。选举时间写入的数据会被覆盖，就出现了数据不一致的现象。\n7. Redis如何实现分布式锁？ 分布式锁原理：Redis分布式锁由set ex nx 和 lua 脚本组成，分别对应加锁和解锁操作\n为什么用 set ex nx：某个进程对指定key执行 set nx 之后， 返回值为1，其他进程想要对相同的key获取锁，会发现key已存在，返回值为0。这样就是实现了上锁的操作。但是，如果A进程上完锁突然挂了，其他进程就永远不可能拿到锁。所以，设置一个ex过期时间，让其不要一直占用着锁。\n【注意】set ex nx设置value的时候，必须采用唯一值，比如uuid。 不然可能出现如下情况:\nA进程正常申请锁，值设为1。 A进程上锁后, 执行过程时间比较长, 以至于锁已经过期了, A进程还没执行完. 此时，B进程申请锁，值也设为1. 同时，A进程执行完毕, 使用lua脚本把锁删除了 B进程此时还在执行程序，一脸懵逼。（不是，哥们儿，我锁呢？谁偷了我的锁！！！） 为什么用 lua 进行解锁：如上述注意事项所说的一样，A进程执行完毕之后, 会删除锁. 假如他们的值都采用了uuid保证了唯一性。可能会出现下面的情况\nA进程先判断key和其值是否为对应的uuid，然后再删除锁. A进程准备删除锁之前, 锁过期了. B进程同时获取了锁 A进程再删除了该锁 (B进程申请的锁)，发生了误删的现象 所以需要用lua脚本保证解锁的原子性，就可以避免上述问题\n8. Redis的Red Lock是什么？你了解吗? Red Lock定义: 一种分布式锁的实现方案，主要用于解决分布式环境中使用Redis分布式锁的安全性问题 为什么用Red Lock: 假如我们采用一主+两从+哨兵方式部署Redis，如果有A进程在使用分布式锁的过程当中，主节点发送了主从更换，但是原主节点的锁信息不一定同步到新主节点上。所以当前新主节点可能没有锁信息，此时另外的B进程去获取锁，发现锁没被占，成功拿到锁并执行业务逻辑。此时两个竞争者（A和B进程）会同时操作临界资源，会出现数据不一致的情况。 Red Lock实现原理 : 假如当前有五个实例，不需要部署从节点和哨兵，只需要主节点。注意当前的五个实例之间没有任何关系，不进行任何的信息交互 (不同于Redis Cluster集群模式)。对五个实例依次申请上锁，如果最终申请成功的数量超过半数(大于总数/2 + 1)，则表明红锁申请成功。按照下面的流程进行操作： 客户端获取当前时间 t1 客户端依次对五个实例进行set ex nx 操作，锁的过期时间为 t_lock (远小于锁的总过期事件)。如果当前节点请求超时，则立马请求下一个节点。 当获取的锁超过半数，则获取当前的时间 t2。获取锁的过程总耗时t = t2 - t1。如果t小于锁的过期时间 t_lock，则可以判断为加锁成功，否则加锁失败。 加锁成功，则执行业务逻辑。若加锁失败，则依次释放所有节点的锁。 Red Lock是否安全：先说结论，不一定安全\n当前有两个客户端(Client1 和 Client2)，首先Client1 正常获取锁，然后突然被GC执行垃圾回收机制了。在GC的过程当中，Client1 的锁超时释放了，Client2开始申请并获得锁。然后Client2 写入数据并释放锁。 后面Client1 在GC 结束之后又写入数据， 此时就出现了数据不一致的情况。\n9. 说说 Redisson 分布式锁的原理? 【Redisson分布式锁定义】\nRedisson分布式锁是一种基于Redis实现的分布式锁，利用Redis的原子性操作来确保多线程、多进程或多节点系统中，只有一个线程能够获得锁。避免并发操作导致的数据不一致问题。\n主要可以分为四个部分来讲：锁的获取、锁的续期、可重入锁、锁的释放\n【锁的获取】\n执行 exist ，判断锁是否存在 若存在 ，判断唯一标识是否对应。若唯一标识相同 -\u003e 第 3 步 ; 若不同，说明当前锁别其他进程占用 -\u003e 第2 步 若不存在 ，直接 tryLock() 上锁 -\u003e 第 3 步 使用pttl查询锁剩余的过期时间，后续可以再次获取 执行hincrby，设置重入计数为1 （可重入锁才有这一步操作） 执行pexpire， 设置锁的过期时间 （为了防止任务还没执行完，锁就过期了。Redisson实现了用看门狗机制来为锁进行自动续期） 【可重入锁】\n一般是在线程已经获取锁的基础上，为了后续还能拿到锁。因为假如increment()和anotherMethod都需要用到Counter锁。当increment()拿到锁之后，又调用anotherMethod()又需要获取锁。如果不能二次获取锁，那就陷入死锁了。所以，Redisson才搞了可重入锁\npublic class Counter { private int count = 0; public synchronized void increment() { count++; anotherMethod(); } public synchronized void anotherMethod() { // 可以再次获取相同的锁 count++; } } 可重入锁是在获取锁的基础上，多了一层逻辑。具体实现如下：\n实现锁的获取的所有功能 执行hexist 判断是否锁已经存在，且唯一标识匹配(线程id相关)，所以不能直接用exist判断锁是否存在 如果自己的锁存在，用hincrby把重入次数加一 用pexpire，设置锁的过期时间 如果没有获取成功锁，就和上面一样，用pttl查询锁的过期剩余时间 【锁的释放】\n用hexist判断线程自己的锁是否存在，需要判断唯一标识 如果存在 -\u003e 第2步 如果不存在 -\u003e 直接返回，不需要做解锁操作，因为是别人的锁 用hincry减少一次锁的可重入次数 (增加-1 就是减少一次) 判断锁的可重入次数是否大于 0 如果大于 0， 说明还有函数在使用这个锁，则重新设置过期时间 如果等于 0 -\u003e 第4步 用 del 删除对应的key 用 publish 广播通知其他等待锁的进程，此时释放锁了 【Redisson锁的类型】\n公平锁：和可重入锁类似，确保多个线程按请求顺序获得锁 读写锁: 支持读写分离，多个线程同时获得读锁，而且锁是独占的 信号量与可数锁: 允许多个线程同时持有锁，适用于资源的限流和控制。 10. Redisson 看门狗（watch dog）机制了解吗？ 【为什么用看门狗机制】\n因为如果进程获取锁之后，用户的业务逻辑还没有执行完成，锁就过期了。此时，其他进程抢占临界资源，会导致数据不一致的问题。\n【看门口机制的执行流程】\n判断用户是否设置过期时间 (判断 leaseTime \u003e 0 ，默认 leaseTime 为 -1 ) 如果设置了过期时间，不启用看门狗机制，等到指定的过期时间，锁自动释放。 如果没有设置过期时间 -\u003e 第2步 Redssion会启动一个定时任务，用于自动续期锁的过期时间。 定时任务中，设置锁的超时时间默认为30s， 每间隔总时长的1/3，也就是10s。定时任务会自动锁进行续期，续期时间为30s 当客户端主动释放锁，那么Redisson就会取消看门狗机制。 【注意】 如果客户端主动释放锁之前，服务器突然宕机了，定时任务没法儿继续执行。等看门狗机制设置的过期时间到了，锁就自动释放了。所以，不会出现一直占用锁的情况。\n11. Redis 实现分布式锁时可能遇到的问题有哪些？ 业务未执行完，锁提前到期：用户的业务逻辑还没执行完毕，锁提前过期了。被其他的进程获取了锁，同时抢占临界资源，可能出现数据不一致的情况。\n【解决方法】\n通常要保证用户的业务逻辑需要在锁过期之前执行完，因此需要把锁的过期时间稍微设大一些。也不能太大，这样其他程序就拿不到锁，就会降低系统的整体性能。或者使用Redisson分布式锁，会自动调用看门狗机制，定时续期锁，直到任务执行完毕，就不续期锁了。\n单点故障问题：如果只部署了一个Redis节点，当实例宕机或者不可用的时候。整个分布式锁服务将无法完成工作，阻塞业务的正常执行。\n【解决方法】\n可以利用Redis Cluster集群机制，部署多个Redis实例，采用一主+两从的哨兵机制。当某个实例宕机时, 哨兵会自动选举新的有效节点作为主节点。\n主从同步但锁未同步问题：主从复制的过程是异步实现的，如果Redis主节点获取到锁，但是还没同步到从节点。此时，主节点突然宕机，然后哨兵选择新的主节点。但是，由于主从同步没有完成，现在其他客户端可以正常获取锁。就会导致多个应用同时获取锁，会出现数据不一致的问题。\n网络分区问题：在网络不稳定的情况下，客户端和Redis可能会中断再重连。如果没有设置锁的过期时间，那么可能导致锁无法正常释放。如果有多个锁，可能还会引发死锁的现象。\n【多锁死锁现象】\n有两个资源A和B，分别由锁LockA和LockB保护。\n客户端1先获取LockA，然后尝试获取LockB。\n客户端2先获取LockB，然后尝试获取LockA\n如果客户端1拿到了LockA，客户端2拿到了LockB。突然网络不稳定，锁无法正常释放。然后客户端1等待LockB，客户端2等待LockA，就会形成死锁。\n时钟漂移问题：因为Redis分布式锁依赖锁的过期时间来判断是否过期，如果出现时钟漂移，很可能导致锁直接失效。\n【解决方法】\n让所有节点的系统时钟从NTP服务进行同步，减少时钟漂移的影响。\n可重入问题：某个进程可能有多次调用锁，如果锁不能重入的话。当进程获取到锁后，再次申请获取锁，获取不到就死锁了。\n12. Redis为什么这么快? 基于内存: Redis存储的所有数据都存在内存里面，内存的访问速度比硬盘快，提升了读写速度 单线程模型 + I/O多路复用： Redis采用单线程+I/O多路复用的方式，避免了线程上下文切换和竞争条件，提高了并发处理效率 高效数据结构：提供String、List、Hash、Set、Sorted Set 五种数据结构，他们的操作复杂度大部分为O(1) 异步持久化: 持久化操作由子线程异步完成，减少了持久化对主线程的影响，提升了整体性能。 【注意】Redis从6.0开始对网络处理引入了多线程机制，提高I/O性能。网络请求可以并发处理，减少网络I/O等待的影响。但是，Redis 仍然保持了核心命令处理逻辑的单线程特性。\n【I/O多路复用技术】\nLinux多路复用技术允许多个进程的I/O注册到同一管道和内核交互，准备好数据之后再copy到用户空间，实现一个线程处理多个I/O流。 Linux下I/O多路复用有select、poll、epoll 三种，功能类似，细节不同 13. 为什么 Redis 设计为单线程？6.0 版本为何引入多线程？ 【Redis采用单线程的原因】\n基于内存操作，Redis的瓶颈主要是内存，多数操作的性能瓶颈不是CPU带来的 (增加多线程也没啥用) 单线程模型的代码简单，可以减少线程上下文切换的性能开销。 单线程结合I/O多路复用模型，能提高I/O利用率 【注意】 Redis的单线程是指网络请求模块和数据操作模块是单线程的, 但是持久化存储模块和集群支撑模块是多线程的。\n【为什么引入多线程】\n随着数据规模和请求量的增加，执行瓶颈主要在网络I/O部分。引入多线程可以提高网络I/O的速度。但是，Redis内核去还是保持单线程处理，比如读写命令部分还是单线程，所以线程安全问题就不存在了。\n【Redis多线程I/O场景下的结构】\n14. 如何使用Redis快速实现布隆过滤器? Redis可以使用位图Bitmap或者用Redis模块RedisBloom来实现布隆过滤器\n位图 bitmap 实现 bitmap 本质是一个位数组，提供了setbit和getbit来设置和获取某个值，可以用来标识某个元素是否存在 对应给定的key，可以用哈希函数来计算位置索引。如果位图中的值为1， 表示该元素可能存在 RedisBloom 模块实现：封装了哈希函数和位图大小，可以直接用于创建和管理布隆过滤器 【布隆过滤器原理】\n布隆过滤器是由一个位数组+k个独立的哈希函数组成。每次验证某个key对应的数据是否存在的时候，需要k个哈希函数都对其进行运算，如果位数组中的值都为1，说明该key对应的数据可能存在。只要有一个位置不为1， 就说明key对应的数据一定不存在。\n为什么k个函数查到的值都为1， 也不能说明key对应的数据一定存在呢？\n因为可能存在哈希冲突，比如key 和 key1 的k个hash函数的值都为1。但是key对应的数据在数据库里面，但是key1的数据不在数据库里面。\n15. Redis 中常见的数据类型有哪些？ 【Redis常见的五种数据结构】\n数据结构名称 底层 特性 适用场景 String SDS 简单动态字符串 String字符串 1.缓存数据：缓存Session、Token、序列化后的对象\n2. 分布式锁:set ex nx\n3.计数：用户单位时间访问次数，页面单位时间访问次数 List ListPack / QuickList / ZipList / LinkedList 双向有序链表，各节点都包含字符串 1. 信息流展示：历史记录、更新文章、更新动态\n2.消息队列：不推荐，缺陷多 Hash Dict / ZipList 无序散列表，存储键值对 存储信息：用户、商品、文章、购物车信息 Set Dict / Intset 无序去重集合，包含不同的字符串 1.不重复数据：点赞次数、下单次数\n2.共同资源：共同好友、统统粉丝、共同关注 (交集、并集)\n3.随机抽取: 抽奖系统、随机点名 ZSet ZipList / SkipList 跳表 + HashTable哈希表 有序集合，value包含member 成员和score分数，按照score 进行排序 1.各类排行榜：点赞排行版、热门话题排行榜\n2. 优先级/重要程度: 优先级队列 【其他数据结构】\n数据结构名称 特性 适用场景 BitMap 存储二进制数据，0 和1 1. 布隆过滤器： 防止缓存穿透\n2. 签到统计： 每日签到用 1 标记，未签到用0标记，可以快速统计某日签到人数和连续签到天数 HyperLogLog 基于概率算法实现，存储海量数据进行计数统计 一般用于页面的页面浏览量PV和独立访客数UV， 快速估算访问量 GEO 存储地理位置信息，经纬度坐标和位置名称 一般用于计算不同位置的距离，比如外卖单中计算配送距离 Stream 能够生成全局唯一消息id的消息队列 用于可靠消息传递、异步任务处理的场景 16. Redis 中如何保证缓存与数据库的数据一致性？ 为了保证缓存和数据库的数据一致性，有这么几种方案：\n先修改缓存，再修改数据库\n事务A准备修改指定id的 name 为 小张 ，先修改缓存 事务B准备修改指定id的 name 为 小王，先修改缓存, 然后修改数据库为小王 事务A修改数据库为 小张 (网络延迟)， 此时出现数据不一致的情况 先修改数据库，再修改缓存\n事务A准备修改指定id的 name 为 小张 ，先修改数据库 事务B准备修改指定id的 name 为 小王，先修改数据库, 然后修改缓存为小王 事务A修改缓存为 小张 (网络延迟)， 此时出现数据不一致的情况 先删除缓存，再修改数据库\n事务B读取指定id的name， 发现找不到缓存，读取数据库中的数据为小王\n事务A准备修改指定id的 name 为 小张 ，先删除缓存，然后修改数据库为 小张\n事务B修改缓存为小王 (读到空数据，返回来写)，此时出现数据不一致的情况\n先修改数据库，再删除缓存：基本不会出现问题 （除非删除缓存的请求失败）\n延迟双删，先删除缓存，再修改数据库，再删除缓存： 难以评定休眠时间\n如果要保证数据库和缓存的强一致性怎么办？\n用消息队列：把写策略里面的删除缓存操作加入到消息队列中，让消费者来操作数据。如果删除失败，则可以冲消息队列中重新读取，在一定重试次数下删除成功的话，将该消息删除。 （确保删除缓存成功） binlog + Canal: 模仿MySQL主从同步的方式，结合Canal 订阅MySQL的binlog。其实就是等MySQL写入数据库, 然后去删除缓存。 如果需要避免缓存失效 (比如热点Key), 如何设计呢?\n分布式锁：同一时间只允许一个请求更新缓存，确保缓存和数据库一致。但是，可能会降低写性能 添加短暂过期时间：在先修改数据库再修改缓存的基础上，给缓存加一个短暂的过期时间，确保缓存不一致的情况时间比较少。 17. Redis 中跳表的实现原理是什么？ 跳表是由多层链表组成的，它是Redis中 ZSet 的底层结构。最底层存所有的元素，上层是下层的子集 (可以理解成一种索引)。跳表的插入、删除、查找操作，实现方式如下：\n查找：从最高层开始，通过范围确定位置，逐层向下查找，时间复杂度为 O(log n) 插入：从最高层开始，先逐层向下找到存放位置，然后随机确定新节点层数，插入并更新指针 删除：从最高层开始，通过范围确定位置，在各层更新指针保持结构 【Redis跳表结构】\nRedis的跳表相对于普通的跳表多了一个回退指针, 而且 score 是可以重复的。\n首先，我们可以看一下跳表的节点实现的原理\ntypedef struct zskiplistNode { //Zset 对象的元素值 sds ele; // 采用Redis字符串底层实现sds,用于存储数据 //元素权重值 double score; //后退指针 struct zskiplistNode *backward; // 用于指向前一个节点 //节点的level数组，保存每层上的前向指针和跨度 struct zskiplistLevel { struct zskiplistNode *forward; unsigned long span; // 当前层的跨度值 } level[]; } zskiplistNode; 上面的图片看起来比较抽象，可以按照下面的图片进行理解。上述的查找、删除、插入操作，其实都是先从level[0] 开始进行遍历，然后找到合适的位置。再往下进入level[1]进行遍历，再找到合适的位置。一直重复这个操作，直到进入最底层，然后就可以确定位置了。\n然后，我们来看一下跳表的底层实现原理\ntypedef struct zskiplist{ struct zskiplistNode *header, *tail, // 头节点和尾节点 unsigned long length,\t// 跳表长度 int level; // 跳表的最大层数 } zskiplist; 【注意】跳表的头节点、尾节点、跳表长度、跳表的最大层数都可以在o(1)时间复杂度进行访问\n【跳表查询过程细节】\n从头节点的最高层开始，逐一遍历每一层 遍历某一层节点时，根据节点的 SDS 类型元素和元素权重进行判断 如果当前节点权重 \u003c 要查找的权重， 继续向前遍历 如果当前节点权重 = 要找的权重 \u0026\u0026 当前节点的 SDS 类型数据 \u003c 要查找的数据，继续向前遍历 如果上面两个条件都不满足或者下一个节点为空，则跳到下一层level数组里面，继遍历续查找 如果当前当前节点权重 = 要找的权重 \u0026\u0026 当前节点的 SDS 类型数据 = 要查找的数据， 返回当前节点值，查询结束 【跳表的插入细节】\n参数检查和初始化：检查要插入的节点的score是否为NaN，初始化遍历指针x指向跳表的头节点，定义update 数组记录每层查找的最右节点 (后续要修改它的指针)，rank 数组记录每层跨越的节点数。 查找插入位置：和上面查找过程一样，从最高层开始，逐层往下查询。每一层中，把满足条件的最右节点记录在 update 数组中，并更新 rank 数组记录跨越的节点数。 生成新节点层数：调用zsRandomLevel 函数生新节点的随机层数。如果新节点层数 \u003e 当前跳表总层数，则更新跳表最大层数，并初始化新增层的update 和 rank 数组数据。 创建并插入新节点：创建新节点，根据 update 和 rank 数组信息，在每一层插入节点，设置forward 指针 和 span 跨度值 更新其他节点的span值：对于没有触及到的层，更新 update 节点的 span 值 设置前后指针：设置新节点的backward指针，指向下一个节点。如果下一个节点为空，则更新跳表的tail指针。 更新跳表的长度：跳标的节点数 + 1， 返回插入的新节点指针。 【为什么ZSet要用跳表不用哈希表和平衡树】\n主要有三个原因：\n内存更少：跳表相比B树可以占用更少的内存，主要取决于如何设置节点层数的概率参数 局部性良好：跳表在执行ZRANGE 和 ZREVRANGE 等操作时，其缓存局部性表现良好，不比其他平衡树差 实现简单：跳表的代码更简单和易于调试 18. Redis Zset 的实现原理是什么？ ZSet 的实现方式有两种，第一种是压缩列表 Ziplist / 紧凑列表 Listpack，另一种是跳表 skiplist + 哈希表 HashTable。主要判断条件如下：\n元素数量 \u003c zset-max-ziplist-entries zset压缩列表最大键值对个数 (默认是128) 每个元素大小(key 和 value 的长度) \u003c zset-max-ziplist-value (默认为64) 【ZSet压缩列表结构】\nZSet 的 压缩列表结构和数组很相似，用一段连续的内存空间存储数据。每个节点都占用相邻的一小段内存，节点之间通过内存偏移量而非指针记录相对位置。\n【注意】压缩列表比传统的链表更加节省内存，但是压缩列表也有明显的缺点，它的修改成本高。\n倒序遍历都需要依赖上一个节点的长度prevlen，如果当前节点有修改，后续节点就需要修改prevlen 当prevlen \u003e 当前节点编码类型的最大大小时，就需要改变编码类型，重新分配内存 后继节点重新分配内存后，其他后面的节点都会面临同样的情况，导致发生连锁更新。 压缩列表的头部分别有记录了三个重要属性：\n列表大小zlbytes: 整段列表在内存中占用的字节数 尾节点位置 zltail：从队列头到最后一个节点起始位置的内存偏移量。 节点数量 zllen： 总共的节点个数 每个节点当中又可以化分为三个部分：\n上一节点长度 prevlen：用于倒序遍历时确认上一节点的位置 节点编码 encoding：同时记录了长度和编码类型 数据 data：节点中存放的数据 【ZSet紧凑列表结构】\n紧凑列表的头部分别有记录两个重要属性：\n列表大小size: 整段列表在内存中占用的字节数 列表元素数量num：总共的元素个数 每个节点当中又可以化分为三个部分：\n节点编码 encoding：同时记录了长度和编码类型 数据 data：节点中存放的数据 节点长度len：节点编码encoding + 数据data的总长度。正向或反向遍历都依赖它完成 紧凑列表相比压缩列表的优点：无需记录上一节点的长度，上一节点重新分配内存后，本身节点无需做任何修改。\n【跳表 + 哈希表】\n当ZSet 处理比较大的数据的时候，会选择跳表+哈希表的方式。其中，跳表的节点保存指向member的指针和score，哈希表保存member和score之间对应的关系，方便实现高效的随机查找和范围查找。\n跳表的具体实现细节可以参考17. Redis Zset 的实现原理是什么？\n19. Redis 的 hash 是什么？ Hash 是 Redis五大常规数据结构(String、List、Hash、Set、ZSet)的一种，主要用于存储key-value 键值对集合。Hash 一般会用来存储商品的属性、用户的信息等等。\n【Hash底层数据结构】\nHash 的底层数据结构要分为Redis 6.0 和 7.0来看\nRedis 6.0: 压缩列表 zipList + 哈希表 HashTable Redis 7.0: 紧凑列表 Listpack + 哈希表 HashTable 当Hash当中的数据达到指定的阈值的时候，就会从压缩列表zipList/紧凑列表ListPack 转为哈希表HashTable。当满足下面两个条件的时候才能用压缩列表zipList/紧凑列表ListPack\n哈希类型的个数 \u003c 哈希紧凑列表最大键值对个数 hash-max-listpack-entries (默认是512) 哈希的 key 和 value 的长度 \u003c hash-max-ziplist-value 64 【为什么Hash会选择压缩列表 zipList /紧凑列表 ListPack呢?】\nHash 结构采用压缩列表 zipList /紧凑列表 ListPack的主要目的应该是基于省内存的角度去考虑。主要有两个原因吧：\n内存占用少： 压缩列表 zipList 和 紧凑列表 ListPack 都属于紧凑型的内存结构，没有哈希表那样存在额外的指针开销。哈希表为了维持快速查找的特性，内部才用了链表解决哈希冲突，每个哈希桶的内部都会带有指针，比较占用内存空间。另外的两个数据结构主要通过将数据存储在一块连续的内存，利用了计算机的局部性原理，从而使得内存占用最小。 时间复杂度：哈希表的访问速率是O(1)，但是如果冲突比较多，最坏也会降到(O(n))。因为冲突之后，就需要遍历链表或者查红黑树。但是 压缩列表 zipList 和 紧凑列表 ListPack 是连续数组存储，肯定能在O(1)的时间找到这个元素 【Redis中HashTable的结构】\nHashTable 就是由哈希表数组实现的，查询时间复杂度为O(1)， 效率比较快。具体数据结构如下\ntypedef struct dictht { //哈希表数组 dictEntry **table; //哈希表大小 unsigned long size; //哈希表大小掩码，用于计算索引值 (index = hash(key) \u0026 sizemask), sizemask = size - 1 unsigned long sizemask; //该哈希表已有的节点数量 unsigned long used; } dictht; 哈希节点dictEntry 由三个key、value 和 下一个哈希节点指针next组成\ntypedef struct dictEntry { //键值对中的键 void *key; // 键值对中的值 union { void *val; // 用于指向实际值的指针，比如存放string uint64_t u64; int64_t s64; double d; } v; //指向下一个哈希表节点，形成链表 struct dictEntry *next; } dictEntry; 【渐进式扩容rehash】\nRedis中的hash表结构会随着数据量的增大而扩容, 将数组的大小扩张为原来的两倍。在扩张的过程当中，由于容量的变化，会导致之前的节点，移动到新的位置，这个变化的过程就是 rehash 实现的。\nrehash 扩容的过程可以分为一下三步:\n增加哈希表2的空间：给哈希表2分配空间，一般是哈希表1的两倍。此时，rehash 索引的值rehashidx 从 -1 暂时变成 0。 迁移数据：将哈希表1的数据迁移到哈希表2 （迁移的过程，一般是在对指定节点做增删改查的时候，所以叫渐进扩容，有点类似 ConcurrentHashMap 的扩容机制），迁移之后，rehashidx + 1。 迁移过程分为多次完成。 释放原哈希表1：迁移完成之后，哈希表1的空间会被释放，并且把哈希表2设置为哈希表1。然后，哈希表2再创建一个空白的哈希表。为下一次 rehash 做准备。 【注意】 rehash的出发条件和其负载因子相关，负载因子 = 已存储的哈希表节点数量 / 哈希表总容量 。当达到下面的任一条件就可能触发。\n负载因子 \u003e= 1 ， 资源相对紧张，如果Redis没有在执行bgsave 和 bgrewriteAOF 命令 (生成RDB文件和AOF文件)，就会触发 负载因子 \u003e= 5，资源非常紧张，直接触发 20. Redis String 类型的底层实现是什么？（SDS） Redis中的 String 类型的底层实现是简单动态字符串 SDS, 结合 int 、embstr 、raw等不同的编码方式进行优化存储。\n【简单动态字符串 SDS 结构】\nlen 字符数组长度：表示整个 SDS 字符串数组的长度，获取长度时直接返回该值 (时间复杂度 o(1)) alloc 分配内存： 表示已分配字符数组的存储空间大小，通过alloc - len 可以计算剩余空间。可用于判断是否满足修改要求，解决缓冲区溢出的问题。 flags SDS类型: 一共有 sdshdr5、sdshdr8、sdshdr16、sdshdr32、sdshdr64 五种类型，后面的数字表示2的幂次方，能够灵活存储不同大小的字符串，节省内存空间 buf 存储数据的字符数组： 用于保存字符串，二进制数据等 struct __attribute__ ((__packed__)) sdshdr64 { uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; 【Redis底层结构 redisObject】\nBTW, Redis的底层结构就是redisObject。\nredisObject 包含数据类型，编码类型和数据指针三个元素。其中编码类型，包含int、embstr、raw 等类型\nstruct redisObject { unsigned type:4; // 数据类型（字符串、哈希等） unsigned encoding:4; // 编码类型（int、embstr、raw等） int64_t ptr; // 实际的数据指针，这里直接存储整数值 }; redisObject 的具体编码类型由下面几个条件决定：\n如果字符串对象保存的整数值能用long 类型表示，该对象会把整数值存储到ptr 数据指针指向的long 结构里面 （将 void* 转为 long），并将编码设置为int 如果字符串对象保存的字符串长度 \u003c= 32 个字节，会用 上面提到的sds 保存字符串，并且把对象编码设置为embstr。 如果字符串对象保存的字符串长度 \u003e 32 个字节，也会用上面提到的sds 保存字符串，并且把对象编码设置为raw。 【注意】\n上面32个字节是redis 2.0版本，redis 5.0 版本是44 个字节 embstr 和 raw编码区别：embstr 只调用一次内存分配函数，分配一块连续内存保存redisObject和 SDS。raw 调用两次内存分配函数，分别分配两块内存空间保存 redisObject 和 SDS。 21. Redis 中的缓存击穿、缓存穿透和缓存雪崩是什么？ (缓存三兄弟) 问题类型 说明 解决方案 缓存穿透 查询的数据是不存在的，数据库和缓存都没有。所有的请求都会绕过缓存，直接打到数据库上，可能会遭受恶意攻击。 1.请求参数校验 2. 缓存空值 3. 布隆过滤器 缓存雪崩 大量的缓存同时失效或者Redis宕机了，导致请求直接打到数据库，可能造成系统崩溃。 1. 设置随机过期时间 2.Redis 高可用集群 3.服务熔断或限流 缓存击穿 某个热点数据缓存失效，大量并发请求直接访问数据库，导致数据库压力剧增，性能下降。 1. 互斥锁 2. 逻辑过期 【缓存穿透具体解决方案】\n请求参数校验：如果请求参数含有非法字段，则直接返回错误，避免进一步查询缓存和数据库\npublic boolean validateRequest(String key) { if(key == null || key.isEmpty()) { return false;\t} } 缓存空值：如果查到不存在的数据，也将其存入缓存，value 采用 ”null“ 字符串。后续查询，直接返回给用户。\npublic Object getDataWithEmptyCache(String key) { //先从缓存中获取数据 String value = redisTemplate.opsForValue().get(key); //如果缓存为空 if (value == null) { Object databaseValue = queryFromDatabase(key);\t//从数据库中获取 if (databaseValue == null) { //缓存空值 redisTemplate.opsForValue().set(key, \"null\", 60, TimeUnit.SECONDS); return null; } else { redisTemplate.opsForValue().set(key, databaseValue, 3600, TimeUnit.SECONDS); return databaseValue; } } return \"null\".equals(value) ? null : value; // 如果是空值缓存，返回 null } 布隆过滤器：写入数据库时用布隆过滤器做一个标记，然后在用户请求的时候，确认缓存失效了。先通过布隆过滤器快速判断数据是否存在，如果不存在就直接返回。但是，布隆过滤器在一定程度上会出现误判。 因为可能会出现哈希冲突，导致一小部分请求穿透到数据库。 可以采用第三方工具类 Guava 实现布隆过滤器 ）\npublic class TestBloomFilter { public static void main(String[] args) { /** * 构造: * 第二个参数: expectedInsertions 期望插入的元素数量 * 第三个参数: 预测错误率 传入 0.01 表示预测正确的概率是 99% * */ BloomFilter\u003cInteger\u003e filter = BloomFilter.create( Funnels.integerFunnel(), 500, 0.01 ); filter.put(1); filter.put(2); filter.put(3); Assert.assertTrue(filter.mightContain(1)); Assert.assertTrue(filter.mightContain(2)); Assert.assertTrue(filter.mightContain(3)); Assert.assertFalse(filter.mightContain(1000)); } /* 当我们设计布隆过滤器时，为预期的元素数量提供一个合理准确的值是很重要的。 否则，我们的过滤器将以比期望高得多的比率返回误报。 让我们看一个例子。 假设我们创建了一个具有 1% 期望误报概率和预期一些元素等于 5 的过滤器， 但随后我们插入了 100,000 个元素： */ @Test public void testOverSaturatedBloomFilter() { BloomFilter\u003cInteger\u003e filter = BloomFilter.create( Funnels.integerFunnel(), 5, 0.01); IntStream.range(0, 100_000).forEach(filter::put); Assert.assertTrue(filter.mightContain(1)); Assert.assertTrue(filter.mightContain(2)); Assert.assertTrue(filter.mightContain(3)); Assert.assertFalse(filter.mightContain(1000000)); //测试不通过 } } 【缓存雪崩具体解决方案】\n缓存雪崩要分为两种不同的情况来解决：大量key同时过期 和 Redis宕机\n【大量key同时过期】\n设置随机的过期时间：写入缓存的时候，给其在基础时间上 + 一个随机的过期时间 互斥锁： 保证同一时间只有一个请求来构建缓存 后台更新缓存：后台采用Scheduled 的方式检查缓存是否失效，如果失效了，就查询数据库更新缓存。 【Redis宕机】\n服务熔断或者限流机制：暂定服务对于缓存服务的访问，直接返回错误。或者启用限流规则，只允许商家请求发送数据库进行处理，过多的请求就会拒接。一般会使用Hystrix 或者 Sentinel 实现熔断或者限流\n@HystrixCommand(fallbackMethod = \"fallbackMethod\") public String getDataFromCache(String key) { // 从 Redis 获取数据 return redisTemplate.opsForValue().get(key); } public String fallbackMethod(String key) { return \"服务繁忙，请稍后重试！\"; // 熔断处理逻辑 } 构建Redis缓存高可用集群: 如果单个缓存服务节点发生故障自动迁移访问流量到另外一个节点.\n【缓存击穿具体解决方案】\n互斥锁：同一时间只允许一个业务线程更新缓存。未获取互斥锁的请求，可以等待锁释放后读取缓存，或者返回空值/默认值。 (对数据一致性要求比较高)\n逻辑过期：不给缓存设置过期时间，value 采用 hash 的方式，设置一个逻辑过期时间。每次判断数据是否过期，未过期直接返回数据。如果已经过期了，则获取互斥锁重建缓存，然后释放锁。如果获取互斥锁失败，则返回已过期缓存数据。\n服务熔断或者限流机制\n22.Redis 数据过期后的删除策略是什么？ 【Redis过期删除策略】\nRedis采用的是 定期删除 + 惰性删除 的结合方式\n策略 实现方式 优缺点 定期删除 Redis每个一段时间 (默认为100ms 随机检查 一定数量的键，非全部key)，过期则删除 可以减少内存占用, 但是对CPU有一定消耗，且不能保证及时删除所有过期键 惰性删除 当客户端访问一个key时，Redis会检查是否过期，若过期则立即删除 对CPU友好，大量过期键未被访问时仍占用内存 【定期删除细节】\nRedis会周期性执行过期key检查，默认每100ms 执行一次 每次检查会随机抽取部分key，默认每次 20 个， 判断是否过期 为了避免过多的CPU占用，Redis限制检查的执行时间 (默认为执行时间的25%，也就是25ms) 和 过期键的比例 (默认只检查 10% ) 如果过期间比例超过限制，则会重复检查以提高清理效率 【为什么Redis删除不直接吧所有过期key都删除了？】\n定期删除不能除所有过期key原因: 如果一次性清理所有过期间,可能会导致Redis长时间阻塞，影响性能。随机抽样和时间限制的方式能在清理内存和性能之间取得平衡。 惰性删除不能删除所有过期key原因：惰性删除旨在访问key的时候触发，如果没有被访问到，就可能一致存在，无法清理。 【如何优化大量key集中过期的情况 - 缓存雪崩】\n设置随机过期时间：设置过期时间的时候，加上一个随机值 开启lazy free 机制： 配置 lazyfree-lazy-expire， 让过期的key删除操作由后台线程异步执行，减少主线程的压力 23. 如何解决 Redis 中的热点 key 问题？ 热点 key 是指访问频率显著高于其他 key 的键，通常表现为以下几种情况：\n类别 特性 QPS 集中 某个key 的QPS (每秒请求量) 占Redis总QPS的较大比例 带宽集中 某个key 的数据量较大(比如1MB 以上的hash 数据)，被频繁请求 CPU消耗集中 某个key的复杂操作(比如ZRANGE查询较大的ZSet数据) 占用Redis过多CPU时间 热点key 问题就是某个瞬间，大量的请求集中访问Redis里的同一个固定key，假如热点key过期，可能会导致缓存击穿，让大量的请求直接打到数据库里面。像热点新闻、热点评论、明星直播 这种读多写少的场景，就很容易出现热点key 问题。因为Redis的单节点查询性能一般在 2w QPS， 一般超过 这个数值，可能就会宕机。\n【热点key的危害】\n消耗CPU和带宽资源： 热点 key 可能占用Redis大部分资源，影响其他请求的处理时间 Redis宕机风险: 如果超过Redis所能承载的最大QPS， 可能会导致Redis宕机。然后大量的请求转发到后端数据库，导致数据库崩溃。 【如何发现热点key】\n根据业务经验判断：比如像明星八卦爆料、重大新闻、热点评论都会能会导致热点key。 好处是不需要消耗什么成本，坏处是无法预防突发情况。 Redis进行集群监控： 查看哪个Redis出现了 QPS 倾斜，出现QPS倾斜的实例有很大概率存在热点key hotkey 监控：命令行执行redis-cli 的时候添加--hotkeys 参数，它是基于scan + object freq 扫描目标出现频率时间的。但是需要设置maxmemory-policy 参数，来采用不同的淘汰手段： volatile-lfu (least frequently used)： 淘汰已经过期数据集中最不常用的数据 allkeys-lfu：当内存不足的时候，移除最不常用的key monitor 命令： 集合一些Redis的日志和相关分析工具进行统计, 非常消耗性能, 单客户端会消耗 50% 的性能 代理层收集：利用有些服务在请求Redis前会先请求代理服务的特点, 在代理层统一收集Redis热key数据。比如采用 京东的 JD-hotkey、有赞透明多级缓存解决方案(TMC) 客户端收集：在操作Redis前添加统计每个key的查询频次，将统计数据发送到聚合计算平台计算，之后查看结果。对性能消耗较低，但是成本比较大，需要介入聚合计算平台。 【如何解决热点key】\n多级缓存：结合使用一级缓存和二级缓存。一级缓存就是应用程序的本地缓存，比如JVM内存中的缓存，可采用Caffeine 、阿里巴巴jetcache )。 二级缓存是Redis缓存，当以及缓存中不存在的时候，再访问二级缓存。\n针对热点key请求, 本地一级缓存可以将同一个key的大量请求，根据网络层负载均衡到不同的机器节点上，避免全部打到单个Redis节点的情况，减少网络交互。但是需要耗费更多的经历去保证分布式缓存一致性，会增加系统复杂度。\n热点key备份：在多个Redis节点上备份热key，避免固定key总是访问同一个Redis节点。通过初始化时为key 拼接 0~2n (n为集群数量) 之间的随机数，让其散落在各个姐电商。若有热点key请求的时候，随机选一个备份的节点进行取值。可以有效减轻单个Redis节点的负担。 热点key拆分：将热点key拆分为多个带后缀名的key，让其分散存储在多个实例当中。客户端请求的时候按照规则计算出固定key，然后请求对应的Redis节点。比如“某音热搜某明星离婚”。可以拆分为多个带编号后缀的key存储在不同的节点，用户查询时根据用户id 算出要访问的对应节点。虽然用户只能看到一部分数据，等待热点降温后再汇总数据，挑选优质内容重新推送给未收到的用户。 【注意】 热点key备份和热点key拆分的区别在于，热点key备份是同一份数据全量复制到其他节点，热点key拆分是把一份数据拆分成多份。\nRedis集群 + 读写分离: 增加Redis从节点, 分散读请求压力。然后利用集群，可以将热点key拆分或者备份到不同的Redis实例上。 限流和降级：采用限流策略，减少对Redis的请求，在必要的时候返回降级的数据或者空值。 24. Redis 中的 Big Key 问题是什么？如何解决？ Redis当中的 Big Key (也可以叫big memory key)是指某个key 对应的value数据量过大，比如包含大量元素的List、Hash、Set、ZSet 或超长字符串), 可能会导致性能瓶颈和系统不稳定。 一般来说，String 类型的value 超过 1MB ，或者符合类型当中的元素超过5000个，就算big key。\n【Big Key 典型场景】\nString: 存储超大JSON文本、图片base64数据等 Hash：存储海量的字段，比如用户的行为记录 List / Set：存储百万个元素 ZSet： 包含大量的排序元素 【Big Key 导致的问题】\n性能问题：Redis是单线程处理机制，在处理big key的时候，需要更长的时间，阻塞工作流程，没法儿处理后面的命令。如果处理的时间过长，会导致客户端长时间未收到响应。另外，big key 占用的带宽过高，传输时间比较长，也容易导致阻塞。 内存问题：big key 会导致Redis内存变得很大，增加内存碎片化风险。单次大对象内存分配失败，可能导致整个Redis服务崩溃。集群模式下，会出现数据和查询倾斜的情况，big key 的 Redis节点会占用较多的内存 持久化问题：如果AOF写回策略为always，也就是说主线程执行完指令之后，把对应数据写入AOF文件后，直接 fsync 写入磁盘操作。如果是一个大key， 阻塞的时间可能比较就，同步到硬盘的过程很耗时。 【如何找Big Key】\n内置--bigkeys： 采用内置的--bigkeys命令，基于scan 查找所有的big key\nredis-cli --bigkeys 使用第三方工具\nhttps://github.com/sripathikrishnan/redis-rdb-tools https://github.com/weiyanwei412/rdb_bigkeys 【如何处理Big Key问题】\nBig Key 问题可以从下面说三个层面来解决：\n开发层面：将数据压缩后再存; 将大JSON对象拆分为多个小字段; 将数据保存为更合理的数据结构 (利用hash替代大字符串); 避免会造成阻塞的命令\n业务层面：调整存储策略，只存储必要的数据 (比如用户的收货地址等不常用信息不存储，只存储用户ID、姓名、头像等); 优化业务逻辑，使用更小的数据来满足业务要求; 规划好数据的生命\n架构层面：采用Redis集群的方式进行Redis部署，然后将大Key拆分散落到不同的服务器上面, 加快响应速度\n",
  "wordCount" : "1791",
  "inLanguage": "en",
  "image": "https://swimmingliu.cn/papermod-cover.png","datePublished": "2025-02-20T21:21:45+08:00",
  "dateModified": "2025-02-20T21:21:45+08:00",
  "author":[{
    "@type": "Person",
    "name": "SwimmingLiu"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://swimmingliu.cn/posts/job/redis-interview-questions/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "SwimmingLiu's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://swimmingliu.cn/images/swimmingliu_icon.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://swimmingliu.cn/" accesskey="h" title="𝓢𝔀𝓲𝓶𝓶𝓲𝓷𝓰𝓛𝓲𝓾&#39;𝓼 𝓑𝓵𝓸𝓰 (Alt + H)">
                <img src="https://swimmingliu.cn/images/swimmingliu_icon.png" alt="" aria-label="logo"
                    height="30">𝓢𝔀𝓲𝓶𝓶𝓲𝓷𝓰𝓛𝓲𝓾&#39;𝓼 𝓑𝓵𝓸𝓰</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://swimmingliu.cn/index.html" title="🏡 Home">
                    <span>🏡 Home</span>
                </a>
            </li>
            <li>
                <a href="https://swimmingliu.cn/search/" title="🔍 Search">
                    <span>🔍 Search</span>
                </a>
            </li>
            <li>
                <a href="https://swimmingliu.cn/posts/" title="🗒️ Posts">
                    <span>🗒️ Posts</span>
                </a>
            </li>
            <li>
                <a href="https://swimmingliu.cn/archives/" title="📃 Archive">
                    <span>📃 Archive</span>
                </a>
            </li>
            <li>
                <a href="https://swimmingliu.cn/tags/" title="📑 Tags">
                    <span>📑 Tags</span>
                </a>
            </li>
            <li>
                <a href="https://bento.me/swimmingliu" title="👨🏻‍🎓 About Me">
                    <span>👨🏻‍🎓 About Me</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
            <li>
                <a href="https://www.emojisearch.app/" title="Emoji">
                    <span>Emoji</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://swimmingliu.cn/">Home</a>&nbsp;»&nbsp;<a href="https://swimmingliu.cn/posts/">📚 Posts</a>&nbsp;»&nbsp;<a href="https://swimmingliu.cn/posts/job/">💻 Job</a></div>
    <h1 class="post-title entry-hint-parent">
      Redis面试题笔记
    </h1>
    <div class="post-meta"><span title='2025-02-20 21:21:45 +0800 CST'>February 20, 2025</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;SwimmingLiu

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#1-redis%e4%b8%bb%e4%bb%8e%e5%a4%8d%e5%88%b6%e7%9a%84%e5%8e%9f%e7%90%86" aria-label="1. Redis主从复制的原理">1. Redis主从复制的原理</a></li>
                <li>
                    <a href="#2-redis%e9%9b%86%e7%be%a4%e7%9a%84%e5%ae%9e%e7%8e%b0%e5%8e%9f%e7%90%86%e6%98%af%e4%bb%80%e4%b9%88" aria-label="2. Redis集群的实现原理是什么?">2. Redis集群的实现原理是什么?</a></li>
                <li>
                    <a href="#3-redis%e7%9a%84%e5%93%a8%e5%85%b5%e6%9c%ba%e5%88%b6sentinel%e6%98%af%e4%bb%80%e4%b9%88" aria-label="3. Redis的哨兵机制（Sentinel）是什么？">3. Redis的哨兵机制（Sentinel）是什么？</a></li>
                <li>
                    <a href="#4--redis-cluster-%e9%9b%86%e7%be%a4%e6%a8%a1%e5%bc%8f%e4%b8%8e-sentinel-%e5%93%a8%e5%85%b5%e6%a8%a1%e5%bc%8f%e7%9a%84%e5%8c%ba%e5%88%ab%e6%98%af%e4%bb%80%e4%b9%88" aria-label="4.  Redis Cluster 集群模式与 Sentinel 哨兵模式的区别是什么？">4.  Redis Cluster 集群模式与 Sentinel 哨兵模式的区别是什么？</a></li>
                <li>
                    <a href="#5-redis-%e5%9c%a8%e7%94%9f%e6%88%90-rdb-%e6%96%87%e4%bb%b6%e6%97%b6%e5%a6%82%e4%bd%95%e5%a4%84%e7%90%86%e8%af%b7%e6%b1%82" aria-label="5. Redis 在生成 RDB 文件时如何处理请求？">5. Redis 在生成 RDB 文件时如何处理请求？</a></li>
                <li>
                    <a href="#%e8%a1%a5%e5%85%85-5-redis%e7%9a%84%e6%8c%81%e4%b9%85%e5%8c%96%e6%9c%ba%e5%88%b6%e6%9c%89%e5%93%aa%e4%ba%9b" aria-label="[补充] 5. Redis的持久化机制有哪些？">[补充] 5. Redis的持久化机制有哪些？</a></li>
                <li>
                    <a href="#6-redis%e9%9b%86%e7%be%a4%e4%bc%9a%e5%87%ba%e7%8e%b0%e8%84%91%e8%a3%82%e9%97%ae%e9%a2%98%e5%90%97" aria-label="6. Redis集群会出现脑裂问题吗？">6. Redis集群会出现脑裂问题吗？</a></li>
                <li>
                    <a href="#7-redis%e5%a6%82%e4%bd%95%e5%ae%9e%e7%8e%b0%e5%88%86%e5%b8%83%e5%bc%8f%e9%94%81" aria-label="7. Redis如何实现分布式锁？">7. Redis如何实现分布式锁？</a></li>
                <li>
                    <a href="#8-redis%e7%9a%84red-lock%e6%98%af%e4%bb%80%e4%b9%88%e4%bd%a0%e4%ba%86%e8%a7%a3%e5%90%97" aria-label="8. Redis的Red Lock是什么？你了解吗?">8. Redis的Red Lock是什么？你了解吗?</a></li>
                <li>
                    <a href="#9-%e8%af%b4%e8%af%b4-redisson-%e5%88%86%e5%b8%83%e5%bc%8f%e9%94%81%e7%9a%84%e5%8e%9f%e7%90%86" aria-label="9. 说说 Redisson 分布式锁的原理?">9. 说说 Redisson 分布式锁的原理?</a></li>
                <li>
                    <a href="#10-redisson-%e7%9c%8b%e9%97%a8%e7%8b%97watch-dog%e6%9c%ba%e5%88%b6%e4%ba%86%e8%a7%a3%e5%90%97" aria-label="10. Redisson 看门狗（watch dog）机制了解吗？">10. Redisson 看门狗（watch dog）机制了解吗？</a></li>
                <li>
                    <a href="#11-redis-%e5%ae%9e%e7%8e%b0%e5%88%86%e5%b8%83%e5%bc%8f%e9%94%81%e6%97%b6%e5%8f%af%e8%83%bd%e9%81%87%e5%88%b0%e7%9a%84%e9%97%ae%e9%a2%98%e6%9c%89%e5%93%aa%e4%ba%9b" aria-label="11. Redis 实现分布式锁时可能遇到的问题有哪些？">11. Redis 实现分布式锁时可能遇到的问题有哪些？</a></li>
                <li>
                    <a href="#12-redis%e4%b8%ba%e4%bb%80%e4%b9%88%e8%bf%99%e4%b9%88%e5%bf%ab" aria-label="12. Redis为什么这么快?">12. Redis为什么这么快?</a></li>
                <li>
                    <a href="#13-%e4%b8%ba%e4%bb%80%e4%b9%88-redis-%e8%ae%be%e8%ae%a1%e4%b8%ba%e5%8d%95%e7%ba%bf%e7%a8%8b60-%e7%89%88%e6%9c%ac%e4%b8%ba%e4%bd%95%e5%bc%95%e5%85%a5%e5%a4%9a%e7%ba%bf%e7%a8%8b" aria-label="13. 为什么 Redis 设计为单线程？6.0 版本为何引入多线程？">13. 为什么 Redis 设计为单线程？6.0 版本为何引入多线程？</a></li>
                <li>
                    <a href="#14-%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8redis%e5%bf%ab%e9%80%9f%e5%ae%9e%e7%8e%b0%e5%b8%83%e9%9a%86%e8%bf%87%e6%bb%a4%e5%99%a8" aria-label="14. 如何使用Redis快速实现布隆过滤器?">14. 如何使用Redis快速实现布隆过滤器?</a></li>
                <li>
                    <a href="#15-redis-%e4%b8%ad%e5%b8%b8%e8%a7%81%e7%9a%84%e6%95%b0%e6%8d%ae%e7%b1%bb%e5%9e%8b%e6%9c%89%e5%93%aa%e4%ba%9b" aria-label="15. Redis 中常见的数据类型有哪些？">15. Redis 中常见的数据类型有哪些？</a></li>
                <li>
                    <a href="#16-redis-%e4%b8%ad%e5%a6%82%e4%bd%95%e4%bf%9d%e8%af%81%e7%bc%93%e5%ad%98%e4%b8%8e%e6%95%b0%e6%8d%ae%e5%ba%93%e7%9a%84%e6%95%b0%e6%8d%ae%e4%b8%80%e8%87%b4%e6%80%a7" aria-label="16. Redis 中如何保证缓存与数据库的数据一致性？">16. Redis 中如何保证缓存与数据库的数据一致性？</a></li>
                <li>
                    <a href="#17-redis-%e4%b8%ad%e8%b7%b3%e8%a1%a8%e7%9a%84%e5%ae%9e%e7%8e%b0%e5%8e%9f%e7%90%86%e6%98%af%e4%bb%80%e4%b9%88" aria-label="17. Redis 中跳表的实现原理是什么？">17. Redis 中跳表的实现原理是什么？</a></li>
                <li>
                    <a href="#18-redis-zset-%e7%9a%84%e5%ae%9e%e7%8e%b0%e5%8e%9f%e7%90%86%e6%98%af%e4%bb%80%e4%b9%88" aria-label="18. Redis Zset 的实现原理是什么？">18. Redis Zset 的实现原理是什么？</a></li>
                <li>
                    <a href="#19-redis-%e7%9a%84-hash-%e6%98%af%e4%bb%80%e4%b9%88" aria-label="19. Redis 的 hash 是什么？">19. Redis 的 hash 是什么？</a></li>
                <li>
                    <a href="#20-redis-string-%e7%b1%bb%e5%9e%8b%e7%9a%84%e5%ba%95%e5%b1%82%e5%ae%9e%e7%8e%b0%e6%98%af%e4%bb%80%e4%b9%88sds" aria-label="20. Redis String 类型的底层实现是什么？（SDS）">20. Redis String 类型的底层实现是什么？（SDS）</a></li>
                <li>
                    <a href="#21-redis-%e4%b8%ad%e7%9a%84%e7%bc%93%e5%ad%98%e5%87%bb%e7%a9%bf%e7%bc%93%e5%ad%98%e7%a9%bf%e9%80%8f%e5%92%8c%e7%bc%93%e5%ad%98%e9%9b%aa%e5%b4%a9%e6%98%af%e4%bb%80%e4%b9%88-%e7%bc%93%e5%ad%98%e4%b8%89%e5%85%84%e5%bc%9f" aria-label="21. Redis 中的缓存击穿、缓存穿透和缓存雪崩是什么？ (缓存三兄弟)">21. Redis 中的缓存击穿、缓存穿透和缓存雪崩是什么？ (缓存三兄弟)</a></li>
                <li>
                    <a href="#22redis-%e6%95%b0%e6%8d%ae%e8%bf%87%e6%9c%9f%e5%90%8e%e7%9a%84%e5%88%a0%e9%99%a4%e7%ad%96%e7%95%a5%e6%98%af%e4%bb%80%e4%b9%88" aria-label="22.Redis 数据过期后的删除策略是什么？">22.Redis 数据过期后的删除策略是什么？</a></li>
                <li>
                    <a href="#23-%e5%a6%82%e4%bd%95%e8%a7%a3%e5%86%b3-redis-%e4%b8%ad%e7%9a%84%e7%83%ad%e7%82%b9-key-%e9%97%ae%e9%a2%98" aria-label="23. 如何解决 Redis 中的热点 key 问题？">23. 如何解决 Redis 中的热点 key 问题？</a></li>
                <li>
                    <a href="#24-redis-%e4%b8%ad%e7%9a%84-big-key-%e9%97%ae%e9%a2%98%e6%98%af%e4%bb%80%e4%b9%88%e5%a6%82%e4%bd%95%e8%a7%a3%e5%86%b3" aria-label="24. Redis 中的 Big Key 问题是什么？如何解决？">24. Redis 中的 Big Key 问题是什么？如何解决？</a>
                </li>
            </ul>
        </div>
    </details>
</div>
  <div class="post-content"><h2 id="1-redis主从复制的原理">1. Redis主从复制的原理<a hidden class="anchor" aria-hidden="true" href="#1-redis主从复制的原理">#</a></h2>
<p>【<strong>主从复制的原理</strong>】</p>
<ol>
<li>同步：从节点向主节点发送<code>psync</code>命令进行同步，从节点保存主节点返回的 <code>runid</code> 和 <code> offset</code></li>
<li>全量复制：如果是第一次连接或者连接失败且<code>repl_backlog_buffer</code> 缓存区不包含<code>slave_repl_offset</code>， 则生成主节点的数据快照(RDB文件)发给从节点</li>
<li>增量复制：全量复制完毕后，主从节点之间会保持长连接。如果连接没有断开或者<code>slave_repl_offset</code>仍然在<code>repl_backlog_buffer</code>中，则将后续的写操作传递给从节点，让数据保持一致。</li>
</ol>
<p><strong>【全量复制细节】</strong></p>
<p>全量复制的过程是基于TCP长连接的，主要流程如下</p>
<ol>
<li>从节点发送<code>psync ? -1</code>表示需要建立连接进行同步，主节点返回主节点ID <code>runid</code> 和 复制进度<code>offset</code> (第一次同步用 -1 表示)。从节点接受之后，保存主节点的信息。</li>
<li>主节点执行<code>bgsave</code>命令生成数据快照RDB文件，然后将RDB文件发送给从节点。从节点接受文件后，清除现有的所有数据，然后加载RDB文件</li>
<li>如果在制作数据快照RDB文件的过程当中，主节点接收到了新的写操作，主节点会将其记录在<code>repl buffer</code> 里面。然后将<code>repl buffer</code>当中的写操作发给从节点，让其数据保持一致。</li>
</ol>
<p><img alt="Redis主从全量复制" loading="lazy" src="https://oss.swimmingliu.cn/ac630d4c-ef8d-11ef-a882-c858c0c1deba"></p>
<p><strong>【增量复制细节】</strong></p>
<p>如果主从节点意外断开连接，为了保持数据的一致性，必须重新同步数据。如果使用全量复制来保持一致性的话，开销太大，所以采用增量复制。</p>
<p>增量复制的具体流程如下：</p>
<ol>
<li>连接恢复后，从节点会发送<code>psync {runid} {offset}</code>， 其中主节点ID <code>runid</code> 和 复制进度<code>offset</code>用于标识是哪一个服务器主机和复制进度。</li>
<li>主节点收到<code>psync</code> 命令之后，会用<code>conitnue</code>响应告知从节点，采用增量复制同步数据</li>
<li>最后，主节点根据<code>offset</code>查找对应的进度，将断线期间未同步的写命令，发送给从节点。同时，主节点将所有的写命令写入<code>repl_backlog_buffer</code>， 用于后续判断是采用增量复制还是全量复制。</li>
</ol>
<p>【注意】从节点 <code>psync</code> 携带的 <code>offset</code> 为 <code>slave_repl_offset</code>。如果 <code>repl_backlog_buffer</code>包含<code>slave_repl_offset</code> 对应的部分，则采用增量复制，否则采用全量复制。<code>repl_backlog_buffer</code>的默认缓冲区大小为<code>1M</code></p>
<p><img alt="Redis主从增量复制" loading="lazy" src="https://oss.swimmingliu.cn/ac9f21a3-ef8d-11ef-9016-c858c0c1deba"></p>
<p>【<strong>为什么要主从复制</strong>】</p>
<ul>
<li><strong>备份数据</strong>：主从复制实现了数据的热备份，是持久化之外的数据冗余方式</li>
<li><strong>故障恢复</strong>：当主节点宕机之后，可以采用从节点提供服务。</li>
<li><strong>负载均衡</strong>:  主从复制实现了读写分离，只有主节点支持读写操作，从节点只有读操作。在读多写少的场景下，可以提高Redis服务器的并发量。</li>
</ul>
<p><img alt="Redis主从读写分离" loading="lazy" src="https://oss.swimmingliu.cn/acad0d12-ef8d-11ef-b17f-c858c0c1deba"></p>
<h2 id="2-redis集群的实现原理是什么">2. Redis集群的实现原理是什么?<a hidden class="anchor" aria-hidden="true" href="#2-redis集群的实现原理是什么">#</a></h2>
<p>【<strong>Redis集群基本知识</strong>】</p>
<ul>
<li><strong>定义</strong>: Redis集群由多个实例组成，每个实例存储部分数据 (每个实例之间的数据不重复) 。</li>
</ul>
<p>【注】集群和主从节点不是一个东西，集群的某一个实例当中可能包含一个主节点 + 多个从节点</p>
<ul>
<li><strong>为什么用</strong></li>
</ul>
<table>
  <thead>
      <tr>
          <th>问题</th>
          <th>解决方案</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>容量不足</strong></td>
          <td>数据分片，将数据分散不存到不同的主节点</td>
      </tr>
      <tr>
          <td><strong>高并发写入</strong></td>
          <td>数据分片，将写入请求分摊到多个主节点</td>
      </tr>
      <tr>
          <td><strong>主机宕机问题</strong></td>
          <td>自动切换主从节点，避免影响服务， 不需要手动修改客户端配置</td>
      </tr>
  </tbody>
</table>
<ul>
<li><strong>节点通信协议</strong>：Redis集群采用Gossip协议, 支持分布式信息传播、延迟低、效率高。采用去中心化思想，任意实例(主节点)都可以作为请求入口，节点间相互通信。</li>
<li><strong>分片原理</strong>： 采用哈希槽(Hash Slot)机制来分配数据，整个空间可以划分为<strong>16384</strong> (16 * 1024)个槽。 每个Redis负责一定范围的哈希槽,数据的key经过哈希函数计算之后对<strong>16384</strong>取余可定位到对应的节点。</li>
</ul>
<p><img alt="Redis集群架构图" loading="lazy" src="https://oss.swimmingliu.cn/acc54635-ef8d-11ef-971e-c858c0c1deba"></p>
<p>【<strong>集群节点之间的交互协议</strong>】</p>
<ul>
<li><strong>为什么用Gossip协议</strong></li>
</ul>
<ol>
<li>分布式信息传播：每个节点定期向其他节点传播状态信息，确保所有节点对集群的状态有一致视图 (采用<code>ping</code> 发送 和 <code>pong</code> 接受，就像检查心跳一样 )</li>
<li>低延迟、高效率：轻量级通信方式，传递信息很快</li>
<li>去中心化：没有中心节点，任意实例(主节点)都可以作为请求入口，节点间相互通信。</li>
</ol>
<ul>
<li><strong>Gossip协议工作原理</strong></li>
</ul>
<ol>
<li>状态报告和信息更新：特定时间间隔内，向随机的其他节点报告自身情况 （主从关系、槽位分布）。其他节点接收到之后，会相应的更新对应的节点状态信息</li>
<li>节点检测：通过周期性交换状态信息，可以检测到其他节点的存活状态。预定时间内未响应，则标记为故障节点。</li>
<li>容错处理：如果某个节点故障之后，集群中的其他节点可以重新分配槽位，保持系统的可用性</li>
</ol>
<p>【<strong>哈希槽的相关机制</strong>】</p>
<p>假定集群中有三个节点，Node1 (0 - 5460)、Node2(5461-10922)、Node3(10923-16383)</p>
<p>集群使用哈希槽的流程如下：</p>
<ul>
<li><strong>计算哈希槽</strong></li>
</ul>
<ol>
<li>使用CRC16哈希算法计算<code>user:0001</code>的CRC16的值</li>
<li>将CRC16的值对16384进行取余 (哈希槽 = CRC16 % 16383)</li>
<li>假如CRC16为12345，哈希槽 = 12345 % 16383 = 12345</li>
</ol>
<ul>
<li><strong>确定目标节点</strong> ：查询到12345为Node3的存储的键，向该节点发送请求</li>
<li><strong>当前非对应节点</strong> ：假设当前连接的节点为Node1，Node1将返回<code>MOVED</code>错误到客户端，并让客户端根据<code>MOVED</code>携带的Node3的信息(<code>ip</code>和端口)重新进行连接，最后从新发送<code>GET user:0001</code>请求，获得结果。</li>
</ul>
<h2 id="3-redis的哨兵机制sentinel是什么">3. Redis的哨兵机制（Sentinel）是什么？<a hidden class="anchor" aria-hidden="true" href="#3-redis的哨兵机制sentinel是什么">#</a></h2>
<p><strong>【哨兵作用】</strong></p>
<ul>
<li>监控：哨兵不断监控主从节点的运行状态,定时发送ping进行检测</li>
<li>故障转移: 当主节点发生故障时, 哨兵会先踢出所有失效的节点, 然后选择一个有效的从节点作为新的主节点, 并通知客户端更新主节点的地址</li>
<li>通知: 哨兵可以发送服务各个节点的状态通知，方便观察Redis实例的状态变化。（比如主节点g了，已经更换为新的主节点）</li>
</ul>
<p><strong>【哨兵机制的主观下线和客观下线】</strong></p>
<ul>
<li>
<p><strong>主观下线</strong>：哨兵在监控的过程中，每隔1s会发送 <code>ping</code> 命令给所有的节点。如果哨兵超过<code>down-after-milliseconds</code> 所配置的时间，没有收到 <code>pong</code> 的响应，就会认为节点主观下线。</p>
</li>
<li>
<p><strong>客观下线</strong>：某个哨兵发现节点主线下线后，不能确认节点是否真的下线了（可能是网络不稳定），就询问其他的哨兵是否主观下线了。等待其他哨兵的确认，进行投票，如果超过半数+1 (总哨兵数/2 + 1)，就认定为客观下线。</p>
</li>
</ul>
<p>【注】客观下线只对主节点适用，因为从节点也没必要这样子判断，g了就g了呗。</p>
<p><strong>【哨兵leader如何选举】</strong></p>
<p>哨兵leader是采用分布式算法raft选出来的。具体流程如下：</p>
<ol>
<li>候选人：当哨兵判断为主观下线，则可以当选候选人</li>
<li>投票：每个哨兵都可以投票，但是只能投一票。候选者会优先投给自己。</li>
<li>选举：选取投票结果半数以上的候选人作为leader (哨兵一般设置为奇数，防止平票)</li>
</ol>
<p><strong>【主节点如何选举】</strong></p>
<p>哨兵判断主节点客观下线之后，会踢出所有下线的节点，然后从有效的从节点选新的主节点。选取依据如下：</p>
<ol>
<li>优先级：按照从节点的优先级 <code>slave-priority</code>，优先级的值越小越高。</li>
<li>主从复制offset值：如果优先级相同，则判断主从复制的offset值哪一个大，表明其同步的数据越多，优先级就越高。</li>
<li>从节点ID：如果上述条件均相同，则选取ID较小的从节点作为主节点。</li>
</ol>
<h2 id="4--redis-cluster-集群模式与-sentinel-哨兵模式的区别是什么">4.  Redis Cluster 集群模式与 Sentinel 哨兵模式的区别是什么？<a hidden class="anchor" aria-hidden="true" href="#4--redis-cluster-集群模式与-sentinel-哨兵模式的区别是什么">#</a></h2>
<ol>
<li><strong>Cluster集群模式</strong>：集群模式用于对数据进行分片，主要用于解决大数据、高吞吐量的场景。将数据自动分不到多个Redis实例上，支持自动故障转移（如果某个实例失效，集群会自动重写配置和平衡，不需要手动进行调整，因为内置了<strong>哨兵逻辑</strong>）</li>
<li><strong>Sentinel哨兵模式</strong>: 哨兵模式用于保证主从节点的高可用，读写分离场景。如果主节点宕机，哨兵会将从节点升为主节点。</li>
</ol>
<h2 id="5-redis-在生成-rdb-文件时如何处理请求">5. Redis 在生成 RDB 文件时如何处理请求？<a hidden class="anchor" aria-hidden="true" href="#5-redis-在生成-rdb-文件时如何处理请求">#</a></h2>
<p>首先，Redis生成RDB文件的操作是异步的，由<code>fork</code>子线程进行，主线程用于处理客户端的请求。下面具体说明生成RDB文件的流程</p>
<p><strong>【生成RDB文件原理】</strong></p>
<ol>
<li>使用<code>bgsave</code>命令，开启<code>fork</code>子线程进行操作</li>
<li><code>fork</code>子线程会复制主线程对应的页表（里面包含了需要操作数据的物理地址）</li>
<li>如果过程中，主线程接收到写命令，需要修改数据。主线程会将对应数据的所在页面复制一份，子线程仍然指向老的页面。（老的数据才叫数据快照）</li>
</ol>
<p><strong>【注意事项】</strong></p>
<p>RDB处理的时间比较长，过程中会发生大量的磁盘I/O和CPU负载。如果RDB生成的时间过长，并且Redis的写并发高，就可能出现系统抖动的现象，应该选取Redis使用频率较低的时间段生成RDB文件。</p>
<h2 id="补充-5-redis的持久化机制有哪些">[补充] 5. Redis的持久化机制有哪些？<a hidden class="anchor" aria-hidden="true" href="#补充-5-redis的持久化机制有哪些">#</a></h2>
<p>Redis的持久化机制分为三种，<code>RDB</code> 、<code>AOF</code> 和 混合持久化这三种方式。不过 <code>RDB</code> 和 <code>AOF</code> 各有优缺点，所以一般不会单独使用，而是采用混合持久化机制。</p>
<table>
  <thead>
      <tr>
          <th>持久化方案</th>
          <th>说明</th>
          <th>优缺点</th>
          <th>适用场景</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>RDB 数据快照</strong></td>
          <td>将内存当中的数据定期保存为<code>dump.rdb</code>， 记录某个时刻的数据快照</td>
          <td>文件小，性能高，恢复快。但是数据丢失风险高，<code>fork</code>会阻塞主进程。</td>
          <td>适合低频备份的场景，比如冷备份，灾难恢复，全量数据加载(主从复制)</td>
      </tr>
      <tr>
          <td><strong>AOF 追加日志</strong></td>
          <td>将每个写操作记录到日志文件<code>appendonly.aof</code>， 通过重放日志文件恢复数据</td>
          <td>数据更安全，文件可读性强。但是文件体积大，恢复速度慢，性能开销大</td>
          <td>适合对持久化实时性要求高的场景，例如金融交易，用户数据保存等。</td>
      </tr>
      <tr>
          <td><strong>混合持久化</strong></td>
          <td>结合<code>RDB</code> 和 <code>AOF</code> 的优点，先生成<code>RDB</code>快照文件，再记录快照之后的写操作到日志文件当中。</td>
          <td></td>
          <td>适合需要快速恢复且尽量保证减少数据丢失的场景，一般用于生产环境</td>
      </tr>
  </tbody>
</table>
<p>下面具体说一下不同持久化机制的执行过程</p>
<p><strong>【RDB 持久化】</strong></p>
<ol>
<li><strong>定时生成 <code>RDB</code></strong>：Redis定期根据配置触发 <code>RDB</code> 快照 （或者主动用<code>bgsave</code>命令手动触发）</li>
<li><strong><code>fork</code> 子进程</strong>： 主进程判断是否有正在执行的子进程，如果有，直接返回。如果没有，则 <code>fork</code> 创建一个新的子进程用于持久化数据 （<code>fork</code> 的过程，主进程是阻塞等待的）</li>
<li><strong>子进程更新<code>RDB</code>文件</strong>： 子进程将数据异步写入临时 <code>RDB</code> 文件，完成后替换旧的 <code>RDB</code> 文件。同时发信号给主进程，主进程更新一下 <code>RDB</code> 数据快照的统计消息</li>
</ol>
<p><strong>【注意】</strong> 采用<code>bgsave</code> 而 不采用<code>save</code> 命令的原因是，<code>save</code> 命令在生成 <code>RDB</code>文件的过程中，会阻塞Redis执行其他操作。</p>
<p><img alt="生成RDB数据快照过程" loading="lazy" src="https://oss.swimmingliu.cn/dcddfe3b-f8f8-11ef-82b8-c858c0c1deba"></p>
<p>那么子进程在生成<code>RDB</code>临时文件的过程中，如果客户端对Redis发起新的写操作。Redis同样可以处理这些命令, 这种方式就是<strong>写时复制技术</strong>。</p>
<p><strong>【写时复制技术】</strong></p>
<p>Redis在执行<code>bgsave</code>命令的时候，会通过<code>fork</code> 创建子进程。为了节约内存，父子进程是共享同一片内存数据的。创建子进程的时候，会复制父进程的也表，但是页表指向的物理内存还是同一个。当客户端向Redis发起新的写操作时，物理内存会被复制一份。子进程仍然指向之前的内存地址 (数据快照)，主进程指向复制的物理内存地址，并完成写操作。</p>
<p><strong>【优缺点】</strong></p>
<ul>
<li><strong>优点</strong>：写时复制技术可以减少子进程的内存消耗，加快创建速度(<code>fork</code> 子进程，会阻塞父进程)。由于子进程共享内存当中的数据，创建后可以直接读取主进程中的内存做数据，然后把数据写入<code>RDB</code>文件。</li>
<li><strong>缺点</strong>：客户端在写时复制操作的时候，不会把新的数据记录到RDB文件中。如果Redis在生成<code>RDB</code>文件后，马上宕机，那么主进程新写入的这些数据都丢失了。另外，如果数据被修改，每次复制的过程都会制造两份内存，内存占用就是之前的两倍了。</li>
</ul>
<p><img alt="RDB生成文件写时复制过程" loading="lazy" src="https://oss.swimmingliu.cn/dd17eb2f-f8f8-11ef-858e-c858c0c1deba"></p>
<p><strong>【AOF 日志文件生成过程】</strong></p>
<p><code>AOF</code> 是通过把Redis的每个写操作追加到日志文件 <code>appendonly.aof</code> 实现持久化的方式。Redis每次重启时,会重放日志文件的命令来恢复数据。口诀：先写内存，再写日志， 过大重写。</p>
<ol>
<li><strong>先写内存</strong>：每次写操作都会被写入内存的<code>AOF</code>缓冲当中</li>
<li><strong>再写日志</strong>：然后从<code>AOF</code> 缓冲中同步到磁盘 (三种写回策略)</li>
<li><strong>过大重写</strong>：当<code>AOF</code> 文件过大的时候，Redis会触发<code>AOF</code> 重写，将冗余命令合并，生成新的<code>AOF</code> 文件</li>
</ol>
<p><strong>【注意】</strong> 先写内存，再存日志可以避免额外的检查开销 (只存执行成功的指令)，而且不会阻塞当前操作，指令只想成功后，才将命令记录到<code>AOF</code>日志文件。但是如果还没写完<code>AOF</code> 文件就宕机了，会导致数据丢失。执行写命令和记录到日志都是主线程操作，可能会造成阻塞风险。</p>
<table>
  <thead>
      <tr>
          <th>写会策略配置</th>
          <th>写回时机</th>
          <th>作用</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>always</code></td>
          <td>同步写回</td>
          <td>每次都<code>fsync</code> 同步数据到磁盘，性能最低。如果写入<code>AOF</code>文件期间Redis宕机，则无法通过<code>AOF</code> 进行恢复</td>
      </tr>
      <tr>
          <td><code>everysec</code></td>
          <td>每秒写回</td>
          <td>每秒调用一次<code>fsync</code>写回磁盘，安全和性能居中，Redis最多丢<code>1s</code>的数据</td>
      </tr>
      <tr>
          <td><code>no</code></td>
          <td>操作系统决定写回时间</td>
          <td>性能高，安全性低</td>
      </tr>
  </tbody>
</table>
<p><img alt="AOF生成过程" loading="lazy" src="https://oss.swimmingliu.cn/dd40a4cc-f8f8-11ef-b47e-c858c0c1deba"></p>
<p><strong>【AOF重写机制】</strong> 当Redis检测到<code>AOF</code> 文件过大的时候，会触发<code>AOF</code> 重写机制</p>
<ol>
<li><strong>创建子进程</strong>：Redis通过<code>BGREWRITEAOF</code>命令创建一个子进程来进行<code>AOF</code> 重写</li>
<li><strong>生成新<code>AOF</code> 文件</strong>：子进程基于当前数据库状态，将每个键的最新值转换为写命令，并写入<code>AOF</code>文件</li>
<li><strong>处理新写入的命令</strong>：重写期间，把客户端新的写操作同时追加到现有的<code>AOF</code>文件和缓存区的<code>AOF</code>重写缓冲里面</li>
<li><strong>合并新的写入指令</strong>：子进程完成<code>AOF</code>文件重写之后，需要确保<code>AOF</code>文件当中的写操作都是最新的。</li>
<li><strong>替换旧的<code>AOF</code> 文件</strong>： 最后用新的<code>AOF</code>文件替换旧的<code>AOF</code>文件</li>
</ol>
<p>**【MP-AOF】**Redis 7.0 采用 <code>Multi-Part Append Only File</code> 解决 <code>AOF</code> 当中的内存开销大(<code>AOF  </code> 缓存和<code>AOF</code> 重写缓存包含大量重复数据)、CPU开销大(主进程需要耗时将数据写入<code>AOF </code>重写缓存，然后传给子进程，子进程要耗时把<code>AOF</code> 重写缓存写入新的<code>AOF</code> 文件)、磁盘开销大(同一份数据会被写入两次，一次写入当前<code>AOF</code>文件，另一次写入新<code>AOF</code> 文件)。其处理过程如下：</p>
<p>将一个<code>AOF</code>文件拆分成多个文件</p>
<ul>
<li>一个基础文件 <code>basefile</code>, 代表数据的初始快照</li>
<li>一个增量文件 <code>incremental files</code>，记录自基础文件创建以来的所有写操作， 可以有多个该文件</li>
<li>基础文件和增量文会放到一个单独的目录中，并且由一个清单文件 <code>manifest file</code> 进行统一跟踪和管理</li>
</ul>
<p>该方案可以避免写入多个和<code>AOF</code>相关的缓存，子进程独立写基础<code>AOF</code>文件，进程之间无交互，不用切换上下文。</p>
<p><img alt="MP-AOF执行过程" loading="lazy" src="https://oss.swimmingliu.cn/dd568385-f8f8-11ef-a237-c858c0c1deba"></p>
<p><strong>【为什么Redis需要持久化】</strong> Redis是基于内存的数据库，所有数据存储在内存里面。如果Redis发生了宕机事件，内存中的数据就会全部丢失。为了保证数据的安全，Redis采用持久化机制，让数据保存在磁盘中，方便宕机后进行恢复。如果没有持久化机制，Redis需要从数据库(MySQL)当中恢复数据, 可能会出现下面的问题：</p>
<ol>
<li>**性能瓶颈 + 恢复缓慢 **：后端数据库无法向Redis一样快速提供数据。如果数据量比较大，恢复就会变得非常缓慢。</li>
<li><strong>系统压力</strong>：恢复的过程比较久，就会给数据库带来很大压力，影响其他的业务。</li>
</ol>
<h2 id="6-redis集群会出现脑裂问题吗">6. Redis集群会出现脑裂问题吗？<a hidden class="anchor" aria-hidden="true" href="#6-redis集群会出现脑裂问题吗">#</a></h2>
<ol>
<li>
<p><strong>脑裂定义</strong>: 在网络分区的情况下，Redis同一个集群的实例当中出现多个主节点，导致数据不一致。</p>
</li>
<li>
<p><strong>脑裂发生的原因</strong>：比如当前集群实例是一主+两从的模式，当网络发送分区，分为A区和B区。主节点(原)被分到A区,其他节点和哨兵集群都在B区。哨兵机制无法检测到A区的原主节点, 只能重新选取新的主节点(新)。此时，集群当中就有两个主节点，A区的主节点(原)被写入的新数据不会同步到B区的节点上。会出现数据不一致的情况。</p>
</li>
<li>
<p><strong>如何避免脑裂</strong>：<code>min-slaves-to-write</code> 主节点写操作所要求有效从节点个数、<code>min-slaves-max-lag</code> 从节点的最大延迟。比如 <code>min-slaves-to-write = 3</code> 和<code>min-slaves-max-lag = 10</code>  表明需要至少3个延时低于10s的从节点才可以接受写操作。</p>
<p>【注意】脑裂并不能够完全避免，比如说在选举主节点的过程中，主节点(原)突然恢复了，然后发现主节点和从节点的延迟都不超过10s，客户端正常在主节点(原)进行写操作。等选举完毕，选出新的主节点，让主节点(原) slaveof 为从节点。选举时间写入的数据会被覆盖，就出现了数据不一致的现象。</p>
</li>
</ol>
<h2 id="7-redis如何实现分布式锁">7. Redis如何实现分布式锁？<a hidden class="anchor" aria-hidden="true" href="#7-redis如何实现分布式锁">#</a></h2>
<ol>
<li>
<p><strong>分布式锁原理</strong>：Redis分布式锁由<code>set ex nx</code> 和 <code>lua</code> 脚本组成，分别对应加锁和解锁操作</p>
</li>
<li>
<p><strong>为什么用 <code>set ex nx</code></strong>：某个进程对指定key执行 <code>set nx</code> 之后， 返回值为1，其他进程想要对相同的key获取锁，会发现key已存在，返回值为0。这样就是实现了上锁的操作。但是，如果A进程上完锁突然挂了，其他进程就永远不可能拿到锁。所以，设置一个<code>ex</code>过期时间，让其不要一直占用着锁。</p>
<p>【注意】<code>set ex nx</code>设置value的时候，必须采用唯一值，比如<code>uuid</code>。 不然可能出现如下情况:</p>
<ol>
<li>A进程正常申请锁，值设为1。</li>
<li>A进程上锁后, 执行过程时间比较长, 以至于锁已经过期了, A进程还没执行完.</li>
<li>此时，B进程申请锁，值也设为1. 同时，A进程执行完毕, 使用<code>lua</code>脚本把锁删除了</li>
<li>B进程此时还在执行程序，一脸懵逼。（不是，哥们儿，我锁呢？谁偷了我的锁！！！）</li>
</ol>
</li>
<li>
<p><strong>为什么用 <code>lua</code> 进行解锁</strong>：如上述注意事项所说的一样，A进程执行完毕之后, 会删除锁. 假如他们的值都采用了<code>uuid</code>保证了唯一性。可能会出现下面的情况</p>
<ul>
<li>A进程先判断key和其值是否为对应的<code>uuid</code>，然后再删除锁.</li>
<li>A进程准备删除锁之前, 锁过期了. B进程同时获取了锁</li>
<li>A进程再删除了该锁 (B进程申请的锁)，发生了误删的现象</li>
</ul>
<p>所以需要用<code>lua</code>脚本保证解锁的原子性，就可以避免上述问题</p>
</li>
</ol>
<h2 id="8-redis的red-lock是什么你了解吗">8. Redis的Red Lock是什么？你了解吗?<a hidden class="anchor" aria-hidden="true" href="#8-redis的red-lock是什么你了解吗">#</a></h2>
<ol>
<li><strong>Red Lock定义</strong>: 一种分布式锁的实现方案，主要用于解决分布式环境中使用Redis分布式锁的安全性问题</li>
<li><strong>为什么用Red Lock</strong>: 假如我们采用一主+两从+哨兵方式部署Redis，如果有A进程在使用分布式锁的过程当中，主节点发送了主从更换，但是原主节点的锁信息不一定同步到新主节点上。所以当前新主节点可能没有锁信息，此时另外的B进程去获取锁，发现锁没被占，成功拿到锁并执行业务逻辑。此时两个竞争者（A和B进程）会同时操作临界资源，会出现数据不一致的情况。</li>
<li><strong>Red Lock实现原理</strong> : 假如当前有五个实例，不需要部署从节点和哨兵，只需要主节点。注意当前的五个实例之间没有任何关系，不进行任何的信息交互 (不同于Redis Cluster集群模式)。对五个实例依次申请上锁，如果最终申请成功的数量超过半数(大于总数/2 + 1)，则表明红锁申请成功。按照下面的流程进行操作：
<ol>
<li>客户端获取当前时间 <code>t1</code></li>
<li>客户端依次对五个实例进行<code>set ex nx</code> 操作，锁的过期时间为 <code>t_lock</code> (远小于锁的总过期事件)。如果当前节点请求超时，则立马请求下一个节点。</li>
<li>当获取的锁超过半数，则获取当前的时间 <code>t2</code>。获取锁的过程总耗时<code>t = t2 - t1</code>。如果<code>t</code>小于锁的过期时间 <code>t_lock</code>，则可以判断为加锁成功，否则加锁失败。</li>
<li>加锁成功，则执行业务逻辑。若加锁失败，则依次释放所有节点的锁。</li>
</ol>
</li>
</ol>
<p><img alt="Redis的RedLock结构图" loading="lazy" src="https://oss.swimmingliu.cn/2bdcd99d-f187-11ef-b6b9-c858c0c1deba"></p>
<ol start="4">
<li>
<p><strong>Red Lock是否安全</strong>：先说结论，不一定安全</p>
<p>当前有两个客户端(<code>Client1</code> 和 <code>Client2</code>)，首先<code>Client1</code> 正常获取锁，然后突然被<code>GC</code>执行垃圾回收机制了。在<code>GC</code>的过程当中，<code>Client1</code> 的锁超时释放了，<code>Client2</code>开始申请并获得锁。然后<code>Client2</code> 写入数据并释放锁。 后面<code>Client1</code> 在<code>GC</code> 结束之后又写入数据， 此时就出现了数据不一致的情况。</p>
</li>
</ol>
<p><img alt="Redis的RedLock安全问题" loading="lazy" src="https://oss.swimmingliu.cn/2c131f31-f187-11ef-8c21-c858c0c1deba"></p>
<h2 id="9-说说-redisson-分布式锁的原理">9. 说说 Redisson 分布式锁的原理?<a hidden class="anchor" aria-hidden="true" href="#9-说说-redisson-分布式锁的原理">#</a></h2>
<p><strong>【Redisson分布式锁定义】</strong></p>
<p>Redisson分布式锁是一种基于Redis实现的分布式锁，利用Redis的原子性操作来确保多线程、多进程或多节点系统中，只有一个线程能够获得锁。避免并发操作导致的数据不一致问题。</p>
<p>主要可以分为四个部分来讲：<strong>锁的获取</strong>、<strong>锁的续期</strong>、<strong>可重入锁</strong>、<strong>锁的释放</strong></p>
<p><strong>【锁的获取】</strong></p>
<ol>
<li>执行 <code>exist</code> ，判断锁是否存在
<ul>
<li>若存在 ，判断唯一标识是否对应。若唯一标识相同 -&gt; 第 3 步 ; 若不同，说明当前锁别其他进程占用  -&gt; 第2 步</li>
<li>若不存在 ，直接 <code>tryLock()</code> 上锁 -&gt; 第 3 步</li>
</ul>
</li>
<li>使用<code>pttl</code>查询锁剩余的过期时间，后续可以再次获取</li>
<li>执行<code>hincrby</code>，设置重入计数为<code>1</code> （可重入锁才有这一步操作）</li>
<li>执行<code>pexpire</code>， 设置锁的过期时间 （为了防止任务还没执行完，锁就过期了。Redisson实现了用看门狗机制来为锁进行自动续期）</li>
</ol>
<p><strong>【可重入锁】</strong></p>
<p>一般是在线程已经获取锁的基础上，为了后续还能拿到锁。因为假如<code>increment()</code>和<code>anotherMethod</code>都需要用到<code>Counter</code>锁。当<code>increment()</code>拿到锁之后，又调用<code>anotherMethod()</code>又需要获取锁。如果不能二次获取锁，那就陷入死锁了。所以，Redisson才搞了可重入锁</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-java" data-lang="java"><span class="line"><span class="cl"><span class="kd">public</span><span class="w"> </span><span class="kd">class</span> <span class="nc">Counter</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">private</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">count</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">0</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">public</span><span class="w"> </span><span class="kd">synchronized</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">increment</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">count</span><span class="o">++</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">anotherMethod</span><span class="p">();</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">public</span><span class="w"> </span><span class="kd">synchronized</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">anotherMethod</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c1">// 可以再次获取相同的锁</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">count</span><span class="o">++</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></div><p>可重入锁是在获取锁的基础上，多了一层逻辑。具体实现如下：</p>
<ol>
<li>实现锁的获取的所有功能</li>
<li>执行<code>hexist</code> 判断是否锁已经存在，且唯一标识匹配(线程id相关)，所以不能直接用<code>exist</code>判断锁是否存在</li>
<li>如果自己的锁存在，用<code>hincrby</code>把重入次数加一</li>
<li>用<code>pexpire</code>，设置锁的过期时间</li>
<li>如果没有获取成功锁，就和上面一样，用<code>pttl</code>查询锁的过期剩余时间</li>
</ol>
<p><strong>【锁的释放】</strong></p>
<ol>
<li>用<code>hexist</code>判断线程自己的锁是否存在，需要判断唯一标识
<ul>
<li>如果存在 -&gt; 第2步</li>
<li>如果不存在 -&gt; 直接返回，不需要做解锁操作，因为是别人的锁</li>
</ul>
</li>
<li>用<code>hincry</code>减少一次锁的可重入次数 (增加<code>-1</code> 就是减少一次)</li>
<li>判断锁的可重入次数是否大于 <code>0</code>
<ul>
<li>如果大于 <code>0</code>， 说明还有函数在使用这个锁，则重新设置过期时间</li>
<li>如果等于 <code>0</code> -&gt; 第4步</li>
</ul>
</li>
<li>用 <code>del</code> 删除对应的key</li>
<li>用 <code>publish</code> 广播通知其他等待锁的进程，此时释放锁了</li>
</ol>
<p><img alt="Redisson分布式锁" loading="lazy" src="https://oss.swimmingliu.cn/843994be-f4b5-11ef-9fba-c858c0c1deba"></p>
<p><strong>【Redisson锁的类型】</strong></p>
<ul>
<li><strong>公平锁</strong>：和可重入锁类似，确保多个线程按请求顺序获得锁</li>
<li><strong>读写锁</strong>: 支持读写分离，多个线程同时获得读锁，而且锁是独占的</li>
<li><strong>信号量与可数锁</strong>: 允许多个线程同时持有锁，适用于资源的限流和控制。</li>
</ul>
<h2 id="10-redisson-看门狗watch-dog机制了解吗">10. Redisson 看门狗（watch dog）机制了解吗？<a hidden class="anchor" aria-hidden="true" href="#10-redisson-看门狗watch-dog机制了解吗">#</a></h2>
<p><strong>【为什么用看门狗机制】</strong></p>
<p>因为如果进程获取锁之后，用户的业务逻辑还没有执行完成，锁就过期了。此时，其他进程抢占临界资源，会导致数据不一致的问题。</p>
<p><strong>【看门口机制的执行流程】</strong></p>
<ol>
<li>判断用户是否设置过期时间 (判断 <code>leaseTime &gt; 0</code> ，默认 <code>leaseTime</code> 为 <code>-1</code> )
<ul>
<li>如果设置了过期时间，不启用看门狗机制，等到指定的过期时间，锁自动释放。</li>
<li>如果没有设置过期时间 -&gt; 第2步</li>
</ul>
</li>
<li>Redssion会启动一个定时任务，用于自动续期锁的过期时间。</li>
<li>定时任务中，设置锁的超时时间默认为<code>30s</code>， 每间隔总时长的<code>1/3</code>，也就是<code>10s</code>。定时任务会自动锁进行续期，续期时间为<code>30s</code></li>
<li>当客户端主动释放锁，那么Redisson就会取消看门狗机制。</li>
</ol>
<p>【注意】 如果客户端主动释放锁之前，服务器突然宕机了，定时任务没法儿继续执行。等看门狗机制设置的过期时间到了，锁就自动释放了。所以，不会出现一直占用锁的情况。</p>
<p><img alt="Redisson分布式锁执行流程" loading="lazy" src="https://oss.swimmingliu.cn/846a0583-f4b5-11ef-964d-c858c0c1deba"></p>
<h2 id="11-redis-实现分布式锁时可能遇到的问题有哪些">11. Redis 实现分布式锁时可能遇到的问题有哪些？<a hidden class="anchor" aria-hidden="true" href="#11-redis-实现分布式锁时可能遇到的问题有哪些">#</a></h2>
<ol>
<li>
<p><strong>业务未执行完，锁提前到期</strong>：用户的业务逻辑还没执行完毕，锁提前过期了。被其他的进程获取了锁，同时抢占临界资源，可能出现数据不一致的情况。</p>
<p>【解决方法】</p>
<p>通常要保证用户的业务逻辑需要在锁过期之前执行完，因此需要把锁的过期时间稍微设大一些。也不能太大，这样其他程序就拿不到锁，就会降低系统的整体性能。或者使用Redisson分布式锁，会自动调用看门狗机制，定时续期锁，直到任务执行完毕，就不续期锁了。</p>
</li>
<li>
<p><strong>单点故障问题</strong>：如果只部署了一个Redis节点，当实例宕机或者不可用的时候。整个分布式锁服务将无法完成工作，阻塞业务的正常执行。</p>
<p>【解决方法】</p>
<p>可以利用Redis Cluster集群机制，部署多个Redis实例，采用一主+两从的哨兵机制。当某个实例宕机时, 哨兵会自动选举新的有效节点作为主节点。</p>
</li>
<li>
<p><strong>主从同步但锁未同步问题</strong>：主从复制的过程是异步实现的，如果Redis主节点获取到锁，但是还没同步到从节点。此时，主节点突然宕机，然后哨兵选择新的主节点。但是，由于主从同步没有完成，现在其他客户端可以正常获取锁。就会导致多个应用同时获取锁，会出现数据不一致的问题。</p>
</li>
<li>
<p><strong>网络分区问题</strong>：在网络不稳定的情况下，客户端和Redis可能会中断再重连。如果没有设置锁的过期时间，那么可能导致锁无法正常释放。如果有多个锁，可能还会引发死锁的现象。</p>
<p>【多锁死锁现象】</p>
<ul>
<li>
<p>有两个资源A和B，分别由锁LockA和LockB保护。</p>
</li>
<li>
<p>客户端1先获取LockA，然后尝试获取LockB。</p>
</li>
<li>
<p>客户端2先获取LockB，然后尝试获取LockA</p>
</li>
</ul>
<p>如果客户端1拿到了LockA，客户端2拿到了LockB。突然网络不稳定，锁无法正常释放。然后客户端1等待LockB，客户端2等待LockA，就会形成死锁。</p>
</li>
<li>
<p><strong>时钟漂移问题</strong>：因为Redis分布式锁依赖锁的过期时间来判断是否过期，如果出现时钟漂移，很可能导致锁直接失效。</p>
<p>【解决方法】</p>
<p>让所有节点的系统时钟从NTP服务进行同步，减少时钟漂移的影响。</p>
</li>
<li>
<p><strong>可重入问题</strong>：某个进程可能有多次调用锁，如果锁不能重入的话。当进程获取到锁后，再次申请获取锁，获取不到就死锁了。</p>
</li>
</ol>
<h2 id="12-redis为什么这么快">12. Redis为什么这么快?<a hidden class="anchor" aria-hidden="true" href="#12-redis为什么这么快">#</a></h2>
<ol>
<li><strong>基于内存</strong>: Redis存储的所有数据都存在内存里面，内存的访问速度比硬盘快，提升了读写速度</li>
<li><strong>单线程模型 + I/O多路复用</strong>： Redis采用单线程+I/O多路复用的方式，避免了线程上下文切换和竞争条件，提高了并发处理效率</li>
<li><strong>高效数据结构</strong>：提供<code>String</code>、<code>List</code>、<code>Hash</code>、<code>Set</code>、<code>Sorted Set</code> 五种数据结构，他们的操作复杂度大部分为O(1)</li>
<li><strong>异步持久化</strong>: 持久化操作由子线程异步完成，减少了持久化对主线程的影响，提升了整体性能。</li>
</ol>
<p>【注意】Redis从6.0开始对网络处理引入了多线程机制，提高I/O性能。网络请求可以并发处理，减少网络I/O等待的影响。但是，Redis 仍然保持了<strong>核心命令处理逻辑的单线程特性</strong>。</p>
<p><strong>【I/O多路复用技术】</strong></p>
<ul>
<li>Linux多路复用技术允许多个进程的I/O注册到同一管道和内核交互，准备好数据之后再copy到用户空间，实现一个线程处理多个I/O流。</li>
<li>Linux下I/O多路复用有<code>select</code>、<code>poll</code>、<code>epoll</code> 三种，功能类似，细节不同</li>
</ul>
<h2 id="13-为什么-redis-设计为单线程60-版本为何引入多线程">13. 为什么 Redis 设计为单线程？6.0 版本为何引入多线程？<a hidden class="anchor" aria-hidden="true" href="#13-为什么-redis-设计为单线程60-版本为何引入多线程">#</a></h2>
<p><strong>【Redis采用单线程的原因】</strong></p>
<ol>
<li>基于内存操作，Redis的瓶颈主要是内存，多数操作的性能瓶颈不是CPU带来的 (增加多线程也没啥用)</li>
<li>单线程模型的代码简单，可以减少线程上下文切换的性能开销。</li>
<li>单线程结合I/O多路复用模型，能提高I/O利用率</li>
</ol>
<p><strong>【注意】</strong> Redis的单线程是指<strong>网络请求</strong>模块和<strong>数据操作</strong>模块是<strong>单线程</strong>的, 但是<strong>持久化存储</strong>模块和<strong>集群支撑</strong>模块是<strong>多线程</strong>的。</p>
<p><strong>【为什么引入多线程】</strong></p>
<p>随着数据规模和请求量的增加，执行瓶颈主要在网络I/O部分。引入多线程可以提高网络I/O的速度。但是，Redis内核去还是保持单线程处理，比如读写命令部分还是单线程，所以线程安全问题就不存在了。</p>
<p><strong>【Redis多线程I/O场景下的结构】</strong></p>
<p><img alt="Redis多线程IO场景下的结构" loading="lazy" src="https://oss.swimmingliu.cn/34a92269-f63f-11ef-b381-c858c0c1deba"></p>
<h2 id="14-如何使用redis快速实现布隆过滤器">14. 如何使用Redis快速实现布隆过滤器?<a hidden class="anchor" aria-hidden="true" href="#14-如何使用redis快速实现布隆过滤器">#</a></h2>
<p>Redis可以使用位图<code>Bitmap</code>或者用Redis模块<code>RedisBloom</code>来实现布隆过滤器</p>
<ol>
<li><strong>位图 <code>bitmap</code> 实现</strong>
<ul>
<li>bitmap 本质是一个位数组，提供了<code>setbit</code>和<code>getbit</code>来设置和获取某个值，可以用来标识某个元素是否存在</li>
<li>对应给定的key，可以用哈希函数来计算位置索引。如果位图中的值为<code>1</code>， 表示该元素可能存在</li>
</ul>
</li>
<li><strong><code>RedisBloom</code> 模块实现</strong>：封装了哈希函数和位图大小，可以直接用于创建和管理布隆过滤器</li>
</ol>
<p><strong>【布隆过滤器原理】</strong></p>
<p>布隆过滤器是由<strong>一个位数组+k个独立的哈希函数</strong>组成。每次验证某个key对应的数据是否存在的时候，需要k个哈希函数都对其进行运算，如果位数组中的值都为<code>1</code>，说明该key对应的数据可能存在。只要有一个位置不为<code>1</code>， 就说明key对应的数据一定不存在。</p>
<p>为什么k个函数查到的值都为<code>1</code>， 也不能说明key对应的数据一定存在呢？</p>
<p>因为可能存在哈希冲突，比如<code>key</code> 和 <code>key1</code> 的k个hash函数的值都为<code>1</code>。但是<code>key</code>对应的数据在数据库里面，但是<code>key1</code>的数据不在数据库里面。</p>
<p><img alt="布隆过滤器hash冲突" loading="lazy" src="https://oss.swimmingliu.cn/848e3fbb-f4b5-11ef-80c9-c858c0c1deba"></p>
<h2 id="15-redis-中常见的数据类型有哪些">15. Redis 中常见的数据类型有哪些？<a hidden class="anchor" aria-hidden="true" href="#15-redis-中常见的数据类型有哪些">#</a></h2>
<p><strong>【Redis常见的五种数据结构】</strong></p>
<table>
  <thead>
      <tr>
          <th>数据结构名称</th>
          <th>底层</th>
          <th>特性</th>
          <th>适用场景</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>String</strong></td>
          <td><code>SDS</code> 简单动态字符串</td>
          <td>String字符串</td>
          <td>1.<strong>缓存数据</strong>：缓存Session、Token、序列化后的对象<br />2. <strong>分布式锁</strong>:<code>set ex nx</code><br />3.<strong>计数</strong>：用户单位时间访问次数，页面单位时间访问次数</td>
      </tr>
      <tr>
          <td><strong>List</strong></td>
          <td><code>ListPack</code> / <code>QuickList</code> / <code>ZipList</code> / <code>LinkedList</code></td>
          <td>双向有序链表，各节点都包含字符串</td>
          <td>1. <strong>信息流展示</strong>：历史记录、更新文章、更新动态<br />2.<strong>消息队列</strong>：不推荐，缺陷多</td>
      </tr>
      <tr>
          <td><strong>Hash</strong></td>
          <td><code>Dict</code> / <code>ZipList</code></td>
          <td>无序散列表，存储键值对</td>
          <td><strong>存储信息</strong>：用户、商品、文章、购物车信息</td>
      </tr>
      <tr>
          <td><strong>Set</strong></td>
          <td><code>Dict</code> / <code>Intset</code></td>
          <td>无序去重集合，包含不同的字符串</td>
          <td>1.<strong>不重复数据</strong>：点赞次数、下单次数<br />2.<strong>共同资源</strong>：共同好友、统统粉丝、共同关注 (交集、并集)<br />3.<strong>随机抽取</strong>: 抽奖系统、随机点名</td>
      </tr>
      <tr>
          <td><strong>ZSet</strong></td>
          <td><code>ZipList</code> / <code>SkipList</code> 跳表 + <code>HashTable</code>哈希表</td>
          <td>有序集合，<code>value</code>包含<code>member</code> 成员和<code>score</code>分数，按照<code>score</code> 进行排序</td>
          <td>1.<strong>各类排行榜</strong>：点赞排行版、热门话题排行榜<br />2. <strong>优先级/重要程度</strong>: 优先级队列</td>
      </tr>
  </tbody>
</table>
<p><strong>【其他数据结构】</strong></p>
<table>
  <thead>
      <tr>
          <th>数据结构名称</th>
          <th>特性</th>
          <th>适用场景</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>BitMap</strong></td>
          <td>存储二进制数据，<code>0</code> 和<code>1</code></td>
          <td>1. <strong>布隆过滤器</strong>： 防止缓存穿透<br />2. <strong>签到统计</strong>： 每日签到用 <code>1</code> 标记，未签到用<code>0</code>标记，可以快速统计某日签到人数和连续签到天数</td>
      </tr>
      <tr>
          <td><strong>HyperLogLog</strong></td>
          <td>基于概率算法实现，存储海量数据进行计数统计</td>
          <td>一般用于页面的页面浏览量<code>PV</code>和独立访客数<code>UV</code>， 快速估算访问量</td>
      </tr>
      <tr>
          <td><strong>GEO</strong></td>
          <td>存储地理位置信息，经纬度坐标和位置名称</td>
          <td>一般用于计算不同位置的距离，比如外卖单中计算配送距离</td>
      </tr>
      <tr>
          <td><strong>Stream</strong></td>
          <td>能够生成全局唯一消息id的消息队列</td>
          <td>用于可靠消息传递、异步任务处理的场景</td>
      </tr>
  </tbody>
</table>
<h2 id="16-redis-中如何保证缓存与数据库的数据一致性">16. Redis 中如何保证缓存与数据库的数据一致性？<a hidden class="anchor" aria-hidden="true" href="#16-redis-中如何保证缓存与数据库的数据一致性">#</a></h2>
<p>为了保证缓存和数据库的数据一致性，有这么几种方案：</p>
<ol>
<li>
<p><strong>先修改缓存，再修改数据库</strong></p>
<ul>
<li>事务A准备修改指定id的 <code>name</code> 为 <code>小张</code> ，先修改缓存</li>
<li>事务B准备修改指定id的 <code>name</code> 为 <code>小王</code>，先修改缓存, 然后修改数据库为<code>小王</code></li>
<li>事务A修改数据库为 <code>小张</code> (网络延迟)， 此时出现数据不一致的情况</li>
</ul>
</li>
<li>
<p><strong>先修改数据库，再修改缓存</strong></p>
<ul>
<li>事务A准备修改指定id的 <code>name</code> 为 <code>小张</code> ，先修改数据库</li>
<li>事务B准备修改指定id的 <code>name</code> 为 <code>小王</code>，先修改数据库, 然后修改缓存为<code>小王</code></li>
<li>事务A修改缓存为 <code>小张</code> (网络延迟)， 此时出现数据不一致的情况</li>
</ul>
</li>
<li>
<p><strong>先删除缓存，再修改数据库</strong></p>
<ul>
<li>
<p>事务B读取指定id的<code>name</code>， 发现找不到缓存，读取数据库中的数据为<code>小王</code></p>
</li>
<li>
<p>事务A准备修改指定id的 <code>name</code> 为 <code>小张</code> ，先删除缓存，然后修改数据库为 <code>小张</code></p>
</li>
<li>
<p>事务B修改缓存为<code>小王</code> (读到空数据，返回来写)，此时出现数据不一致的情况</p>
</li>
</ul>
</li>
<li>
<p><strong>先修改数据库，再删除缓存</strong>：基本不会出现问题 （除非删除缓存的请求失败）</p>
</li>
<li>
<p><strong>延迟双删，先删除缓存，再修改数据库，再删除缓存</strong>： 难以评定休眠时间</p>
</li>
</ol>
<p>如果要保证数据库和缓存的强一致性怎么办？</p>
<ol>
<li><strong>用消息队列</strong>：把写策略里面的删除缓存操作加入到消息队列中，让消费者来操作数据。如果删除失败，则可以冲消息队列中重新读取，在一定重试次数下删除成功的话，将该消息删除。 （确保删除缓存成功）</li>
<li><strong><code>binlog</code> + <code>Canal</code></strong>: 模仿MySQL主从同步的方式，结合<code>Canal</code> 订阅MySQL的<code>binlog</code>。其实就是等MySQL写入数据库, 然后去删除缓存。</li>
</ol>
<p><img alt="Canal和binlog确保缓存和数据库一致" loading="lazy" src="https://oss.swimmingliu.cn/34cc84c8-f63f-11ef-a5a6-c858c0c1deba"></p>
<p>如果需要避免缓存失效 (比如热点Key), 如何设计呢?</p>
<ol>
<li><strong>分布式锁</strong>：同一时间只允许一个请求更新缓存，确保缓存和数据库一致。但是，可能会降低写性能</li>
<li><strong>添加短暂过期时间</strong>：在先修改数据库再修改缓存的基础上，给缓存加一个短暂的过期时间，确保缓存不一致的情况时间比较少。</li>
</ol>
<p><img alt="添加短过期时间确保缓存和数据库一致" loading="lazy" src="https://oss.swimmingliu.cn/34e3f1bb-f63f-11ef-90ef-c858c0c1deba"></p>
<h2 id="17-redis-中跳表的实现原理是什么">17. Redis 中跳表的实现原理是什么？<a hidden class="anchor" aria-hidden="true" href="#17-redis-中跳表的实现原理是什么">#</a></h2>
<p>跳表是由多层链表组成的，它是Redis中 <code>ZSet</code> 的底层结构。最底层存所有的元素，上层是下层的子集 (可以理解成一种索引)。跳表的插入、删除、查找操作，实现方式如下：</p>
<ul>
<li><strong>查找</strong>：从最高层开始，通过范围确定位置，逐层向下查找，时间复杂度为 <code>O(log n)</code></li>
<li><strong>插入</strong>：从最高层开始，先逐层向下找到存放位置，然后随机确定新节点层数，插入并更新指针</li>
<li><strong>删除</strong>：从最高层开始，通过范围确定位置，在各层更新指针保持结构</li>
</ul>
<p><strong>【Redis跳表结构】</strong></p>
<p>Redis的跳表相对于普通的跳表多了一个回退指针, 而且 <code>score</code> 是可以重复的。</p>
<p>首先，我们可以看一下跳表的节点实现的原理</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="k">typedef</span> <span class="k">struct</span> <span class="nc">zskiplistNode</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//Zset 对象的元素值
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">sds</span> <span class="n">ele</span><span class="p">;</span> <span class="c1">// 采用Redis字符串底层实现sds,用于存储数据
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//元素权重值
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">double</span> <span class="n">score</span><span class="p">;</span> 
</span></span><span class="line"><span class="cl">    <span class="c1">//后退指针
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">struct</span> <span class="nc">zskiplistNode</span> <span class="o">*</span><span class="n">backward</span><span class="p">;</span> <span class="c1">// 用于指向前一个节点
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//节点的level数组，保存每层上的前向指针和跨度
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">struct</span> <span class="nc">zskiplistLevel</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">struct</span> <span class="nc">zskiplistNode</span> <span class="o">*</span><span class="n">forward</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">span</span><span class="p">;</span> <span class="c1">// 当前层的跨度值
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">}</span> <span class="n">level</span><span class="p">[];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span> <span class="n">zskiplistNode</span><span class="p">;</span>
</span></span></code></pre></div><p><img alt="Redis跳表的-数据结构版本" loading="lazy" src="https://oss.swimmingliu.cn/dd6c724e-f8f8-11ef-b3e8-c858c0c1deba"></p>
<p>上面的图片看起来比较抽象，可以按照下面的图片进行理解。上述的<strong>查找、删除、插入操作</strong>，其实都是先从<code>level[0]</code> 开始进行遍历，然后找到合适的位置。再往下进入<code>level[1]</code>进行遍历，再找到合适的位置。一直重复这个操作，直到进入最底层，然后就可以确定位置了。</p>
<p><img alt="Redis跳表的结构" loading="lazy" src="https://oss.swimmingliu.cn/dd7e3c46-f8f8-11ef-8d73-c858c0c1deba"></p>
<p>然后，我们来看一下跳表的底层实现原理</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">typedef</span> <span class="k">struct</span> <span class="nc">zskiplist</span><span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">struct</span> <span class="nc">zskiplistNode</span> <span class="o">*</span><span class="n">header</span><span class="p">,</span> <span class="o">*</span><span class="n">tail</span><span class="p">,</span> <span class="c1">// 头节点和尾节点
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">length</span><span class="p">,</span>	<span class="c1">// 跳表长度
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kt">int</span> <span class="n">level</span><span class="p">;</span> <span class="c1">// 跳表的最大层数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span> <span class="n">zskiplist</span><span class="p">;</span>
</span></span></code></pre></div><p>【注意】跳表的头节点、尾节点、跳表长度、跳表的最大层数都可以在o(1)时间复杂度进行访问</p>
<p><strong>【跳表查询过程细节】</strong></p>
<ol>
<li>从头节点的最高层开始，逐一遍历每一层</li>
<li>遍历某一层节点时，根据节点的 <code>SDS</code> 类型元素和元素权重进行判断
<ul>
<li>如果当前节点权重 <code>&lt;</code> 要查找的权重， 继续向前遍历</li>
<li>如果当前节点权重 <code>=</code> 要找的权重 &amp;&amp; 当前节点的 <code>SDS</code> 类型数据 <code>&lt;</code> 要查找的数据，继续向前遍历</li>
<li>如果上面两个条件都不满足或者下一个节点为空，则跳到下一层<code>level</code>数组里面，继遍历续查找</li>
<li>如果当前当前节点权重 <code>=</code> 要找的权重 &amp;&amp; 当前节点的 <code>SDS</code> 类型数据 <code>=</code> 要查找的数据， 返回当前节点值，查询结束</li>
</ul>
</li>
</ol>
<p><img alt="Redis跳表查询过程" loading="lazy" src="https://oss.swimmingliu.cn/dd94647c-f8f8-11ef-aa51-c858c0c1deba"></p>
<p><strong>【跳表的插入细节】</strong></p>
<ol>
<li><strong>参数检查和初始化</strong>：检查要插入的节点的<code>score</code>是否为<code>NaN</code>，初始化遍历指针<code>x</code>指向跳表的头节点，定义<code>update</code> 数组记录每层查找的最右节点 (后续要修改它的指针)，<code>rank</code> 数组记录每层跨越的节点数。</li>
<li><strong>查找插入位置</strong>：和上面查找过程一样，从最高层开始，逐层往下查询。每一层中，把满足条件的最右节点记录在 <code>update</code> 数组中，并更新 <code>rank</code> 数组记录跨越的节点数。</li>
<li><strong>生成新节点层数</strong>：调用<code>zsRandomLevel</code> 函数生新节点的随机层数。如果新节点层数 <code>&gt;</code> 当前跳表总层数，则更新跳表最大层数，并初始化新增层的<code>update</code> 和 <code>rank</code> 数组数据。</li>
<li><strong>创建并插入新节点</strong>：创建新节点，根据 <code>update</code> 和 <code>rank</code> 数组信息，在每一层插入节点，设置<code>forward</code> 指针 和 <code>span</code> 跨度值</li>
<li><strong>更新其他节点的span值</strong>：对于没有触及到的层，更新 <code>update</code> 节点的 <code>span</code> 值</li>
<li><strong>设置前后指针</strong>：设置新节点的<code>backward</code>指针，指向下一个节点。如果下一个节点为空，则更新跳表的<code>tail</code>指针。</li>
<li><strong>更新跳表的长度</strong>：跳标的节点数 + 1， 返回插入的新节点指针。</li>
</ol>
<p><strong>【为什么ZSet要用跳表不用哈希表和平衡树】</strong></p>
<p>主要有三个原因：</p>
<ol>
<li><strong>内存更少</strong>：跳表相比B树可以占用更少的内存，主要取决于如何设置节点层数的概率参数</li>
<li><strong>局部性良好</strong>：跳表在执行<code>ZRANGE</code> 和 <code>ZREVRANGE</code> 等操作时，其缓存局部性表现良好，不比其他平衡树差</li>
<li><strong>实现简单</strong>：跳表的代码更简单和易于调试</li>
</ol>
<h2 id="18-redis-zset-的实现原理是什么">18. Redis Zset 的实现原理是什么？<a hidden class="anchor" aria-hidden="true" href="#18-redis-zset-的实现原理是什么">#</a></h2>
<p><code>ZSet</code> 的实现方式有两种，第一种是压缩列表 <code>Ziplist</code> / 紧凑列表 <code>Listpack</code>，另一种是跳表 <code>skiplist</code> + 哈希表 <code>HashTable</code>。主要判断条件如下：</p>
<ul>
<li>元素数量 &lt; <code>zset-max-ziplist-entries</code> zset压缩列表最大键值对个数 (默认是128)</li>
<li>每个元素大小(<code>key</code> 和 <code>value</code> 的长度) &lt; <code>zset-max-ziplist-value</code> (默认为64)</li>
</ul>
<p><strong>【ZSet压缩列表结构】</strong></p>
<p><code>ZSet</code> 的 压缩列表结构和数组很相似，用一段连续的内存空间存储数据。每个节点都占用相邻的一小段内存，节点之间通过内存偏移量而非指针记录相对位置。</p>
<p>【注意】压缩列表比传统的链表更加节省内存，但是压缩列表也有明显的缺点，它的修改成本高。</p>
<ol>
<li>倒序遍历都需要依赖上一个节点的长度<code>prevlen</code>，如果当前节点有修改，后续节点就需要修改<code>prevlen</code></li>
<li>当<code>prevlen</code> &gt; 当前节点编码类型的最大大小时，就需要改变编码类型，重新分配内存</li>
<li>后继节点重新分配内存后，其他后面的节点都会面临同样的情况，导致发生连锁更新。</li>
</ol>
<p>压缩列表的头部分别有记录了三个重要属性：</p>
<ol>
<li><strong>列表大小<code>zlbytes</code></strong>: 整段列表在内存中占用的字节数</li>
<li><strong>尾节点位置 <code>zltail</code></strong>：从队列头到最后一个节点起始位置的内存偏移量。</li>
<li><strong>节点数量 <code>zllen</code></strong>： 总共的节点个数</li>
</ol>
<p><img alt="ZSet压缩列表结构" loading="lazy" src="https://oss.swimmingliu.cn/ddb1f12b-f8f8-11ef-abc5-c858c0c1deba"></p>
<p>每个节点当中又可以化分为三个部分：</p>
<ol>
<li><strong>上一节点长度 <code>prevlen</code></strong>：用于倒序遍历时确认上一节点的位置</li>
<li><strong>节点编码 <code>encoding</code></strong>：同时记录了长度和编码类型</li>
<li><strong>数据 <code>data</code></strong>：节点中存放的数据</li>
</ol>
<p><strong>【ZSet紧凑列表结构】</strong></p>
<p>紧凑列表的头部分别有记录两个重要属性：</p>
<ol>
<li><strong>列表大小<code>size</code></strong>: 整段列表在内存中占用的字节数</li>
<li><strong>列表元素数量<code>num</code></strong>：总共的元素个数</li>
</ol>
<p><img alt="ZSet紧凑列表结构" loading="lazy" src="https://oss.swimmingliu.cn/ddc5b9a4-f8f8-11ef-b116-c858c0c1deba"></p>
<p>每个节点当中又可以化分为三个部分：</p>
<ol>
<li><strong>节点编码 <code>encoding</code></strong>：同时记录了长度和编码类型</li>
<li><strong>数据 <code>data</code></strong>：节点中存放的数据</li>
<li><strong>节点长度<code>len</code></strong>：节点编码<code>encoding</code> + 数据<code>data</code>的总长度。正向或反向遍历都依赖它完成</li>
</ol>
<p>紧凑列表相比压缩列表的优点：无需记录上一节点的长度，上一节点重新分配内存后，本身节点无需做任何修改。</p>
<p><strong>【跳表 + 哈希表】</strong></p>
<p>当<code>ZSet</code> 处理比较大的数据的时候，会选择跳表+哈希表的方式。其中，跳表的节点保存指向<code>member</code>的指针和<code>score</code>，哈希表保存<code>member</code>和<code>score</code>之间对应的关系，方便实现高效的随机查找和范围查找。</p>
<p>跳表的具体实现细节可以参考<a href="https://swimmingliu.cn/posts/job/redis-interview-questions/#17.%20Redis%20Zset%20%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F">17. Redis Zset 的实现原理是什么？</a></p>
<h2 id="19-redis-的-hash-是什么">19. Redis 的 hash 是什么？<a hidden class="anchor" aria-hidden="true" href="#19-redis-的-hash-是什么">#</a></h2>
<p><code>Hash</code> 是 Redis五大常规数据结构(<code>String</code>、<code>List</code>、<code>Hash</code>、<code>Set</code>、<code>ZSet</code>)的一种，主要用于存储key-value 键值对集合。<code>Hash</code> 一般会用来存储商品的属性、用户的信息等等。</p>
<p><strong>【Hash底层数据结构】</strong></p>
<p><code>Hash</code> 的底层数据结构要分为Redis <code>6.0</code> 和 <code>7.0</code>来看</p>
<ul>
<li>Redis <code>6.0</code>: 压缩列表 <code>zipList</code> + 哈希表 <code>HashTable</code></li>
<li>Redis <code>7.0</code>: 紧凑列表 <code>Listpack</code> + 哈希表 <code>HashTable</code></li>
</ul>
<p>当<code>Hash</code>当中的数据达到指定的阈值的时候，就会从压缩列表<code>zipList</code>/紧凑列表<code>ListPack</code> 转为哈希表<code>HashTable</code>。当满足下面两个条件的时候才能用压缩列表<code>zipList</code>/紧凑列表<code>ListPack</code></p>
<ul>
<li>哈希类型的个数 &lt; 哈希紧凑列表最大键值对个数 <code>hash-max-listpack-entries</code> (默认是512)</li>
<li>哈希的 <code>key</code> 和 <code>value</code> 的长度 &lt; <code>hash-max-ziplist-value</code> 64</li>
</ul>
<p><strong>【为什么Hash会选择压缩列表 <code>zipList</code> /紧凑列表 <code>ListPack</code>呢?】</strong></p>
<p><code>Hash</code> 结构采用压缩列表 <code>zipList</code> /紧凑列表 <code>ListPack</code>的主要目的应该是基于省内存的角度去考虑。主要有两个原因吧：</p>
<ol>
<li><strong>内存占用少</strong>： 压缩列表 <code>zipList</code> 和 紧凑列表 <code>ListPack</code> 都属于紧凑型的内存结构，没有哈希表那样存在额外的指针开销。哈希表为了维持快速查找的特性，内部才用了链表解决哈希冲突，每个哈希桶的内部都会带有指针，比较占用内存空间。另外的两个数据结构主要通过将数据存储在一块连续的内存，利用了计算机的局部性原理，从而使得内存占用最小。</li>
<li><strong>时间复杂度</strong>：哈希表的访问速率是<code>O(1)</code>，但是如果冲突比较多，最坏也会降到(<code>O(n)</code>)。因为冲突之后，就需要遍历链表或者查红黑树。但是 压缩列表 <code>zipList</code> 和 紧凑列表 <code>ListPack</code> 是连续数组存储，肯定能在<code>O(1)</code>的时间找到这个元素</li>
</ol>
<p><strong>【Redis中HashTable的结构】</strong></p>
<p><code>HashTable</code> 就是由哈希表数组实现的，查询时间复杂度为<code>O(1)</code>， 效率比较快。具体数据结构如下</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="k">typedef</span> <span class="k">struct</span> <span class="nc">dictht</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//哈希表数组
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">dictEntry</span> <span class="o">**</span><span class="n">table</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//哈希表大小
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">size</span><span class="p">;</span>  
</span></span><span class="line"><span class="cl">    <span class="c1">//哈希表大小掩码，用于计算索引值 (index = hash(key) &amp; sizemask), sizemask = size - 1
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">sizemask</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//该哈希表已有的节点数量
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">used</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span> <span class="n">dictht</span><span class="p">;</span>
</span></span></code></pre></div><p>哈希节点<code>dictEntry</code> 由三个<code>key</code>、<code>value</code> 和 下一个哈希节点指针<code>next</code>组成</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="k">typedef</span> <span class="k">struct</span> <span class="nc">dictEntry</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//键值对中的键
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">void</span> <span class="o">*</span><span class="n">key</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">    <span class="c1">// 键值对中的值
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">union</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="kt">void</span> <span class="o">*</span><span class="n">val</span><span class="p">;</span> <span class="c1">// 用于指向实际值的指针，比如存放string
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="kt">uint64_t</span> <span class="n">u64</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="kt">int64_t</span> <span class="n">s64</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="kt">double</span> <span class="n">d</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span> <span class="n">v</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//指向下一个哈希表节点，形成链表
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">struct</span> <span class="nc">dictEntry</span> <span class="o">*</span><span class="n">next</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span> <span class="n">dictEntry</span><span class="p">;</span>
</span></span></code></pre></div><p><strong>【渐进式扩容rehash】</strong></p>
<p>Redis中的hash表结构会随着数据量的增大而扩容, 将数组的大小扩张为原来的两倍。在扩张的过程当中，由于容量的变化，会导致之前的节点，移动到新的位置，这个变化的过程就是 <code>rehash</code> 实现的。</p>
<p><img alt="hashtable数组dict结构" loading="lazy" src="https://oss.swimmingliu.cn/ddec728b-f8f8-11ef-9da1-c858c0c1deba"></p>
<p><code>rehash</code> 扩容的过程可以分为一下三步:</p>
<ol>
<li><strong>增加哈希表2的空间</strong>：给哈希表2分配空间，一般是哈希表1的两倍。此时，<code>rehash</code> 索引的值<code>rehashidx</code> 从 <code>-1</code> 暂时变成 <code>0</code>。</li>
<li><strong>迁移数据</strong>：将哈希表1的数据迁移到哈希表2 （迁移的过程，一般是在对指定节点做增删改查的时候，所以叫渐进扩容，有点类似 <code>ConcurrentHashMap</code> 的扩容机制），迁移之后，<code>rehashidx + 1</code>。 迁移过程分为多次完成。</li>
<li><strong>释放原哈希表1</strong>：迁移完成之后，哈希表1的空间会被释放，并且把哈希表2设置为哈希表1。然后，哈希表2再创建一个空白的哈希表。为下一次 <code>rehash </code>做准备。</li>
</ol>
<p><strong>【注意】</strong> <code>rehash</code>的出发条件和其负载因子相关，<code>负载因子 = 已存储的哈希表节点数量 / 哈希表总容量</code> 。当达到下面的任一条件就可能触发。</p>
<ul>
<li><code>负载因子 &gt;= 1</code> ， 资源相对紧张，如果Redis没有在执行<code>bgsave</code> 和 <code>bgrewriteAOF</code> 命令 (生成<code>RDB</code>文件和<code>AOF</code>文件)，就会触发</li>
<li><code>负载因子 &gt;= 5</code>，资源非常紧张，直接触发</li>
</ul>
<p><img alt="Redis哈希表rehash过程" loading="lazy" src="https://oss.swimmingliu.cn/de057a22-f8f8-11ef-a7b8-c858c0c1deba"></p>
<h2 id="20-redis-string-类型的底层实现是什么sds">20. Redis String 类型的底层实现是什么？（SDS）<a hidden class="anchor" aria-hidden="true" href="#20-redis-string-类型的底层实现是什么sds">#</a></h2>
<p>Redis中的 <code>String</code> 类型的底层实现是简单动态字符串 <code>SDS</code>, 结合 <code>int</code> 、<code>embstr</code> 、<code>raw</code>等不同的编码方式进行优化存储。</p>
<p><strong>【简单动态字符串 <code>SDS</code> 结构】</strong></p>
<ul>
<li><strong><code>len</code>  字符数组长度</strong>：表示整个 <code>SDS</code> 字符串数组的长度，获取长度时直接返回该值 (时间复杂度 <code>o(1)</code>)</li>
<li><strong><code>alloc</code> 分配内存</strong>： 表示已分配字符数组的存储空间大小，通过<code>alloc - len</code> 可以计算剩余空间。可用于判断是否满足修改要求，解决缓冲区溢出的问题。</li>
<li><strong><code>flags</code> SDS类型</strong>: 一共有 <code>sdshdr5</code>、<code>sdshdr8</code>、<code>sdshdr16</code>、<code>sdshdr32</code>、<code>sdshdr64</code> 五种类型，后面的数字表示2的幂次方，能够灵活存储不同大小的字符串，节省内存空间</li>
<li><strong><code>buf</code> 存储数据的字符数组</strong>： 用于保存字符串，二进制数据等</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">struct</span> <span class="nf">__attribute__</span> <span class="p">((</span><span class="n">__packed__</span><span class="p">))</span> <span class="n">sdshdr64</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">uint64_t</span> <span class="n">len</span><span class="p">;</span> <span class="cm">/* used */</span>
</span></span><span class="line"><span class="cl">    <span class="kt">uint64_t</span> <span class="n">alloc</span><span class="p">;</span> <span class="cm">/* excluding the header and null terminator */</span>
</span></span><span class="line"><span class="cl">    <span class="kt">unsigned</span> <span class="kt">char</span> <span class="n">flags</span><span class="p">;</span> <span class="cm">/* 3 lsb of type, 5 unused bits */</span>
</span></span><span class="line"><span class="cl">    <span class="kt">char</span> <span class="n">buf</span><span class="p">[];</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span></code></pre></div><p><strong>【Redis底层结构 <code>redisObject</code>】</strong></p>
<p>BTW, Redis的底层结构就是<code>redisObject</code>。</p>
<p><img alt="Redis底层结构RedisObject" loading="lazy" src="https://oss.swimmingliu.cn/de1cfe07-f8f8-11ef-8efd-c858c0c1deba"></p>
<p><code>redisObject</code> 包含数据类型，编码类型和数据指针三个元素。其中编码类型，包含<code>int</code>、<code>embstr</code>、<code>raw</code> 等类型</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">struct</span> <span class="nc">redisObject</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">unsigned</span> <span class="nl">type</span><span class="p">:</span><span class="mi">4</span><span class="p">;</span>      <span class="c1">// 数据类型（字符串、哈希等）
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">unsigned</span> <span class="nl">encoding</span><span class="p">:</span><span class="mi">4</span><span class="p">;</span>  <span class="c1">// 编码类型（int、embstr、raw等）
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">int64_t</span> <span class="n">ptr</span><span class="p">;</span>          <span class="c1">// 实际的数据指针，这里直接存储整数值
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">};</span>
</span></span></code></pre></div><p><code>redisObject</code> 的具体编码类型由下面几个条件决定：</p>
<ul>
<li>如果字符串对象保存的整数值能用<code>long</code> 类型表示，该对象会把整数值存储到<code>ptr</code> 数据指针指向的<code>long</code> 结构里面 （将 <code>void*</code> 转为 <code>long</code>），并将编码设置为<code>int</code></li>
<li>如果字符串对象保存的字符串长度 &lt;=  <code>32</code> 个字节，会用 上面提到的<code>sds</code> 保存字符串，并且把对象编码设置为<code>embstr</code>。</li>
<li>如果字符串对象保存的字符串长度 &gt;  <code>32</code> 个字节，也会用上面提到的<code>sds</code> 保存字符串，并且把对象编码设置为<code>raw</code>。</li>
</ul>
<p><strong>【注意】</strong></p>
<ol>
<li>上面<code>32</code>个字节是<code>redis 2.0</code>版本，<code>redis 5.0</code> 版本是<code>44</code> 个字节</li>
<li><code>embstr</code> 和 <code>raw</code>编码区别：<code>embstr</code> 只调用一次内存分配函数，分配一块连续内存保存<code>redisObject</code>和 <code>SDS</code>。<code>raw</code> 调用两次内存分配函数，分别分配两块内存空间保存 <code>redisObject</code> 和 <code>SDS</code>。</li>
</ol>
<h2 id="21-redis-中的缓存击穿缓存穿透和缓存雪崩是什么-缓存三兄弟">21. Redis 中的缓存击穿、缓存穿透和缓存雪崩是什么？ (缓存三兄弟)<a hidden class="anchor" aria-hidden="true" href="#21-redis-中的缓存击穿缓存穿透和缓存雪崩是什么-缓存三兄弟">#</a></h2>
<table>
  <thead>
      <tr>
          <th>问题类型</th>
          <th>说明</th>
          <th>解决方案</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>缓存穿透</strong></td>
          <td>查询的数据是不存在的，数据库和缓存都没有。所有的请求都会绕过缓存，直接打到数据库上，可能会遭受恶意攻击。</td>
          <td>1.请求参数校验 2. 缓存空值 3. 布隆过滤器</td>
      </tr>
      <tr>
          <td><strong>缓存雪崩</strong></td>
          <td>大量的缓存同时失效或者Redis宕机了，导致请求直接打到数据库，可能造成系统崩溃。</td>
          <td>1. 设置随机过期时间 2.Redis 高可用集群 3.服务熔断或限流</td>
      </tr>
      <tr>
          <td><strong>缓存击穿</strong></td>
          <td>某个热点数据缓存失效，大量并发请求直接访问数据库，导致数据库压力剧增，性能下降。</td>
          <td>1. 互斥锁 2. 逻辑过期</td>
      </tr>
  </tbody>
</table>
<p><strong>【缓存穿透具体解决方案】</strong></p>
<ol>
<li>
<p><strong>请求参数校验</strong>：如果请求参数含有非法字段，则直接返回错误，避免进一步查询缓存和数据库</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-java" data-lang="java"><span class="line"><span class="cl"><span class="kd">public</span><span class="w"> </span><span class="kt">boolean</span><span class="w"> </span><span class="nf">validateRequest</span><span class="p">(</span><span class="n">String</span><span class="w"> </span><span class="n">key</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">if</span><span class="p">(</span><span class="n">key</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="kc">null</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="n">key</span><span class="p">.</span><span class="na">isEmpty</span><span class="p">())</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="kc">false</span><span class="p">;</span><span class="w">	
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></div></li>
<li>
<p><strong>缓存空值</strong>：如果查到不存在的数据，也将其存入缓存，<code>value</code> 采用 ”null“ 字符串。后续查询，直接返回给用户。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-java" data-lang="java"><span class="line"><span class="cl"><span class="kd">public</span><span class="w"> </span><span class="n">Object</span><span class="w"> </span><span class="nf">getDataWithEmptyCache</span><span class="p">(</span><span class="n">String</span><span class="w"> </span><span class="n">key</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c1">//先从缓存中获取数据</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">String</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">redisTemplate</span><span class="p">.</span><span class="na">opsForValue</span><span class="p">().</span><span class="na">get</span><span class="p">(</span><span class="n">key</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c1">//如果缓存为空</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">value</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="kc">null</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">Object</span><span class="w"> </span><span class="n">databaseValue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">queryFromDatabase</span><span class="p">(</span><span class="n">key</span><span class="p">);</span><span class="w">	</span><span class="c1">//从数据库中获取</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">databaseValue</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="kc">null</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="c1">//缓存空值</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="n">redisTemplate</span><span class="p">.</span><span class="na">opsForValue</span><span class="p">().</span><span class="na">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;null&#34;</span><span class="p">,</span><span class="w"> </span><span class="n">60</span><span class="p">,</span><span class="w"> </span><span class="n">TimeUnit</span><span class="p">.</span><span class="na">SECONDS</span><span class="p">);</span><span class="w"> 
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="kc">null</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="n">redisTemplate</span><span class="p">.</span><span class="na">opsForValue</span><span class="p">().</span><span class="na">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span><span class="w"> </span><span class="n">databaseValue</span><span class="p">,</span><span class="w"> </span><span class="n">3600</span><span class="p">,</span><span class="w"> </span><span class="n">TimeUnit</span><span class="p">.</span><span class="na">SECONDS</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">databaseValue</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="s">&#34;null&#34;</span><span class="p">.</span><span class="na">equals</span><span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="kc">null</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="n">value</span><span class="p">;</span><span class="w"> </span><span class="c1">// 如果是空值缓存，返回 null</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></div></li>
<li>
<p><strong>布隆过滤器</strong>：写入数据库时用布隆过滤器做一个标记，然后在用户请求的时候，确认缓存失效了。先通过布隆过滤器快速判断数据是否存在，如果不存在就直接返回。但是，布隆过滤器在一定程度上会出现误判。 因为可能会出现哈希冲突，导致一小部分请求穿透到数据库。
可以采用第三方工具类 <a href="https://github.com/eugenp/tutorials/tree/master/guava-modules/guava-utilities">Guava</a> 实现布隆过滤器 ）</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-java" data-lang="java"><span class="line"><span class="cl"><span class="kd">public</span><span class="w"> </span><span class="kd">class</span> <span class="nc">TestBloomFilter</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">public</span><span class="w"> </span><span class="kd">static</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="n">String</span><span class="o">[]</span><span class="w"> </span><span class="n">args</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="cm">/**
</span></span></span><span class="line"><span class="cl"><span class="cm">         * 构造:
</span></span></span><span class="line"><span class="cl"><span class="cm">         * 第二个参数: expectedInsertions 期望插入的元素数量
</span></span></span><span class="line"><span class="cl"><span class="cm">         * 第三个参数: 预测错误率 传入 0.01 表示预测正确的概率是 99%
</span></span></span><span class="line"><span class="cl"><span class="cm">         *           
</span></span></span><span class="line"><span class="cl"><span class="cm">         */</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">BloomFilter</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">&gt;</span><span class="w"> </span><span class="n">filter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BloomFilter</span><span class="p">.</span><span class="na">create</span><span class="p">(</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                </span><span class="n">Funnels</span><span class="p">.</span><span class="na">integerFunnel</span><span class="p">(),</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                </span><span class="n">500</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                </span><span class="n">0</span><span class="p">.</span><span class="na">01</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">filter</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="n">1</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">filter</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="n">2</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">filter</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="n">3</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">Assert</span><span class="p">.</span><span class="na">assertTrue</span><span class="p">(</span><span class="n">filter</span><span class="p">.</span><span class="na">mightContain</span><span class="p">(</span><span class="n">1</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">Assert</span><span class="p">.</span><span class="na">assertTrue</span><span class="p">(</span><span class="n">filter</span><span class="p">.</span><span class="na">mightContain</span><span class="p">(</span><span class="n">2</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">Assert</span><span class="p">.</span><span class="na">assertTrue</span><span class="p">(</span><span class="n">filter</span><span class="p">.</span><span class="na">mightContain</span><span class="p">(</span><span class="n">3</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">Assert</span><span class="p">.</span><span class="na">assertFalse</span><span class="p">(</span><span class="n">filter</span><span class="p">.</span><span class="na">mightContain</span><span class="p">(</span><span class="n">1000</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="cm">/*
</span></span></span><span class="line"><span class="cl"><span class="cm">    当我们设计布隆过滤器时，为预期的元素数量提供一个合理准确的值是很重要的。
</span></span></span><span class="line"><span class="cl"><span class="cm">    否则，我们的过滤器将以比期望高得多的比率返回误报。
</span></span></span><span class="line"><span class="cl"><span class="cm">    让我们看一个例子。
</span></span></span><span class="line"><span class="cl"><span class="cm">    假设我们创建了一个具有 1% 期望误报概率和预期一些元素等于 5 的过滤器，
</span></span></span><span class="line"><span class="cl"><span class="cm">    但随后我们插入了 100,000 个元素：
</span></span></span><span class="line"><span class="cl"><span class="cm">     */</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nd">@Test</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">public</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">testOverSaturatedBloomFilter</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">BloomFilter</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">&gt;</span><span class="w"> </span><span class="n">filter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BloomFilter</span><span class="p">.</span><span class="na">create</span><span class="p">(</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                </span><span class="n">Funnels</span><span class="p">.</span><span class="na">integerFunnel</span><span class="p">(),</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                </span><span class="n">5</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                </span><span class="n">0</span><span class="p">.</span><span class="na">01</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">IntStream</span><span class="p">.</span><span class="na">range</span><span class="p">(</span><span class="n">0</span><span class="p">,</span><span class="w"> </span><span class="n">100_000</span><span class="p">).</span><span class="na">forEach</span><span class="p">(</span><span class="n">filter</span><span class="p">::</span><span class="n">put</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">Assert</span><span class="p">.</span><span class="na">assertTrue</span><span class="p">(</span><span class="n">filter</span><span class="p">.</span><span class="na">mightContain</span><span class="p">(</span><span class="n">1</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">Assert</span><span class="p">.</span><span class="na">assertTrue</span><span class="p">(</span><span class="n">filter</span><span class="p">.</span><span class="na">mightContain</span><span class="p">(</span><span class="n">2</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">Assert</span><span class="p">.</span><span class="na">assertTrue</span><span class="p">(</span><span class="n">filter</span><span class="p">.</span><span class="na">mightContain</span><span class="p">(</span><span class="n">3</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">Assert</span><span class="p">.</span><span class="na">assertFalse</span><span class="p">(</span><span class="n">filter</span><span class="p">.</span><span class="na">mightContain</span><span class="p">(</span><span class="n">1000000</span><span class="p">));</span><span class="w"> </span><span class="c1">//测试不通过</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></div></li>
</ol>
<p><img alt="布隆过滤器示意图" loading="lazy" src="https://oss.swimmingliu.cn/de2d30fc-f8f8-11ef-b879-c858c0c1deba"></p>
<p><strong>【缓存雪崩具体解决方案】</strong></p>
<p>缓存雪崩要分为两种不同的情况来解决：大量key同时过期 和 Redis宕机</p>
<p><strong>【大量key同时过期】</strong></p>
<ol>
<li><strong>设置随机的过期时间</strong>：写入缓存的时候，给其在基础时间上 + 一个随机的过期时间</li>
<li><strong>互斥锁</strong>： 保证同一时间只有一个请求来构建缓存</li>
<li><strong>后台更新缓存</strong>：后台采用<code>Scheduled</code> 的方式检查缓存是否失效，如果失效了，就查询数据库更新缓存。</li>
</ol>
<p><strong>【Redis宕机】</strong></p>
<ol>
<li>
<p><strong>服务熔断或者限流机制</strong>：暂定服务对于缓存服务的访问，直接返回错误。或者启用限流规则，只允许商家请求发送数据库进行处理，过多的请求就会拒接。一般会使用<code>Hystrix</code> 或者 <code>Sentinel</code> 实现熔断或者限流</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-java" data-lang="java"><span class="line"><span class="cl"><span class="nd">@HystrixCommand</span><span class="p">(</span><span class="n">fallbackMethod</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&#34;fallbackMethod&#34;</span><span class="p">)</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kd">public</span><span class="w"> </span><span class="n">String</span><span class="w"> </span><span class="nf">getDataFromCache</span><span class="p">(</span><span class="n">String</span><span class="w"> </span><span class="n">key</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c1">// 从 Redis 获取数据</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">redisTemplate</span><span class="p">.</span><span class="na">opsForValue</span><span class="p">().</span><span class="na">get</span><span class="p">(</span><span class="n">key</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kd">public</span><span class="w"> </span><span class="n">String</span><span class="w"> </span><span class="nf">fallbackMethod</span><span class="p">(</span><span class="n">String</span><span class="w"> </span><span class="n">key</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="s">&#34;服务繁忙，请稍后重试！&#34;</span><span class="p">;</span><span class="w"> </span><span class="c1">// 熔断处理逻辑</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></div></li>
<li>
<p><strong>构建Redis缓存高可用集群</strong>: 如果单个缓存服务节点发生故障自动迁移访问流量到另外一个节点.</p>
</li>
</ol>
<p><strong>【缓存击穿具体解决方案】</strong></p>
<ol>
<li>
<p><strong>互斥锁</strong>：同一时间只允许一个业务线程更新缓存。未获取互斥锁的请求，可以等待锁释放后读取缓存，或者返回空值/默认值。 (对数据一致性要求比较高)</p>
</li>
<li>
<p><strong>逻辑过期</strong>：不给缓存设置过期时间，<code>value</code> 采用 <code>hash</code> 的方式，设置一个逻辑过期时间。每次判断数据是否过期，未过期直接返回数据。如果已经过期了，则获取互斥锁重建缓存，然后释放锁。如果获取互斥锁失败，则返回已过期缓存数据。</p>
</li>
<li>
<p><strong>服务熔断或者限流机制</strong></p>
</li>
</ol>
<h2 id="22redis-数据过期后的删除策略是什么">22.Redis 数据过期后的删除策略是什么？<a hidden class="anchor" aria-hidden="true" href="#22redis-数据过期后的删除策略是什么">#</a></h2>
<p><strong>【Redis过期删除策略】</strong></p>
<p>Redis采用的是 <code>定期删除</code> + <code>惰性删除</code> 的结合方式</p>
<table>
  <thead>
      <tr>
          <th>策略</th>
          <th>实现方式</th>
          <th>优缺点</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>定期删除</strong></td>
          <td>Redis每个一段时间 (默认为<code>100ms</code> 随机检查 一定数量的键，非全部key)，过期则删除</td>
          <td>可以减少内存占用, 但是对CPU有一定消耗，且不能保证及时删除所有过期键</td>
      </tr>
      <tr>
          <td><strong>惰性删除</strong></td>
          <td>当客户端访问一个key时，Redis会检查是否过期，若过期则立即删除</td>
          <td>对CPU友好，大量过期键未被访问时仍占用内存</td>
      </tr>
  </tbody>
</table>
<p><strong>【定期删除细节】</strong></p>
<ol>
<li>Redis会周期性执行过期key检查，默认每<code>100ms</code> 执行一次</li>
<li>每次检查会随机抽取部分key，默认每次 <code>20</code> 个， 判断是否过期</li>
<li>为了避免过多的CPU占用，Redis限制检查的执行时间 (默认为执行时间的<code>25%</code>，也就是<code>25ms</code>) 和 过期键的比例 (默认只检查 <code>10% </code>)</li>
<li>如果过期间比例超过限制，则会重复检查以提高清理效率</li>
</ol>
<p><strong>【为什么Redis删除不直接吧所有过期key都删除了？】</strong></p>
<ul>
<li><strong>定期删除不能除所有过期key原因</strong>: 如果一次性清理所有过期间,可能会导致Redis长时间阻塞，影响性能。随机抽样和时间限制的方式能在清理内存和性能之间取得平衡。</li>
<li><strong>惰性删除不能删除所有过期key原因</strong>：惰性删除旨在访问key的时候触发，如果没有被访问到，就可能一致存在，无法清理。</li>
</ul>
<p><strong>【如何优化大量key集中过期的情况 - 缓存雪崩】</strong></p>
<ol>
<li>设置随机过期时间：设置过期时间的时候，加上一个随机值</li>
<li>开启<code>lazy free</code> 机制： 配置 <code>lazyfree-lazy-expire</code>， 让过期的key删除操作由后台线程异步执行，减少主线程的压力</li>
</ol>
<h2 id="23-如何解决-redis-中的热点-key-问题">23. 如何解决 Redis 中的热点 key 问题？<a hidden class="anchor" aria-hidden="true" href="#23-如何解决-redis-中的热点-key-问题">#</a></h2>
<p>热点 <code>key</code> 是指访问频率显著高于其他 <code>key</code> 的键，通常表现为以下几种情况：</p>
<table>
  <thead>
      <tr>
          <th>类别</th>
          <th>特性</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong><code>QPS</code> 集中</strong></td>
          <td>某个<code>key</code> 的<code>QPS</code> (每秒请求量) 占Redis总QPS的较大比例</td>
      </tr>
      <tr>
          <td><strong>带宽集中</strong></td>
          <td>某个<code>key</code> 的数据量较大(比如<code>1MB</code> 以上的<code>hash</code> 数据)，被频繁请求</td>
      </tr>
      <tr>
          <td><strong>CPU消耗集中</strong></td>
          <td>某个<code>key</code>的复杂操作(比如<code>ZRANGE</code>查询较大的<code>ZSet</code>数据) 占用Redis过多CPU时间</td>
      </tr>
  </tbody>
</table>
<p>热点<code>key</code> 问题就是某个瞬间，大量的请求集中访问Redis里的同一个固定<code>key</code>，假如热点<code>key</code>过期，可能会导致缓存击穿，让大量的请求直接打到数据库里面。像<code>热点新闻</code>、<code>热点评论</code>、<code>明星直播</code> 这种读多写少的场景，就很容易出现热点<code>key</code> 问题。因为Redis的单节点查询性能一般在 <code>2w QPS</code>， 一般超过 这个数值，可能就会宕机。</p>
<p><strong>【热点<code>key</code>的危害】</strong></p>
<ul>
<li><strong>消耗CPU和带宽资源</strong>： 热点 <code>key</code> 可能占用Redis大部分资源，影响其他请求的处理时间</li>
<li><strong>Redis宕机风险</strong>: 如果超过Redis所能承载的最大<code>QPS</code>， 可能会导致Redis宕机。然后大量的请求转发到后端数据库，导致数据库崩溃。</li>
</ul>
<p><strong>【如何发现热点<code>key</code>】</strong></p>
<ol>
<li><strong>根据业务经验判断</strong>：比如像<code>明星八卦爆料</code>、<code>重大新闻</code>、<code>热点评论</code>都会能会导致热点<code>key</code>。 好处是不需要消耗什么成本，坏处是无法预防突发情况。</li>
<li><strong>Redis进行集群监控</strong>： 查看哪个Redis出现了 <code>QPS</code> 倾斜，出现<code>QPS</code>倾斜的实例有很大概率存在热点<code>key</code></li>
<li><strong><code>hotkey</code> 监控</strong>：命令行执行<code>redis-cli</code> 的时候添加<code>--hotkeys</code> 参数，它是基于<code>scan + object freq</code> 扫描目标出现频率时间的。但是需要设置<code>maxmemory-policy</code> 参数，来采用不同的淘汰手段：
<ul>
<li><code>volatile-lfu (least frequently used)</code>： 淘汰已经过期数据集中最不常用的数据</li>
<li><code>allkeys-lfu</code>：当内存不足的时候，移除最不常用的<code>key</code></li>
</ul>
</li>
<li><strong><code>monitor</code> 命令</strong>： 集合一些Redis的日志和相关分析工具进行统计, 非常消耗性能, 单客户端会消耗 <code>50%</code> 的性能</li>
<li><strong>代理层收集</strong>：利用有些服务在请求Redis前会先请求代理服务的特点, 在代理层统一收集Redis热<code>key</code>数据。比如采用 <a href="https://gitee.com/jd-platform-opensource/hotkey">京东的 <code>JD-hotkey</code></a>、<a href="https://tech.youzan.com/tmc/">有赞透明多级缓存解决方案(TMC)</a></li>
<li><strong>客户端收集</strong>：在操作Redis前添加统计每个<code>key</code>的查询频次，将统计数据发送到聚合计算平台计算，之后查看结果。对性能消耗较低，但是成本比较大，需要介入聚合计算平台。</li>
</ol>
<p><strong>【如何解决热点<code>key</code>】</strong></p>
<ol>
<li>
<p><strong>多级缓存</strong>：结合使用一级缓存和二级缓存。一级缓存就是应用程序的本地缓存，比如JVM内存中的缓存，可采用<a href="https://github.com/ben-manes/caffeine">Caffeine</a> 、<a href="https://github.com/alibaba/jetcache">阿里巴巴jetcache</a> )。 二级缓存是Redis缓存，当以及缓存中不存在的时候，再访问二级缓存。</p>
<p>针对热点<code>key</code>请求, 本地一级缓存可以将同一个<code>key</code>的大量请求，根据网络层负载均衡到不同的机器节点上，避免全部打到单个Redis节点的情况，减少网络交互。但是需要耗费更多的经历去保证分布式缓存一致性，会增加系统复杂度。</p>
</li>
</ol>
<p><img alt="多级缓存解决热点key" loading="lazy" src="https://oss.swimmingliu.cn/40d261e4-f9c8-11ef-a8a5-c858c0c1deba"></p>
<ol start="2">
<li><strong>热点key备份</strong>：在多个Redis节点上备份热<code>key</code>，避免固定<code>key</code>总是访问同一个Redis节点。通过初始化时为<code>key</code> 拼接 <code>0~2n</code> (<code>n</code>为集群数量) 之间的随机数，让其散落在各个姐电商。若有热点<code>key</code>请求的时候，随机选一个备份的节点进行取值。可以有效减轻单个Redis节点的负担。</li>
<li><strong>热点key拆分</strong>：将热点<code>key</code>拆分为多个带后缀名的<code>key</code>，让其分散存储在多个实例当中。客户端请求的时候按照规则计算出固定<code>key</code>，然后请求对应的Redis节点。比如“某音热搜某明星离婚”。可以拆分为多个带编号后缀的<code>key</code>存储在不同的节点，用户查询时根据用户<code>id</code> 算出要访问的对应节点。虽然用户只能看到一部分数据，等待热点降温后再汇总数据，挑选优质内容重新推送给未收到的用户。</li>
</ol>
<p><strong>【注意】</strong> 热点key备份和热点key拆分的区别在于，热点key备份是同一份数据全量复制到其他节点，热点key拆分是把一份数据拆分成多份。</p>
<ol start="4">
<li><strong>Redis集群 + 读写分离</strong>: 增加Redis从节点, 分散读请求压力。然后利用集群，可以将热点<code>key</code>拆分或者备份到不同的Redis实例上。</li>
<li><strong>限流和降级</strong>：采用限流策略，减少对Redis的请求，在必要的时候返回降级的数据或者空值。</li>
</ol>
<h2 id="24-redis-中的-big-key-问题是什么如何解决">24. Redis 中的 Big Key 问题是什么？如何解决？<a hidden class="anchor" aria-hidden="true" href="#24-redis-中的-big-key-问题是什么如何解决">#</a></h2>
<p>Redis当中的 <code>Big Key</code> (也可以叫<code>big memory key</code>)是指某个<code>key</code> 对应的<code>value</code>数据量过大，比如包含大量元素的<code>List</code>、<code>Hash</code>、<code>Set</code>、<code>ZSet</code> 或超长字符串), 可能会导致性能瓶颈和系统不稳定。 一般来说，<code>String</code> 类型的<code>value</code> 超过 <code>1MB</code> ，或者符合类型当中的元素超过<code>5000</code>个，就算<code>big key</code>。</p>
<p><strong>【Big Key 典型场景】</strong></p>
<ul>
<li><strong>String</strong>: 存储超大JSON文本、图片base64数据等</li>
<li><strong>Hash</strong>：存储海量的字段，比如用户的行为记录</li>
<li><strong>List / Set</strong>：存储百万个元素</li>
<li><strong>ZSet</strong>： 包含大量的排序元素</li>
</ul>
<p><strong>【Big Key 导致的问题】</strong></p>
<ul>
<li><strong>性能问题</strong>：Redis是单线程处理机制，在处理<code>big key</code>的时候，需要更长的时间，阻塞工作流程，没法儿处理后面的命令。如果处理的时间过长，会导致客户端长时间未收到响应。另外，<code>big key</code> 占用的带宽过高，传输时间比较长，也容易导致阻塞。</li>
<li><strong>内存问题</strong>：<code>big key</code> 会导致Redis内存变得很大，增加内存碎片化风险。单次大对象内存分配失败，可能导致整个Redis服务崩溃。集群模式下，会出现数据和查询倾斜的情况，<code>big key</code> 的 Redis节点会占用较多的内存</li>
<li><strong>持久化问题</strong>：如果<code>AOF</code>写回策略为<code>always</code>，也就是说主线程执行完指令之后，把对应数据写入<code>AOF</code>文件后，直接 <code>fsync</code> 写入磁盘操作。如果是一个大<code>key</code>， 阻塞的时间可能比较就，同步到硬盘的过程很耗时。</li>
</ul>
<p><strong>【如何找Big Key】</strong></p>
<ul>
<li>
<p>内置<code>--bigkeys</code>： 采用内置的<code>--bigkeys</code>命令，基于<code>scan</code> 查找所有的<code>big key</code></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">redis-cli --bigkeys
</span></span></code></pre></div></li>
<li>
<p>使用第三方工具</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">https://github.com/sripathikrishnan/redis-rdb-tools
</span></span><span class="line"><span class="cl">https://github.com/weiyanwei412/rdb_bigkeys
</span></span></code></pre></div></li>
</ul>
<p><strong>【如何处理Big Key问题】</strong></p>
<p><code>Big Key</code> 问题可以从下面说三个层面来解决：</p>
<ul>
<li>
<p><strong>开发层面</strong>：将数据压缩后再存; 将大JSON对象拆分为多个小字段; 将数据保存为更合理的数据结构 (利用<code>hash</code>替代大字符串); 避免会造成阻塞的命令</p>
</li>
<li>
<p><strong>业务层面</strong>：调整存储策略，只存储必要的数据 (比如用户的收货地址等不常用信息不存储，只存储用户ID、姓名、头像等); 优化业务逻辑，使用更小的数据来满足业务要求; 规划好数据的生命</p>
</li>
<li>
<p><strong>架构层面</strong>：采用Redis集群的方式进行Redis部署，然后将大Key拆分散落到不同的服务器上面, 加快响应速度</p>
</li>
</ul>


  </div>



  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://swimmingliu.cn/tags/java/">Java</a></li>
      <li><a href="https://swimmingliu.cn/tags/redis/">Redis</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://swimmingliu.cn/posts/job/personal-interview-hot-question/">
    <span class="title">« Prev</span>
    <br>
    <span>个人简历常问问题</span>
  </a>
  <a class="next" href="https://swimmingliu.cn/posts/job/java-set-interview-questions/">
    <span class="title">Next »</span>
    <br>
    <span>Java集合面试题笔记</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2023-2025 <a href="https://swimmingliu.cn/">SwimmingLiu&#39;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
    <span>
        <a href="https://beian.miit.gov.cn/">浙ICP备2024056260号</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
